Using TensorFlow backend.
[2019-03-18 13:09:58,120] A3C_AGENT_MAIN INFO:Namespace(action_repeat_n=1, action_space='part3_v1', activation='linear', agent_num=5, check_args_only=False, clip_norm=5.0, debug_log_prob=0.0005, decay_steps=1000000, dropout_prob=0.0, end_e=0.0, env='Part3-NA-Pit-Train-v1', eval_act_func='part3_v2', eval_env_res_max_keep=20, eval_epi_num=1, eval_freq=100000, forecast_dim=0, gamma=0.99, h_decay_bounds=[], h_regu_frac=[0.0], init_e=0.0, isNoisyNet=True, isNoisyNetEval_rmNoise=True, is_greedy_policy=False, is_learning_rate_decay_staircase=False, is_warm_start=False, job_mode='Train', learning_rate=0.001, learning_rate_decay_rate=1.0, learning_rate_decay_steps=100000, max_interactions=5000000, metric_func='part3_v1', model_dir='None', model_param=[19, 1], model_type='nn', num_threads=16, output='./Part3-NA-Pit-Train-v1-res1', p_loss_frac=1.0, raw_state_prcs_func='cslDx_1', reward_func='part3_v2', rmsprop_decay=0.99, rmsprop_epsil=1e-10, rmsprop_momet=0.0, rwd_e_para=7.0, rwd_p_para=1.0, save_freq=500000, save_max_to_keep=5, save_scope='all', sharedNet_type='Dense', state_dim=17, test_env=['Part3-NA-Pit-Test-v1', 'Part3-NA-Pit-Test-v2', 'Part3-NA-Pit-Test-v3', 'Part3-NA-Pit-Test-v4'], test_mode='Multiple', train_act_func='part3_v3', train_freq=5, v_loss_frac=0.5, violation_penalty_scl=50.0, weight_initer='glorot_uniform', window_len=21)
[2019-03-18 13:09:58,120] A3C_AGENT_MAIN INFO:Start compiling...
2019-03-18 13:09:58.152750: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[2019-03-18 13:10:12,967] A3C_AGENT_MAIN INFO:Start the learning...
[2019-03-18 13:10:12,967] A3C_AGENT_MAIN INFO:Prepare the evaluation environments ['Part3-NA-Pit-Train-v1', 'Part3-NA-Pit-Test-v1', 'Part3-NA-Pit-Test-v2', 'Part3-NA-Pit-Test-v3', 'Part3-NA-Pit-Test-v4'] ...
[2019-03-18 13:10:12,977] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation worker starts!
[2019-03-18 13:10:12,979] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation worker starts!
[2019-03-18 13:10:12,981] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation worker starts!
[2019-03-18 13:10:12,986] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation worker starts!
[2019-03-18 13:10:12,989] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation worker starts!
[2019-03-18 13:10:12,989] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-18 13:10:12,990] A3C_AGENT_WORKER-Thread-2 INFO:Local worker starts!
[2019-03-18 13:10:13,041] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-18 13:10:13,041] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/13/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run1
[2019-03-18 13:10:13,991] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-18 13:10:13,993] A3C_AGENT_WORKER-Thread-3 INFO:Local worker starts!
[2019-03-18 13:10:14,079] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-18 13:10:14,079] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/13/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run1
[2019-03-18 13:10:14,221] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-18 13:10:14,222] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-18 13:10:14,222] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-18 13:10:14,222] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-18 13:10:14,223] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-18 13:10:14,223] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-18 13:10:14,224] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-18 13:10:14,224] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-18 13:10:14,224] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-18 13:10:14,224] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-18 13:10:14,225] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-18 13:10:14,228] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/13/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run1
[2019-03-18 13:10:14,237] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/13/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run1
[2019-03-18 13:10:14,238] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/13/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run1
[2019-03-18 13:10:14,238] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/13/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run1
[2019-03-18 13:10:14,258] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/13/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run1
[2019-03-18 13:10:14,993] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-18 13:10:14,993] A3C_AGENT_WORKER-Thread-9 INFO:Local worker starts!
[2019-03-18 13:10:15,085] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-18 13:10:15,086] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/13/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run1
[2019-03-18 13:10:15,994] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-18 13:10:15,996] A3C_AGENT_WORKER-Thread-10 INFO:Local worker starts!
[2019-03-18 13:10:16,076] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-18 13:10:16,077] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/13/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run1
[2019-03-18 13:10:16,997] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-18 13:10:16,998] A3C_AGENT_WORKER-Thread-11 INFO:Local worker starts!
[2019-03-18 13:10:17,077] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-18 13:10:17,078] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/13/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run1
[2019-03-18 13:10:17,999] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-18 13:10:18,004] A3C_AGENT_WORKER-Thread-12 INFO:Local worker starts!
[2019-03-18 13:10:18,062] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-18 13:10:18,064] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/13/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run1
[2019-03-18 13:10:19,003] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-18 13:10:19,007] A3C_AGENT_WORKER-Thread-13 INFO:Local worker starts!
[2019-03-18 13:10:19,100] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-18 13:10:19,102] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/13/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run1
[2019-03-18 13:10:20,008] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-18 13:10:20,016] A3C_AGENT_WORKER-Thread-14 INFO:Local worker starts!
[2019-03-18 13:10:20,131] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-18 13:10:20,133] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/13/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run1
[2019-03-18 13:10:20,385] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-18 13:10:20,385] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [15.6, 69.0, 1.0, 2.0, 0.9729605337332167, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769667364, 1057066.925366973, 1057066.925366973, 169424.5015488581]
[2019-03-18 13:10:20,386] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-18 13:10:20,388] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.15636672 0.30231154 0.2841202  0.09945469 0.15774685], sampled 0.0025427386943365216
[2019-03-18 13:10:20,389] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1057066.925366973 W.
[2019-03-18 13:10:21,013] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-18 13:10:21,019] A3C_AGENT_WORKER-Thread-15 INFO:Local worker starts!
[2019-03-18 13:10:21,076] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-18 13:10:21,077] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/13/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run1
[2019-03-18 13:10:22,017] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-18 13:10:22,018] A3C_AGENT_WORKER-Thread-16 INFO:Local worker starts!
[2019-03-18 13:10:22,083] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-18 13:10:22,083] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/13/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run1
[2019-03-18 13:10:23,019] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-18 13:10:23,020] A3C_AGENT_WORKER-Thread-17 INFO:Local worker starts!
[2019-03-18 13:10:23,097] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-18 13:10:23,098] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/13/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run1
[2019-03-18 13:10:24,021] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-18 13:10:24,022] A3C_AGENT_WORKER-Thread-18 INFO:Local worker starts!
[2019-03-18 13:10:24,110] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-18 13:10:24,111] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/13/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run1
[2019-03-18 13:10:24,369] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-18 13:10:24,369] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.99781933666667, 90.45809224666667, 1.0, 2.0, 0.7313061589499477, 1.0, 2.0, 0.7313061589499477, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 127.9014693543214, 1659121.836847062, 1659121.836847062, 283317.8731189138]
[2019-03-18 13:10:24,371] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-18 13:10:24,374] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.14865017 0.12748274 0.49570012 0.06359649 0.16457054], sampled 0.28020398286542014
[2019-03-18 13:10:24,376] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Action function: raw action [0, 0, 1, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 1659121.836847062 W.
[2019-03-18 13:10:25,023] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-18 13:10:25,024] A3C_AGENT_WORKER-Thread-19 INFO:Local worker starts!
[2019-03-18 13:10:25,118] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-18 13:10:25,119] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/13/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run1
[2019-03-18 13:10:26,026] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-18 13:10:26,031] A3C_AGENT_WORKER-Thread-20 INFO:Local worker starts!
[2019-03-18 13:10:26,085] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-18 13:10:26,086] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/13/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run1
[2019-03-18 13:10:27,029] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-18 13:10:27,030] A3C_AGENT_WORKER-Thread-21 INFO:Local worker starts!
[2019-03-18 13:10:27,092] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-18 13:10:27,093] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/13/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run1
[2019-03-18 13:10:28,031] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-18 13:10:28,032] A3C_AGENT_WORKER-Thread-22 INFO:Local worker starts!
[2019-03-18 13:10:28,104] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-18 13:10:28,104] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/13/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run1
[2019-03-18 13:10:31,348] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-18 13:10:31,350] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.98076811333334, 76.42439052333334, 1.0, 2.0, 0.799827640556419, 1.0, 2.0, 0.6435639855613591, 1.0, 2.0, 0.9843934892199467, 6.911199999999999, 6.9112, 134.6345170175134, 2172007.420427124, 2172007.420427124, 435667.1349649123]
[2019-03-18 13:10:31,351] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-18 13:10:31,354] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.07517383 0.04266903 0.615568   0.14441971 0.12216954], sampled 0.11749319716544271
[2019-03-18 13:10:31,354] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 0, 1] for the demand 2172007.420427124 W.
[2019-03-18 13:10:34,996] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-18 13:10:34,998] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.7, 84.0, 1.0, 2.0, 0.8419074682828667, 1.0, 2.0, 0.8419074682828667, 0.0, 1.0, 0.0, 6.9112, 6.9112, 126.6490080298893, 1917928.601818944, 1917928.601818944, 338532.7081272105]
[2019-03-18 13:10:34,999] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-18 13:10:35,001] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.10418876 0.05619079 0.6198102  0.04124522 0.178565  ], sampled 0.6616111645275564
[2019-03-18 13:10:35,002] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Action function: raw action [0, 0, 1, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 1917928.601818944 W.
[2019-03-18 13:11:15,355] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-18 13:11:15,357] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.38333333333333, 80.66666666666666, 1.0, 2.0, 0.8619969496093199, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9378115129905081, 6.953864692497669, 6.9112, 109.763990472973, 1531046.50910564, 1511377.712122084, 313230.4917848902]
[2019-03-18 13:11:15,357] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-18 13:11:15,360] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.08443628 0.09856564 0.5475276  0.12246685 0.1470036 ], sampled 0.5299981673139846
[2019-03-18 13:11:21,803] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-18 13:11:21,803] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.89267093, 94.2106648, 1.0, 2.0, 0.6026526085073876, 1.0, 1.0, 0.6026526085073876, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 116.5874894908994, 1354091.012033694, 1354091.012033694, 241352.5732429198]
[2019-03-18 13:11:21,803] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-18 13:11:21,805] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.19470178 0.25589433 0.21224459 0.15130009 0.18585931], sampled 0.6254169674886217
[2019-03-18 13:11:46,854] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-18 13:11:46,856] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [10.62379463666667, 89.49660754333334, 1.0, 2.0, 0.3514948915978282, 0.0, 1.0, 0.0, 1.0, 2.0, 0.6561639585125933, 6.9112, 6.9112, 95.55338769695034, 763572.3724182216, 763572.3724182216, 159526.4595983045]
[2019-03-18 13:11:46,858] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-18 13:11:46,861] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.07511973 0.18709086 0.49564868 0.07107406 0.17106673], sampled 0.1166068981398265
[2019-03-18 13:12:06,286] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-18 13:12:06,286] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.560805705, 88.07556866499999, 1.0, 2.0, 0.7900990560883208, 1.0, 2.0, 0.7900990560883208, 0.0, 2.0, 0.0, 6.9112, 6.9112, 130.1036056166641, 1803054.352036759, 1803054.352036759, 310824.952469274]
[2019-03-18 13:12:06,287] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-18 13:12:06,291] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.147658   0.04705202 0.62292206 0.06824786 0.11412007], sampled 0.7860020387207282
[2019-03-18 13:12:06,291] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [0, 0, 1, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 1803054.352036759 W.
[2019-03-18 13:12:12,849] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-18 13:12:12,850] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.10550859, 69.41202995, 1.0, 2.0, 0.8017861365846685, 1.0, 2.0, 0.8017861365846685, 0.0, 2.0, 0.0, 6.9112, 6.9112, 129.7790135477073, 1830225.27980671, 1830225.27980671, 315428.5057444189]
[2019-03-18 13:12:12,850] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-18 13:12:12,852] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.16795264 0.16022578 0.4669252  0.04773448 0.1571619 ], sampled 0.23239664744995048
[2019-03-18 13:12:12,852] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 1830225.27980671 W.
[2019-03-18 13:12:21,974] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 3549.7466 2060895290.6113 709.0000
[2019-03-18 13:12:22,504] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 6360.0481 3858181290.6681 4708.0000
[2019-03-18 13:12:22,518] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 6558.1584 3935221204.1895 4774.0000
[2019-03-18 13:12:22,668] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 6407.5417 3744994862.7933 5006.0000
[2019-03-18 13:12:22,693] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 6459.9143 3773855385.4435 4705.0000
[2019-03-18 13:12:23,710] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 0, evaluation results [0.0, 3549.7465825581553, 2060895290.6112912, 709.0, 6407.5416956278805, 3744994862.7933016, 5006.0, 6558.1584060952355, 3935221204.1895256, 4774.0, 6459.914319462515, 3773855385.4434843, 4705.0, 6360.048109114069, 3858181290.66808, 4708.0]
[2019-03-18 13:12:26,884] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.07739839 0.25407526 0.3194699  0.2269452  0.12211127], sum to 1.0000
[2019-03-18 13:12:26,897] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3976
[2019-03-18 13:12:26,991] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.5, 100.0, 1.0, 1.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.340360763737985, 6.911199999999999, 6.9112, 77.32846344354104, 391990.3129621024, 391990.3129621026, 151921.8314490964], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 23400.0000, 
sim time next is 24000.0000, 
raw observation next is [17.66666666666667, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3535634919073218, 6.9112, 6.9112, 77.32846344354104, 406905.1405526898, 406905.1405526898, 153801.9752679597], 
processed observation next is [1.0, 0.2608695652173913, 0.4393939393939396, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.07651927415331684, 0.0, 0.0, 0.5084288129206541, 0.15070560761210733, 0.15070560761210733, 0.3751267689462432], 
reward next is 0.3779, 
noisyNet noise sample is [array([0.62511605], dtype=float32), 1.5307345]. 
=============================================
[2019-03-18 13:12:27,005] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[2.4648402]
 [2.4216845]
 [2.6399302]
 [2.7975008]
 [2.8269556]], R is [[3.04227376]
 [3.01185107]
 [2.98173261]
 [2.95191526]
 [2.92239618]].
[2019-03-18 13:12:46,064] A3C_AGENT_WORKER-Thread-2 INFO:Local step 500, global step 7933: loss 0.0430
[2019-03-18 13:12:46,117] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 500, global step 7935: learning rate 0.0010
[2019-03-18 13:12:46,128] A3C_AGENT_WORKER-Thread-11 INFO:Local step 500, global step 7945: loss 0.0622
[2019-03-18 13:12:46,130] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 500, global step 7946: learning rate 0.0010
[2019-03-18 13:12:46,157] A3C_AGENT_WORKER-Thread-20 INFO:Local step 500, global step 7960: loss 0.0453
[2019-03-18 13:12:46,162] A3C_AGENT_WORKER-Thread-10 INFO:Local step 500, global step 7961: loss 0.0128
[2019-03-18 13:12:46,163] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 500, global step 7961: learning rate 0.0010
[2019-03-18 13:12:46,164] A3C_AGENT_WORKER-Thread-16 INFO:Local step 500, global step 7962: loss 0.0245
[2019-03-18 13:12:46,167] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 500, global step 7962: learning rate 0.0010
[2019-03-18 13:12:46,171] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 500, global step 7962: learning rate 0.0010
[2019-03-18 13:12:46,189] A3C_AGENT_WORKER-Thread-9 INFO:Local step 500, global step 7968: loss 0.0417
[2019-03-18 13:12:46,193] A3C_AGENT_WORKER-Thread-18 INFO:Local step 500, global step 7970: loss 0.0127
[2019-03-18 13:12:46,195] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 500, global step 7970: learning rate 0.0010
[2019-03-18 13:12:46,196] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 500, global step 7971: learning rate 0.0010
[2019-03-18 13:12:46,214] A3C_AGENT_WORKER-Thread-13 INFO:Local step 500, global step 7979: loss 0.0043
[2019-03-18 13:12:46,215] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 500, global step 7979: learning rate 0.0010
[2019-03-18 13:12:46,237] A3C_AGENT_WORKER-Thread-21 INFO:Local step 500, global step 7984: loss 0.0013
[2019-03-18 13:12:46,244] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 500, global step 7986: learning rate 0.0010
[2019-03-18 13:12:46,250] A3C_AGENT_WORKER-Thread-3 INFO:Local step 500, global step 7986: loss 0.0003
[2019-03-18 13:12:46,252] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 500, global step 7987: learning rate 0.0010
[2019-03-18 13:12:46,258] A3C_AGENT_WORKER-Thread-14 INFO:Local step 500, global step 7990: loss 0.0101
[2019-03-18 13:12:46,260] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 500, global step 7991: learning rate 0.0010
[2019-03-18 13:12:46,299] A3C_AGENT_WORKER-Thread-19 INFO:Local step 500, global step 8006: loss 0.0072
[2019-03-18 13:12:46,302] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 500, global step 8006: learning rate 0.0010
[2019-03-18 13:12:46,304] A3C_AGENT_WORKER-Thread-15 INFO:Local step 500, global step 8007: loss 0.0298
[2019-03-18 13:12:46,311] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 500, global step 8008: learning rate 0.0010
[2019-03-18 13:12:46,346] A3C_AGENT_WORKER-Thread-12 INFO:Local step 500, global step 8024: loss 0.0529
[2019-03-18 13:12:46,351] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 500, global step 8024: learning rate 0.0010
[2019-03-18 13:12:46,432] A3C_AGENT_WORKER-Thread-22 INFO:Local step 500, global step 8057: loss 0.1629
[2019-03-18 13:12:46,434] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 500, global step 8058: learning rate 0.0010
[2019-03-18 13:12:46,454] A3C_AGENT_WORKER-Thread-17 INFO:Local step 500, global step 8063: loss 0.1735
[2019-03-18 13:12:46,456] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 500, global step 8063: learning rate 0.0010
[2019-03-18 13:12:52,234] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.2150405e-11 1.9663649e-13 1.0000000e+00 6.4337841e-11 4.2376618e-15], sum to 1.0000
[2019-03-18 13:12:52,234] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6445
[2019-03-18 13:12:52,324] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.16666666666667, 65.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 323455.697139952, 323455.6971399517, 114712.6313820075], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 382200.0000, 
sim time next is 382800.0000, 
raw observation next is [17.33333333333334, 62.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 320907.2378513027, 320907.2378513027, 113499.7121452235], 
processed observation next is [1.0, 0.43478260869565216, 0.42424242424242453, 0.6266666666666667, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.11885453253751953, 0.11885453253751953, 0.27682856620786217], 
reward next is 0.4039, 
noisyNet noise sample is [array([-1.2646521], dtype=float32), -0.62671185]. 
=============================================
[2019-03-18 13:12:57,642] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.1632118e-11 9.2774952e-13 1.0000000e+00 1.6662378e-12 8.9355381e-12], sum to 1.0000
[2019-03-18 13:12:57,653] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7751
[2019-03-18 13:12:57,749] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 252172.6276719159, 252172.6276719156, 100225.1177530461], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 462600.0000, 
sim time next is 463200.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 279905.5844561808, 279905.5844561808, 105182.6011583735], 
processed observation next is [1.0, 0.34782608695652173, 0.22727272727272727, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.10366873498377067, 0.10366873498377067, 0.2565429296545695], 
reward next is 0.3802, 
noisyNet noise sample is [array([0.8596748], dtype=float32), 0.13011923]. 
=============================================
[2019-03-18 13:12:58,371] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.1498253e-13 5.7697915e-15 1.0000000e+00 1.7020496e-16 7.4459543e-16], sum to 1.0000
[2019-03-18 13:12:58,386] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8305
[2019-03-18 13:12:58,489] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3433542590835734, 6.9112, 6.9112, 77.32846344354104, 399468.6811796461, 399468.6811796461, 129790.3101447375], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 469800.0000, 
sim time next is 470400.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.333961173360478, 6.911199999999999, 6.9112, 77.32846344354104, 388536.1162651173, 388536.1162651176, 128435.309951027], 
processed observation next is [1.0, 0.43478260869565216, 0.2727272727272727, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.04851596194353999, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14390226528337677, 0.14390226528337688, 0.3132568535390902], 
reward next is 0.4322, 
noisyNet noise sample is [array([-0.6273667], dtype=float32), 0.4234384]. 
=============================================
[2019-03-18 13:13:06,736] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1000, global step 15882: loss 0.3062
[2019-03-18 13:13:06,738] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1000, global step 15882: learning rate 0.0010
[2019-03-18 13:13:06,769] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1000, global step 15893: loss 0.2794
[2019-03-18 13:13:06,774] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1000, global step 15893: learning rate 0.0010
[2019-03-18 13:13:06,829] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1000, global step 15912: loss 0.1362
[2019-03-18 13:13:06,838] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1000, global step 15913: learning rate 0.0010
[2019-03-18 13:13:06,861] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1000, global step 15924: loss 0.0823
[2019-03-18 13:13:06,864] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1000, global step 15925: learning rate 0.0010
[2019-03-18 13:13:06,946] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1000, global step 15958: loss 0.0701
[2019-03-18 13:13:06,948] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1000, global step 15958: learning rate 0.0010
[2019-03-18 13:13:06,956] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1000, global step 15960: loss 0.0250
[2019-03-18 13:13:06,960] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1000, global step 15960: learning rate 0.0010
[2019-03-18 13:13:06,981] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1000, global step 15970: loss 0.0202
[2019-03-18 13:13:06,985] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1000, global step 15971: learning rate 0.0010
[2019-03-18 13:13:07,050] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1000, global step 15989: loss 0.0010
[2019-03-18 13:13:07,055] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1000, global step 15990: learning rate 0.0010
[2019-03-18 13:13:07,125] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1000, global step 16019: loss 0.0017
[2019-03-18 13:13:07,129] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 1000, global step 16020: learning rate 0.0010
[2019-03-18 13:13:07,130] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1000, global step 16022: loss 0.0066
[2019-03-18 13:13:07,132] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1000, global step 16022: learning rate 0.0010
[2019-03-18 13:13:07,141] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1000, global step 16027: loss 0.0041
[2019-03-18 13:13:07,147] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1000, global step 16029: learning rate 0.0010
[2019-03-18 13:13:07,163] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1000, global step 16035: loss 0.0329
[2019-03-18 13:13:07,168] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1000, global step 16035: learning rate 0.0010
[2019-03-18 13:13:07,191] A3C_AGENT_WORKER-Thread-21 INFO:Local step 1000, global step 16045: loss 0.0122
[2019-03-18 13:13:07,194] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 1000, global step 16045: learning rate 0.0010
[2019-03-18 13:13:07,227] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1000, global step 16054: loss 0.0911
[2019-03-18 13:13:07,233] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1000, global step 16055: learning rate 0.0010
[2019-03-18 13:13:07,247] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1000, global step 16060: loss 0.0627
[2019-03-18 13:13:07,250] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1000, global step 16061: learning rate 0.0010
[2019-03-18 13:13:07,261] A3C_AGENT_WORKER-Thread-22 INFO:Local step 1000, global step 16065: loss 0.0891
[2019-03-18 13:13:07,265] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 1000, global step 16067: learning rate 0.0010
[2019-03-18 13:13:09,324] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.3695501e-10 2.1186896e-14 1.0000000e+00 8.8907207e-13 8.2462726e-13], sum to 1.0000
[2019-03-18 13:13:09,341] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8859
[2019-03-18 13:13:09,435] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.0, 88.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 313647.4933773316, 313647.4933773314, 138535.1126364428], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 631800.0000, 
sim time next is 632400.0000, 
raw observation next is [17.33333333333334, 86.66666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 322195.0226338727, 322195.0226338727, 139960.5536266023], 
processed observation next is [1.0, 0.30434782608695654, 0.42424242424242453, 0.8666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.11933148986439729, 0.11933148986439729, 0.34136720396732273], 
reward next is 0.3289, 
noisyNet noise sample is [array([-1.3987554], dtype=float32), -0.3873608]. 
=============================================
[2019-03-18 13:13:22,842] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.06851116e-12 2.39256574e-18 1.00000000e+00 6.44553427e-16
 1.10491994e-16], sum to 1.0000
[2019-03-18 13:13:22,849] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4247
[2019-03-18 13:13:22,941] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.0, 59.33333333333334, 1.0, 2.0, 0.2890695170020238, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5849126467358655, 6.911199999999999, 6.9112, 77.32846344354104, 652881.3656993136, 652881.3656993138, 192629.7785945946], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 823800.0000, 
sim time next is 824400.0000, 
raw observation next is [29.0, 58.0, 1.0, 2.0, 0.2830763991538336, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5731244045603888, 6.9112, 6.9112, 77.32846344354104, 640662.7482449465, 640662.7482449465, 190464.2838088011], 
processed observation next is [0.0, 0.5652173913043478, 0.9545454545454546, 0.58, 1.0, 1.0, 0.10384549894229197, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3901777208005555, 0.0, 0.0, 0.5084288129206541, 0.23728249934998016, 0.23728249934998016, 0.46454703368000266], 
reward next is 0.4805, 
noisyNet noise sample is [array([-2.1331913], dtype=float32), -0.7742776]. 
=============================================
[2019-03-18 13:13:27,742] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1500, global step 23838: loss 0.0404
[2019-03-18 13:13:27,744] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1500, global step 23838: learning rate 0.0010
[2019-03-18 13:13:27,945] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1500, global step 23915: loss 0.0009
[2019-03-18 13:13:27,947] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1500, global step 23916: learning rate 0.0010
[2019-03-18 13:13:27,962] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1500, global step 23920: loss 0.0002
[2019-03-18 13:13:27,964] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1500, global step 23921: learning rate 0.0010
[2019-03-18 13:13:27,991] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1500, global step 23932: loss 0.0039
[2019-03-18 13:13:27,992] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1500, global step 23932: learning rate 0.0010
[2019-03-18 13:13:28,030] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1500, global step 23944: loss 0.0120
[2019-03-18 13:13:28,035] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1500, global step 23944: learning rate 0.0010
[2019-03-18 13:13:28,050] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1500, global step 23951: loss 0.0121
[2019-03-18 13:13:28,055] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1500, global step 23951: learning rate 0.0010
[2019-03-18 13:13:28,077] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1500, global step 23965: loss 0.0220
[2019-03-18 13:13:28,082] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1500, global step 23965: learning rate 0.0010
[2019-03-18 13:13:28,145] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1500, global step 23988: loss 0.0684
[2019-03-18 13:13:28,150] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1500, global step 23988: learning rate 0.0010
[2019-03-18 13:13:28,153] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1500, global step 23991: loss 0.0665
[2019-03-18 13:13:28,158] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1500, global step 23992: learning rate 0.0010
[2019-03-18 13:13:28,169] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1500, global step 23998: loss 0.0607
[2019-03-18 13:13:28,172] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 1500, global step 23998: learning rate 0.0010
[2019-03-18 13:13:28,215] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1500, global step 24008: loss 0.0576
[2019-03-18 13:13:28,217] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1500, global step 24008: learning rate 0.0010
[2019-03-18 13:13:28,282] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1500, global step 24031: loss 0.0378
[2019-03-18 13:13:28,291] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1500, global step 24034: learning rate 0.0010
[2019-03-18 13:13:28,338] A3C_AGENT_WORKER-Thread-21 INFO:Local step 1500, global step 24052: loss 0.0340
[2019-03-18 13:13:28,341] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 1500, global step 24055: learning rate 0.0010
[2019-03-18 13:13:28,371] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1500, global step 24067: loss 0.0155
[2019-03-18 13:13:28,373] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1500, global step 24069: learning rate 0.0010
[2019-03-18 13:13:28,387] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1500, global step 24074: loss 0.0128
[2019-03-18 13:13:28,391] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1500, global step 24074: learning rate 0.0010
[2019-03-18 13:13:28,543] A3C_AGENT_WORKER-Thread-22 INFO:Local step 1500, global step 24131: loss 0.0150
[2019-03-18 13:13:28,547] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 1500, global step 24131: learning rate 0.0010
[2019-03-18 13:13:30,691] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0786541e-15 2.8531089e-21 1.0000000e+00 6.2762391e-19 3.5476565e-18], sum to 1.0000
[2019-03-18 13:13:30,702] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1546
[2019-03-18 13:13:30,709] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.33333333333333, 98.0, 1.0, 2.0, 0.2093562506750443, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4167695593380001, 6.9112, 6.9112, 77.32846344354104, 475639.4166596321, 475639.4166596321, 164483.6357825716], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 935400.0000, 
sim time next is 936000.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.2074977551779523, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4125226972734067, 6.9112, 6.9112, 77.32846344354104, 471085.8969415362, 471085.8969415362, 163829.8607063781], 
processed observation next is [0.0, 0.8695652173913043, 0.5, 1.0, 1.0, 1.0, 0.009372193972440358, 0.0, 1.0, -0.25, 1.0, 1.0, 0.160746710390581, 0.0, 0.0, 0.5084288129206541, 0.1744762581264949, 0.1744762581264949, 0.3995850261131173], 
reward next is 0.4108, 
noisyNet noise sample is [array([-0.07589024], dtype=float32), 1.2483296]. 
=============================================
[2019-03-18 13:13:30,722] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[47.053726]
 [47.026752]
 [47.003757]
 [46.98336 ]
 [46.96454 ]], R is [[47.01723099]
 [46.9601593 ]
 [46.90585327]
 [46.85406113]
 [46.80451584]].
[2019-03-18 13:13:44,260] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.4043686e-15 6.3815894e-21 1.0000000e+00 2.8881922e-15 2.3535450e-15], sum to 1.0000
[2019-03-18 13:13:44,272] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2055
[2019-03-18 13:13:44,371] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.0, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3264353430512223, 6.911199999999999, 6.9112, 77.32846344354104, 376383.6839816473, 376383.6839816476, 149840.9187234455], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1137600.0000, 
sim time next is 1138200.0000, 
raw observation next is [18.0, 94.00000000000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3360699461480846, 6.9112, 6.9112, 77.32846344354104, 387424.695148423, 387424.695148423, 151044.7755550253], 
processed observation next is [1.0, 0.17391304347826086, 0.45454545454545453, 0.9400000000000002, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.051528494497263745, 0.0, 0.0, 0.5084288129206541, 0.14349062783274927, 0.14349062783274927, 0.36840189159762265], 
reward next is 0.3664, 
noisyNet noise sample is [array([0.58465594], dtype=float32), 2.1626842]. 
=============================================
[2019-03-18 13:13:48,409] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2000, global step 31817: loss 0.0297
[2019-03-18 13:13:48,412] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2000, global step 31817: learning rate 0.0010
[2019-03-18 13:13:48,669] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2000, global step 31908: loss 0.0063
[2019-03-18 13:13:48,674] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2000, global step 31908: learning rate 0.0010
[2019-03-18 13:13:48,743] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2000, global step 31940: loss 0.0101
[2019-03-18 13:13:48,746] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2000, global step 31941: learning rate 0.0010
[2019-03-18 13:13:48,756] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2000, global step 31946: loss 0.0004
[2019-03-18 13:13:48,759] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2000, global step 31947: learning rate 0.0010
[2019-03-18 13:13:48,771] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2000, global step 31951: loss 0.0078
[2019-03-18 13:13:48,778] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2000, global step 31955: learning rate 0.0010
[2019-03-18 13:13:48,811] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2000, global step 31969: loss 0.0003
[2019-03-18 13:13:48,814] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2000, global step 31969: learning rate 0.0010
[2019-03-18 13:13:48,818] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2000, global step 31970: loss 0.0176
[2019-03-18 13:13:48,820] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2000, global step 31970: loss 0.0096
[2019-03-18 13:13:48,821] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2000, global step 31970: learning rate 0.0010
[2019-03-18 13:13:48,824] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2000, global step 31970: learning rate 0.0010
[2019-03-18 13:13:48,838] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2000, global step 31975: loss 0.0135
[2019-03-18 13:13:48,842] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2000, global step 31975: learning rate 0.0010
[2019-03-18 13:13:48,845] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2000, global step 31976: loss 0.0074
[2019-03-18 13:13:48,848] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 2000, global step 31976: learning rate 0.0010
[2019-03-18 13:13:48,859] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2000, global step 31981: loss 0.0035
[2019-03-18 13:13:48,860] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2000, global step 31981: learning rate 0.0010
[2019-03-18 13:13:49,017] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2000, global step 32040: loss 0.0003
[2019-03-18 13:13:49,019] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2000, global step 32041: learning rate 0.0010
[2019-03-18 13:13:49,033] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2000, global step 32048: loss 0.0058
[2019-03-18 13:13:49,036] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2000, global step 32049: learning rate 0.0010
[2019-03-18 13:13:49,124] A3C_AGENT_WORKER-Thread-21 INFO:Local step 2000, global step 32075: loss 0.0538
[2019-03-18 13:13:49,126] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 2000, global step 32075: learning rate 0.0010
[2019-03-18 13:13:49,152] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2000, global step 32087: loss 0.0819
[2019-03-18 13:13:49,160] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2000, global step 32089: learning rate 0.0010
[2019-03-18 13:13:49,320] A3C_AGENT_WORKER-Thread-22 INFO:Local step 2000, global step 32152: loss 0.0121
[2019-03-18 13:13:49,325] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 2000, global step 32153: learning rate 0.0010
[2019-03-18 13:14:03,957] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.5731089e-14 3.7575639e-18 1.0000000e+00 3.1372298e-13 2.2016499e-12], sum to 1.0000
[2019-03-18 13:14:03,971] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1730
[2019-03-18 13:14:03,975] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.2558315747785972, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5180313634667449, 6.9112, 6.9112, 77.32846344354104, 582533.6119282111, 582533.6119282111, 181171.972764709], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1415400.0000, 
sim time next is 1416000.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.2562232042162187, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5188255902800917, 6.9112, 6.9112, 77.32846344354104, 583422.5301735264, 583422.5301735264, 181270.1511763849], 
processed observation next is [0.0, 0.391304347826087, 0.6818181818181818, 0.89, 1.0, 1.0, 0.07027900527027335, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3126079861144167, 0.0, 0.0, 0.5084288129206541, 0.21608241858278754, 0.21608241858278754, 0.4421223199424022], 
reward next is 0.4598, 
noisyNet noise sample is [array([-1.8839842], dtype=float32), 0.5530633]. 
=============================================
[2019-03-18 13:14:03,992] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[37.75624 ]
 [37.768562]
 [37.782383]
 [37.79027 ]
 [37.793907]], R is [[37.82052994]
 [37.90166473]
 [37.98167419]
 [38.06071472]
 [38.13834763]].
[2019-03-18 13:14:09,344] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2500, global step 39815: loss 0.0178
[2019-03-18 13:14:09,350] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2500, global step 39817: learning rate 0.0010
[2019-03-18 13:14:09,521] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2500, global step 39881: loss 0.0002
[2019-03-18 13:14:09,526] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2500, global step 39883: learning rate 0.0010
[2019-03-18 13:14:09,618] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2500, global step 39914: loss 0.0054
[2019-03-18 13:14:09,624] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2500, global step 39916: learning rate 0.0010
[2019-03-18 13:14:09,659] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.7560172e-14 3.9392695e-21 1.0000000e+00 7.1788616e-17 2.2117787e-14], sum to 1.0000
[2019-03-18 13:14:09,674] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8661
[2019-03-18 13:14:09,680] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.66666666666667, 92.33333333333334, 1.0, 2.0, 0.2718868572130338, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5503949120793222, 6.9112, 6.9112, 77.32846344354104, 614996.5673150481, 614996.5673150481, 187599.3341037706], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1498800.0000, 
sim time next is 1499400.0000, 
raw observation next is [24.0, 91.5, 1.0, 2.0, 0.2772793223344566, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5609661463076485, 6.911200000000001, 6.9112, 77.32846344354104, 625929.2756125516, 625929.2756125513, 189500.246723958], 
processed observation next is [0.0, 0.34782608695652173, 0.7272727272727273, 0.915, 1.0, 1.0, 0.09659915291807077, 0.0, 1.0, -0.25, 1.0, 1.0, 0.37280878043949794, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23182565763427837, 0.23182565763427823, 0.4621957237169707], 
reward next is 0.4719, 
noisyNet noise sample is [array([-0.720193], dtype=float32), -1.5984696]. 
=============================================
[2019-03-18 13:14:09,692] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2500, global step 39944: loss 0.0392
[2019-03-18 13:14:09,695] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2500, global step 39945: learning rate 0.0010
[2019-03-18 13:14:09,721] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2500, global step 39957: loss 0.0265
[2019-03-18 13:14:09,723] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2500, global step 39957: learning rate 0.0010
[2019-03-18 13:14:09,764] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2500, global step 39970: loss 0.0400
[2019-03-18 13:14:09,766] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 2500, global step 39971: learning rate 0.0010
[2019-03-18 13:14:09,771] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2500, global step 39973: loss 0.0235
[2019-03-18 13:14:09,772] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2500, global step 39973: learning rate 0.0010
[2019-03-18 13:14:09,779] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2500, global step 39975: loss 0.0367
[2019-03-18 13:14:09,783] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2500, global step 39975: learning rate 0.0010
[2019-03-18 13:14:09,811] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2500, global step 39984: loss 0.0502
[2019-03-18 13:14:09,817] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2500, global step 39986: learning rate 0.0010
[2019-03-18 13:14:09,828] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2500, global step 39992: loss 0.0259
[2019-03-18 13:14:09,830] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2500, global step 39992: learning rate 0.0010
[2019-03-18 13:14:09,882] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2500, global step 40013: loss 0.0474
[2019-03-18 13:14:09,889] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2500, global step 40013: learning rate 0.0010
[2019-03-18 13:14:09,899] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2500, global step 40017: loss 0.0265
[2019-03-18 13:14:09,901] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2500, global step 40018: learning rate 0.0010
[2019-03-18 13:14:09,952] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2500, global step 40038: loss 0.0341
[2019-03-18 13:14:09,955] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2500, global step 40038: learning rate 0.0010
[2019-03-18 13:14:10,014] A3C_AGENT_WORKER-Thread-21 INFO:Local step 2500, global step 40059: loss 0.0089
[2019-03-18 13:14:10,018] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 2500, global step 40060: learning rate 0.0010
[2019-03-18 13:14:10,079] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2500, global step 40084: loss 0.0044
[2019-03-18 13:14:10,081] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2500, global step 40085: learning rate 0.0010
[2019-03-18 13:14:10,310] A3C_AGENT_WORKER-Thread-22 INFO:Local step 2500, global step 40169: loss 0.0002
[2019-03-18 13:14:10,315] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 2500, global step 40170: learning rate 0.0010
[2019-03-18 13:14:10,823] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.1014559e-17 4.6511072e-23 1.0000000e+00 1.5434314e-14 3.5632420e-17], sum to 1.0000
[2019-03-18 13:14:10,835] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0983
[2019-03-18 13:14:10,926] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.5, 68.0, 1.0, 2.0, 0.302916496444487, 0.0, 2.0, 0.0, 1.0, 2.0, 0.612915008990136, 6.911199999999999, 6.9112, 77.32846344354104, 680796.4859539922, 680796.4859539925, 198083.3040292416], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1513800.0000, 
sim time next is 1514400.0000, 
raw observation next is [28.66666666666666, 67.33333333333334, 1.0, 2.0, 0.3038687519522992, 0.0, 2.0, 0.0, 1.0, 2.0, 0.614841783200132, 6.9112, 6.9112, 77.32846344354104, 682938.1578666389, 682938.1578666389, 198367.2569450251], 
processed observation next is [0.0, 0.5217391304347826, 0.9393939393939391, 0.6733333333333335, 1.0, 1.0, 0.12983593994037396, 0.0, 1.0, -0.25, 1.0, 1.0, 0.4497739760001887, 0.0, 0.0, 0.5084288129206541, 0.2529400584691255, 0.2529400584691255, 0.48382257791469535], 
reward next is 0.4918, 
noisyNet noise sample is [array([-0.4746303], dtype=float32), 0.06611445]. 
=============================================
[2019-03-18 13:14:11,618] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.6727947e-18 3.2064630e-23 1.0000000e+00 1.6689133e-15 2.4980148e-16], sum to 1.0000
[2019-03-18 13:14:11,626] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1328
[2019-03-18 13:14:11,636] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.0, 83.0, 1.0, 2.0, 0.2586571815203222, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5238902039472977, 6.911199999999999, 6.9112, 77.32846344354104, 588453.6895724321, 588453.6895724324, 182314.175808316], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1525800.0000, 
sim time next is 1526400.0000, 
raw observation next is [24.0, 83.0, 1.0, 2.0, 0.2585679053929745, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5237092402941933, 6.9112, 6.9112, 77.32846344354104, 588251.2399771304, 588251.2399771304, 182291.5951442877], 
processed observation next is [0.0, 0.6956521739130435, 0.7272727272727273, 0.83, 1.0, 1.0, 0.07320988174121808, 0.0, 1.0, -0.25, 1.0, 1.0, 0.31958462899170476, 0.0, 0.0, 0.5084288129206541, 0.21787082962115942, 0.21787082962115942, 0.44461364669338466], 
reward next is 0.4610, 
noisyNet noise sample is [array([-0.7906869], dtype=float32), 0.2123297]. 
=============================================
[2019-03-18 13:14:13,390] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.2899375e-17 4.0297628e-22 1.0000000e+00 8.9026360e-16 2.5103007e-15], sum to 1.0000
[2019-03-18 13:14:13,400] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7089
[2019-03-18 13:14:13,406] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.0, 94.0, 1.0, 2.0, 0.2077089589478843, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4143690022161637, 6.9112, 6.9112, 77.32846344354104, 472396.0438087173, 472396.0438087173, 164716.9949156125], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1555200.0000, 
sim time next is 1555800.0000, 
raw observation next is [20.16666666666667, 93.00000000000001, 1.0, 2.0, 0.2078319635438172, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4147235948547666, 6.9112, 6.9112, 77.32846344354104, 472735.5356292424, 472735.5356292424, 164807.1955062518], 
processed observation next is [1.0, 0.0, 0.5530303030303032, 0.9300000000000002, 1.0, 1.0, 0.009789954429771479, 0.0, 1.0, -0.25, 1.0, 1.0, 0.16389084979252377, 0.0, 0.0, 0.5084288129206541, 0.17508723541823792, 0.17508723541823792, 0.4019687695274434], 
reward next is 0.4098, 
noisyNet noise sample is [array([0.33838066], dtype=float32), -0.80926514]. 
=============================================
[2019-03-18 13:14:23,948] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.3463619e-16 1.1793720e-22 1.0000000e+00 1.4673335e-13 5.6983091e-15], sum to 1.0000
[2019-03-18 13:14:23,957] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3329
[2019-03-18 13:14:24,054] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.86942914e-16 4.70762300e-22 1.00000000e+00 1.05364814e-13
 9.69521641e-16], sum to 1.0000
[2019-03-18 13:14:24,057] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.66666666666667, 50.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 273331.1606441266, 273331.1606441263, 100860.5628903071], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1707600.0000, 
sim time next is 1708200.0000, 
raw observation next is [17.5, 50.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 270259.7868428361, 270259.7868428358, 100160.6418005315], 
processed observation next is [1.0, 0.782608695652174, 0.4318181818181818, 0.505, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10009621734919856, 0.10009621734919844, 0.24429424829397928], 
reward next is 0.3855, 
noisyNet noise sample is [array([0.21823566], dtype=float32), 1.0101708]. 
=============================================
[2019-03-18 13:14:24,063] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8864
[2019-03-18 13:14:24,072] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.0, 54.5, 1.0, 2.0, 0.23400869035477, 0.0, 2.0, 0.0, 1.0, 2.0, 0.436842959200726, 6.9112, 6.9112, 77.32846344354104, 508293.1073818978, 508293.1073818978, 143864.7603779793], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1701000.0000, 
sim time next is 1701600.0000, 
raw observation next is [19.66666666666667, 55.0, 1.0, 2.0, 0.2528624697676677, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4720388349537227, 6.9112, 6.9112, 77.32846344354104, 549268.766980015, 549268.766980015, 146201.9082761607], 
processed observation next is [1.0, 0.6956521739130435, 0.5303030303030305, 0.55, 1.0, 1.0, 0.0660780872095846, 0.0, 1.0, -0.25, 1.0, 1.0, 0.24576976421960386, 0.0, 0.0, 0.5084288129206541, 0.2034328766592648, 0.2034328766592648, 0.35659002018575786], 
reward next is 0.5367, 
noisyNet noise sample is [array([-1.9046369], dtype=float32), -0.11953686]. 
=============================================
[2019-03-18 13:14:26,761] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.7278903e-20 4.7260746e-26 1.0000000e+00 5.1984775e-21 6.7992659e-19], sum to 1.0000
[2019-03-18 13:14:26,769] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9615
[2019-03-18 13:14:26,777] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [8.0, 84.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3024629163450247, 6.911199999999999, 6.9112, 77.32846344354104, 351877.2484505497, 351877.24845055, 108709.4324626657], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1744200.0000, 
sim time next is 1744800.0000, 
raw observation next is [8.0, 85.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3009122221732087, 6.9112, 6.9112, 77.32846344354104, 350072.5630547138, 350072.5630547138, 108558.558514039], 
processed observation next is [1.0, 0.17391304347826086, 0.0, 0.85, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0013031745331552682, 0.0, 0.0, 0.5084288129206541, 0.1296565048350792, 0.1296565048350792, 0.26477697198546096], 
reward next is 0.4607, 
noisyNet noise sample is [array([0.72945625], dtype=float32), -1.4385052]. 
=============================================
[2019-03-18 13:14:30,119] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3000, global step 47794: loss 0.0975
[2019-03-18 13:14:30,122] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 3000, global step 47795: learning rate 0.0010
[2019-03-18 13:14:30,377] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3000, global step 47892: loss 0.0003
[2019-03-18 13:14:30,380] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 3000, global step 47892: learning rate 0.0010
[2019-03-18 13:14:30,397] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3000, global step 47897: loss 0.0001
[2019-03-18 13:14:30,400] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 3000, global step 47898: learning rate 0.0010
[2019-03-18 13:14:30,408] A3C_AGENT_WORKER-Thread-20 INFO:Local step 3000, global step 47901: loss 0.0125
[2019-03-18 13:14:30,410] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 3000, global step 47901: learning rate 0.0010
[2019-03-18 13:14:30,463] A3C_AGENT_WORKER-Thread-18 INFO:Local step 3000, global step 47927: loss 0.0001
[2019-03-18 13:14:30,465] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 3000, global step 47927: learning rate 0.0010
[2019-03-18 13:14:30,479] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3000, global step 47932: loss 0.0017
[2019-03-18 13:14:30,483] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 3000, global step 47932: learning rate 0.0010
[2019-03-18 13:14:30,531] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3000, global step 47951: loss 0.0246
[2019-03-18 13:14:30,533] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 3000, global step 47951: learning rate 0.0010
[2019-03-18 13:14:30,550] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3000, global step 47957: loss 0.0129
[2019-03-18 13:14:30,555] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 3000, global step 47957: learning rate 0.0010
[2019-03-18 13:14:30,557] A3C_AGENT_WORKER-Thread-19 INFO:Local step 3000, global step 47958: loss 0.0067
[2019-03-18 13:14:30,561] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 3000, global step 47958: learning rate 0.0010
[2019-03-18 13:14:30,686] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3000, global step 48008: loss 0.0489
[2019-03-18 13:14:30,691] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 3000, global step 48009: learning rate 0.0010
[2019-03-18 13:14:30,722] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3000, global step 48020: loss 0.0317
[2019-03-18 13:14:30,725] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 3000, global step 48022: learning rate 0.0010
[2019-03-18 13:14:30,772] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3000, global step 48034: loss 0.0137
[2019-03-18 13:14:30,774] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 3000, global step 48035: learning rate 0.0010
[2019-03-18 13:14:30,936] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3000, global step 48099: loss 0.0098
[2019-03-18 13:14:30,942] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 3000, global step 48100: learning rate 0.0010
[2019-03-18 13:14:30,950] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3000, global step 48104: loss 0.0138
[2019-03-18 13:14:30,952] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 3000, global step 48104: learning rate 0.0010
[2019-03-18 13:14:31,073] A3C_AGENT_WORKER-Thread-21 INFO:Local step 3000, global step 48150: loss 0.0092
[2019-03-18 13:14:31,075] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 3000, global step 48150: learning rate 0.0010
[2019-03-18 13:14:31,130] A3C_AGENT_WORKER-Thread-22 INFO:Local step 3000, global step 48175: loss 0.0004
[2019-03-18 13:14:31,133] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 3000, global step 48175: learning rate 0.0010
[2019-03-18 13:14:32,555] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.8526034e-19 2.2739808e-25 1.0000000e+00 2.7442296e-19 4.9330864e-18], sum to 1.0000
[2019-03-18 13:14:32,566] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0214
[2019-03-18 13:14:32,570] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [12.5, 83.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 190742.1750290577, 190742.175029058, 84154.54628071752], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1819800.0000, 
sim time next is 1820400.0000, 
raw observation next is [12.0, 86.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 184359.2246924184, 184359.2246924187, 82822.47723995514], 
processed observation next is [1.0, 0.043478260869565216, 0.18181818181818182, 0.8666666666666667, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.06828119433052533, 0.06828119433052544, 0.2020060420486711], 
reward next is 0.3180, 
noisyNet noise sample is [array([-0.17972508], dtype=float32), 3.7582207]. 
=============================================
[2019-03-18 13:14:50,716] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3500, global step 55810: loss 0.0019
[2019-03-18 13:14:50,722] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 3500, global step 55811: learning rate 0.0010
[2019-03-18 13:14:50,813] A3C_AGENT_WORKER-Thread-18 INFO:Local step 3500, global step 55850: loss 0.0005
[2019-03-18 13:14:50,816] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 3500, global step 55850: learning rate 0.0010
[2019-03-18 13:14:50,859] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3500, global step 55866: loss 0.0001
[2019-03-18 13:14:50,861] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3500, global step 55866: loss 0.0002
[2019-03-18 13:14:50,862] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 3500, global step 55866: learning rate 0.0010
[2019-03-18 13:14:50,863] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 3500, global step 55867: learning rate 0.0010
[2019-03-18 13:14:51,031] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3500, global step 55931: loss 0.0178
[2019-03-18 13:14:51,035] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 3500, global step 55932: learning rate 0.0010
[2019-03-18 13:14:51,062] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3500, global step 55943: loss 0.0034
[2019-03-18 13:14:51,067] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 3500, global step 55943: learning rate 0.0010
[2019-03-18 13:14:51,070] A3C_AGENT_WORKER-Thread-20 INFO:Local step 3500, global step 55943: loss 0.0143
[2019-03-18 13:14:51,075] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 3500, global step 55944: learning rate 0.0010
[2019-03-18 13:14:51,122] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3500, global step 55961: loss 0.0047
[2019-03-18 13:14:51,128] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 3500, global step 55963: learning rate 0.0010
[2019-03-18 13:14:51,244] A3C_AGENT_WORKER-Thread-19 INFO:Local step 3500, global step 56007: loss 0.0002
[2019-03-18 13:14:51,251] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 3500, global step 56007: learning rate 0.0010
[2019-03-18 13:14:51,252] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3500, global step 56007: loss 0.0001
[2019-03-18 13:14:51,260] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 3500, global step 56007: learning rate 0.0010
[2019-03-18 13:14:51,280] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3500, global step 56018: loss 0.0013
[2019-03-18 13:14:51,286] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 3500, global step 56019: learning rate 0.0010
[2019-03-18 13:14:51,382] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3500, global step 56059: loss 0.0103
[2019-03-18 13:14:51,385] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 3500, global step 56061: learning rate 0.0010
[2019-03-18 13:14:51,394] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3500, global step 56064: loss 0.0207
[2019-03-18 13:14:51,400] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 3500, global step 56067: learning rate 0.0010
[2019-03-18 13:14:51,523] A3C_AGENT_WORKER-Thread-21 INFO:Local step 3500, global step 56122: loss 0.0007
[2019-03-18 13:14:51,527] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 3500, global step 56122: learning rate 0.0010
[2019-03-18 13:14:51,576] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3500, global step 56137: loss 0.0004
[2019-03-18 13:14:51,578] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 3500, global step 56138: learning rate 0.0010
[2019-03-18 13:14:51,782] A3C_AGENT_WORKER-Thread-22 INFO:Local step 3500, global step 56217: loss 0.0164
[2019-03-18 13:14:51,786] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 3500, global step 56218: learning rate 0.0010
[2019-03-18 13:15:00,320] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.2721478e-14 1.3132252e-18 1.0000000e+00 4.7821054e-14 3.0624785e-15], sum to 1.0000
[2019-03-18 13:15:00,336] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4162
[2019-03-18 13:15:00,437] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.5, 80.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.380769812586433, 6.9112, 6.9112, 77.32846344354104, 436891.0216773673, 436891.0216773673, 158423.9074184744], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2230200.0000, 
sim time next is 2230800.0000, 
raw observation next is [20.33333333333333, 81.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3806500942545918, 6.911200000000001, 6.9112, 77.32846344354104, 436880.5888211131, 436880.5888211128, 158295.2336914346], 
processed observation next is [1.0, 0.8260869565217391, 0.5606060606060604, 0.8133333333333332, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.11521442036370258, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16180762548930114, 0.16180762548930105, 0.38608593583276735], 
reward next is 0.3943, 
noisyNet noise sample is [array([0.3762727], dtype=float32), 1.8239455]. 
=============================================
[2019-03-18 13:15:04,754] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.0790971e-15 3.6380902e-21 1.0000000e+00 3.0389776e-18 4.4637329e-18], sum to 1.0000
[2019-03-18 13:15:04,764] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7633
[2019-03-18 13:15:04,858] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.0, 49.0, 1.0, 2.0, 0.206409646425043, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3853215904725195, 6.911199999999999, 6.9112, 77.32846344354104, 448317.2486012555, 448317.2486012558, 132460.4912495655], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2293200.0000, 
sim time next is 2293800.0000, 
raw observation next is [20.0, 49.0, 1.0, 2.0, 0.2067356254689882, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3859301219333749, 6.9112, 6.9112, 77.32846344354104, 449025.594929533, 449025.594929533, 132835.1651881709], 
processed observation next is [1.0, 0.5652173913043478, 0.5454545454545454, 0.49, 1.0, 1.0, 0.008419531836235221, 0.0, 1.0, -0.25, 1.0, 1.0, 0.12275731704767844, 0.0, 0.0, 0.5084288129206541, 0.16630577589982704, 0.16630577589982704, 0.3239882077760266], 
reward next is 0.4829, 
noisyNet noise sample is [array([0.51663536], dtype=float32), -0.6673858]. 
=============================================
[2019-03-18 13:15:05,094] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.0267092e-16 4.7573976e-21 1.0000000e+00 8.6525201e-18 3.2983781e-17], sum to 1.0000
[2019-03-18 13:15:05,108] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7592
[2019-03-18 13:15:05,214] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.0, 53.0, 1.0, 2.0, 0.2457567065864584, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4587739317966944, 6.9112, 6.9112, 77.32846344354104, 533825.1270756198, 533825.1270756198, 144492.7526524295], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2300400.0000, 
sim time next is 2301000.0000, 
raw observation next is [20.0, 52.33333333333334, 1.0, 2.0, 0.2674169200837589, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4992088051628722, 6.9112, 6.9112, 77.32846344354104, 580902.8883598561, 580902.8883598561, 148639.4651458392], 
processed observation next is [1.0, 0.6521739130434783, 0.5454545454545454, 0.5233333333333334, 1.0, 1.0, 0.0842711501046986, 0.0, 1.0, -0.25, 1.0, 1.0, 0.28458400737553174, 0.0, 0.0, 0.5084288129206541, 0.21514921791105782, 0.21514921791105782, 0.3625352808435103], 
reward next is 0.5583, 
noisyNet noise sample is [array([0.48309168], dtype=float32), -0.18491645]. 
=============================================
[2019-03-18 13:15:05,244] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[50.40619 ]
 [50.35172 ]
 [50.324924]
 [50.288544]
 [50.309856]], R is [[50.57858276]
 [50.60057831]
 [50.61140442]
 [50.6166954 ]
 [50.60673904]].
[2019-03-18 13:15:06,801] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.9918257e-14 1.1723518e-15 1.0000000e+00 1.1551635e-14 1.7467791e-15], sum to 1.0000
[2019-03-18 13:15:06,813] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7105
[2019-03-18 13:15:06,818] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.5, 53.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 263337.3425577041, 263337.3425577038, 99642.01734848045], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2320200.0000, 
sim time next is 2320800.0000, 
raw observation next is [17.33333333333333, 54.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 261678.4762256738, 261678.4762256741, 99161.79522657843], 
processed observation next is [1.0, 0.8695652173913043, 0.42424242424242403, 0.54, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09691795415765696, 0.09691795415765707, 0.24185803713799617], 
reward next is 0.3770, 
noisyNet noise sample is [array([0.7602311], dtype=float32), 0.6287096]. 
=============================================
[2019-03-18 13:15:07,197] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.1667651e-15 1.6365419e-20 1.0000000e+00 3.4985126e-16 1.6812257e-16], sum to 1.0000
[2019-03-18 13:15:07,207] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0660
[2019-03-18 13:15:07,214] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.0, 54.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 253466.0763310824, 253466.0763310824, 97055.51731452497], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2326800.0000, 
sim time next is 2327400.0000, 
raw observation next is [17.0, 53.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 253002.6005956023, 253002.600595602, 96850.92982631674], 
processed observation next is [1.0, 0.9565217391304348, 0.4090909090909091, 0.535, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0937046668872601, 0.09370466688726001, 0.23622178006418718], 
reward next is 0.3732, 
noisyNet noise sample is [array([0.20008156], dtype=float32), 0.22773495]. 
=============================================
[2019-03-18 13:15:07,512] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.2584826e-15 9.7195676e-19 1.0000000e+00 1.8469452e-15 2.4964407e-14], sum to 1.0000
[2019-03-18 13:15:07,526] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8666
[2019-03-18 13:15:07,532] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [16.5, 60.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 247563.8331610175, 247563.8331610178, 96626.47090038136], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2331000.0000, 
sim time next is 2331600.0000, 
raw observation next is [16.33333333333333, 62.66666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 244509.4896483061, 244509.4896483064, 96452.3931189648], 
processed observation next is [1.0, 1.0, 0.37878787878787856, 0.6266666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09055907024011337, 0.09055907024011348, 0.2352497393145483], 
reward next is 0.3621, 
noisyNet noise sample is [array([1.2020994], dtype=float32), -0.36099416]. 
=============================================
[2019-03-18 13:15:08,098] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.8060869e-16 1.0458552e-21 1.0000000e+00 1.6386990e-18 2.2264192e-14], sum to 1.0000
[2019-03-18 13:15:08,108] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2837
[2019-03-18 13:15:08,209] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [12.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 197734.3300852345, 197734.3300852345, 85424.67002263619], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2343600.0000, 
sim time next is 2344200.0000, 
raw observation next is [12.16666666666667, 88.00000000000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 250277.0627789807, 250277.0627789807, 95017.1682678905], 
processed observation next is [1.0, 0.13043478260869565, 0.18939393939393953, 0.8800000000000001, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.09269520843665952, 0.09269520843665952, 0.23174919089729393], 
reward next is 0.3763, 
noisyNet noise sample is [array([0.09332301], dtype=float32), -0.85505897]. 
=============================================
[2019-03-18 13:15:09,499] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.5027496e-15 2.5315313e-17 1.0000000e+00 9.5892580e-14 6.1891647e-14], sum to 1.0000
[2019-03-18 13:15:09,511] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5017
[2019-03-18 13:15:09,515] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.0, 72.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 247971.3194589373, 247971.319458937, 103305.068376411], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2361600.0000, 
sim time next is 2362200.0000, 
raw observation next is [17.33333333333334, 70.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 249549.8409801, 249549.8409801003, 103988.0560322907], 
processed observation next is [1.0, 0.34782608695652173, 0.42424242424242453, 0.7, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09242586702966667, 0.09242586702966678, 0.2536294049568066], 
reward next is 0.3428, 
noisyNet noise sample is [array([1.4537203], dtype=float32), -0.08852143]. 
=============================================
[2019-03-18 13:15:11,174] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.0403646e-19 2.2398170e-27 1.0000000e+00 6.1202615e-20 8.2849671e-19], sum to 1.0000
[2019-03-18 13:15:11,183] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5716
[2019-03-18 13:15:11,278] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 47.0, 1.0, 2.0, 0.3043906243326985, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5695565330922373, 6.9112, 6.9112, 77.32846344354104, 661854.0668666321, 661854.0668666321, 170751.1740073786], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2386800.0000, 
sim time next is 2387400.0000, 
raw observation next is [23.0, 46.50000000000001, 1.0, 2.0, 0.3653663702293879, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6847370878263266, 6.911199999999999, 6.9112, 77.32846344354104, 795559.2531173255, 795559.2531173258, 185243.9219752824], 
processed observation next is [1.0, 0.6521739130434783, 0.6818181818181818, 0.4650000000000001, 1.0, 1.0, 0.20670796278673484, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5496244111804666, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.29465157522863905, 0.2946515752286392, 0.4518144438421522], 
reward next is 0.6135, 
noisyNet noise sample is [array([1.6246358], dtype=float32), 0.8442782]. 
=============================================
[2019-03-18 13:15:12,106] A3C_AGENT_WORKER-Thread-18 INFO:Local step 4000, global step 63826: loss 0.3292
[2019-03-18 13:15:12,107] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 4000, global step 63826: learning rate 0.0010
[2019-03-18 13:15:12,145] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4000, global step 63840: loss 0.4803
[2019-03-18 13:15:12,150] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 4000, global step 63840: learning rate 0.0010
[2019-03-18 13:15:12,203] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4000, global step 63861: loss 0.1504
[2019-03-18 13:15:12,208] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 4000, global step 63861: learning rate 0.0010
[2019-03-18 13:15:12,257] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4000, global step 63883: loss 0.1947
[2019-03-18 13:15:12,260] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 4000, global step 63883: learning rate 0.0010
[2019-03-18 13:15:12,285] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4000, global step 63893: loss 0.0932
[2019-03-18 13:15:12,291] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 4000, global step 63893: learning rate 0.0010
[2019-03-18 13:15:12,459] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4000, global step 63957: loss 0.0236
[2019-03-18 13:15:12,462] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 4000, global step 63958: learning rate 0.0010
[2019-03-18 13:15:12,491] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4000, global step 63970: loss 0.0021
[2019-03-18 13:15:12,494] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 4000, global step 63970: learning rate 0.0010
[2019-03-18 13:15:12,526] A3C_AGENT_WORKER-Thread-20 INFO:Local step 4000, global step 63982: loss 0.0018
[2019-03-18 13:15:12,528] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 4000, global step 63982: learning rate 0.0010
[2019-03-18 13:15:12,536] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4000, global step 63987: loss 0.0195
[2019-03-18 13:15:12,540] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 4000, global step 63987: learning rate 0.0010
[2019-03-18 13:15:12,587] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4000, global step 64006: loss 0.0046
[2019-03-18 13:15:12,593] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 4000, global step 64008: learning rate 0.0010
[2019-03-18 13:15:12,615] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.1100282e-18 2.6384676e-25 1.0000000e+00 3.5240926e-18 1.2373607e-18], sum to 1.0000
[2019-03-18 13:15:12,625] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8614
[2019-03-18 13:15:12,634] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.16666666666667, 55.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 303703.6053237452, 303703.6053237452, 119265.4810063341], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2404200.0000, 
sim time next is 2404800.0000, 
raw observation next is [20.0, 56.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 300674.4395236934, 300674.4395236934, 118010.6872236283], 
processed observation next is [1.0, 0.8695652173913043, 0.5454545454545454, 0.56, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.11136090352729386, 0.11136090352729386, 0.2878309444478739], 
reward next is 0.3640, 
noisyNet noise sample is [array([-0.7069587], dtype=float32), 0.62943786]. 
=============================================
[2019-03-18 13:15:12,654] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4000, global step 64030: loss 0.0448
[2019-03-18 13:15:12,656] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 4000, global step 64031: learning rate 0.0010
[2019-03-18 13:15:12,740] A3C_AGENT_WORKER-Thread-21 INFO:Local step 4000, global step 64067: loss 0.0910
[2019-03-18 13:15:12,743] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 4000, global step 64067: learning rate 0.0010
[2019-03-18 13:15:12,766] A3C_AGENT_WORKER-Thread-19 INFO:Local step 4000, global step 64075: loss 0.0743
[2019-03-18 13:15:12,772] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 4000, global step 64075: learning rate 0.0010
[2019-03-18 13:15:12,782] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4000, global step 64079: loss 0.0874
[2019-03-18 13:15:12,784] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 4000, global step 64079: learning rate 0.0010
[2019-03-18 13:15:12,845] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4000, global step 64105: loss 0.0584
[2019-03-18 13:15:12,850] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 4000, global step 64107: learning rate 0.0010
[2019-03-18 13:15:13,142] A3C_AGENT_WORKER-Thread-22 INFO:Local step 4000, global step 64219: loss 0.0700
[2019-03-18 13:15:13,148] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 4000, global step 64219: learning rate 0.0010
[2019-03-18 13:15:16,134] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.6042161e-17 3.6450064e-22 1.0000000e+00 2.9418331e-15 6.7321764e-15], sum to 1.0000
[2019-03-18 13:15:16,147] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5058
[2019-03-18 13:15:16,153] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [14.5, 91.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 245863.8447757002, 245863.8447757002, 101308.3461936512], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2442600.0000, 
sim time next is 2443200.0000, 
raw observation next is [14.66666666666667, 90.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 247284.5676204636, 247284.5676204636, 101885.1999534231], 
processed observation next is [1.0, 0.2608695652173913, 0.30303030303030315, 0.9, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.09158687689646801, 0.09158687689646801, 0.24850048769127586], 
reward next is 0.3467, 
noisyNet noise sample is [array([0.968925], dtype=float32), -1.5592284]. 
=============================================
[2019-03-18 13:15:21,760] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.4241833e-17 5.0137297e-20 1.0000000e+00 1.5613651e-15 6.4616808e-17], sum to 1.0000
[2019-03-18 13:15:21,770] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6949
[2019-03-18 13:15:21,783] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.0, 77.0, 1.0, 2.0, 0.2643990005616932, 0.0, 2.0, 0.0, 1.0, 2.0, 0.493651366957657, 6.9112, 6.9112, 77.32846344354104, 574343.2661856238, 574343.2661856238, 162405.844851157], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2545200.0000, 
sim time next is 2545800.0000, 
raw observation next is [18.33333333333333, 74.83333333333334, 1.0, 2.0, 0.2881662213234464, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5382237081438731, 6.9112, 6.9112, 77.32846344354104, 626005.0884971328, 626005.0884971328, 167024.6456276778], 
processed observation next is [1.0, 0.4782608695652174, 0.4696969696969695, 0.7483333333333334, 1.0, 1.0, 0.11020777665430796, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3403195830626759, 0.0, 0.0, 0.5084288129206541, 0.23185373648041954, 0.23185373648041954, 0.40737718445775073], 
reward next is 0.5354, 
noisyNet noise sample is [array([-0.761014], dtype=float32), -0.3839966]. 
=============================================
[2019-03-18 13:15:22,601] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0673386e-19 7.0994507e-24 1.0000000e+00 8.1909170e-18 7.0504804e-20], sum to 1.0000
[2019-03-18 13:15:22,610] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7781
[2019-03-18 13:15:22,619] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 60.0, 1.0, 2.0, 0.2196589142488166, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4127915602567489, 6.9112, 6.9112, 77.32846344354104, 479180.5530418289, 479180.5530418289, 155942.7598152364], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2552400.0000, 
sim time next is 2553000.0000, 
raw observation next is [21.0, 59.33333333333333, 1.0, 2.0, 0.2359077211898518, 0.0, 2.0, 0.0, 1.0, 2.0, 0.442764320026995, 6.9112, 6.9112, 77.32846344354104, 514124.5857006753, 514124.5857006753, 158364.4949214149], 
processed observation next is [1.0, 0.5652173913043478, 0.5909090909090909, 0.5933333333333333, 1.0, 1.0, 0.04488465148731472, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2039490286099929, 0.0, 0.0, 0.5084288129206541, 0.19041651322247233, 0.19041651322247233, 0.3862548656619876], 
reward next is 0.4638, 
noisyNet noise sample is [array([0.783191], dtype=float32), 0.86774975]. 
=============================================
[2019-03-18 13:15:22,630] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[44.425484]
 [44.591103]
 [44.680977]
 [44.80245 ]
 [44.968586]], R is [[44.41017151]
 [44.40504456]
 [44.42593384]
 [44.44482803]
 [44.46473694]].
[2019-03-18 13:15:23,878] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2525017e-16 1.0927440e-22 1.0000000e+00 1.3260842e-15 1.2964814e-17], sum to 1.0000
[2019-03-18 13:15:23,888] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0145
[2019-03-18 13:15:23,895] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 50.0, 1.0, 2.0, 0.3539116351310972, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6721735708535309, 6.911200000000001, 6.9112, 77.32846344354104, 778751.9644787258, 778751.9644787256, 185489.4854809082], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2566800.0000, 
sim time next is 2567400.0000, 
raw observation next is [22.83333333333334, 50.5, 1.0, 2.0, 0.2222028687480592, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4205282293561783, 6.9112, 6.9112, 77.32846344354104, 487442.1132710903, 487442.1132710903, 157380.8751362489], 
processed observation next is [1.0, 0.7391304347826086, 0.6742424242424245, 0.505, 1.0, 1.0, 0.02775358593507398, 0.0, 1.0, -0.25, 1.0, 1.0, 0.17218318479454042, 0.0, 0.0, 0.5084288129206541, 0.18053411602632974, 0.18053411602632974, 0.38385579301524125], 
reward next is 0.4425, 
noisyNet noise sample is [array([1.2707914], dtype=float32), -0.25336185]. 
=============================================
[2019-03-18 13:15:24,814] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.3240905e-18 1.0213785e-21 1.0000000e+00 3.0020865e-16 1.2731663e-18], sum to 1.0000
[2019-03-18 13:15:24,828] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7998
[2019-03-18 13:15:24,838] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.51666666666667, 65.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 279231.6341993414, 279231.6341993411, 113656.1069201784], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2585400.0000, 
sim time next is 2586000.0000, 
raw observation next is [18.43333333333334, 67.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 280375.0153503872, 280375.0153503869, 114921.6464463464], 
processed observation next is [1.0, 0.9565217391304348, 0.4742424242424246, 0.67, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10384259827792118, 0.10384259827792108, 0.28029669864962536], 
reward next is 0.3485, 
noisyNet noise sample is [array([-0.24943955], dtype=float32), -1.0051959]. 
=============================================
[2019-03-18 13:15:24,855] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[40.416424]
 [40.44079 ]
 [40.474487]
 [40.498814]
 [40.526073]], R is [[40.34292984]
 [40.29047394]
 [40.24255371]
 [40.19382095]
 [40.14440536]].
[2019-03-18 13:15:32,576] A3C_AGENT_WORKER-Thread-18 INFO:Local step 4500, global step 71752: loss 0.0063
[2019-03-18 13:15:32,579] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 4500, global step 71753: learning rate 0.0010
[2019-03-18 13:15:32,834] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4500, global step 71850: loss 0.0134
[2019-03-18 13:15:32,836] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 4500, global step 71850: learning rate 0.0010
[2019-03-18 13:15:32,853] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4500, global step 71854: loss 0.0100
[2019-03-18 13:15:32,859] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 4500, global step 71855: learning rate 0.0010
[2019-03-18 13:15:32,879] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4500, global step 71865: loss 0.0086
[2019-03-18 13:15:32,881] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 4500, global step 71865: learning rate 0.0010
[2019-03-18 13:15:32,895] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4500, global step 71870: loss 0.0198
[2019-03-18 13:15:32,896] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 4500, global step 71870: learning rate 0.0010
[2019-03-18 13:15:33,069] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4500, global step 71936: loss 0.0008
[2019-03-18 13:15:33,071] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 4500, global step 71936: learning rate 0.0010
[2019-03-18 13:15:33,118] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4500, global step 71953: loss 0.0062
[2019-03-18 13:15:33,120] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 4500, global step 71953: learning rate 0.0010
[2019-03-18 13:15:33,177] A3C_AGENT_WORKER-Thread-20 INFO:Local step 4500, global step 71976: loss 0.0138
[2019-03-18 13:15:33,180] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 4500, global step 71976: learning rate 0.0010
[2019-03-18 13:15:33,235] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4500, global step 71999: loss 0.0163
[2019-03-18 13:15:33,236] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 4500, global step 71999: learning rate 0.0010
[2019-03-18 13:15:33,244] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4500, global step 72000: loss 0.0190
[2019-03-18 13:15:33,246] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 4500, global step 72000: learning rate 0.0010
[2019-03-18 13:15:33,267] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.8489475e-18 1.4882399e-23 1.0000000e+00 3.6042167e-15 3.3711689e-15], sum to 1.0000
[2019-03-18 13:15:33,278] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1278
[2019-03-18 13:15:33,286] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [17.46666666666667, 99.16666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3312899330700882, 6.911199999999999, 6.9112, 77.32846344354104, 382045.6504955766, 382045.6504955769, 150350.3692118523], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2704200.0000, 
sim time next is 2704800.0000, 
raw observation next is [17.93333333333333, 98.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.342091715284931, 6.9112, 6.9112, 77.32846344354104, 393720.9328433673, 393720.9328433673, 152379.3802256064], 
processed observation next is [0.0, 0.30434782608695654, 0.45151515151515137, 0.9833333333333334, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.060131021835615715, 0.0, 0.0, 0.5084288129206541, 0.14582256771976565, 0.14582256771976565, 0.37165702494050346], 
reward next is 0.3691, 
noisyNet noise sample is [array([-0.0365245], dtype=float32), -0.043054488]. 
=============================================
[2019-03-18 13:15:33,358] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4500, global step 72039: loss 0.0022
[2019-03-18 13:15:33,361] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 4500, global step 72039: learning rate 0.0010
[2019-03-18 13:15:33,425] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4500, global step 72065: loss 0.0001
[2019-03-18 13:15:33,431] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 4500, global step 72067: learning rate 0.0010
[2019-03-18 13:15:33,495] A3C_AGENT_WORKER-Thread-21 INFO:Local step 4500, global step 72089: loss 0.0015
[2019-03-18 13:15:33,499] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 4500, global step 72090: learning rate 0.0010
[2019-03-18 13:15:33,633] A3C_AGENT_WORKER-Thread-19 INFO:Local step 4500, global step 72142: loss 0.0009
[2019-03-18 13:15:33,638] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 4500, global step 72143: learning rate 0.0010
[2019-03-18 13:15:33,646] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4500, global step 72147: loss 0.0021
[2019-03-18 13:15:33,651] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 4500, global step 72147: learning rate 0.0010
[2019-03-18 13:15:33,918] A3C_AGENT_WORKER-Thread-22 INFO:Local step 4500, global step 72251: loss 0.0267
[2019-03-18 13:15:33,919] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 4500, global step 72251: learning rate 0.0010
[2019-03-18 13:15:36,519] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.8523673e-19 2.3796219e-26 1.0000000e+00 1.2142858e-16 1.6359383e-18], sum to 1.0000
[2019-03-18 13:15:36,530] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6288
[2019-03-18 13:15:36,540] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 87.16666666666667, 1.0, 2.0, 0.2522866079048604, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5106508372447277, 6.9112, 6.9112, 77.32846344354104, 574879.0405564978, 574879.0405564978, 179860.880268373], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2751000.0000, 
sim time next is 2751600.0000, 
raw observation next is [23.0, 85.33333333333334, 1.0, 2.0, 0.2492911783437798, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5042468118602205, 6.911200000000001, 6.9112, 77.32846344354104, 568454.8491451875, 568454.8491451873, 178573.693646405], 
processed observation next is [0.0, 0.8695652173913043, 0.6818181818181818, 0.8533333333333334, 1.0, 1.0, 0.06161397292972475, 0.0, 1.0, -0.25, 1.0, 1.0, 0.291781159800315, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21053883301673612, 0.21053883301673604, 0.43554559425952444], 
reward next is 0.4548, 
noisyNet noise sample is [array([-1.3121732], dtype=float32), 1.3177211]. 
=============================================
[2019-03-18 13:15:38,674] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.6752271e-16 1.2234010e-20 1.0000000e+00 1.1556703e-14 3.1288114e-12], sum to 1.0000
[2019-03-18 13:15:38,687] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2307
[2019-03-18 13:15:38,693] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.308422407783241, 6.9112, 6.9112, 77.32846344354104, 356815.0092823989, 356815.0092823989, 146546.779157124], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2778600.0000, 
sim time next is 2779200.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3086651482200139, 6.911199999999999, 6.9112, 77.32846344354104, 357095.8849514835, 357095.8849514838, 146573.8154355125], 
processed observation next is [1.0, 0.17391304347826086, 0.45454545454545453, 0.88, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.01237878317144844, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13225773516721612, 0.13225773516721623, 0.35749711081832314], 
reward next is 0.3480, 
noisyNet noise sample is [array([-0.34018004], dtype=float32), -1.9347779]. 
=============================================
[2019-03-18 13:15:41,784] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.4362512e-18 2.1596315e-26 1.0000000e+00 6.7853418e-22 1.8501044e-11], sum to 1.0000
[2019-03-18 13:15:41,796] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2565
[2019-03-18 13:15:41,801] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.33333333333333, 51.33333333333334, 1.0, 2.0, 0.2275400671773048, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4593981826188924, 6.911199999999999, 6.9112, 77.32846344354104, 519225.6154865143, 519225.6154865146, 172627.3205721685], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2828400.0000, 
sim time next is 2829000.0000, 
raw observation next is [28.16666666666667, 51.16666666666666, 1.0, 2.0, 0.2270667847644915, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4580211649145103, 6.911200000000001, 6.9112, 77.32846344354104, 518189.8476602717, 518189.8476602715, 172090.8383356569], 
processed observation next is [1.0, 0.7391304347826086, 0.9166666666666669, 0.5116666666666666, 1.0, 1.0, 0.03383348095561435, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2257445213064433, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19192216580010063, 0.19192216580010055, 0.4197337520381876], 
reward next is 0.4302, 
noisyNet noise sample is [array([0.6648307], dtype=float32), -1.4215405]. 
=============================================
[2019-03-18 13:15:41,816] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[59.877605]
 [60.159035]
 [60.714115]
 [61.801064]
 [62.785126]], R is [[59.61946869]
 [59.45295715]
 [59.28790665]
 [59.14590454]
 [59.12124252]].
[2019-03-18 13:15:42,617] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.3323893e-19 2.6923095e-28 1.0000000e+00 1.3403815e-21 1.9764703e-15], sum to 1.0000
[2019-03-18 13:15:42,628] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5778
[2019-03-18 13:15:42,635] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 54.0, 1.0, 2.0, 0.2254218159249247, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4531018249891295, 6.911199999999999, 6.9112, 77.32846344354104, 514192.7636929251, 514192.7636929254, 170358.339159492], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2835000.0000, 
sim time next is 2835600.0000, 
raw observation next is [27.0, 54.0, 1.0, 2.0, 0.2244395728013436, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4511231494201826, 6.9112, 6.9112, 77.32846344354104, 511949.8166195824, 511949.8166195824, 170155.5975988234], 
processed observation next is [1.0, 0.8260869565217391, 0.8636363636363636, 0.54, 1.0, 1.0, 0.030549466001679494, 0.0, 1.0, -0.25, 1.0, 1.0, 0.21589021345740375, 0.0, 0.0, 0.5084288129206541, 0.18961104319243793, 0.18961104319243793, 0.4150136526800571], 
reward next is 0.4298, 
noisyNet noise sample is [array([0.69697934], dtype=float32), 0.3825944]. 
=============================================
[2019-03-18 13:15:43,621] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.3121164e-19 9.6477535e-27 1.0000000e+00 2.8865766e-20 5.9407593e-16], sum to 1.0000
[2019-03-18 13:15:43,633] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5838
[2019-03-18 13:15:43,643] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 83.0, 1.0, 2.0, 0.2442549858007228, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4933419656523861, 6.911199999999999, 6.9112, 77.32846344354104, 557343.437838671, 557343.4378386713, 176488.0856998462], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2847600.0000, 
sim time next is 2848200.0000, 
raw observation next is [23.0, 82.16666666666667, 1.0, 2.0, 0.2430008903874825, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4905754622669447, 6.911200000000001, 6.9112, 77.32846344354104, 554532.7982444533, 554532.798244453, 175950.2759689712], 
processed observation next is [1.0, 1.0, 0.6818181818181818, 0.8216666666666668, 1.0, 1.0, 0.053751112984353096, 0.0, 1.0, -0.25, 1.0, 1.0, 0.2722506603813496, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20538251786831602, 0.20538251786831593, 0.4291470145584663], 
reward next is 0.4502, 
noisyNet noise sample is [array([0.01359308], dtype=float32), -0.60089505]. 
=============================================
[2019-03-18 13:15:53,444] A3C_AGENT_WORKER-Thread-18 INFO:Local step 5000, global step 79822: loss 0.9128
[2019-03-18 13:15:53,448] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 5000, global step 79822: learning rate 0.0010
[2019-03-18 13:15:53,573] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5000, global step 79845: loss 0.2811
[2019-03-18 13:15:53,576] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 5000, global step 79845: learning rate 0.0010
[2019-03-18 13:15:53,671] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5000, global step 79860: loss 0.8829
[2019-03-18 13:15:53,675] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 5000, global step 79860: learning rate 0.0010
[2019-03-18 13:15:53,787] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5000, global step 79888: loss 0.8874
[2019-03-18 13:15:53,790] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 5000, global step 79888: learning rate 0.0010
[2019-03-18 13:15:53,791] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5000, global step 79888: loss 1.7905
[2019-03-18 13:15:53,792] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 5000, global step 79888: learning rate 0.0010
[2019-03-18 13:15:54,057] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5000, global step 79948: loss 0.5879
[2019-03-18 13:15:54,060] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 5000, global step 79948: learning rate 0.0010
[2019-03-18 13:15:54,171] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5000, global step 79968: loss 1.2534
[2019-03-18 13:15:54,175] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 5000, global step 79968: learning rate 0.0010
[2019-03-18 13:15:54,270] A3C_AGENT_WORKER-Thread-20 INFO:Local step 5000, global step 79983: loss 0.6448
[2019-03-18 13:15:54,271] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5000, global step 79983: loss 0.4692
[2019-03-18 13:15:54,273] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 5000, global step 79983: learning rate 0.0010
[2019-03-18 13:15:54,275] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 5000, global step 79984: learning rate 0.0010
[2019-03-18 13:15:54,428] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5000, global step 79996: loss 0.7627
[2019-03-18 13:15:54,430] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 5000, global step 79996: learning rate 0.0010
[2019-03-18 13:15:54,525] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5000, global step 80011: loss 1.1280
[2019-03-18 13:15:54,528] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 5000, global step 80012: learning rate 0.0010
[2019-03-18 13:15:54,610] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5000, global step 80023: loss 1.5373
[2019-03-18 13:15:54,610] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 5000, global step 80023: learning rate 0.0010
[2019-03-18 13:15:54,903] A3C_AGENT_WORKER-Thread-19 INFO:Local step 5000, global step 80118: loss 1.1566
[2019-03-18 13:15:54,905] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 5000, global step 80119: learning rate 0.0010
[2019-03-18 13:15:55,013] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5000, global step 80139: loss 0.5570
[2019-03-18 13:15:55,018] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 5000, global step 80140: learning rate 0.0010
[2019-03-18 13:15:55,091] A3C_AGENT_WORKER-Thread-21 INFO:Local step 5000, global step 80147: loss 0.1755
[2019-03-18 13:15:55,093] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 5000, global step 80147: learning rate 0.0010
[2019-03-18 13:15:55,220] A3C_AGENT_WORKER-Thread-22 INFO:Local step 5000, global step 80173: loss 1.1967
[2019-03-18 13:15:55,228] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 5000, global step 80173: learning rate 0.0010
[2019-03-18 13:15:56,128] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.9333637e-20 2.4375253e-23 1.0000000e+00 4.3477573e-18 5.8546148e-24], sum to 1.0000
[2019-03-18 13:15:56,138] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6902
[2019-03-18 13:15:56,145] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.16666666666667, 72.33333333333333, 1.0, 2.0, 0.2204325590190731, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4410142489297061, 6.9112, 6.9112, 77.32846344354104, 501998.0857770644, 501998.0857770644, 167888.0206937445], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3012600.0000, 
sim time next is 3013200.0000, 
raw observation next is [23.0, 73.0, 1.0, 2.0, 0.2197348294149239, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4393546463249526, 6.911199999999999, 6.9112, 77.32846344354104, 500280.2890734402, 500280.2890734405, 167581.1549245633], 
processed observation next is [1.0, 0.9130434782608695, 0.6818181818181818, 0.73, 1.0, 1.0, 0.024668536768654853, 0.0, 1.0, -0.25, 1.0, 1.0, 0.1990780661785037, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.185288995953126, 0.1852889959531261, 0.40873452420625195], 
reward next is 0.4265, 
noisyNet noise sample is [array([0.7308423], dtype=float32), -0.9367232]. 
=============================================
[2019-03-18 13:16:07,864] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.4207027e-19 7.7304572e-26 1.0000000e+00 3.0770514e-19 3.4301482e-18], sum to 1.0000
[2019-03-18 13:16:07,873] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5686
[2019-03-18 13:16:07,878] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.33333333333334, 81.33333333333333, 1.0, 2.0, 0.2263113517050775, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4545361867712431, 6.911200000000001, 6.9112, 77.32846344354104, 516114.0226587578, 516114.0226587575, 170269.892379116], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3181200.0000, 
sim time next is 3181800.0000, 
raw observation next is [22.16666666666667, 82.16666666666667, 1.0, 2.0, 0.22570914664456, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4531417466151814, 6.9112, 6.9112, 77.32846344354104, 514677.3161875619, 514677.3161875619, 170010.2389233962], 
processed observation next is [1.0, 0.8260869565217391, 0.6439393939393941, 0.8216666666666668, 1.0, 1.0, 0.03213643330569997, 0.0, 1.0, -0.25, 1.0, 1.0, 0.21877392373597349, 0.0, 0.0, 0.5084288129206541, 0.1906212282176155, 0.1906212282176155, 0.41465911932535654], 
reward next is 0.4325, 
noisyNet noise sample is [array([1.5384966], dtype=float32), 0.6531817]. 
=============================================
[2019-03-18 13:16:07,909] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.6960371e-21 1.0239195e-26 1.0000000e+00 3.1576131e-19 1.4161430e-18], sum to 1.0000
[2019-03-18 13:16:07,914] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2668
[2019-03-18 13:16:07,919] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 88.00000000000001, 1.0, 2.0, 0.2188878624205118, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4378320118447858, 6.9112, 6.9112, 77.32846344354104, 498434.4322055266, 498434.4322055266, 167528.4542028249], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3190200.0000, 
sim time next is 3190800.0000, 
raw observation next is [21.0, 88.0, 1.0, 2.0, 0.2195529831921758, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4391660724400746, 6.9112, 6.9112, 77.32846344354104, 499951.5339478414, 499951.5339478414, 167659.457212503], 
processed observation next is [1.0, 0.9565217391304348, 0.5909090909090909, 0.88, 1.0, 1.0, 0.02444122899021975, 0.0, 1.0, -0.25, 1.0, 1.0, 0.19880867491439233, 0.0, 0.0, 0.5084288129206541, 0.18516723479549682, 0.18516723479549682, 0.4089255053963488], 
reward next is 0.4260, 
noisyNet noise sample is [array([0.50087273], dtype=float32), -0.06535069]. 
=============================================
