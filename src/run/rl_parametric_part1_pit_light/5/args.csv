reward_func,rwd_e_para,env,rmsprop_epsil,gamma,forecast_dim,train_freq,eval_act_func,decay_steps,violation_penalty_scl,test_env,is_warm_start,test_mode,h_regu_frac,agent_num,num_threads,metric_func,end_e,learning_rate,window_len,model_dir,is_learning_rate_decay_staircase,check_args_only,raw_state_prcs_func,sharedNet_type,isNoisyNetEval_rmNoise,model_param,eval_epi_num,action_space,init_e,max_interactions,activation,save_scope,learning_rate_decay_rate,eval_freq,action_repeat_n,model_type,save_freq,h_decay_bounds,clip_norm,v_loss_frac,output,train_act_func,state_dim,rwd_p_para,p_loss_frac,save_max_to_keep,weight_initer,dropout_prob,rmsprop_decay,is_greedy_policy,rmsprop_momet,learning_rate_decay_steps,job_mode,isNoisyNet,debug_log_prob
part1_v1,1.2,Part1-Light-Pit-Train-v1,1e-10,0.99,0,5,part1_v1,1000000,10.0,"['Part1-Light-Pit-Test-v1', 'Part1-Light-Pit-Test-v2', 'Part1-Light-Pit-Test-v3', 'Part1-Light-Pit-Test-v4']",False,Multiple,[0.0],5,16,part1_v1,0.0,1e-05,35,None,False,True,cslDx_1,Dense,True,"[73, 1]",1,part1_v1,0.0,2500000,linear,all,1.0,100000,1,nn,500000,[],5.0,0.5,.,part1_v1,71,1.0,1.0,5,glorot_uniform,0.0,0.99,False,0.0,100000,Train,True,0.0005
