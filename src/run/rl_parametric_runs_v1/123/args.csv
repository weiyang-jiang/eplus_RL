reward_func,train_freq,is_learning_rate_decay_staircase,learning_rate_decay_rate,isNoisyNetEval_rmNoise,eval_act_func,window_len,model_type,debug_log_prob,eval_epi_num,decay_steps,sharedNet_type,test_env,h_regu_frac,save_max_to_keep,test_mode,rwd_e_para,activation,check_args_only,eval_freq,action_repeat_n,h_decay_bounds,clip_norm,job_mode,raw_state_prcs_func,rmsprop_decay,init_e,metric_func,dropout_prob,gamma,violation_penalty_scl,isNoisyNet,v_loss_frac,weight_initer,p_loss_frac,state_dim,action_space,forecast_dim,is_warm_start,learning_rate_decay_steps,train_act_func,rwd_p_para,env,end_e,save_scope,max_interactions,rmsprop_epsil,is_greedy_policy,rmsprop_momet,output,model_dir,agent_num,learning_rate,model_param,num_threads,save_freq
cslDxCool_1,5,False,0.9,False,cslDxActCool_1,6,lstm,0.0005,1,1000000,Dense,Model1-Test-Cool-v1,[0.1],5,Multiple,1.0,tanh/linear,True,250000,1,[],5.0,Train,cslDx_1,0.99,0.0,cslDxCool_1,0.0,0.99,10.0,False,0.5,glorot_uniform,1.0,49,cslDxCool_1,0,False,100000,cslDxActCool_1,1.0,Model1-Cool-v1,0.0,all,10000000,1e-10,False,0.0,a3c-res-v0.1,None,5,0.001,"[512, 4, 512, 4]",16,500000
