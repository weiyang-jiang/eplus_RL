reward_func,max_interactions,state_dim,test_env,train_act_func,save_freq,gamma,is_warm_start,save_scope,test_mode,train_freq,num_threads,violation_penalty_scl,eval_epi_num,end_e,forecast_dim,is_greedy_policy,h_regu_frac,weight_initer,job_mode,sharedNet_type,rwd_e_para,env,agent_num,save_max_to_keep,init_e,window_len,isNoisyNet,raw_state_prcs_func,learning_rate_decay_steps,model_dir,v_loss_frac,clip_norm,learning_rate,model_param,rmsprop_decay,decay_steps,learning_rate_decay_rate,model_type,dropout_prob,eval_act_func,isNoisyNetEval_rmNoise,output,rwd_p_para,metric_func,h_decay_bounds,eval_freq,action_space,check_args_only,action_repeat_n,activation,debug_log_prob,is_learning_rate_decay_staircase,rmsprop_epsil,rmsprop_momet,p_loss_frac
cslDxCool_1,10000000,49,Model1-Test-Cool-v1,cslDxActCool_1,500000,0.99,False,all,Multiple,5,16,10.0,1,0.0,0,False,[0.01],glorot_uniform,Train,Dense,1.0,Model1-Cool-v1,5,5,0.0,3,False,cslDx_1,100000,None,0.5,5.0,0.01,"[512, 4]",0.99,1000000,0.96,nn,0.0,cslDxActCool_1,False,a3c-res-v0.1,1.0,cslDxCool_1,[],250000,cslDxCool_1,True,1,relu,0.0005,False,1e-10,0.0,1.0
