reward_func,init_e,model_type,debug_log_prob,v_loss_frac,rmsprop_decay,env,weight_initer,h_regu_frac,action_space,h_decay_bounds,decay_steps,eval_freq,activation,state_dim,model_dir,check_args_only,learning_rate_decay_rate,end_e,rwd_e_para,dropout_prob,model_param,save_max_to_keep,learning_rate_decay_steps,isNoisyNetEval_rmNoise,save_freq,is_greedy_policy,output,clip_norm,is_learning_rate_decay_staircase,num_threads,train_act_func,raw_state_prcs_func,learning_rate,agent_num,metric_func,job_mode,gamma,isNoisyNet,action_repeat_n,forecast_dim,max_interactions,save_scope,rmsprop_momet,sharedNet_type,p_loss_frac,train_freq,test_env,eval_act_func,eval_epi_num,window_len,rmsprop_epsil,is_warm_start,rwd_p_para,test_mode,violation_penalty_scl
cslDxCool_1,0.0,lstm,0.0005,0.5,0.99,Model1-Cool-v1,glorot_uniform,[0.1],cslDxCool_1,[],1000000,250000,tanh/linear,49,None,True,0.9,0.0,1.0,0.0,"[512, 1, 512, 1]",5,100000,False,500000,False,a3c-res-v0.1,5.0,False,16,cslDxActCool_1,cslDx_1,0.001,5,cslDxCool_1,Train,0.99,False,1,0,10000000,all,0.0,Dense,1.0,5,Model1-Test-Cool-v1,cslDxActCool_1,1,6,1e-10,False,1.0,Multiple,10.0
