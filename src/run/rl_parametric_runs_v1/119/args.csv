reward_func,h_decay_bounds,env,weight_initer,isNoisyNet,learning_rate_decay_steps,rmsprop_decay,eval_act_func,metric_func,train_act_func,train_freq,is_greedy_policy,agent_num,window_len,rwd_e_para,clip_norm,dropout_prob,num_threads,is_warm_start,rmsprop_epsil,model_type,action_space,test_env,save_scope,rwd_p_para,save_freq,eval_epi_num,model_param,test_mode,sharedNet_type,forecast_dim,save_max_to_keep,init_e,action_repeat_n,isNoisyNetEval_rmNoise,learning_rate,state_dim,raw_state_prcs_func,is_learning_rate_decay_staircase,v_loss_frac,job_mode,eval_freq,end_e,model_dir,decay_steps,max_interactions,violation_penalty_scl,p_loss_frac,output,check_args_only,rmsprop_momet,activation,learning_rate_decay_rate,h_regu_frac,gamma,debug_log_prob
cslDxCool_1,[],Model1-Cool-v1,glorot_uniform,False,100000,0.99,cslDxActCool_1,cslDxCool_1,cslDxActCool_1,5,False,5,6,1.0,5.0,0.0,16,False,1e-10,lstm,cslDxCool_1,Model1-Test-Cool-v1,all,1.0,500000,1,"[512, 2, 512, 2]",Multiple,Dense,0,5,0.0,1,False,0.001,49,cslDx_1,False,0.5,Train,250000,0.0,None,1000000,10000000,10.0,1.0,a3c-res-v0.1,True,0.0,tanh/linear,0.9,[0.1],0.99,0.0005
