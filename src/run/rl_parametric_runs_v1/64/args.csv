eval_act_func,activation,action_space,learning_rate_decay_rate,learning_rate_decay_steps,is_greedy_policy,gamma,save_scope,agent_num,violation_penalty_scl,model_dir,train_freq,end_e,max_interactions,clip_norm,rmsprop_epsil,test_env,isNoisyNetEval_rmNoise,debug_log_prob,isNoisyNet,learning_rate,rmsprop_momet,save_freq,window_len,action_repeat_n,model_type,reward_func,decay_steps,num_threads,init_e,dropout_prob,state_dim,train_act_func,forecast_dim,env,p_loss_frac,h_regu_frac,is_warm_start,is_learning_rate_decay_staircase,rwd_e_para,raw_state_prcs_func,rmsprop_decay,sharedNet_type,eval_freq,v_loss_frac,h_decay_bounds,model_param,weight_initer,job_mode,output,metric_func,save_max_to_keep,check_args_only,eval_epi_num,rwd_p_para,test_mode
cslDxActCool_1,tanh/relu,cslDxCool_1,0.96,100000,False,0.99,all,5,10.0,None,5,0.0,10000000,5.0,1e-10,Model1-Test-Cool-v1,False,0.0005,False,0.001,0.0,500000,3,1,lstm,cslDxCool_1,1000000,16,0.0,0.0,49,cslDxActCool_1,0,Model1-Cool-v1,1.0,[0.1],False,False,1.0,cslDx_1,0.99,Dense,250000,0.5,[],"[128, 2, 128, 2]",glorot_uniform,Train,a3c-res-v0.1,cslDxCool_1,5,True,1,1.0,Multiple
