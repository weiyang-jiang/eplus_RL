Using TensorFlow backend.
[2019-03-26 14:17:28,333] A3C_AGENT_MAIN INFO:Namespace(action_repeat_n=1, action_space='part3_v1', activation='linear', agent_num=5, check_args_only=False, clip_norm=5.0, debug_log_prob=0.0005, decay_steps=1000000, dropout_prob=0.0, end_e=0.0, env='Part3-NA-Shg-Train-v1', eval_act_func='part3_shg_det_v1', eval_env_res_max_keep=50, eval_epi_num=1, eval_freq=25000, forecast_dim=0, gamma=0.99, h_decay_bounds=[], h_regu_frac=[0.0], init_e=0.0, isNoisyNet=True, isNoisyNetEval_rmNoise=True, is_greedy_policy=False, is_learning_rate_decay_staircase=False, is_warm_start=False, job_mode='Train', learning_rate=1e-05, learning_rate_decay_rate=1.0, learning_rate_decay_steps=100000, max_interactions=2500000, metric_func='part3_v1', model_dir='None', model_param=[19, 1], model_type='nn', num_threads=16, output='./Part3-NA-Shg-Train-v1-res1', p_loss_frac=1.0, raw_state_prcs_func='cslDx_1', reward_func='part3_v3', rmsprop_decay=0.99, rmsprop_epsil=1e-10, rmsprop_momet=0.0, rwd_e_para=1.0, rwd_p_para=1.0, save_freq=500000, save_max_to_keep=5, save_scope='all', sharedNet_type='Dense', state_dim=17, test_env=['Part3-NA-Shg-Test-v1', 'Part3-NA-Shg-Test-v2', 'Part3-NA-Shg-Test-v3', 'Part3-NA-Shg-Test-v4'], test_mode='Multiple', train_act_func='part3_shg_sto_v1', train_freq=5, v_loss_frac=0.5, violation_penalty_scl=50.0, weight_initer='glorot_uniform', window_len=29)
[2019-03-26 14:17:28,334] A3C_AGENT_MAIN INFO:Start compiling...
2019-03-26 14:17:28.366847: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[2019-03-26 14:17:45,050] A3C_AGENT_MAIN INFO:Start the learning...
[2019-03-26 14:17:45,051] A3C_AGENT_MAIN INFO:Prepare the evaluation environments ['Part3-NA-Shg-Train-v1', 'Part3-NA-Shg-Test-v1', 'Part3-NA-Shg-Test-v2', 'Part3-NA-Shg-Test-v3', 'Part3-NA-Shg-Test-v4'] ...
[2019-03-26 14:17:45,060] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation worker starts!
[2019-03-26 14:17:45,065] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation worker starts!
[2019-03-26 14:17:45,070] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation worker starts!
[2019-03-26 14:17:45,075] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation worker starts!
[2019-03-26 14:17:45,078] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation worker starts!
[2019-03-26 14:17:45,078] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 14:17:45,079] A3C_AGENT_WORKER-Thread-2 INFO:Local worker starts!
[2019-03-26 14:17:45,134] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:17:45,135] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run1
[2019-03-26 14:17:46,080] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 14:17:46,081] A3C_AGENT_WORKER-Thread-3 INFO:Local worker starts!
[2019-03-26 14:17:46,146] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:17:46,146] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run1
[2019-03-26 14:17:46,329] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-26 14:17:46,329] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 14:17:46,330] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 14:17:46,330] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:17:46,330] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 14:17:46,331] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 14:17:46,331] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:17:46,331] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:17:46,332] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:17:46,331] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 14:17:46,332] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:17:46,336] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run1
[2019-03-26 14:17:46,336] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run1
[2019-03-26 14:17:46,337] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run1
[2019-03-26 14:17:46,344] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run1
[2019-03-26 14:17:46,373] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run1
[2019-03-26 14:17:47,082] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 14:17:47,083] A3C_AGENT_WORKER-Thread-9 INFO:Local worker starts!
[2019-03-26 14:17:47,162] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:17:47,163] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run1
[2019-03-26 14:17:48,084] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 14:17:48,087] A3C_AGENT_WORKER-Thread-10 INFO:Local worker starts!
[2019-03-26 14:17:48,144] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:17:48,144] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run1
[2019-03-26 14:17:49,089] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 14:17:49,092] A3C_AGENT_WORKER-Thread-11 INFO:Local worker starts!
[2019-03-26 14:17:49,147] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:17:49,149] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run1
[2019-03-26 14:17:50,092] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 14:17:50,095] A3C_AGENT_WORKER-Thread-12 INFO:Local worker starts!
[2019-03-26 14:17:50,161] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:17:50,162] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run1
[2019-03-26 14:17:51,096] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 14:17:51,104] A3C_AGENT_WORKER-Thread-13 INFO:Local worker starts!
[2019-03-26 14:17:51,185] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:17:51,187] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run1
[2019-03-26 14:17:52,101] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 14:17:52,108] A3C_AGENT_WORKER-Thread-14 INFO:Local worker starts!
[2019-03-26 14:17:52,182] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:17:52,183] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run1
[2019-03-26 14:17:53,106] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 14:17:53,110] A3C_AGENT_WORKER-Thread-15 INFO:Local worker starts!
[2019-03-26 14:17:53,164] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:17:53,164] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run1
[2019-03-26 14:17:54,110] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 14:17:54,113] A3C_AGENT_WORKER-Thread-16 INFO:Local worker starts!
[2019-03-26 14:17:54,178] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:17:54,179] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run1
[2019-03-26 14:17:55,113] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 14:17:55,118] A3C_AGENT_WORKER-Thread-17 INFO:Local worker starts!
[2019-03-26 14:17:55,220] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:17:55,221] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run1
[2019-03-26 14:17:56,117] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 14:17:56,120] A3C_AGENT_WORKER-Thread-18 INFO:Local worker starts!
[2019-03-26 14:17:56,173] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:17:56,174] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run1
[2019-03-26 14:17:57,122] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 14:17:57,127] A3C_AGENT_WORKER-Thread-19 INFO:Local worker starts!
[2019-03-26 14:17:57,224] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:17:57,224] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run1
[2019-03-26 14:17:58,126] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 14:17:58,130] A3C_AGENT_WORKER-Thread-20 INFO:Local worker starts!
[2019-03-26 14:17:58,183] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:17:58,184] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run1
[2019-03-26 14:17:59,129] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 14:17:59,134] A3C_AGENT_WORKER-Thread-21 INFO:Local worker starts!
[2019-03-26 14:17:59,189] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:17:59,190] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run1
[2019-03-26 14:18:00,133] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 14:18:00,136] A3C_AGENT_WORKER-Thread-22 INFO:Local worker starts!
[2019-03-26 14:18:00,195] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:18:00,196] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run1
[2019-03-26 14:18:09,382] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-26 14:18:09,384] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.0, 84.0, 1.0, 2.0, 0.17, 1.0, 1.0, 0.17, 1.0, 2.0, 0.2400930986485386, 6.9112, 6.9112, 170.5573041426782, 610162.1693887323, 610162.1693887323, 246627.3668036331]
[2019-03-26 14:18:09,385] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 14:18:09,388] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [0.18767612 0.21391414 0.29088172 0.27840814 0.02911981], sampled 0.10881529628991049
[2019-03-26 14:19:42,046] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 4096.9668 3448682037.1867 1050.0000
[2019-03-26 14:19:42,135] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 4189.4818 3295479292.6964 964.0000
[2019-03-26 14:19:42,367] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 4322.4004 3157033896.6782 606.0000
[2019-03-26 14:19:42,407] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 4277.0284 3111293297.6850 549.0000
[2019-03-26 14:19:42,410] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 4317.4139 3231718579.8111 706.0000
[2019-03-26 14:19:43,423] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 0, evaluation results [0.0, 4096.966819411209, 3448682037.186697, 1050.0, 4317.413915407258, 3231718579.811099, 706.0, 4277.028408690734, 3111293297.684951, 549.0, 4189.481829185215, 3295479292.696386, 964.0, 4322.400390758529, 3157033896.6781735, 606.0]
[2019-03-26 14:19:45,570] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.21724305 0.38661462 0.14298283 0.16617237 0.08698719], sum to 1.0000
[2019-03-26 14:19:45,577] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6819
[2019-03-26 14:19:45,671] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.2, 84.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.4983174979004336, 6.9112, 6.9112, 168.912956510431, 442406.1943459234, 442406.1943459234, 151732.2229975646], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3600.0000, 
sim time next is 4200.0000, 
raw observation next is [20.26666666666667, 84.16666666666667, 1.0, 1.0, 0.17, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2456334254456415, 6.911199999999999, 6.9112, 168.912956510431, 437108.9403396423, 437108.9403396429, 181678.1261561768], 
processed observation next is [1.0, 0.043478260869565216, 0.15955766192733034, 0.8416666666666667, 1.0, 0.5, 0.0, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.0800407627385872, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12141915009434508, 0.12141915009434526, 0.2711613823226519], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.3122218], dtype=float32), 0.3299331]. 
=============================================
[2019-03-26 14:20:00,113] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.17395398 0.29481417 0.3552162  0.16477814 0.01123757], sum to 1.0000
[2019-03-26 14:20:00,121] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0466
[2019-03-26 14:20:00,222] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.5, 91.0, 1.0, 2.0, 0.283538673397948, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 455739.8957269777, 455739.895726977, 163981.1503470945], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 255600.0000, 
sim time next is 256200.0000, 
raw observation next is [20.5, 91.16666666666667, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5163599176600696, 6.9112, 6.9112, 168.912956510431, 455922.8266757238, 455922.8266757238, 154125.4546744875], 
processed observation next is [0.0, 1.0, 0.1706161137440759, 0.9116666666666667, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 0.5, 0.41019502153667026, 0.0, 0.0, 0.8294399451523027, 0.1266452296321455, 0.1266452296321455, 0.23003799205147388], 
reward next is 0.7700, 
noisyNet noise sample is [array([-0.04845324], dtype=float32), 2.0056133]. 
=============================================
[2019-03-26 14:20:01,000] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.25929153 0.24645334 0.38970828 0.09694684 0.00759994], sum to 1.0000
[2019-03-26 14:20:01,010] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9751
[2019-03-26 14:20:01,118] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.53333333333333, 95.16666666666667, 1.0, 2.0, 0.17, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2463474529851975, 6.911199999999998, 6.9112, 168.912956510431, 436380.2894901971, 436380.2894901984, 182009.9428317052], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 274200.0000, 
sim time next is 274800.0000, 
raw observation next is [19.46666666666667, 95.33333333333334, 1.0, 2.0, 0.17, 1.0, 1.0, 0.17, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 434407.4157892678, 434407.4157892678, 220489.8960171746], 
processed observation next is [0.0, 0.17391304347826086, 0.12164296998420236, 0.9533333333333335, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.12066872660812994, 0.12066872660812994, 0.32908939704055906], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2161084], dtype=float32), -0.85063183]. 
=============================================
[2019-03-26 14:20:02,517] A3C_AGENT_WORKER-Thread-12 INFO:Local step 500, global step 7916: loss -0.1007
[2019-03-26 14:20:02,570] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 500, global step 7916: learning rate 0.0000
[2019-03-26 14:20:02,599] A3C_AGENT_WORKER-Thread-14 INFO:Local step 500, global step 7936: loss 3.1579
[2019-03-26 14:20:02,602] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 500, global step 7937: learning rate 0.0000
[2019-03-26 14:20:02,623] A3C_AGENT_WORKER-Thread-10 INFO:Local step 500, global step 7948: loss 1.5620
[2019-03-26 14:20:02,626] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 500, global step 7948: learning rate 0.0000
[2019-03-26 14:20:02,658] A3C_AGENT_WORKER-Thread-21 INFO:Local step 500, global step 7966: loss 5.0826
[2019-03-26 14:20:02,659] A3C_AGENT_WORKER-Thread-9 INFO:Local step 500, global step 7966: loss 3.9069
[2019-03-26 14:20:02,661] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 500, global step 7966: learning rate 0.0000
[2019-03-26 14:20:02,663] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 500, global step 7966: learning rate 0.0000
[2019-03-26 14:20:02,669] A3C_AGENT_WORKER-Thread-13 INFO:Local step 500, global step 7971: loss 16.3946
[2019-03-26 14:20:02,672] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 500, global step 7971: learning rate 0.0000
[2019-03-26 14:20:02,673] A3C_AGENT_WORKER-Thread-15 INFO:Local step 500, global step 7971: loss 6.6666
[2019-03-26 14:20:02,680] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 500, global step 7972: learning rate 0.0000
[2019-03-26 14:20:02,695] A3C_AGENT_WORKER-Thread-22 INFO:Local step 500, global step 7980: loss 19.1329
[2019-03-26 14:20:02,697] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 500, global step 7980: learning rate 0.0000
[2019-03-26 14:20:02,711] A3C_AGENT_WORKER-Thread-18 INFO:Local step 500, global step 7986: loss 17.6906
[2019-03-26 14:20:02,714] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 500, global step 7986: learning rate 0.0000
[2019-03-26 14:20:02,727] A3C_AGENT_WORKER-Thread-3 INFO:Local step 500, global step 7993: loss 1.3768
[2019-03-26 14:20:02,730] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 500, global step 7995: learning rate 0.0000
[2019-03-26 14:20:02,739] A3C_AGENT_WORKER-Thread-11 INFO:Local step 500, global step 7998: loss 1.0736
[2019-03-26 14:20:02,742] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 500, global step 7999: learning rate 0.0000
[2019-03-26 14:20:02,770] A3C_AGENT_WORKER-Thread-20 INFO:Local step 500, global step 8012: loss 6.2019
[2019-03-26 14:20:02,771] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 500, global step 8012: learning rate 0.0000
[2019-03-26 14:20:02,783] A3C_AGENT_WORKER-Thread-19 INFO:Local step 500, global step 8019: loss 0.1794
[2019-03-26 14:20:02,784] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 500, global step 8019: learning rate 0.0000
[2019-03-26 14:20:02,822] A3C_AGENT_WORKER-Thread-2 INFO:Local step 500, global step 8038: loss 17.0683
[2019-03-26 14:20:02,825] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 500, global step 8039: learning rate 0.0000
[2019-03-26 14:20:02,829] A3C_AGENT_WORKER-Thread-17 INFO:Local step 500, global step 8039: loss 12.1762
[2019-03-26 14:20:02,831] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 500, global step 8040: learning rate 0.0000
[2019-03-26 14:20:02,855] A3C_AGENT_WORKER-Thread-16 INFO:Local step 500, global step 8052: loss -3.8618
[2019-03-26 14:20:02,859] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 500, global step 8052: learning rate 0.0000
[2019-03-26 14:20:07,997] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.17937382 0.48669332 0.27529004 0.05366655 0.00497637], sum to 1.0000
[2019-03-26 14:20:08,007] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.15960872 0.38937664 0.38851953 0.0602074  0.00228772], sum to 1.0000
[2019-03-26 14:20:08,007] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5341
[2019-03-26 14:20:08,013] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.68333333333333, 73.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.570016867221166, 6.911200000000001, 6.9112, 168.912956510431, 504413.3474573882, 504413.3474573876, 161391.7437120602], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 391800.0000, 
sim time next is 392400.0000, 
raw observation next is [22.7, 73.0, 1.0, 1.0, 0.3208541955583899, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.912956510431, 518560.6218782662, 518560.6218782662, 168466.7604623978], 
processed observation next is [1.0, 0.5652173913043478, 0.27488151658767773, 0.73, 1.0, 0.5, 0.18175204284143362, 0.0, 1.0, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14404461718840728, 0.14404461718840728, 0.2514429260632803], 
reward next is 0.7486, 
noisyNet noise sample is [array([0.07186801], dtype=float32), -1.8348148]. 
=============================================
[2019-03-26 14:20:08,019] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1793
[2019-03-26 14:20:08,126] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.56666666666667, 72.83333333333333, 1.0, 2.0, 0.5086680743245704, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 824134.3303615414, 824134.3303615414, 197071.6434930955], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 388200.0000, 
sim time next is 388800.0000, 
raw observation next is [22.6, 73.0, 1.0, 2.0, 0.5011530477389516, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 811252.6944798813, 811252.6944798807, 195670.2670836571], 
processed observation next is [1.0, 0.5217391304347826, 0.27014218009478685, 0.73, 1.0, 1.0, 0.39897957558909836, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22534797068885593, 0.22534797068885576, 0.292045174751727], 
reward next is 0.7080, 
noisyNet noise sample is [array([-0.18660687], dtype=float32), -0.37674996]. 
=============================================
[2019-03-26 14:20:19,852] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1000, global step 15909: loss 13.4844
[2019-03-26 14:20:19,856] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1000, global step 15911: learning rate 0.0000
[2019-03-26 14:20:19,866] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1000, global step 15917: loss 6.0181
[2019-03-26 14:20:19,868] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1000, global step 15917: learning rate 0.0000
[2019-03-26 14:20:19,886] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1000, global step 15925: loss 5.3331
[2019-03-26 14:20:19,889] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1000, global step 15926: learning rate 0.0000
[2019-03-26 14:20:19,900] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1000, global step 15929: loss 6.3607
[2019-03-26 14:20:19,903] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1000, global step 15930: learning rate 0.0000
[2019-03-26 14:20:19,918] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1000, global step 15937: loss -0.1495
[2019-03-26 14:20:19,919] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1000, global step 15937: learning rate 0.0000
[2019-03-26 14:20:19,949] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1000, global step 15950: loss 7.6226
[2019-03-26 14:20:19,950] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 1000, global step 15950: learning rate 0.0000
[2019-03-26 14:20:19,965] A3C_AGENT_WORKER-Thread-21 INFO:Local step 1000, global step 15957: loss 7.5759
[2019-03-26 14:20:19,969] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 1000, global step 15958: learning rate 0.0000
[2019-03-26 14:20:19,984] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1000, global step 15968: loss 3.2653
[2019-03-26 14:20:19,986] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1000, global step 15968: learning rate 0.0000
[2019-03-26 14:20:20,024] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1000, global step 15986: loss 6.1699
[2019-03-26 14:20:20,025] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1000, global step 15987: learning rate 0.0000
[2019-03-26 14:20:20,059] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1000, global step 16002: loss 1.8586
[2019-03-26 14:20:20,061] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1000, global step 16003: learning rate 0.0000
[2019-03-26 14:20:20,078] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1000, global step 16011: loss 6.6018
[2019-03-26 14:20:20,079] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1000, global step 16011: learning rate 0.0000
[2019-03-26 14:20:20,089] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1000, global step 16013: loss 6.3975
[2019-03-26 14:20:20,092] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1000, global step 16014: learning rate 0.0000
[2019-03-26 14:20:20,103] A3C_AGENT_WORKER-Thread-22 INFO:Local step 1000, global step 16020: loss 5.9501
[2019-03-26 14:20:20,106] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 1000, global step 16021: learning rate 0.0000
[2019-03-26 14:20:20,206] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1000, global step 16070: loss 7.4435
[2019-03-26 14:20:20,212] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1000, global step 16071: learning rate 0.0000
[2019-03-26 14:20:20,263] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1000, global step 16097: loss 8.9568
[2019-03-26 14:20:20,265] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1000, global step 16097: learning rate 0.0000
[2019-03-26 14:20:20,314] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1000, global step 16119: loss 5.8805
[2019-03-26 14:20:20,317] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1000, global step 16119: learning rate 0.0000
[2019-03-26 14:20:23,973] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.6390998e-02 8.9802539e-01 7.2616927e-02 2.9289036e-03 3.7802849e-05], sum to 1.0000
[2019-03-26 14:20:23,982] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3376
[2019-03-26 14:20:24,088] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.96666666666667, 62.66666666666667, 1.0, 2.0, 0.2497542568945788, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 411159.580403137, 411159.5804031377, 160874.4699915117], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 670800.0000, 
sim time next is 671400.0000, 
raw observation next is [22.75, 64.0, 1.0, 2.0, 0.2477770850463792, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 407900.3416524674, 407900.341652468, 160680.6588214141], 
processed observation next is [1.0, 0.782608695652174, 0.27725118483412325, 0.64, 1.0, 1.0, 0.09370733138117973, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11330565045901872, 0.1133056504590189, 0.23982187883793152], 
reward next is 0.7602, 
noisyNet noise sample is [array([-0.32080534], dtype=float32), -0.39315283]. 
=============================================
[2019-03-26 14:20:26,616] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.5343033e-02 8.8225013e-01 1.0052520e-01 1.8455139e-03 3.6087538e-05], sum to 1.0000
[2019-03-26 14:20:26,623] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0809
[2019-03-26 14:20:26,628] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.03333333333333, 84.83333333333334, 1.0, 2.0, 0.2348593271864305, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 389869.3055047795, 389869.3055047789, 159212.0337395724], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 713400.0000, 
sim time next is 714000.0000, 
raw observation next is [19.26666666666667, 83.66666666666667, 1.0, 2.0, 0.2273105243081439, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 377038.4691451734, 377038.4691451727, 158558.7234487103], 
processed observation next is [1.0, 0.2608695652173913, 0.1121642969984204, 0.8366666666666667, 1.0, 1.0, 0.06904882446764325, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1047329080958815, 0.1047329080958813, 0.23665481111747808], 
reward next is 0.7633, 
noisyNet noise sample is [array([-0.9305087], dtype=float32), -0.80759037]. 
=============================================
[2019-03-26 14:20:26,648] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[18.061115]
 [18.007181]
 [17.910742]
 [17.89865 ]
 [17.898138]], R is [[18.67977142]
 [19.25534439]
 [19.82677078]
 [20.39279556]
 [20.9535141 ]].
[2019-03-26 14:20:27,096] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.4267196e-02 8.3193749e-01 1.0181103e-01 1.9678469e-03 1.6428567e-05], sum to 1.0000
[2019-03-26 14:20:27,105] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6039
[2019-03-26 14:20:27,201] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.78333333333333, 67.16666666666667, 1.0, 2.0, 0.2614723346752234, 0.0, 2.0, 0.0, 1.0, 1.0, 0.4799628592581696, 6.9112, 6.9112, 168.912956510431, 853277.6490000526, 853277.6490000526, 220235.9477934655], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 724200.0000, 
sim time next is 724800.0000, 
raw observation next is [22.96666666666667, 66.33333333333334, 1.0, 2.0, 0.5340383296237438, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.912956510431, 872045.3916993379, 872045.3916993379, 202095.244166643], 
processed observation next is [1.0, 0.391304347826087, 0.2875197472353872, 0.6633333333333334, 1.0, 1.0, 0.43860039713704063, 0.0, 1.0, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.24223483102759386, 0.24223483102759386, 0.30163469278603433], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.33036128], dtype=float32), -1.0934843]. 
=============================================
[2019-03-26 14:20:32,217] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.7985104e-02 9.3073094e-01 5.0240740e-02 1.0349910e-03 8.3462128e-06], sum to 1.0000
[2019-03-26 14:20:32,226] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7860
[2019-03-26 14:20:32,323] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 73.0, 1.0, 2.0, 0.2874972932409157, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 461288.1406071365, 461288.1406071359, 164353.5380346322], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 810000.0000, 
sim time next is 810600.0000, 
raw observation next is [23.28333333333334, 72.0, 1.0, 2.0, 0.2879159252807811, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 461782.0591718462, 461782.0591718456, 164385.9963949967], 
processed observation next is [0.0, 0.391304347826087, 0.30252764612954214, 0.72, 1.0, 1.0, 0.14206737985636275, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12827279421440171, 0.12827279421440155, 0.24535223342536822], 
reward next is 0.7546, 
noisyNet noise sample is [array([-0.62396663], dtype=float32), -0.2749375]. 
=============================================
[2019-03-26 14:20:36,685] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1500, global step 23873: loss 4.2499
[2019-03-26 14:20:36,689] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1500, global step 23874: learning rate 0.0000
[2019-03-26 14:20:36,699] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1500, global step 23877: loss 4.5784
[2019-03-26 14:20:36,701] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1500, global step 23878: learning rate 0.0000
[2019-03-26 14:20:36,807] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1500, global step 23923: loss 4.8986
[2019-03-26 14:20:36,811] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1500, global step 23924: learning rate 0.0000
[2019-03-26 14:20:36,845] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1500, global step 23941: loss 3.7503
[2019-03-26 14:20:36,850] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1500, global step 23942: loss 4.0519
[2019-03-26 14:20:36,851] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1500, global step 23942: learning rate 0.0000
[2019-03-26 14:20:36,854] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 1500, global step 23942: learning rate 0.0000
[2019-03-26 14:20:36,894] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1500, global step 23968: loss 3.9667
[2019-03-26 14:20:36,896] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1500, global step 23968: learning rate 0.0000
[2019-03-26 14:20:36,915] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1500, global step 23979: loss 3.8408
[2019-03-26 14:20:36,919] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1500, global step 23979: learning rate 0.0000
[2019-03-26 14:20:36,924] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1500, global step 23983: loss 6.1350
[2019-03-26 14:20:36,928] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1500, global step 23984: learning rate 0.0000
[2019-03-26 14:20:36,929] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1500, global step 23984: loss 3.7540
[2019-03-26 14:20:36,932] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1500, global step 23985: learning rate 0.0000
[2019-03-26 14:20:36,949] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1500, global step 23991: loss 3.6246
[2019-03-26 14:20:36,950] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1500, global step 23991: learning rate 0.0000
[2019-03-26 14:20:36,977] A3C_AGENT_WORKER-Thread-21 INFO:Local step 1500, global step 24000: loss -0.2587
[2019-03-26 14:20:36,978] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1500, global step 24000: loss 3.0984
[2019-03-26 14:20:36,979] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 1500, global step 24000: learning rate 0.0000
[2019-03-26 14:20:36,981] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1500, global step 24000: learning rate 0.0000
[2019-03-26 14:20:37,060] A3C_AGENT_WORKER-Thread-22 INFO:Local step 1500, global step 24041: loss 1.4589
[2019-03-26 14:20:37,062] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 1500, global step 24041: learning rate 0.0000
[2019-03-26 14:20:37,091] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1500, global step 24054: loss 3.8917
[2019-03-26 14:20:37,097] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1500, global step 24055: learning rate 0.0000
[2019-03-26 14:20:37,143] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1500, global step 24075: loss 3.5634
[2019-03-26 14:20:37,144] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1500, global step 24075: learning rate 0.0000
[2019-03-26 14:20:37,299] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1500, global step 24148: loss 3.5253
[2019-03-26 14:20:37,303] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1500, global step 24148: learning rate 0.0000
[2019-03-26 14:20:38,064] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.3591682e-03 9.6284246e-01 3.1212403e-02 5.8537343e-04 6.1248750e-07], sum to 1.0000
[2019-03-26 14:20:38,072] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6026
[2019-03-26 14:20:38,174] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.63333333333333, 69.33333333333333, 1.0, 2.0, 0.3155173422487395, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 496224.8312151646, 496224.8312151639, 166682.3374941126], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 918600.0000, 
sim time next is 919200.0000, 
raw observation next is [24.56666666666667, 69.66666666666667, 1.0, 2.0, 0.314944250029077, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 495460.0831677268, 495460.0831677268, 166628.6931227838], 
processed observation next is [0.0, 0.6521739130434783, 0.3633491311216432, 0.6966666666666668, 1.0, 1.0, 0.17463162654105663, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13762780087992413, 0.13762780087992413, 0.24869954197430416], 
reward next is 0.7513, 
noisyNet noise sample is [array([-0.7083328], dtype=float32), -1.1709722]. 
=============================================
[2019-03-26 14:20:38,521] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.89837418e-03 9.92561042e-01 5.43000037e-03 1.10360874e-04
 9.00516284e-08], sum to 1.0000
[2019-03-26 14:20:38,529] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3269
[2019-03-26 14:20:38,625] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.05, 73.5, 1.0, 2.0, 0.3166512713863182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 497365.1924567967, 497365.1924567967, 166751.2736341544], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 924600.0000, 
sim time next is 925200.0000, 
raw observation next is [24.0, 74.0, 1.0, 2.0, 0.3174580353314876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 498329.8766802831, 498329.8766802831, 166815.7604252182], 
processed observation next is [0.0, 0.7391304347826086, 0.3364928909952607, 0.74, 1.0, 1.0, 0.17766028353191274, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1384249657445231, 0.1384249657445231, 0.24897874690331076], 
reward next is 0.7510, 
noisyNet noise sample is [array([0.89083093], dtype=float32), 1.6224822]. 
=============================================
[2019-03-26 14:20:39,306] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-26 14:20:39,308] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 14:20:39,309] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 14:20:39,309] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 14:20:39,310] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:20:39,311] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 14:20:39,312] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 14:20:39,311] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:20:39,312] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:20:39,315] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:20:39,313] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:20:39,330] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run2
[2019-03-26 14:20:39,346] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run2
[2019-03-26 14:20:39,347] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run2
[2019-03-26 14:20:39,382] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run2
[2019-03-26 14:20:39,383] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run2
[2019-03-26 14:20:41,718] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.03313208], dtype=float32), 0.034292188]
[2019-03-26 14:20:41,719] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.95, 67.5, 1.0, 2.0, 0.4551758110401472, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 653891.1290076618, 653891.1290076612, 179160.7621679404]
[2019-03-26 14:20:41,721] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 14:20:41,723] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [7.8054436e-04 9.8847836e-01 1.0717411e-02 2.3638471e-05 1.1795206e-08], sampled 0.5420354054607437
[2019-03-26 14:21:18,975] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.03313208], dtype=float32), 0.034292188]
[2019-03-26 14:21:18,975] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.0, 79.83333333333334, 1.0, 2.0, 0.4894840688501706, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 683973.2053727263, 683973.2053727269, 181964.649621705]
[2019-03-26 14:21:18,977] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 14:21:18,978] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.4918949e-03 9.8233551e-01 1.6112182e-02 6.0403738e-05 4.5111211e-08], sampled 0.8824202850535678
[2019-03-26 14:21:21,169] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.03313208], dtype=float32), 0.034292188]
[2019-03-26 14:21:21,172] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [32.85, 56.0, 1.0, 2.0, 0.5823751674841519, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9942085721784859, 6.9112, 6.9112, 168.912382100539, 1628269.852694504, 1628269.852694504, 352738.6425155178]
[2019-03-26 14:21:21,173] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 14:21:21,175] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [6.3998753e-04 9.7322875e-01 2.6095061e-02 3.6187997e-05 1.0028607e-08], sampled 0.5650849824204749
[2019-03-26 14:21:33,405] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.03313208], dtype=float32), 0.034292188]
[2019-03-26 14:21:33,406] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [31.49859612, 62.36675254666667, 1.0, 2.0, 0.6374086734045835, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 890760.0988395016, 890760.0988395016, 207915.256498537]
[2019-03-26 14:21:33,408] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 14:21:33,412] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.3005933e-03 9.8169589e-01 1.6955009e-02 4.8536371e-05 3.6526355e-08], sampled 0.034709753416198086
[2019-03-26 14:22:18,227] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.03313208], dtype=float32), 0.034292188]
[2019-03-26 14:22:18,229] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.64171939, 75.09761452000001, 1.0, 2.0, 0.3419384830933695, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 538969.7241091045, 538969.7241091045, 170021.2084620222]
[2019-03-26 14:22:18,229] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 14:22:18,232] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.6177524e-03 9.7324455e-01 2.4009991e-02 1.2759453e-04 1.3965267e-07], sampled 0.130360061750614
[2019-03-26 14:22:27,646] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.03313208], dtype=float32), 0.034292188]
[2019-03-26 14:22:27,648] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.7, 79.33333333333333, 1.0, 2.0, 0.4928439590178461, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 688669.619224498, 688669.6192244975, 182481.2646449126]
[2019-03-26 14:22:27,650] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 14:22:27,654] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.2002785e-03 9.7438043e-01 2.3319330e-02 9.9778488e-05 8.9156195e-08], sampled 0.8309922558621261
[2019-03-26 14:22:34,649] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8076.2556 2931613556.6188 1335.0000
[2019-03-26 14:22:34,665] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7842.9451 3011443051.1526 1764.0000
[2019-03-26 14:22:34,810] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8503.0637 2782805569.9076 929.0000
[2019-03-26 14:22:34,909] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7754.4654 3167097201.7208 1776.0000
[2019-03-26 14:22:34,919] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8336.0370 2845737955.6221 1132.0000
[2019-03-26 14:22:35,936] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 25000, evaluation results [25000.0, 7754.46543735347, 3167097201.7208242, 1776.0, 8076.255626345255, 2931613556.6187615, 1335.0, 8503.06373229686, 2782805569.907615, 929.0, 7842.945052937736, 3011443051.1526165, 1764.0, 8336.03697336941, 2845737955.622146, 1132.0]
[2019-03-26 14:22:41,703] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.7070165e-04 9.9340856e-01 6.3193534e-03 1.3961329e-06 3.8291320e-10], sum to 1.0000
[2019-03-26 14:22:41,712] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0696
[2019-03-26 14:22:41,829] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.13333333333333, 97.33333333333333, 1.0, 2.0, 0.372787209659153, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 564968.6092827584, 564968.6092827584, 171655.3101044312], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1035600.0000, 
sim time next is 1036200.0000, 
raw observation next is [22.16666666666666, 97.16666666666667, 1.0, 2.0, 0.3735297665692196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 565849.4265649362, 565849.4265649356, 171724.4730006552], 
processed observation next is [1.0, 1.0, 0.24960505529225885, 0.9716666666666667, 1.0, 1.0, 0.24521658622797543, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15718039626803781, 0.15718039626803768, 0.2563051835830675], 
reward next is 0.7437, 
noisyNet noise sample is [array([0.780531], dtype=float32), 2.9705331]. 
=============================================
[2019-03-26 14:22:42,449] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.5449271e-04 9.7041255e-01 2.8827893e-02 5.1414086e-06 1.0372785e-09], sum to 1.0000
[2019-03-26 14:22:42,458] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1429
[2019-03-26 14:22:42,464] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.15, 96.5, 1.0, 2.0, 0.3606971938124785, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 547255.1984593577, 547255.1984593577, 170157.3581204329], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1045800.0000, 
sim time next is 1046400.0000, 
raw observation next is [22.0, 96.66666666666666, 1.0, 2.0, 0.3577942907489665, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 545108.0214218537, 545108.0214218537, 170052.4684641506], 
processed observation next is [1.0, 0.08695652173913043, 0.2417061611374408, 0.9666666666666666, 1.0, 1.0, 0.22625818162526085, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1514188948394038, 0.1514188948394038, 0.25380965442410536], 
reward next is 0.7462, 
noisyNet noise sample is [array([-0.7295657], dtype=float32), 0.5220463]. 
=============================================
[2019-03-26 14:22:44,419] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.4902612e-05 9.9327290e-01 6.6708936e-03 1.2761880e-06 1.7870928e-10], sum to 1.0000
[2019-03-26 14:22:44,427] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0048
[2019-03-26 14:22:44,434] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.93333333333334, 71.0, 1.0, 2.0, 0.5978268269340206, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 928211.6839156456, 928211.6839156456, 211449.8595906605], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1084800.0000, 
sim time next is 1085400.0000, 
raw observation next is [25.1, 70.5, 1.0, 2.0, 0.6693726469150276, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1036894.003653821, 1036894.003653821, 226848.2525120601], 
processed observation next is [1.0, 0.5652173913043478, 0.38862559241706174, 0.705, 1.0, 1.0, 0.6016537914638886, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2880261121260614, 0.2880261121260614, 0.33857948136128374], 
reward next is 0.6614, 
noisyNet noise sample is [array([-1.30807], dtype=float32), -0.18449134]. 
=============================================
[2019-03-26 14:22:49,977] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.2787091e-06 9.9893600e-01 1.0587329e-03 2.3545541e-08 6.5409039e-13], sum to 1.0000
[2019-03-26 14:22:49,984] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3472
[2019-03-26 14:22:50,090] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.6, 59.0, 1.0, 2.0, 0.99189320344214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1514832.984715675, 1514832.984715675, 315390.8894443341], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1177200.0000, 
sim time next is 1177800.0000, 
raw observation next is [27.6, 58.83333333333334, 1.0, 2.0, 0.9342209316084197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1428344.877944785, 1428344.877944785, 296995.1814569918], 
processed observation next is [1.0, 0.6521739130434783, 0.5071090047393366, 0.5883333333333334, 1.0, 1.0, 0.92074811037159, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3967624660957736, 0.3967624660957736, 0.44327639023431614], 
reward next is 0.5567, 
noisyNet noise sample is [array([1.8431529], dtype=float32), -0.8533659]. 
=============================================
[2019-03-26 14:22:50,932] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2000, global step 31809: loss 0.1781
[2019-03-26 14:22:50,935] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2000, global step 31809: learning rate 0.0000
[2019-03-26 14:22:51,055] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2000, global step 31866: loss 0.1906
[2019-03-26 14:22:51,058] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2000, global step 31870: learning rate 0.0000
[2019-03-26 14:22:51,212] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2000, global step 31941: loss 0.1486
[2019-03-26 14:22:51,215] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2000, global step 31941: learning rate 0.0000
[2019-03-26 14:22:51,241] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2000, global step 31955: loss 0.1612
[2019-03-26 14:22:51,244] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2000, global step 31956: learning rate 0.0000
[2019-03-26 14:22:51,272] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2000, global step 31967: loss 0.2134
[2019-03-26 14:22:51,278] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2000, global step 31969: learning rate 0.0000
[2019-03-26 14:22:51,282] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2000, global step 31969: loss 0.2188
[2019-03-26 14:22:51,284] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2000, global step 31970: learning rate 0.0000
[2019-03-26 14:22:51,301] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2000, global step 31978: loss 0.1914
[2019-03-26 14:22:51,302] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2000, global step 31978: learning rate 0.0000
[2019-03-26 14:22:51,303] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2000, global step 31978: loss 0.1422
[2019-03-26 14:22:51,306] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2000, global step 31978: learning rate 0.0000
[2019-03-26 14:22:51,326] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2000, global step 31988: loss 0.2314
[2019-03-26 14:22:51,327] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2000, global step 31988: learning rate 0.0000
[2019-03-26 14:22:51,342] A3C_AGENT_WORKER-Thread-22 INFO:Local step 2000, global step 31994: loss 0.1943
[2019-03-26 14:22:51,345] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 2000, global step 31994: learning rate 0.0000
[2019-03-26 14:22:51,372] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2000, global step 32008: loss 0.1962
[2019-03-26 14:22:51,375] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2000, global step 32009: learning rate 0.0000
[2019-03-26 14:22:51,414] A3C_AGENT_WORKER-Thread-21 INFO:Local step 2000, global step 32029: loss 0.1797
[2019-03-26 14:22:51,419] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 2000, global step 32030: learning rate 0.0000
[2019-03-26 14:22:51,424] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2000, global step 32032: loss 0.1705
[2019-03-26 14:22:51,428] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 2000, global step 32035: learning rate 0.0000
[2019-03-26 14:22:51,446] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2000, global step 32045: loss 0.2127
[2019-03-26 14:22:51,447] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2000, global step 32045: learning rate 0.0000
[2019-03-26 14:22:51,601] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2000, global step 32110: loss 0.1809
[2019-03-26 14:22:51,605] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2000, global step 32110: learning rate 0.0000
[2019-03-26 14:22:51,655] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2000, global step 32135: loss 0.1658
[2019-03-26 14:22:51,656] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2000, global step 32136: learning rate 0.0000
[2019-03-26 14:22:58,396] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.0700021e-05 9.9900848e-01 9.7081804e-04 5.7802283e-09 8.9986043e-14], sum to 1.0000
[2019-03-26 14:22:58,404] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7702
[2019-03-26 14:22:58,408] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.85, 93.5, 1.0, 2.0, 0.5543588314973338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 802578.0055774802, 802578.0055774802, 196096.477506292], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1319400.0000, 
sim time next is 1320000.0000, 
raw observation next is [23.76666666666667, 93.66666666666667, 1.0, 2.0, 0.536796362988044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 779058.4267126544, 779058.4267126544, 193226.5869690716], 
processed observation next is [1.0, 0.2608695652173913, 0.32543443917851517, 0.9366666666666668, 1.0, 1.0, 0.4419233289012578, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2164051185312929, 0.2164051185312929, 0.2883978909986143], 
reward next is 0.7116, 
noisyNet noise sample is [array([-0.04785764], dtype=float32), -1.7740134]. 
=============================================
[2019-03-26 14:22:58,429] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[52.90762 ]
 [52.793243]
 [52.70563 ]
 [52.722538]
 [52.68234 ]], R is [[53.14536285]
 [53.32122803]
 [53.49936676]
 [53.6840477 ]
 [53.88388443]].
[2019-03-26 14:22:59,112] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.2366596e-06 9.9962366e-01 3.7505280e-04 6.1380727e-09 1.1056124e-13], sum to 1.0000
[2019-03-26 14:22:59,118] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9510
[2019-03-26 14:22:59,122] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.98333333333333, 95.0, 1.0, 2.0, 0.8096201733490408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1202973.091506808, 1202973.091506808, 256087.5527103175], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1332600.0000, 
sim time next is 1333200.0000, 
raw observation next is [22.96666666666667, 95.0, 1.0, 2.0, 0.8086954594068322, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1202305.55719818, 1202305.55719818, 255934.45372449], 
processed observation next is [1.0, 0.43478260869565216, 0.2875197472353872, 0.95, 1.0, 1.0, 0.7695126016949785, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3339737658883833, 0.3339737658883833, 0.3819917219768508], 
reward next is 0.6180, 
noisyNet noise sample is [array([0.855995], dtype=float32), -0.014939478]. 
=============================================
[2019-03-26 14:23:08,313] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2500, global step 39760: loss 1.4486
[2019-03-26 14:23:08,316] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2500, global step 39762: learning rate 0.0000
[2019-03-26 14:23:08,508] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2500, global step 39853: loss 1.0829
[2019-03-26 14:23:08,511] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2500, global step 39853: learning rate 0.0000
[2019-03-26 14:23:08,673] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2500, global step 39929: loss 0.9363
[2019-03-26 14:23:08,679] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2500, global step 39930: learning rate 0.0000
[2019-03-26 14:23:08,707] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2500, global step 39944: loss 0.9523
[2019-03-26 14:23:08,710] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2500, global step 39946: learning rate 0.0000
[2019-03-26 14:23:08,727] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2500, global step 39952: loss 0.9583
[2019-03-26 14:23:08,730] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2500, global step 39952: learning rate 0.0000
[2019-03-26 14:23:08,747] A3C_AGENT_WORKER-Thread-22 INFO:Local step 2500, global step 39962: loss 1.0583
[2019-03-26 14:23:08,749] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 2500, global step 39962: learning rate 0.0000
[2019-03-26 14:23:08,776] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2500, global step 39969: loss 1.0255
[2019-03-26 14:23:08,778] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2500, global step 39970: learning rate 0.0000
[2019-03-26 14:23:08,790] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2500, global step 39976: loss 0.9635
[2019-03-26 14:23:08,791] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2500, global step 39976: learning rate 0.0000
[2019-03-26 14:23:08,881] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2500, global step 40024: loss 1.0158
[2019-03-26 14:23:08,881] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2500, global step 40024: loss 0.9554
[2019-03-26 14:23:08,883] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2500, global step 40025: learning rate 0.0000
[2019-03-26 14:23:08,886] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2500, global step 40025: learning rate 0.0000
[2019-03-26 14:23:08,887] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2500, global step 40026: loss 1.0408
[2019-03-26 14:23:08,893] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2500, global step 40027: learning rate 0.0000
[2019-03-26 14:23:08,916] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2500, global step 40038: loss 0.9404
[2019-03-26 14:23:08,921] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2500, global step 40040: learning rate 0.0000
[2019-03-26 14:23:08,955] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2500, global step 40052: loss 0.9997
[2019-03-26 14:23:08,961] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 2500, global step 40052: learning rate 0.0000
[2019-03-26 14:23:08,969] A3C_AGENT_WORKER-Thread-21 INFO:Local step 2500, global step 40058: loss 1.0448
[2019-03-26 14:23:08,974] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 2500, global step 40058: learning rate 0.0000
[2019-03-26 14:23:09,078] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2500, global step 40110: loss 1.0249
[2019-03-26 14:23:09,080] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2500, global step 40111: learning rate 0.0000
[2019-03-26 14:23:09,122] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2500, global step 40133: loss 0.9007
[2019-03-26 14:23:09,123] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2500, global step 40133: learning rate 0.0000
[2019-03-26 14:23:24,656] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.8488569e-08 9.9999106e-01 8.9162386e-06 1.0696343e-11 2.9728951e-17], sum to 1.0000
[2019-03-26 14:23:24,664] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1253
[2019-03-26 14:23:24,667] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 85.33333333333333, 1.0, 2.0, 0.6590610138828128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1039346.497714092, 1039346.497714092, 226309.5044178158], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1779000.0000, 
sim time next is 1779600.0000, 
raw observation next is [21.93333333333333, 86.66666666666667, 1.0, 2.0, 0.6317802615002365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 997703.614510872, 997703.614510872, 220280.7405242832], 
processed observation next is [1.0, 0.6086956521739131, 0.23854660347551332, 0.8666666666666667, 1.0, 1.0, 0.5563617608436584, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.27713989291968666, 0.27713989291968666, 0.32877722466310927], 
reward next is 0.6712, 
noisyNet noise sample is [array([-0.23865941], dtype=float32), 0.4150977]. 
=============================================
[2019-03-26 14:23:25,481] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3000, global step 47728: loss 0.0206
[2019-03-26 14:23:25,485] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 3000, global step 47728: learning rate 0.0000
[2019-03-26 14:23:25,796] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3000, global step 47876: loss 0.0170
[2019-03-26 14:23:25,799] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 3000, global step 47876: learning rate 0.0000
[2019-03-26 14:23:25,812] A3C_AGENT_WORKER-Thread-20 INFO:Local step 3000, global step 47885: loss 0.0127
[2019-03-26 14:23:25,814] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 3000, global step 47885: learning rate 0.0000
[2019-03-26 14:23:25,820] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3000, global step 47888: loss 0.0140
[2019-03-26 14:23:25,822] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 3000, global step 47888: learning rate 0.0000
[2019-03-26 14:23:25,872] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3000, global step 47911: loss 0.0189
[2019-03-26 14:23:25,874] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 3000, global step 47912: learning rate 0.0000
[2019-03-26 14:23:25,910] A3C_AGENT_WORKER-Thread-22 INFO:Local step 3000, global step 47929: loss 0.0219
[2019-03-26 14:23:25,912] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 3000, global step 47930: learning rate 0.0000
[2019-03-26 14:23:26,100] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3000, global step 48016: loss 0.0152
[2019-03-26 14:23:26,103] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 3000, global step 48016: learning rate 0.0000
[2019-03-26 14:23:26,104] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3000, global step 48017: loss 0.0469
[2019-03-26 14:23:26,106] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 3000, global step 48017: learning rate 0.0000
[2019-03-26 14:23:26,116] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3000, global step 48022: loss 0.0263
[2019-03-26 14:23:26,117] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 3000, global step 48022: learning rate 0.0000
[2019-03-26 14:23:26,129] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3000, global step 48028: loss 0.0121
[2019-03-26 14:23:26,132] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 3000, global step 48028: learning rate 0.0000
[2019-03-26 14:23:26,184] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3000, global step 48051: loss 0.0317
[2019-03-26 14:23:26,188] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 3000, global step 48052: learning rate 0.0000
[2019-03-26 14:23:26,198] A3C_AGENT_WORKER-Thread-18 INFO:Local step 3000, global step 48059: loss 0.0120
[2019-03-26 14:23:26,201] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 3000, global step 48059: learning rate 0.0000
[2019-03-26 14:23:26,233] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3000, global step 48073: loss 0.0181
[2019-03-26 14:23:26,239] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 3000, global step 48073: learning rate 0.0000
[2019-03-26 14:23:26,264] A3C_AGENT_WORKER-Thread-19 INFO:Local step 3000, global step 48089: loss 0.0133
[2019-03-26 14:23:26,264] A3C_AGENT_WORKER-Thread-21 INFO:Local step 3000, global step 48089: loss 0.0151
[2019-03-26 14:23:26,267] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 3000, global step 48090: learning rate 0.0000
[2019-03-26 14:23:26,269] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 3000, global step 48090: learning rate 0.0000
[2019-03-26 14:23:26,397] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3000, global step 48150: loss 0.0178
[2019-03-26 14:23:26,399] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 3000, global step 48150: learning rate 0.0000
[2019-03-26 14:23:27,884] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.12157899e-07 9.99899626e-01 1.00268786e-04 3.30789285e-10
 8.98090373e-17], sum to 1.0000
[2019-03-26 14:23:27,893] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6344
[2019-03-26 14:23:27,996] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 95.0, 1.0, 2.0, 0.3684247733673023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 557112.2904422659, 557112.2904422659, 170935.6785943345], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1836000.0000, 
sim time next is 1836600.0000, 
raw observation next is [22.61666666666667, 94.5, 1.0, 2.0, 0.3781118518647175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 570729.9378662504, 570729.937866251, 172088.9409996399], 
processed observation next is [1.0, 0.2608695652173913, 0.2709320695102688, 0.945, 1.0, 1.0, 0.2507371709213464, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15853609385173623, 0.1585360938517364, 0.25684916567110433], 
reward next is 0.7432, 
noisyNet noise sample is [array([-0.02302114], dtype=float32), -0.60379773]. 
=============================================
[2019-03-26 14:23:30,040] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-26 14:23:30,042] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 14:23:30,042] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 14:23:30,043] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 14:23:30,044] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 14:23:30,045] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:23:30,046] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:23:30,047] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:23:30,045] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 14:23:30,044] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:23:30,050] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:23:30,066] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run3
[2019-03-26 14:23:30,066] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run3
[2019-03-26 14:23:30,067] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run3
[2019-03-26 14:23:30,082] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run3
[2019-03-26 14:23:30,099] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run3
[2019-03-26 14:23:53,831] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.06228941], dtype=float32), 0.062819965]
[2019-03-26 14:23:53,832] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [24.83333333333334, 80.66666666666666, 1.0, 2.0, 0.395409073811776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 589369.7088411784, 589369.708841179, 173540.4579229907]
[2019-03-26 14:23:53,834] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 14:23:53,836] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.598585e-07 9.999647e-01 3.489472e-05 7.358520e-10 2.644938e-15], sampled 0.2688112293368493
[2019-03-26 14:24:25,340] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.06228941], dtype=float32), 0.062819965]
[2019-03-26 14:24:25,341] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.56584290333333, 70.14965111666666, 1.0, 2.0, 0.6017197865819307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 857264.8258802163, 857264.8258802157, 203182.6043309458]
[2019-03-26 14:24:25,344] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 14:24:25,348] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.4987302e-07 9.9997973e-01 2.0099938e-05 3.0112504e-10 6.0470947e-16], sampled 0.44909357860678956
[2019-03-26 14:25:17,537] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.06228941], dtype=float32), 0.062819965]
[2019-03-26 14:25:17,538] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [24.19694919666667, 84.94768371333333, 1.0, 2.0, 0.3932407280172625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 585115.1927153106, 585115.1927153106, 173119.3150960378]
[2019-03-26 14:25:17,540] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 14:25:17,543] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [6.4593888e-07 9.9994719e-01 5.2219810e-05 1.2781559e-09 6.6795100e-15], sampled 0.6663703582276364
[2019-03-26 14:25:24,767] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7882.6638 3164094950.4079 1778.0000
[2019-03-26 14:25:25,125] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.6842 2927263131.0635 1338.0000
[2019-03-26 14:25:25,180] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7996.0032 3007665947.5763 1766.0000
[2019-03-26 14:25:25,312] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8658.4766 2779227474.6146 933.0000
[2019-03-26 14:25:25,356] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8494.6508 2842465861.1843 1131.0000
[2019-03-26 14:25:26,370] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 50000, evaluation results [50000.0, 7882.6637926081985, 3164094950.4079256, 1778.0, 8253.684238692544, 2927263131.0635424, 1338.0, 8658.476629447025, 2779227474.614574, 933.0, 7996.003192942072, 3007665947.576305, 1766.0, 8494.65075948551, 2842465861.18431, 1131.0]
[2019-03-26 14:25:28,410] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.4696822e-08 9.9998331e-01 1.6683116e-05 8.5795034e-12 1.1640424e-17], sum to 1.0000
[2019-03-26 14:25:28,422] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1478
[2019-03-26 14:25:28,540] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.3, 95.0, 1.0, 2.0, 0.4625432617026303, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 652647.5764196299, 652647.5764196299, 178752.9072299544], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1904400.0000, 
sim time next is 1905000.0000, 
raw observation next is [24.28333333333333, 95.16666666666667, 1.0, 2.0, 0.463167910437884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 653043.0560201956, 653043.0560201956, 178782.3635346329], 
processed observation next is [1.0, 0.043478260869565216, 0.34992101105845175, 0.9516666666666667, 1.0, 1.0, 0.3532143499251615, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18140084889449878, 0.18140084889449878, 0.2668393485591536], 
reward next is 0.7332, 
noisyNet noise sample is [array([0.6981487], dtype=float32), 1.0673394]. 
=============================================
[2019-03-26 14:25:28,560] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[67.26409]
 [67.34282]
 [67.62405]
 [67.80949]
 [68.03184]], R is [[67.08426666]
 [67.14662933]
 [67.20851898]
 [67.27004242]
 [67.33132172]].
[2019-03-26 14:25:29,317] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.0645354e-08 9.9999225e-01 7.7526838e-06 1.0349112e-10 2.1233951e-17], sum to 1.0000
[2019-03-26 14:25:29,328] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2082
[2019-03-26 14:25:29,438] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.65, 82.5, 1.0, 2.0, 0.9261565077601371, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1326232.476951096, 1326232.476951096, 281979.1999425621], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1931400.0000, 
sim time next is 1932000.0000, 
raw observation next is [25.7, 82.33333333333334, 1.0, 2.0, 0.944622855265667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1351154.575088492, 1351154.575088492, 287167.0202374759], 
processed observation next is [1.0, 0.34782608695652173, 0.4170616113744076, 0.8233333333333335, 1.0, 1.0, 0.9332805485128518, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3753207153023589, 0.3753207153023589, 0.4286074928917551], 
reward next is 0.5714, 
noisyNet noise sample is [array([1.2530141], dtype=float32), -1.1609478]. 
=============================================
[2019-03-26 14:25:29,452] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[66.339745]
 [66.051445]
 [65.83147 ]
 [65.734856]
 [65.70905 ]], R is [[66.54105377]
 [66.45477295]
 [66.41654205]
 [66.46307373]
 [66.52390289]].
[2019-03-26 14:25:31,521] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.2124819e-09 9.9999583e-01 4.2129782e-06 5.4161033e-11 1.3373806e-17], sum to 1.0000
[2019-03-26 14:25:31,535] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9465
[2019-03-26 14:25:31,539] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.88333333333333, 90.5, 1.0, 2.0, 0.4203797811615761, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 617110.0769192945, 617110.0769192945, 175860.9918165033], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1966200.0000, 
sim time next is 1966800.0000, 
raw observation next is [23.76666666666667, 91.0, 1.0, 2.0, 0.4171357844804298, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 613512.9860393727, 613512.9860393734, 175550.7873350897], 
processed observation next is [1.0, 0.782608695652174, 0.32543443917851517, 0.91, 1.0, 1.0, 0.29775395720533715, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17042027389982575, 0.17042027389982595, 0.26201610050013385], 
reward next is 0.7380, 
noisyNet noise sample is [array([-0.28225937], dtype=float32), 0.76019394]. 
=============================================
[2019-03-26 14:25:35,159] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.5569147e-07 9.9997807e-01 2.1552167e-05 7.6284223e-10 1.3526426e-15], sum to 1.0000
[2019-03-26 14:25:35,170] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5617
[2019-03-26 14:25:35,175] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.08333333333333, 90.66666666666666, 1.0, 2.0, 0.5076028214960224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 709299.624672002, 709299.624672002, 184796.0986747059], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2029800.0000, 
sim time next is 2030400.0000, 
raw observation next is [26.2, 90.0, 1.0, 2.0, 0.5083006152379825, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 710275.0138739177, 710275.0138739183, 184907.0869315164], 
processed observation next is [0.0, 0.5217391304347826, 0.44075829383886256, 0.9, 1.0, 1.0, 0.40759110269636445, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19729861496497716, 0.1972986149649773, 0.2759807267634573], 
reward next is 0.7240, 
noisyNet noise sample is [array([-0.42139006], dtype=float32), 1.0762753]. 
=============================================
[2019-03-26 14:25:36,855] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.6686997e-08 9.9999809e-01 1.8977132e-06 1.5212516e-10 3.7950848e-17], sum to 1.0000
[2019-03-26 14:25:36,861] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3069
[2019-03-26 14:25:36,864] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.8, 88.0, 1.0, 2.0, 0.4859981027887919, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 679100.5861074259, 679100.5861074264, 181431.3260307892], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2055600.0000, 
sim time next is 2056200.0000, 
raw observation next is [25.73333333333333, 88.16666666666667, 1.0, 2.0, 0.484744198171802, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 677347.9067545087, 677347.9067545087, 181240.2720779809], 
processed observation next is [0.0, 0.8260869565217391, 0.41864139020537117, 0.8816666666666667, 1.0, 1.0, 0.3792098773154241, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18815219632069688, 0.18815219632069688, 0.2705078687731058], 
reward next is 0.7295, 
noisyNet noise sample is [array([1.3537043], dtype=float32), 0.7471548]. 
=============================================
[2019-03-26 14:25:38,750] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3500, global step 55743: loss 0.3405
[2019-03-26 14:25:38,754] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 3500, global step 55744: learning rate 0.0000
[2019-03-26 14:25:38,987] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3500, global step 55854: loss 0.3202
[2019-03-26 14:25:38,990] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 3500, global step 55855: learning rate 0.0000
[2019-03-26 14:25:38,996] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3500, global step 55856: loss 0.4096
[2019-03-26 14:25:38,999] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 3500, global step 55857: learning rate 0.0000
[2019-03-26 14:25:39,101] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3500, global step 55908: loss 0.2786
[2019-03-26 14:25:39,105] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 3500, global step 55910: learning rate 0.0000
[2019-03-26 14:25:39,128] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3500, global step 55923: loss 0.3354
[2019-03-26 14:25:39,129] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 3500, global step 55923: learning rate 0.0000
[2019-03-26 14:25:39,131] A3C_AGENT_WORKER-Thread-20 INFO:Local step 3500, global step 55923: loss 0.3593
[2019-03-26 14:25:39,133] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 3500, global step 55923: learning rate 0.0000
[2019-03-26 14:25:39,209] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3500, global step 55963: loss 0.3685
[2019-03-26 14:25:39,213] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 3500, global step 55965: learning rate 0.0000
[2019-03-26 14:25:39,287] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3500, global step 56000: loss 0.3287
[2019-03-26 14:25:39,288] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 3500, global step 56000: learning rate 0.0000
[2019-03-26 14:25:39,324] A3C_AGENT_WORKER-Thread-18 INFO:Local step 3500, global step 56018: loss 0.3577
[2019-03-26 14:25:39,326] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 3500, global step 56019: learning rate 0.0000
[2019-03-26 14:25:39,339] A3C_AGENT_WORKER-Thread-22 INFO:Local step 3500, global step 56025: loss 0.2814
[2019-03-26 14:25:39,340] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 3500, global step 56025: learning rate 0.0000
[2019-03-26 14:25:39,382] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3500, global step 56042: loss 0.4592
[2019-03-26 14:25:39,384] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 3500, global step 56043: learning rate 0.0000
[2019-03-26 14:25:39,428] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3500, global step 56066: loss 0.3135
[2019-03-26 14:25:39,429] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3500, global step 56066: loss 0.3375
[2019-03-26 14:25:39,434] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 3500, global step 56066: learning rate 0.0000
[2019-03-26 14:25:39,435] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 3500, global step 56068: learning rate 0.0000
[2019-03-26 14:25:39,461] A3C_AGENT_WORKER-Thread-19 INFO:Local step 3500, global step 56081: loss 0.3066
[2019-03-26 14:25:39,462] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 3500, global step 56082: learning rate 0.0000
[2019-03-26 14:25:39,555] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3500, global step 56122: loss 0.3122
[2019-03-26 14:25:39,561] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 3500, global step 56123: learning rate 0.0000
[2019-03-26 14:25:39,617] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2416956e-07 9.9998403e-01 1.5834768e-05 5.7986161e-11 1.4780650e-17], sum to 1.0000
[2019-03-26 14:25:39,625] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1723
[2019-03-26 14:25:39,630] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.36666666666667, 80.66666666666667, 1.0, 2.0, 0.5318864316745767, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 743244.2379628149, 743244.2379628143, 188743.5019594662], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2108400.0000, 
sim time next is 2109000.0000, 
raw observation next is [28.58333333333333, 79.83333333333334, 1.0, 2.0, 0.5350387497770641, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 747650.7553564993, 747650.7553564986, 189268.6785206307], 
processed observation next is [0.0, 0.391304347826087, 0.5537124802527644, 0.7983333333333335, 1.0, 1.0, 0.4398057226229688, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20768076537680538, 0.2076807653768052, 0.2824905649561652], 
reward next is 0.7175, 
noisyNet noise sample is [array([-1.2589115], dtype=float32), -1.1070876]. 
=============================================
[2019-03-26 14:25:39,650] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[63.074192]
 [62.97588 ]
 [62.879494]
 [62.7943  ]
 [62.69647 ]], R is [[63.25396729]
 [63.33972168]
 [63.42555237]
 [63.51135635]
 [63.59691238]].
[2019-03-26 14:25:39,709] A3C_AGENT_WORKER-Thread-21 INFO:Local step 3500, global step 56195: loss 0.2733
[2019-03-26 14:25:39,712] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 3500, global step 56196: learning rate 0.0000
[2019-03-26 14:25:42,709] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.3109073e-09 9.9999940e-01 6.1503204e-07 2.0166301e-13 8.4515918e-19], sum to 1.0000
[2019-03-26 14:25:42,717] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8149
[2019-03-26 14:25:42,722] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666667, 93.66666666666667, 1.0, 2.0, 0.511557470526853, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 714827.5192284478, 714827.5192284472, 185426.6728663435], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2162400.0000, 
sim time next is 2163000.0000, 
raw observation next is [25.63333333333333, 93.83333333333334, 1.0, 2.0, 0.5110489068622259, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 714116.6362485503, 714116.6362485496, 185345.2931599961], 
processed observation next is [1.0, 0.0, 0.4139020537124801, 0.9383333333333335, 1.0, 1.0, 0.41090229742436857, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19836573229126397, 0.19836573229126378, 0.27663476591044195], 
reward next is 0.7234, 
noisyNet noise sample is [array([-0.57827765], dtype=float32), -1.0779486]. 
=============================================
[2019-03-26 14:25:42,749] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[75.319046]
 [75.408455]
 [75.45283 ]
 [75.6025  ]
 [75.53175 ]], R is [[75.12632751]
 [75.09831238]
 [75.07043457]
 [75.04267883]
 [75.01498413]].
[2019-03-26 14:25:45,895] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.7347072e-11 1.0000000e+00 9.1098218e-10 3.2643173e-14 4.2039196e-20], sum to 1.0000
[2019-03-26 14:25:45,901] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3175
[2019-03-26 14:25:45,906] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2361841.754751718 W.
[2019-03-26 14:25:45,918] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.96666666666667, 66.33333333333334, 1.0, 2.0, 0.8444739162269652, 1.0, 2.0, 0.8444739162269652, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2361841.754751718, 2361841.754751718, 442106.8948895452], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2215200.0000, 
sim time next is 2215800.0000, 
raw observation next is [31.95, 66.5, 1.0, 2.0, 0.8329056932807067, 1.0, 2.0, 0.8329056932807067, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2329457.359410863, 2329457.359410864, 436212.5897732957], 
processed observation next is [1.0, 0.6521739130434783, 0.7132701421800948, 0.665, 1.0, 1.0, 0.7986815581695261, 1.0, 1.0, 0.7986815581695261, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6470714887252397, 0.64707148872524, 0.6510635668258145], 
reward next is 0.3489, 
noisyNet noise sample is [array([2.5168507], dtype=float32), 1.1126482]. 
=============================================
[2019-03-26 14:25:54,141] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.9446771e-10 9.9999988e-01 6.5048539e-08 1.0835235e-13 2.7771824e-18], sum to 1.0000
[2019-03-26 14:25:54,147] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7283
[2019-03-26 14:25:54,152] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.96666666666667, 74.0, 1.0, 2.0, 0.7996931649827262, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1117667.301985129, 1117667.301985129, 243834.6053594766], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2359200.0000, 
sim time next is 2359800.0000, 
raw observation next is [29.1, 73.5, 1.0, 2.0, 0.807574905183571, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1128688.835680201, 1128688.835680201, 245777.8749194095], 
processed observation next is [1.0, 0.30434782608695654, 0.5781990521327015, 0.735, 1.0, 1.0, 0.7681625363657482, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3135246765778336, 0.3135246765778336, 0.36683264913344704], 
reward next is 0.6332, 
noisyNet noise sample is [array([-0.02645878], dtype=float32), 0.73352444]. 
=============================================
[2019-03-26 14:25:55,185] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.60584415e-10 1.00000000e+00 1.13399565e-08 1.05465203e-12
 6.88416888e-18], sum to 1.0000
[2019-03-26 14:25:55,194] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3701
[2019-03-26 14:25:55,203] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2400601.435452296 W.
[2019-03-26 14:25:55,206] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [32.26666666666667, 64.0, 1.0, 2.0, 0.8583190987519767, 1.0, 2.0, 0.8583190987519767, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2400601.435452296, 2400601.435452296, 449263.6606140585], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2373600.0000, 
sim time next is 2374200.0000, 
raw observation next is [32.3, 64.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 8.132077903062886, 6.9112, 168.9052793235634, 3150570.465195814, 2284477.027601241, 473158.4496512892], 
processed observation next is [1.0, 0.4782608695652174, 0.7298578199052131, 0.64, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.12208779030628855, 0.0, 0.8294022466501514, 0.8751584625543928, 0.6345769521114558, 0.7062066412705809], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.1342194], dtype=float32), -0.80028075]. 
=============================================
[2019-03-26 14:25:56,021] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4000, global step 63747: loss 1.8296
[2019-03-26 14:25:56,025] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 4000, global step 63747: learning rate 0.0000
[2019-03-26 14:25:56,067] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4000, global step 63767: loss 1.1478
[2019-03-26 14:25:56,069] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 4000, global step 63767: learning rate 0.0000
[2019-03-26 14:25:56,194] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4000, global step 63831: loss 0.8043
[2019-03-26 14:25:56,196] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 4000, global step 63831: learning rate 0.0000
[2019-03-26 14:25:56,358] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4000, global step 63905: loss 1.2360
[2019-03-26 14:25:56,360] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 4000, global step 63905: learning rate 0.0000
[2019-03-26 14:25:56,401] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4000, global step 63922: loss 0.6424
[2019-03-26 14:25:56,403] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 4000, global step 63922: learning rate 0.0000
[2019-03-26 14:25:56,451] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4000, global step 63947: loss 1.3784
[2019-03-26 14:25:56,452] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 4000, global step 63947: learning rate 0.0000
[2019-03-26 14:25:56,556] A3C_AGENT_WORKER-Thread-18 INFO:Local step 4000, global step 63997: loss 0.9424
[2019-03-26 14:25:56,559] A3C_AGENT_WORKER-Thread-20 INFO:Local step 4000, global step 63997: loss 0.1991
[2019-03-26 14:25:56,561] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 4000, global step 63997: learning rate 0.0000
[2019-03-26 14:25:56,561] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 4000, global step 63998: learning rate 0.0000
[2019-03-26 14:25:56,629] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4000, global step 64028: loss 0.5022
[2019-03-26 14:25:56,630] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 4000, global step 64028: learning rate 0.0000
[2019-03-26 14:25:56,642] A3C_AGENT_WORKER-Thread-22 INFO:Local step 4000, global step 64033: loss 1.3367
[2019-03-26 14:25:56,645] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 4000, global step 64035: learning rate 0.0000
[2019-03-26 14:25:56,649] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4000, global step 64036: loss 0.8324
[2019-03-26 14:25:56,651] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 4000, global step 64037: learning rate 0.0000
[2019-03-26 14:25:56,715] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4000, global step 64067: loss 0.7724
[2019-03-26 14:25:56,717] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 4000, global step 64068: learning rate 0.0000
[2019-03-26 14:25:56,757] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4000, global step 64085: loss 0.9375
[2019-03-26 14:25:56,759] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 4000, global step 64086: learning rate 0.0000
[2019-03-26 14:25:56,763] A3C_AGENT_WORKER-Thread-19 INFO:Local step 4000, global step 64087: loss 1.3580
[2019-03-26 14:25:56,767] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 4000, global step 64087: learning rate 0.0000
[2019-03-26 14:25:56,948] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4000, global step 64173: loss 1.2745
[2019-03-26 14:25:56,950] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 4000, global step 64174: learning rate 0.0000
[2019-03-26 14:25:57,167] A3C_AGENT_WORKER-Thread-21 INFO:Local step 4000, global step 64281: loss 0.6864
[2019-03-26 14:25:57,168] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 4000, global step 64281: learning rate 0.0000
[2019-03-26 14:25:57,992] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.6413571e-10 1.0000000e+00 4.9299391e-09 5.2929677e-13 1.9747028e-19], sum to 1.0000
[2019-03-26 14:25:58,000] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7459
[2019-03-26 14:25:58,104] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.95, 80.0, 1.0, 2.0, 0.5566361447008397, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 777841.5048890228, 777841.5048890234, 192945.4512849399], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2421000.0000, 
sim time next is 2421600.0000, 
raw observation next is [28.9, 80.0, 1.0, 2.0, 0.5547100137790519, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 775148.9538129104, 775148.9538129104, 192611.8932705215], 
processed observation next is [1.0, 0.0, 0.5687203791469194, 0.8, 1.0, 1.0, 0.4635060406976529, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21531915383691955, 0.21531915383691955, 0.2874804377171963], 
reward next is 0.7125, 
noisyNet noise sample is [array([2.0460024], dtype=float32), -0.15913388]. 
=============================================
[2019-03-26 14:25:58,435] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.2520630e-11 1.0000000e+00 8.5190965e-09 8.4031713e-14 1.6065064e-19], sum to 1.0000
[2019-03-26 14:25:58,448] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9358
[2019-03-26 14:25:58,454] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.3, 81.0, 1.0, 2.0, 0.8873752454859619, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1240285.12051485, 1240285.120514849, 266488.8410854088], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2430000.0000, 
sim time next is 2430600.0000, 
raw observation next is [28.23333333333333, 81.16666666666667, 1.0, 2.0, 0.9049218598677752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1264824.646383425, 1264824.646383426, 271295.364362062], 
processed observation next is [1.0, 0.13043478260869565, 0.537124802527646, 0.8116666666666668, 1.0, 1.0, 0.8854480239370786, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.35134017955095137, 0.35134017955095165, 0.40491845427173434], 
reward next is 0.5951, 
noisyNet noise sample is [array([-1.7781758], dtype=float32), -2.5347323]. 
=============================================
[2019-03-26 14:26:01,157] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.2522299e-10 1.0000000e+00 4.1136672e-10 1.8181255e-13 5.0080004e-18], sum to 1.0000
[2019-03-26 14:26:01,165] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6855
[2019-03-26 14:26:01,174] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1815873.634702404 W.
[2019-03-26 14:26:01,180] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.75, 87.5, 1.0, 2.0, 0.432948316554039, 1.0, 2.0, 0.432948316554039, 1.0, 2.0, 0.7412900769175816, 6.9112, 6.9112, 170.5573041426782, 1815873.634702404, 1815873.634702404, 370240.8303725711], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2471400.0000, 
sim time next is 2472000.0000, 
raw observation next is [26.86666666666667, 87.0, 1.0, 2.0, 0.6982961246770574, 1.0, 2.0, 0.6982961246770574, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1952655.539365425, 1952655.539365425, 373391.3251995477], 
processed observation next is [1.0, 0.6086956521739131, 0.4723538704581361, 0.87, 1.0, 1.0, 0.6365013550325992, 1.0, 1.0, 0.6365013550325992, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5424043164903959, 0.5424043164903959, 0.5573004853724592], 
reward next is 0.4427, 
noisyNet noise sample is [array([0.62182695], dtype=float32), 0.32206985]. 
=============================================
[2019-03-26 14:26:01,201] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[64.5933  ]
 [63.822758]
 [63.965088]
 [64.26732 ]
 [64.02283 ]], R is [[64.25022888]
 [64.05513   ]
 [63.41457748]
 [62.78043365]
 [62.15262985]].
[2019-03-26 14:26:07,237] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.3995358e-11 1.0000000e+00 5.9913130e-10 6.3513153e-14 1.2652013e-19], sum to 1.0000
[2019-03-26 14:26:07,243] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5696
[2019-03-26 14:26:07,249] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 91.5, 1.0, 2.0, 0.5004310294897539, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 699274.8109756339, 699274.8109756333, 183663.2336015775], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2590200.0000, 
sim time next is 2590800.0000, 
raw observation next is [25.4, 91.66666666666666, 1.0, 2.0, 0.4971431653930173, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 694679.0281956465, 694679.0281956465, 183149.2888863903], 
processed observation next is [1.0, 1.0, 0.4028436018957346, 0.9166666666666665, 1.0, 1.0, 0.3941483920397798, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1929663967210129, 0.1929663967210129, 0.2733571475916273], 
reward next is 0.7266, 
noisyNet noise sample is [array([-2.3549895], dtype=float32), -0.66411775]. 
=============================================
[2019-03-26 14:26:13,382] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4500, global step 71714: loss 0.5389
[2019-03-26 14:26:13,385] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 4500, global step 71715: learning rate 0.0000
[2019-03-26 14:26:13,415] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4500, global step 71730: loss 0.4517
[2019-03-26 14:26:13,421] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 4500, global step 71730: learning rate 0.0000
[2019-03-26 14:26:13,844] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4500, global step 71815: loss 0.4412
[2019-03-26 14:26:13,846] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 4500, global step 71817: learning rate 0.0000
[2019-03-26 14:26:13,994] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4500, global step 71887: loss 0.4709
[2019-03-26 14:26:13,996] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 4500, global step 71887: learning rate 0.0000
[2019-03-26 14:26:14,097] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4500, global step 71933: loss 0.4779
[2019-03-26 14:26:14,101] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 4500, global step 71933: learning rate 0.0000
[2019-03-26 14:26:14,125] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4500, global step 71946: loss 0.4147
[2019-03-26 14:26:14,129] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 4500, global step 71947: learning rate 0.0000
[2019-03-26 14:26:14,199] A3C_AGENT_WORKER-Thread-18 INFO:Local step 4500, global step 71990: loss 0.4722
[2019-03-26 14:26:14,203] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 4500, global step 71991: learning rate 0.0000
[2019-03-26 14:26:14,245] A3C_AGENT_WORKER-Thread-20 INFO:Local step 4500, global step 72011: loss 0.4198
[2019-03-26 14:26:14,248] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 4500, global step 72011: learning rate 0.0000
[2019-03-26 14:26:14,270] A3C_AGENT_WORKER-Thread-22 INFO:Local step 4500, global step 72024: loss 0.4950
[2019-03-26 14:26:14,274] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 4500, global step 72024: learning rate 0.0000
[2019-03-26 14:26:14,275] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4500, global step 72026: loss 0.4585
[2019-03-26 14:26:14,277] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 4500, global step 72026: learning rate 0.0000
[2019-03-26 14:26:14,283] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4500, global step 72027: loss 0.4386
[2019-03-26 14:26:14,285] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 4500, global step 72029: learning rate 0.0000
[2019-03-26 14:26:14,360] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4500, global step 72065: loss 0.4018
[2019-03-26 14:26:14,362] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 4500, global step 72067: learning rate 0.0000
[2019-03-26 14:26:14,379] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4500, global step 72073: loss 0.4444
[2019-03-26 14:26:14,382] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 4500, global step 72073: learning rate 0.0000
[2019-03-26 14:26:14,450] A3C_AGENT_WORKER-Thread-19 INFO:Local step 4500, global step 72105: loss 0.5201
[2019-03-26 14:26:14,454] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 4500, global step 72107: learning rate 0.0000
[2019-03-26 14:26:14,530] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4500, global step 72143: loss 0.4238
[2019-03-26 14:26:14,533] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 4500, global step 72144: learning rate 0.0000
[2019-03-26 14:26:14,904] A3C_AGENT_WORKER-Thread-21 INFO:Local step 4500, global step 72317: loss 0.4139
[2019-03-26 14:26:14,906] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 4500, global step 72317: learning rate 0.0000
[2019-03-26 14:26:15,325] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.38031342e-09 1.00000000e+00 1.34449225e-08 1.05010903e-13
 5.39932219e-19], sum to 1.0000
[2019-03-26 14:26:15,334] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2930
[2019-03-26 14:26:15,339] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 100.0, 1.0, 2.0, 0.422891704354851, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 616621.4234102467, 616621.4234102473, 175696.9767287749], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2715000.0000, 
sim time next is 2715600.0000, 
raw observation next is [22.66666666666667, 100.0, 1.0, 2.0, 0.4157842069799606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 610144.6145788797, 610144.6145788797, 175191.8476672653], 
processed observation next is [0.0, 0.43478260869565216, 0.27330173775671435, 1.0, 1.0, 1.0, 0.2961255505782658, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1694846151607999, 0.1694846151607999, 0.26148036965263477], 
reward next is 0.7385, 
noisyNet noise sample is [array([-0.18569657], dtype=float32), 0.36667296]. 
=============================================
[2019-03-26 14:26:20,215] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-26 14:26:20,216] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 14:26:20,216] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 14:26:20,216] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:26:20,217] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:26:20,217] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 14:26:20,219] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 14:26:20,220] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 14:26:20,220] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:26:20,220] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:26:20,220] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:26:20,231] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run4
[2019-03-26 14:26:20,231] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run4
[2019-03-26 14:26:20,254] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run4
[2019-03-26 14:26:20,267] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run4
[2019-03-26 14:26:20,279] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run4
[2019-03-26 14:26:48,410] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.06804843], dtype=float32), 0.06845297]
[2019-03-26 14:26:48,411] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [23.0, 92.0, 1.0, 2.0, 0.394081204113536, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 593067.1690914348, 593067.1690914355, 174044.9325423233]
[2019-03-26 14:26:48,411] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 14:26:48,413] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [9.3943874e-11 1.0000000e+00 8.5666224e-10 2.4845699e-14 3.0525333e-20], sampled 0.19860189041059895
[2019-03-26 14:27:09,721] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.06804843], dtype=float32), 0.06845297]
[2019-03-26 14:27:09,722] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.33333333333334, 68.83333333333333, 1.0, 2.0, 0.8714642616102213, 1.0, 2.0, 0.8714642616102213, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2437402.51904506, 2437402.51904506, 456164.0993845579]
[2019-03-26 14:27:09,724] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 14:27:09,728] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.9804748e-12 1.0000000e+00 4.7050912e-11 1.1048157e-14 2.5283123e-21], sampled 0.1351764139131647
[2019-03-26 14:27:09,730] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2437402.51904506 W.
[2019-03-26 14:27:21,584] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.06804843], dtype=float32), 0.06845297]
[2019-03-26 14:27:21,585] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [35.6, 52.0, 1.0, 2.0, 0.8229908939381093, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005982964198855, 6.9112, 168.9123159944354, 2047250.54953473, 1980008.507536216, 413592.2260790381]
[2019-03-26 14:27:21,586] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 14:27:21,589] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.9395105e-11 1.0000000e+00 2.8389027e-10 6.5452671e-15 5.2100516e-21], sampled 0.7665548952611316
[2019-03-26 14:27:21,591] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2047250.54953473 W.
[2019-03-26 14:27:40,019] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.06804843], dtype=float32), 0.06845297]
[2019-03-26 14:27:40,021] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.03333333333333, 79.0, 1.0, 2.0, 0.8346916853147983, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1166608.810970497, 1166608.810970498, 252605.9111221198]
[2019-03-26 14:27:40,023] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 14:27:40,027] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.2603611e-10 1.0000000e+00 1.2284656e-09 3.2344200e-14 5.2469727e-20], sampled 0.05399409482206641
[2019-03-26 14:28:14,630] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.9164 3164002230.9074 1778.0000
[2019-03-26 14:28:15,157] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.6119 2842427357.4275 1131.0000
[2019-03-26 14:28:15,160] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.2362 2779138868.9993 933.0000
[2019-03-26 14:28:15,328] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.4067 2927264152.9822 1338.0000
[2019-03-26 14:28:15,401] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.9559 3007647868.8583 1766.0000
[2019-03-26 14:28:16,419] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 75000, evaluation results [75000.0, 7884.916440885027, 3164002230.907359, 1778.0, 8254.406660643592, 2927264152.9821725, 1338.0, 8659.23621041285, 2779138868.999297, 933.0, 7998.955910945021, 3007647868.858331, 1766.0, 8497.61193292354, 2842427357.427519, 1131.0]
[2019-03-26 14:28:19,306] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0589732e-09 1.0000000e+00 3.4387913e-09 7.5143017e-14 1.1102679e-18], sum to 1.0000
[2019-03-26 14:28:19,316] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8062
[2019-03-26 14:28:19,320] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.00000000000001, 1.0, 2.0, 0.3816734370932218, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 587957.306033519, 587957.3060335184, 173925.3497632101], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2866200.0000, 
sim time next is 2866800.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.350244189542749, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 539528.9942654476, 539528.9942654483, 169777.4929953436], 
processed observation next is [1.0, 0.17391304347826086, 0.2417061611374408, 0.94, 1.0, 1.0, 0.21716167414789037, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14986916507373543, 0.14986916507373563, 0.25339924327663227], 
reward next is 0.7466, 
noisyNet noise sample is [array([-0.6209507], dtype=float32), -0.17769812]. 
=============================================
[2019-03-26 14:28:26,526] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5000, global step 79717: loss 0.0387
[2019-03-26 14:28:26,531] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 5000, global step 79719: learning rate 0.0000
[2019-03-26 14:28:26,644] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5000, global step 79736: loss 0.0290
[2019-03-26 14:28:26,649] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 5000, global step 79738: learning rate 0.0000
[2019-03-26 14:28:26,952] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5000, global step 79849: loss 0.0159
[2019-03-26 14:28:26,955] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 5000, global step 79850: learning rate 0.0000
[2019-03-26 14:28:27,088] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5000, global step 79889: loss 0.0204
[2019-03-26 14:28:27,090] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 5000, global step 79889: learning rate 0.0000
[2019-03-26 14:28:27,202] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5000, global step 79909: loss 0.0369
[2019-03-26 14:28:27,204] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 5000, global step 79909: learning rate 0.0000
[2019-03-26 14:28:27,286] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5000, global step 79917: loss 0.0296
[2019-03-26 14:28:27,295] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 5000, global step 79917: learning rate 0.0000
[2019-03-26 14:28:27,419] A3C_AGENT_WORKER-Thread-18 INFO:Local step 5000, global step 79952: loss 0.0455
[2019-03-26 14:28:27,421] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 5000, global step 79953: learning rate 0.0000
[2019-03-26 14:28:27,558] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5000, global step 79982: loss 0.0444
[2019-03-26 14:28:27,561] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 5000, global step 79982: learning rate 0.0000
[2019-03-26 14:28:27,704] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5000, global step 80020: loss 0.0467
[2019-03-26 14:28:27,706] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 5000, global step 80021: learning rate 0.0000
[2019-03-26 14:28:27,788] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5000, global step 80032: loss 0.0366
[2019-03-26 14:28:27,791] A3C_AGENT_WORKER-Thread-22 INFO:Local step 5000, global step 80032: loss 0.0466
[2019-03-26 14:28:27,791] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 5000, global step 80032: learning rate 0.0000
[2019-03-26 14:28:27,792] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 5000, global step 80032: learning rate 0.0000
[2019-03-26 14:28:27,952] A3C_AGENT_WORKER-Thread-20 INFO:Local step 5000, global step 80043: loss 0.0273
[2019-03-26 14:28:27,954] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 5000, global step 80043: learning rate 0.0000
[2019-03-26 14:28:28,102] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5000, global step 80088: loss 0.0222
[2019-03-26 14:28:28,104] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 5000, global step 80088: learning rate 0.0000
[2019-03-26 14:28:28,255] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5000, global step 80135: loss 0.0313
[2019-03-26 14:28:28,260] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 5000, global step 80138: learning rate 0.0000
[2019-03-26 14:28:28,336] A3C_AGENT_WORKER-Thread-19 INFO:Local step 5000, global step 80144: loss 0.0289
[2019-03-26 14:28:28,339] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 5000, global step 80144: learning rate 0.0000
[2019-03-26 14:28:28,703] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.9742166e-12 1.0000000e+00 3.8423962e-11 1.8873501e-15 3.0561088e-21], sum to 1.0000
[2019-03-26 14:28:28,704] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7959
[2019-03-26 14:28:28,712] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.3041065107829917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 484272.064722271, 484272.064722271, 165928.8890831842], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3011400.0000, 
sim time next is 3012000.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.3044939415586104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 484889.0046768906, 484889.0046768906, 165973.4332609786], 
processed observation next is [1.0, 0.8695652173913043, 0.1469194312796209, 1.0, 1.0, 1.0, 0.16204089344410894, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13469139018802517, 0.13469139018802517, 0.24772154218056508], 
reward next is 0.7523, 
noisyNet noise sample is [array([1.5832881], dtype=float32), 0.3348014]. 
=============================================
[2019-03-26 14:28:28,730] A3C_AGENT_WORKER-Thread-21 INFO:Local step 5000, global step 80311: loss 0.0231
[2019-03-26 14:28:28,736] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 5000, global step 80312: learning rate 0.0000
[2019-03-26 14:28:28,738] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[74.904045]
 [74.991974]
 [75.09266 ]
 [75.20075 ]
 [75.34619 ]], R is [[74.76520538]
 [74.76989746]
 [74.77456665]
 [74.77910614]
 [74.78347015]].
[2019-03-26 14:28:32,978] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.5739981e-13 1.0000000e+00 5.6477652e-12 2.9926974e-17 7.4661507e-23], sum to 1.0000
[2019-03-26 14:28:32,984] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5129
[2019-03-26 14:28:33,082] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333333, 98.0, 1.0, 2.0, 0.8182030209497433, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1182308.866422852, 1182308.866422852, 253874.7332175714], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3084000.0000, 
sim time next is 3084600.0000, 
raw observation next is [23.16666666666667, 99.0, 1.0, 2.0, 0.8289850511146034, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1200021.199769907, 1200021.199769906, 256993.3451680696], 
processed observation next is [1.0, 0.6956521739130435, 0.2969984202211693, 0.99, 1.0, 1.0, 0.7939578929091607, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.33333922215830747, 0.33333922215830725, 0.38357215696726804], 
reward next is 0.6164, 
noisyNet noise sample is [array([1.1386733], dtype=float32), 0.74327636]. 
=============================================
[2019-03-26 14:28:34,167] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.4797800e-11 1.0000000e+00 1.1896249e-10 4.0668711e-15 1.3086881e-20], sum to 1.0000
[2019-03-26 14:28:34,173] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7007
[2019-03-26 14:28:34,175] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 100.0, 1.0, 2.0, 0.3841203323757227, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 578558.9167785364, 578558.9167785364, 172746.2695860706], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3103800.0000, 
sim time next is 3104400.0000, 
raw observation next is [22.0, 100.0, 1.0, 2.0, 0.3842440237526168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 578745.0650865849, 578745.0650865849, 172762.9101557906], 
processed observation next is [1.0, 0.9565217391304348, 0.2417061611374408, 1.0, 1.0, 1.0, 0.25812532982242986, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16076251807960693, 0.16076251807960693, 0.25785508978476207], 
reward next is 0.7421, 
noisyNet noise sample is [array([0.09734461], dtype=float32), -0.71957606]. 
=============================================
[2019-03-26 14:28:44,349] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.6790701e-11 1.0000000e+00 8.1636198e-11 5.3390558e-15 1.6308273e-20], sum to 1.0000
[2019-03-26 14:28:44,352] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6308
[2019-03-26 14:28:44,364] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.4870881078076754, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 680624.172679582, 680624.172679582, 181597.4172454706], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3281400.0000, 
sim time next is 3282000.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.4867241055259631, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 680115.3775419996, 680115.3775420003, 181541.8185202424], 
processed observation next is [0.0, 1.0, 0.4786729857819906, 0.79, 1.0, 1.0, 0.38159530786260615, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.188920938206111, 0.1889209382061112, 0.27095793808991403], 
reward next is 0.7290, 
noisyNet noise sample is [array([-0.09131645], dtype=float32), 0.009784995]. 
=============================================
[2019-03-26 14:28:44,399] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[72.83836 ]
 [72.868935]
 [72.91428 ]
 [72.95171 ]
 [73.01955 ]], R is [[72.81259918]
 [72.81343079]
 [72.81414032]
 [72.81466675]
 [72.81466675]].
[2019-03-26 14:28:44,558] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5500, global step 87683: loss 0.1009
[2019-03-26 14:28:44,562] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 5500, global step 87684: learning rate 0.0000
[2019-03-26 14:28:44,709] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5500, global step 87752: loss 0.1358
[2019-03-26 14:28:44,713] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 5500, global step 87753: learning rate 0.0000
[2019-03-26 14:28:44,960] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5500, global step 87869: loss 0.1205
[2019-03-26 14:28:44,961] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5500, global step 87869: loss 0.1208
[2019-03-26 14:28:44,965] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 5500, global step 87870: learning rate 0.0000
[2019-03-26 14:28:44,966] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 5500, global step 87870: learning rate 0.0000
[2019-03-26 14:28:44,966] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5500, global step 87872: loss 0.1825
[2019-03-26 14:28:44,971] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 5500, global step 87872: learning rate 0.0000
[2019-03-26 14:28:45,186] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5500, global step 87970: loss 0.0823
[2019-03-26 14:28:45,191] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 5500, global step 87972: learning rate 0.0000
[2019-03-26 14:28:45,198] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5500, global step 87976: loss 0.1014
[2019-03-26 14:28:45,203] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 5500, global step 87977: learning rate 0.0000
[2019-03-26 14:28:45,254] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5500, global step 88000: loss 0.0905
[2019-03-26 14:28:45,256] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 5500, global step 88000: learning rate 0.0000
[2019-03-26 14:28:45,282] A3C_AGENT_WORKER-Thread-18 INFO:Local step 5500, global step 88014: loss 0.0842
[2019-03-26 14:28:45,284] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 5500, global step 88014: learning rate 0.0000
[2019-03-26 14:28:45,375] A3C_AGENT_WORKER-Thread-22 INFO:Local step 5500, global step 88055: loss 0.1295
[2019-03-26 14:28:45,379] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 5500, global step 88056: learning rate 0.0000
[2019-03-26 14:28:45,389] A3C_AGENT_WORKER-Thread-20 INFO:Local step 5500, global step 88060: loss 0.0614
[2019-03-26 14:28:45,393] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 5500, global step 88061: learning rate 0.0000
[2019-03-26 14:28:45,445] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5500, global step 88090: loss 0.1011
[2019-03-26 14:28:45,448] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 5500, global step 88090: learning rate 0.0000
[2019-03-26 14:28:45,452] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5500, global step 88091: loss 0.1056
[2019-03-26 14:28:45,458] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 5500, global step 88092: learning rate 0.0000
[2019-03-26 14:28:45,477] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5500, global step 88101: loss 0.0948
[2019-03-26 14:28:45,481] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 5500, global step 88105: learning rate 0.0000
[2019-03-26 14:28:45,520] A3C_AGENT_WORKER-Thread-19 INFO:Local step 5500, global step 88121: loss 0.1374
[2019-03-26 14:28:45,523] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 5500, global step 88124: learning rate 0.0000
[2019-03-26 14:28:45,843] A3C_AGENT_WORKER-Thread-21 INFO:Local step 5500, global step 88275: loss 0.1128
[2019-03-26 14:28:45,844] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 5500, global step 88275: learning rate 0.0000
[2019-03-26 14:28:54,458] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.6891449e-12 1.0000000e+00 5.9379765e-11 5.6364355e-15 4.3287193e-21], sum to 1.0000
[2019-03-26 14:28:54,467] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4814
[2019-03-26 14:28:54,473] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.5087901389756155, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 710959.2798855759, 710959.2798855753, 184984.8540444339], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3456600.0000, 
sim time next is 3457200.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.5085543023491554, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 710629.6227059133, 710629.6227059127, 184947.3115575033], 
processed observation next is [1.0, 0.0, 0.4786729857819906, 0.84, 1.0, 1.0, 0.4078967498182595, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19739711741830923, 0.19739711741830906, 0.27604076351866164], 
reward next is 0.7240, 
noisyNet noise sample is [array([0.50548595], dtype=float32), 1.8446102]. 
=============================================
[2019-03-26 14:28:55,397] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.4663983e-11 1.0000000e+00 6.4827858e-11 2.7738852e-14 7.6062988e-22], sum to 1.0000
[2019-03-26 14:28:55,410] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8492
[2019-03-26 14:28:55,418] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.6314400152950168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 882415.6075562012, 882415.6075562018, 206739.2901925117], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3477000.0000, 
sim time next is 3477600.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.6299421513822115, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 880321.5269919345, 880321.5269919339, 206446.722956264], 
processed observation next is [1.0, 0.2608695652173913, 0.4786729857819906, 0.79, 1.0, 1.0, 0.5541471703400139, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.24453375749775957, 0.24453375749775944, 0.3081294372481552], 
reward next is 0.6919, 
noisyNet noise sample is [array([0.04784673], dtype=float32), -0.5123459]. 
=============================================
[2019-03-26 14:28:56,215] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.6216186e-11 1.0000000e+00 1.5126150e-10 3.6811445e-13 2.8539922e-20], sum to 1.0000
[2019-03-26 14:28:56,225] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4781
[2019-03-26 14:28:56,233] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2144997.45822939 W.
[2019-03-26 14:28:56,239] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.0, 66.0, 1.0, 2.0, 0.7670114111998811, 1.0, 1.0, 0.7670114111998811, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2144997.45822939, 2144997.45822939, 404123.034347956], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3490200.0000, 
sim time next is 3490800.0000, 
raw observation next is [30.0, 66.0, 1.0, 2.0, 0.7566850440086574, 1.0, 2.0, 0.7566850440086574, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2116090.574450688, 2116090.574450688, 399327.2873834728], 
processed observation next is [1.0, 0.391304347826087, 0.6208530805687204, 0.66, 1.0, 1.0, 0.7068494506128403, 1.0, 1.0, 0.7068494506128403, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5878029373474133, 0.5878029373474133, 0.5960108766917505], 
reward next is 0.4040, 
noisyNet noise sample is [array([-0.23725934], dtype=float32), 1.4787571]. 
=============================================
[2019-03-26 14:28:56,279] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.3834011e-11 1.0000000e+00 5.2218546e-12 4.7054879e-14 2.7268549e-19], sum to 1.0000
[2019-03-26 14:28:56,285] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4167
[2019-03-26 14:28:56,293] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1940727.53954735 W.
[2019-03-26 14:28:56,300] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.0, 66.0, 1.0, 2.0, 0.7468764304624694, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.976476033913704, 6.9112, 168.9125678979949, 1940727.53954735, 1894418.581002997, 396168.1301729754], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3489000.0000, 
sim time next is 3489600.0000, 
raw observation next is [30.0, 66.0, 1.0, 2.0, 0.4913822480190611, 1.0, 1.0, 0.4913822480190611, 1.0, 2.0, 0.8384058504574875, 6.9112, 6.9112, 170.5573041426782, 2061193.228968309, 2061193.228968309, 406560.3059006867], 
processed observation next is [1.0, 0.391304347826087, 0.6208530805687204, 0.66, 1.0, 1.0, 0.3872075277338086, 1.0, 0.5, 0.3872075277338086, 1.0, 1.0, 0.8029339639725456, 0.0, 0.0, 0.8375144448122397, 0.5725536747134191, 0.5725536747134191, 0.6068064267174429], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5425266], dtype=float32), -1.256571]. 
=============================================
[2019-03-26 14:29:00,365] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.9458301e-11 1.0000000e+00 3.7827894e-11 3.4276632e-14 7.3657351e-20], sum to 1.0000
[2019-03-26 14:29:00,373] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6973
[2019-03-26 14:29:00,378] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 79.0, 1.0, 2.0, 0.7939722997936991, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1109667.527557437, 1109667.527557437, 242435.3599111704], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3567600.0000, 
sim time next is 3568200.0000, 
raw observation next is [28.16666666666667, 78.16666666666667, 1.0, 2.0, 0.8070051035911043, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1127892.042392526, 1127892.042392526, 245636.3879014691], 
processed observation next is [1.0, 0.30434782608695654, 0.5339652448657191, 0.7816666666666667, 1.0, 1.0, 0.7674760284230172, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.313303345109035, 0.313303345109035, 0.36662147447980464], 
reward next is 0.6334, 
noisyNet noise sample is [array([0.4246174], dtype=float32), 1.5601695]. 
=============================================
[2019-03-26 14:29:01,743] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6000, global step 95701: loss -85.8339
[2019-03-26 14:29:01,744] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 6000, global step 95701: learning rate 0.0000
[2019-03-26 14:29:01,888] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6000, global step 95769: loss -148.1122
[2019-03-26 14:29:01,890] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 6000, global step 95769: learning rate 0.0000
[2019-03-26 14:29:02,081] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6000, global step 95856: loss -120.8217
[2019-03-26 14:29:02,083] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 6000, global step 95856: learning rate 0.0000
[2019-03-26 14:29:02,095] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6000, global step 95860: loss -126.1262
[2019-03-26 14:29:02,098] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 6000, global step 95862: learning rate 0.0000
[2019-03-26 14:29:02,260] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6000, global step 95936: loss -133.6210
[2019-03-26 14:29:02,264] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 6000, global step 95937: learning rate 0.0000
[2019-03-26 14:29:02,335] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6000, global step 95972: loss -163.9070
[2019-03-26 14:29:02,337] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 6000, global step 95972: learning rate 0.0000
[2019-03-26 14:29:02,361] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6000, global step 95983: loss -102.1979
[2019-03-26 14:29:02,365] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 6000, global step 95984: learning rate 0.0000
[2019-03-26 14:29:02,388] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6000, global step 95996: loss -133.2024
[2019-03-26 14:29:02,392] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 6000, global step 95996: learning rate 0.0000
[2019-03-26 14:29:02,468] A3C_AGENT_WORKER-Thread-18 INFO:Local step 6000, global step 96031: loss -112.2226
[2019-03-26 14:29:02,469] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 6000, global step 96031: learning rate 0.0000
[2019-03-26 14:29:02,525] A3C_AGENT_WORKER-Thread-22 INFO:Local step 6000, global step 96059: loss -104.9808
[2019-03-26 14:29:02,527] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 6000, global step 96059: learning rate 0.0000
[2019-03-26 14:29:02,541] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6000, global step 96064: loss -107.2804
[2019-03-26 14:29:02,545] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 6000, global step 96064: learning rate 0.0000
[2019-03-26 14:29:02,554] A3C_AGENT_WORKER-Thread-20 INFO:Local step 6000, global step 96070: loss -101.8123
[2019-03-26 14:29:02,556] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 6000, global step 96071: learning rate 0.0000
[2019-03-26 14:29:02,582] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6000, global step 96081: loss -97.1331
[2019-03-26 14:29:02,583] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 6000, global step 96081: learning rate 0.0000
[2019-03-26 14:29:02,675] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6000, global step 96124: loss -126.0690
[2019-03-26 14:29:02,680] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 6000, global step 96127: learning rate 0.0000
[2019-03-26 14:29:02,812] A3C_AGENT_WORKER-Thread-19 INFO:Local step 6000, global step 96189: loss -68.3713
[2019-03-26 14:29:02,813] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 6000, global step 96189: learning rate 0.0000
[2019-03-26 14:29:02,894] A3C_AGENT_WORKER-Thread-21 INFO:Local step 6000, global step 96226: loss -109.7444
[2019-03-26 14:29:02,899] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 6000, global step 96227: learning rate 0.0000
[2019-03-26 14:29:06,630] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.10945472e-11 1.00000000e+00 1.85721910e-10 1.05199344e-13
 7.23880281e-19], sum to 1.0000
[2019-03-26 14:29:06,638] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1348
[2019-03-26 14:29:06,648] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2077084.072231591 W.
[2019-03-26 14:29:06,652] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.33333333333333, 71.33333333333333, 1.0, 2.0, 0.4951669079973349, 1.0, 2.0, 0.4951669079973349, 1.0, 1.0, 0.8599411649925851, 6.9112, 6.9112, 170.5573041426782, 2077084.072231591, 2077084.072231591, 411819.4050963726], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3663600.0000, 
sim time next is 3664200.0000, 
raw observation next is [30.66666666666667, 70.66666666666667, 1.0, 2.0, 0.7551661749986518, 1.0, 2.0, 0.7551661749986518, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2111838.828450303, 2111838.828450303, 398637.0473215442], 
processed observation next is [1.0, 0.391304347826087, 0.6524486571879939, 0.7066666666666667, 1.0, 1.0, 0.7050194879501829, 1.0, 1.0, 0.7050194879501829, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5866218967917508, 0.5866218967917508, 0.5949806676440959], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2624986], dtype=float32), -0.80091995]. 
=============================================
[2019-03-26 14:29:10,622] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.2315265e-10 1.0000000e+00 5.5159721e-10 2.4447161e-14 3.6659567e-19], sum to 1.0000
[2019-03-26 14:29:10,629] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9865
[2019-03-26 14:29:10,640] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333334, 78.16666666666667, 1.0, 2.0, 0.7734726480349765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1108856.419180989, 1108856.419180989, 241347.843446347], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3737400.0000, 
sim time next is 3738000.0000, 
raw observation next is [26.66666666666667, 77.33333333333334, 1.0, 2.0, 0.7423142376266154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1055433.815284891, 1055433.815284892, 232701.0231211197], 
processed observation next is [1.0, 0.2608695652173913, 0.4628751974723541, 0.7733333333333334, 1.0, 1.0, 0.6895352260561631, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.29317605980135863, 0.2931760598013589, 0.34731495988226824], 
reward next is 0.6527, 
noisyNet noise sample is [array([-0.00076458], dtype=float32), 2.026505]. 
=============================================
[2019-03-26 14:29:10,658] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[64.60941 ]
 [64.49094 ]
 [64.431335]
 [64.471954]
 [64.35137 ]], R is [[64.79219818]
 [64.78405762]
 [64.86110687]
 [64.93842316]
 [65.01533508]].
[2019-03-26 14:29:11,166] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-26 14:29:11,168] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 14:29:11,168] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 14:29:11,168] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:29:11,169] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:29:11,169] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 14:29:11,171] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 14:29:11,173] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:29:11,169] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 14:29:11,174] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:29:11,175] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:29:11,189] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run5
[2019-03-26 14:29:11,189] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run5
[2019-03-26 14:29:11,190] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run5
[2019-03-26 14:29:11,206] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run5
[2019-03-26 14:29:11,237] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run5
[2019-03-26 14:29:18,605] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.06157393], dtype=float32), 0.061847802]
[2019-03-26 14:29:18,607] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [20.50298993, 76.58616857166666, 1.0, 2.0, 0.2612592366612927, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 431140.4616253478, 431140.4616253471, 161998.3575680665]
[2019-03-26 14:29:18,610] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 14:29:18,612] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.28715566e-09 1.00000000e+00 4.92893282e-09 3.30266717e-12
 1.07151766e-16], sampled 0.2923270290972225
[2019-03-26 14:29:24,974] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.06157393], dtype=float32), 0.061847802]
[2019-03-26 14:29:24,977] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [21.8, 95.0, 1.0, 2.0, 0.3426359610186044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 528995.1205086668, 528995.1205086668, 168956.2888355418]
[2019-03-26 14:29:24,979] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 14:29:24,982] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.2920063e-10 1.0000000e+00 8.9853835e-10 3.8097355e-13 7.5808812e-18], sampled 0.35598251690480187
[2019-03-26 14:29:49,955] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.06157393], dtype=float32), 0.061847802]
[2019-03-26 14:29:49,957] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.4, 87.16666666666667, 1.0, 2.0, 0.4845540519757212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 681858.7902087636, 681858.7902087636, 181825.962305322]
[2019-03-26 14:29:49,959] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 14:29:49,962] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.1736458e-10 1.0000000e+00 1.9120153e-10 4.8723795e-14 3.9151839e-19], sampled 0.39324191835908795
[2019-03-26 14:30:25,890] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.06157393], dtype=float32), 0.061847802]
[2019-03-26 14:30:25,894] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [30.510187855, 79.843767335, 1.0, 2.0, 0.6148817151994926, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 859266.5948728019, 859266.5948728019, 203551.156548397]
[2019-03-26 14:30:25,895] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 14:30:25,897] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [5.0148929e-10 1.0000000e+00 8.3872082e-10 2.7894744e-13 4.0291099e-18], sampled 0.698850812178576
[2019-03-26 14:30:26,378] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.06157393], dtype=float32), 0.061847802]
[2019-03-26 14:30:26,379] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [31.75, 72.66666666666666, 1.0, 2.0, 0.8213030511738676, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 7.005983305869747, 6.9112, 168.9115200027923, 2044888.288826809, 1977646.321312346, 413173.2662199519]
[2019-03-26 14:30:26,380] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 14:30:26,386] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.1320421e-11 1.0000000e+00 6.1157621e-11 8.0675407e-15 5.1851116e-20], sampled 0.8438756520402199
[2019-03-26 14:30:26,387] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2044888.288826809 W.
[2019-03-26 14:30:27,275] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.06157393], dtype=float32), 0.061847802]
[2019-03-26 14:30:27,276] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.5, 76.33333333333333, 1.0, 2.0, 0.5591477641935646, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 781352.5245396943, 781352.524539695, 193381.7546499951]
[2019-03-26 14:30:27,281] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 14:30:27,284] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [6.0664675e-11 1.0000000e+00 1.1786641e-10 2.3008249e-14 1.8211812e-19], sampled 0.6230186577116622
[2019-03-26 14:30:53,753] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.06157393], dtype=float32), 0.061847802]
[2019-03-26 14:30:53,755] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.1, 83.33333333333333, 1.0, 2.0, 0.4757443886555056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 664768.2625797977, 664768.2625797983, 179882.6405718185]
[2019-03-26 14:30:53,760] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 14:30:53,762] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [7.7433254e-11 1.0000000e+00 1.4539492e-10 4.7185644e-14 2.4886708e-19], sampled 0.7666612858027357
[2019-03-26 14:31:05,116] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.1685 3164067279.4129 1778.0000
[2019-03-26 14:31:05,535] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.4238 2927327234.8387 1338.0000
[2019-03-26 14:31:05,571] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.5359 3007633228.8372 1766.0000
[2019-03-26 14:31:05,794] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.0947 2842458868.8499 1131.0000
[2019-03-26 14:31:05,855] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.4454 2779139371.5791 933.0000
[2019-03-26 14:31:06,871] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 100000, evaluation results [100000.0, 7884.168455680242, 3164067279.4128904, 1778.0, 8254.423757959617, 2927327234.8387394, 1338.0, 8661.445426124437, 2779139371.579139, 933.0, 7997.535888633051, 3007633228.837176, 1766.0, 8496.094725848043, 2842458868.8498697, 1131.0]
[2019-03-26 14:31:11,123] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.56819699e-09 1.00000000e+00 1.37005065e-08 1.32789331e-12
 2.95119315e-17], sum to 1.0000
[2019-03-26 14:31:11,130] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1964
[2019-03-26 14:31:11,137] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 0.5372182014358915, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 750697.3467929722, 750697.3467929728, 189632.8018916804], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3819600.0000, 
sim time next is 3820200.0000, 
raw observation next is [27.0, 89.0, 1.0, 2.0, 0.5367293006554279, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 750013.925996794, 750013.9259967934, 189550.8769393339], 
processed observation next is [0.0, 0.21739130434782608, 0.4786729857819906, 0.89, 1.0, 1.0, 0.4418425309101541, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20833720166577613, 0.20833720166577596, 0.2829117566258715], 
reward next is 0.7171, 
noisyNet noise sample is [array([0.73897135], dtype=float32), -0.15420002]. 
=============================================
[2019-03-26 14:31:14,891] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6500, global step 103636: loss 0.0753
[2019-03-26 14:31:14,893] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 6500, global step 103637: learning rate 0.0000
[2019-03-26 14:31:15,095] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6500, global step 103732: loss 0.0544
[2019-03-26 14:31:15,098] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 6500, global step 103734: learning rate 0.0000
[2019-03-26 14:31:15,301] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6500, global step 103827: loss 0.0591
[2019-03-26 14:31:15,304] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 6500, global step 103827: learning rate 0.0000
[2019-03-26 14:31:15,387] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6500, global step 103867: loss 0.0842
[2019-03-26 14:31:15,389] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 6500, global step 103867: learning rate 0.0000
[2019-03-26 14:31:15,452] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6500, global step 103896: loss 0.0685
[2019-03-26 14:31:15,455] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 6500, global step 103897: learning rate 0.0000
[2019-03-26 14:31:15,473] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6500, global step 103903: loss 0.0659
[2019-03-26 14:31:15,477] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 6500, global step 103905: learning rate 0.0000
[2019-03-26 14:31:15,617] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6500, global step 103970: loss 0.0303
[2019-03-26 14:31:15,620] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 6500, global step 103970: learning rate 0.0000
[2019-03-26 14:31:15,703] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6500, global step 104011: loss 0.0572
[2019-03-26 14:31:15,705] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 6500, global step 104011: learning rate 0.0000
[2019-03-26 14:31:15,727] A3C_AGENT_WORKER-Thread-18 INFO:Local step 6500, global step 104021: loss 0.0359
[2019-03-26 14:31:15,729] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 6500, global step 104023: learning rate 0.0000
[2019-03-26 14:31:15,764] A3C_AGENT_WORKER-Thread-22 INFO:Local step 6500, global step 104039: loss 0.0746
[2019-03-26 14:31:15,768] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 6500, global step 104039: learning rate 0.0000
[2019-03-26 14:31:15,893] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6500, global step 104098: loss 0.0484
[2019-03-26 14:31:15,894] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 6500, global step 104098: learning rate 0.0000
[2019-03-26 14:31:15,897] A3C_AGENT_WORKER-Thread-20 INFO:Local step 6500, global step 104099: loss 0.0501
[2019-03-26 14:31:15,901] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 6500, global step 104099: learning rate 0.0000
[2019-03-26 14:31:15,928] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6500, global step 104111: loss 0.0393
[2019-03-26 14:31:15,933] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 6500, global step 104112: learning rate 0.0000
[2019-03-26 14:31:15,953] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6500, global step 104125: loss 0.0335
[2019-03-26 14:31:15,959] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 6500, global step 104127: learning rate 0.0000
[2019-03-26 14:31:16,054] A3C_AGENT_WORKER-Thread-19 INFO:Local step 6500, global step 104170: loss 0.0347
[2019-03-26 14:31:16,061] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 6500, global step 104171: learning rate 0.0000
[2019-03-26 14:31:16,326] A3C_AGENT_WORKER-Thread-21 INFO:Local step 6500, global step 104298: loss 0.0761
[2019-03-26 14:31:16,328] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 6500, global step 104299: learning rate 0.0000
[2019-03-26 14:31:22,477] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.1402170e-10 1.0000000e+00 1.7335891e-11 1.0078364e-13 2.5673087e-18], sum to 1.0000
[2019-03-26 14:31:22,481] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9785
[2019-03-26 14:31:22,487] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2324990.784385889 W.
[2019-03-26 14:31:22,492] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.33333333333334, 65.5, 1.0, 2.0, 0.5542067585732458, 1.0, 2.0, 0.5542067585732458, 1.0, 1.0, 0.9624738606660007, 6.911199999999999, 6.9112, 170.5573041426782, 2324990.784385889, 2324990.784385889, 454654.4909143751], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4014600.0000, 
sim time next is 4015200.0000, 
raw observation next is [31.66666666666667, 65.0, 1.0, 2.0, 0.9075889165263953, 1.0, 2.0, 0.9075889165263953, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2538542.371041703, 2538542.371041703, 475646.7017356601], 
processed observation next is [1.0, 0.4782608695652174, 0.6998420221169038, 0.65, 1.0, 1.0, 0.8886613452125244, 1.0, 1.0, 0.8886613452125244, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7051506586226953, 0.7051506586226953, 0.7099204503517315], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.11687473], dtype=float32), 0.5360796]. 
=============================================
[2019-03-26 14:31:22,537] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.7636785e-13 1.0000000e+00 1.4336906e-12 3.3020953e-15 1.0408771e-19], sum to 1.0000
[2019-03-26 14:31:22,543] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1344
[2019-03-26 14:31:22,550] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 3260314.898912178 W.
[2019-03-26 14:31:22,555] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [34.0, 60.0, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 7.400599545809974, 6.9112, 170.5573041426782, 3260314.898912178, 2909738.096747777, 551010.9944137485], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4027200.0000, 
sim time next is 4027800.0000, 
raw observation next is [34.0, 60.0, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 7.697722896298241, 6.9112, 170.5573041426782, 3473404.399479291, 2909986.055154991, 549238.0584920059], 
processed observation next is [1.0, 0.6086956521739131, 0.8104265402843602, 0.6, 1.0, 1.0, 1.0481927710843375, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.2195121951219512, 0.07865228962982407, 0.0, 0.8375144448122397, 0.9648345554109141, 0.8083294597652753, 0.8197582962567252], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.3474763], dtype=float32), 0.3205851]. 
=============================================
[2019-03-26 14:31:23,162] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.5985749e-11 1.0000000e+00 1.2380538e-12 1.2884107e-13 1.5848740e-18], sum to 1.0000
[2019-03-26 14:31:23,168] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0429
[2019-03-26 14:31:23,179] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2505372.09047754 W.
[2019-03-26 14:31:23,182] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.33333333333334, 72.66666666666667, 1.0, 2.0, 0.895741634523536, 1.0, 2.0, 0.895741634523536, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2505372.09047754, 2505372.09047754, 469179.2166594682], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4034400.0000, 
sim time next is 4035000.0000, 
raw observation next is [30.66666666666666, 75.83333333333334, 1.0, 2.0, 0.8735555611775523, 1.0, 2.0, 0.8735555611775523, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2443257.403052772, 2443257.403052772, 457275.1177242014], 
processed observation next is [1.0, 0.6956521739130435, 0.6524486571879934, 0.7583333333333334, 1.0, 1.0, 0.847657302623557, 1.0, 1.0, 0.847657302623557, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6786826119591033, 0.6786826119591033, 0.6825001757077633], 
reward next is 0.3175, 
noisyNet noise sample is [array([-1.1926438], dtype=float32), 0.8561016]. 
=============================================
[2019-03-26 14:31:23,193] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[64.94238]
 [64.9615 ]
 [64.90431]
 [64.54282]
 [65.33421]], R is [[64.55091095]
 [64.20513916]
 [63.56308746]
 [62.9274559 ]
 [62.29818344]].
[2019-03-26 14:31:23,752] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.1567084e-12 1.0000000e+00 2.8853005e-12 8.0695142e-14 4.7519975e-19], sum to 1.0000
[2019-03-26 14:31:23,764] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3769
[2019-03-26 14:31:23,771] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 79.00000000000001, 1.0, 2.0, 0.3922473878307647, 1.0, 1.0, 0.3922473878307647, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1096409.302853629, 1096409.302853629, 270203.0300943994], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4036200.0000, 
sim time next is 4036800.0000, 
raw observation next is [30.0, 79.0, 1.0, 2.0, 0.5430549452168892, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129564852798, 758856.4024633865, 758856.4024633865, 190620.2142024077], 
processed observation next is [1.0, 0.7391304347826086, 0.6208530805687204, 0.79, 1.0, 1.0, 0.4494637894179388, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399450287988, 0.21079344512871848, 0.21079344512871848, 0.28450778239165325], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5301733], dtype=float32), -0.7723018]. 
=============================================
[2019-03-26 14:31:25,783] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.8877715e-11 1.0000000e+00 3.7342286e-11 4.6456471e-15 7.2004861e-21], sum to 1.0000
[2019-03-26 14:31:25,791] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9138
[2019-03-26 14:31:25,794] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 0.6571349986278583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 918338.9833539705, 918338.9833539705, 211865.1391908308], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4082400.0000, 
sim time next is 4083000.0000, 
raw observation next is [27.0, 89.83333333333334, 1.0, 2.0, 0.7336170904601088, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1025273.464897259, 1025273.464897259, 228269.2253772327], 
processed observation next is [1.0, 0.2608695652173913, 0.4786729857819906, 0.8983333333333334, 1.0, 1.0, 0.6790567354941069, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.28479818469368307, 0.28479818469368307, 0.34070033638392944], 
reward next is 0.6593, 
noisyNet noise sample is [array([0.855826], dtype=float32), 0.14944066]. 
=============================================
[2019-03-26 14:31:25,812] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[70.28049]
 [70.22465]
 [70.11993]
 [69.93998]
 [69.84833]], R is [[70.23576355]
 [70.2171936 ]
 [70.18458557]
 [70.1572876 ]
 [70.14261627]].
[2019-03-26 14:31:32,283] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7000, global step 111742: loss -169.7738
[2019-03-26 14:31:32,284] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 7000, global step 111742: learning rate 0.0000
[2019-03-26 14:31:32,392] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7000, global step 111800: loss -160.5389
[2019-03-26 14:31:32,398] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 7000, global step 111800: learning rate 0.0000
[2019-03-26 14:31:32,543] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7000, global step 111869: loss -128.4239
[2019-03-26 14:31:32,545] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 7000, global step 111869: learning rate 0.0000
[2019-03-26 14:31:32,591] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7000, global step 111886: loss -221.7516
[2019-03-26 14:31:32,594] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 7000, global step 111886: learning rate 0.0000
[2019-03-26 14:31:32,599] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7000, global step 111891: loss -157.0259
[2019-03-26 14:31:32,602] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7000, global step 111892: loss -140.8994
[2019-03-26 14:31:32,604] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 7000, global step 111892: learning rate 0.0000
[2019-03-26 14:31:32,608] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 7000, global step 111893: learning rate 0.0000
[2019-03-26 14:31:32,786] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7000, global step 111974: loss -190.5414
[2019-03-26 14:31:32,787] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 7000, global step 111974: learning rate 0.0000
[2019-03-26 14:31:32,845] A3C_AGENT_WORKER-Thread-22 INFO:Local step 7000, global step 112001: loss -182.8692
[2019-03-26 14:31:32,850] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 7000, global step 112002: learning rate 0.0000
[2019-03-26 14:31:32,883] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7000, global step 112023: loss -156.1453
[2019-03-26 14:31:32,885] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 7000, global step 112023: learning rate 0.0000
[2019-03-26 14:31:32,941] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7000, global step 112046: loss -164.9541
[2019-03-26 14:31:32,943] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 7000, global step 112046: learning rate 0.0000
[2019-03-26 14:31:32,983] A3C_AGENT_WORKER-Thread-18 INFO:Local step 7000, global step 112062: loss -180.7849
[2019-03-26 14:31:32,985] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 7000, global step 112063: learning rate 0.0000
[2019-03-26 14:31:33,051] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7000, global step 112099: loss -172.0055
[2019-03-26 14:31:33,052] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 7000, global step 112099: learning rate 0.0000
[2019-03-26 14:31:33,086] A3C_AGENT_WORKER-Thread-19 INFO:Local step 7000, global step 112116: loss -169.5329
[2019-03-26 14:31:33,086] A3C_AGENT_WORKER-Thread-20 INFO:Local step 7000, global step 112116: loss -122.6398
[2019-03-26 14:31:33,089] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 7000, global step 112117: learning rate 0.0000
[2019-03-26 14:31:33,090] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 7000, global step 112117: learning rate 0.0000
[2019-03-26 14:31:33,132] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7000, global step 112132: loss -144.7277
[2019-03-26 14:31:33,135] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 7000, global step 112132: learning rate 0.0000
[2019-03-26 14:31:33,266] A3C_AGENT_WORKER-Thread-21 INFO:Local step 7000, global step 112197: loss -116.5482
[2019-03-26 14:31:33,269] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 7000, global step 112198: learning rate 0.0000
[2019-03-26 14:31:34,120] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.9295932e-12 1.0000000e+00 1.9559558e-12 2.4627991e-15 1.9852760e-20], sum to 1.0000
[2019-03-26 14:31:34,129] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8846
[2019-03-26 14:31:34,142] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.83333333333334, 61.83333333333333, 1.0, 2.0, 0.5989937887316852, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 837055.2594387061, 837055.2594387055, 200559.4754851815], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4216200.0000, 
sim time next is 4216800.0000, 
raw observation next is [33.66666666666667, 63.66666666666667, 1.0, 2.0, 0.6021277200999823, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 841436.4615245695, 841436.4615245695, 201144.1869816601], 
processed observation next is [1.0, 0.8260869565217391, 0.7946287519747238, 0.6366666666666667, 1.0, 1.0, 0.5206358073493762, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23373235042349155, 0.23373235042349155, 0.30021520445023897], 
reward next is 0.6998, 
noisyNet noise sample is [array([-0.57450783], dtype=float32), 1.3555022]. 
=============================================
[2019-03-26 14:31:40,988] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.4690537e-10 1.0000000e+00 6.5966876e-12 5.2958529e-14 1.2657716e-18], sum to 1.0000
[2019-03-26 14:31:40,994] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4167
[2019-03-26 14:31:41,000] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.16666666666667, 88.16666666666667, 1.0, 2.0, 1.004263046753823, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.9129564325563, 1403767.309124314, 1403767.309124314, 300233.0538329502], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4342200.0000, 
sim time next is 4342800.0000, 
raw observation next is [29.33333333333334, 87.33333333333334, 1.0, 2.0, 0.9635833192452767, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.9129565104115, 1346868.77340722, 1346868.773407221, 288032.1660240526], 
processed observation next is [1.0, 0.2608695652173913, 0.5892575039494474, 0.8733333333333334, 1.0, 1.0, 0.9561244810184057, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.829439945152207, 0.37413021483533887, 0.3741302148353392, 0.42989875525978], 
reward next is 0.5701, 
noisyNet noise sample is [array([-0.7900524], dtype=float32), 0.8612875]. 
=============================================
[2019-03-26 14:31:43,472] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.3401257e-11 1.0000000e+00 5.1066755e-11 8.1459650e-15 3.1209925e-19], sum to 1.0000
[2019-03-26 14:31:43,483] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9666
[2019-03-26 14:31:43,488] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 79.0, 1.0, 2.0, 0.6045746050301529, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 844857.1927000735, 844857.1927000735, 201602.8412600016], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4395600.0000, 
sim time next is 4396200.0000, 
raw observation next is [31.0, 79.00000000000001, 1.0, 2.0, 0.6144071240269208, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 858603.1092581487, 858603.1092581487, 203461.6278172622], 
processed observation next is [1.0, 0.9130434782608695, 0.6682464454976303, 0.7900000000000001, 1.0, 1.0, 0.5354302699119527, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2385008636828191, 0.2385008636828191, 0.30367407136904806], 
reward next is 0.6963, 
noisyNet noise sample is [array([1.2965649], dtype=float32), 0.5632303]. 
=============================================
[2019-03-26 14:31:48,429] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.2131289e-10 1.0000000e+00 3.8473849e-10 1.2517149e-14 7.1480844e-19], sum to 1.0000
[2019-03-26 14:31:48,438] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5796
[2019-03-26 14:31:48,442] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.66666666666667, 70.16666666666667, 1.0, 2.0, 0.5812358386290245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 812230.1789829684, 812230.1789829691, 197303.0774052033], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4463400.0000, 
sim time next is 4464000.0000, 
raw observation next is [32.0, 71.0, 1.0, 2.0, 0.5955079195960712, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 832182.0733987939, 832182.0733987939, 199913.1216876702], 
processed observation next is [0.0, 0.6956521739130435, 0.7156398104265403, 0.71, 1.0, 1.0, 0.5126601440916521, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23116168705522053, 0.23116168705522053, 0.2983777935636869], 
reward next is 0.7016, 
noisyNet noise sample is [array([-0.4485382], dtype=float32), 0.5308012]. 
=============================================
[2019-03-26 14:31:48,456] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[64.11109]
 [64.12912]
 [64.14308]
 [64.16738]
 [64.20996]], R is [[64.16217041]
 [64.22606659]
 [64.2930603 ]
 [64.36296082]
 [64.4353714 ]].
[2019-03-26 14:31:48,604] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.2686024e-11 1.0000000e+00 3.6912303e-11 1.1232505e-14 1.9295338e-18], sum to 1.0000
[2019-03-26 14:31:48,611] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0151
[2019-03-26 14:31:48,615] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 71.0, 1.0, 2.0, 0.6030353442904537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 842705.3136804615, 842705.3136804615, 201313.362568434], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4465200.0000, 
sim time next is 4465800.0000, 
raw observation next is [32.0, 71.0, 1.0, 2.0, 0.6035357201647397, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 843404.8362381727, 843404.8362381734, 201407.0364804408], 
processed observation next is [0.0, 0.6956521739130435, 0.7156398104265403, 0.71, 1.0, 1.0, 0.5223321929695658, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2342791211772702, 0.2342791211772704, 0.30060751713498624], 
reward next is 0.6994, 
noisyNet noise sample is [array([0.25502095], dtype=float32), -0.09542955]. 
=============================================
[2019-03-26 14:31:49,347] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7500, global step 119607: loss 0.0785
[2019-03-26 14:31:49,351] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 7500, global step 119607: learning rate 0.0000
[2019-03-26 14:31:49,731] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7500, global step 119786: loss 0.1340
[2019-03-26 14:31:49,738] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 7500, global step 119787: learning rate 0.0000
[2019-03-26 14:31:49,836] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7500, global step 119841: loss 0.1607
[2019-03-26 14:31:49,837] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 7500, global step 119842: learning rate 0.0000
[2019-03-26 14:31:49,838] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7500, global step 119842: loss 0.1235
[2019-03-26 14:31:49,841] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 7500, global step 119843: learning rate 0.0000
[2019-03-26 14:31:49,884] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.4465354e-10 1.0000000e+00 3.6852226e-11 1.6957810e-14 1.2069373e-18], sum to 1.0000
[2019-03-26 14:31:49,886] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7500, global step 119855: loss 0.0769
[2019-03-26 14:31:49,891] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 7500, global step 119855: learning rate 0.0000
[2019-03-26 14:31:49,893] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2313
[2019-03-26 14:31:49,897] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.5079176052521707, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 709739.6352092845, 709739.6352092845, 184845.3994978373], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4500000.0000, 
sim time next is 4500600.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.507745637686434, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 709499.2557531429, 709499.2557531429, 184818.0670325271], 
processed observation next is [0.0, 0.08695652173913043, 0.4312796208530806, 0.89, 1.0, 1.0, 0.40692245504389635, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19708312659809524, 0.19708312659809524, 0.27584786124257776], 
reward next is 0.7242, 
noisyNet noise sample is [array([0.03235888], dtype=float32), 0.13426663]. 
=============================================
[2019-03-26 14:31:49,959] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7500, global step 119894: loss 0.1429
[2019-03-26 14:31:49,962] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 7500, global step 119894: learning rate 0.0000
[2019-03-26 14:31:50,113] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7500, global step 119966: loss 0.1553
[2019-03-26 14:31:50,115] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 7500, global step 119966: learning rate 0.0000
[2019-03-26 14:31:50,201] A3C_AGENT_WORKER-Thread-22 INFO:Local step 7500, global step 120006: loss 0.1141
[2019-03-26 14:31:50,203] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 7500, global step 120006: learning rate 0.0000
[2019-03-26 14:31:50,219] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7500, global step 120011: loss 0.0971
[2019-03-26 14:31:50,222] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 7500, global step 120011: learning rate 0.0000
[2019-03-26 14:31:50,348] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7500, global step 120075: loss 0.1585
[2019-03-26 14:31:50,353] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 7500, global step 120076: learning rate 0.0000
[2019-03-26 14:31:50,355] A3C_AGENT_WORKER-Thread-18 INFO:Local step 7500, global step 120078: loss 0.1256
[2019-03-26 14:31:50,361] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 7500, global step 120078: learning rate 0.0000
[2019-03-26 14:31:50,503] A3C_AGENT_WORKER-Thread-19 INFO:Local step 7500, global step 120142: loss 0.1333
[2019-03-26 14:31:50,505] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 7500, global step 120143: learning rate 0.0000
[2019-03-26 14:31:50,528] A3C_AGENT_WORKER-Thread-20 INFO:Local step 7500, global step 120155: loss 0.0763
[2019-03-26 14:31:50,529] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 7500, global step 120155: learning rate 0.0000
[2019-03-26 14:31:50,559] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7500, global step 120170: loss 0.0966
[2019-03-26 14:31:50,561] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 7500, global step 120170: learning rate 0.0000
[2019-03-26 14:31:50,570] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7500, global step 120173: loss 0.1062
[2019-03-26 14:31:50,572] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 7500, global step 120173: learning rate 0.0000
[2019-03-26 14:31:50,666] A3C_AGENT_WORKER-Thread-21 INFO:Local step 7500, global step 120217: loss 0.0958
[2019-03-26 14:31:50,668] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 7500, global step 120217: learning rate 0.0000
[2019-03-26 14:31:51,920] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.4300398e-10 1.0000000e+00 4.8880089e-10 1.7727326e-13 3.4271400e-18], sum to 1.0000
[2019-03-26 14:31:51,929] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3770
[2019-03-26 14:31:51,935] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.83333333333334, 75.66666666666667, 1.0, 2.0, 0.5013865127069486, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 700610.3909894257, 700610.3909894257, 183813.1069169299], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4524600.0000, 
sim time next is 4525200.0000, 
raw observation next is [28.0, 74.0, 1.0, 2.0, 0.497565174219769, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 695268.9118359083, 695268.9118359083, 183214.9644337025], 
processed observation next is [0.0, 0.391304347826087, 0.5260663507109005, 0.74, 1.0, 1.0, 0.39465683640936017, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1931302532877523, 0.1931302532877523, 0.2734551707965709], 
reward next is 0.7265, 
noisyNet noise sample is [array([-0.71111697], dtype=float32), -1.2312609]. 
=============================================
[2019-03-26 14:31:53,592] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.7044733e-11 1.0000000e+00 1.6400251e-10 5.0473054e-15 1.7896458e-19], sum to 1.0000
[2019-03-26 14:31:53,598] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3175
[2019-03-26 14:31:53,603] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.66666666666667, 75.66666666666667, 1.0, 2.0, 0.5263370743355337, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 735487.0260210639, 735487.0260210639, 187825.1955856867], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4562400.0000, 
sim time next is 4563000.0000, 
raw observation next is [28.5, 76.5, 1.0, 2.0, 0.5284096911494777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 738384.2427864469, 738384.2427864476, 188166.5361804091], 
processed observation next is [0.0, 0.8260869565217391, 0.5497630331753555, 0.765, 1.0, 1.0, 0.43181890499937065, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20510673410734637, 0.20510673410734656, 0.2808455763886703], 
reward next is 0.7192, 
noisyNet noise sample is [array([2.432446], dtype=float32), 0.5885106]. 
=============================================
[2019-03-26 14:31:53,628] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[68.60511]
 [68.58226]
 [68.54246]
 [68.5239 ]
 [68.49766]], R is [[68.66893005]
 [68.7019043 ]
 [68.73472595]
 [68.76679993]
 [68.79826355]].
[2019-03-26 14:32:01,048] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-26 14:32:01,050] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 14:32:01,051] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 14:32:01,051] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:32:01,051] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 14:32:01,052] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 14:32:01,053] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:32:01,052] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:32:01,053] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 14:32:01,055] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:32:01,057] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:32:01,072] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run6
[2019-03-26 14:32:01,073] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run6
[2019-03-26 14:32:01,089] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run6
[2019-03-26 14:32:01,106] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run6
[2019-03-26 14:32:01,122] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run6
[2019-03-26 14:32:19,896] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.06379504], dtype=float32), 0.06342626]
[2019-03-26 14:32:19,897] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [30.51091103333334, 76.69300534666667, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.998854072443056, 6.9112, 168.9069154465721, 2225871.77055815, 1454280.133871262, 311354.8730313723]
[2019-03-26 14:32:19,899] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 14:32:19,902] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [4.07128584e-12 1.00000000e+00 2.47062223e-12 4.87474502e-16
 1.26425025e-20], sampled 0.4076417584688159
[2019-03-26 14:32:19,904] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2225871.77055815 W.
[2019-03-26 14:32:35,954] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.06379504], dtype=float32), 0.06342626]
[2019-03-26 14:32:35,955] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [35.53864040833334, 64.55219767666667, 1.0, 2.0, 0.8686179948791175, 1.0, 2.0, 0.8686179948791175, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 171.5212843490159, 2429420.77083676, 2429420.770836759, 454878.6527060145]
[2019-03-26 14:32:35,956] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 14:32:35,958] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.2722484e-11 1.0000000e+00 5.4267532e-12 5.4508014e-15 1.5969258e-19], sampled 0.10195772276309145
[2019-03-26 14:32:35,961] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2429420.77083676 W.
[2019-03-26 14:32:42,750] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.06379504], dtype=float32), 0.06342626]
[2019-03-26 14:32:42,751] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [24.08308541, 99.43946980666666, 1.0, 2.0, 0.4717369725514896, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 659166.8732209255, 659166.8732209249, 179286.4975155537]
[2019-03-26 14:32:42,752] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 14:32:42,756] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.01967136e-10 1.00000000e+00 5.27986474e-11 1.67814540e-14
 7.15381311e-19], sampled 0.5187121568344456
[2019-03-26 14:32:55,870] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.06379504], dtype=float32), 0.06342626]
[2019-03-26 14:32:55,871] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [33.41621526, 77.59453627333333, 1.0, 2.0, 0.9403142433813075, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005990164567896, 6.9112, 168.9123159477232, 2211463.78308617, 2144216.632936007, 445531.85991522]
[2019-03-26 14:32:55,872] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 14:32:55,875] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.3611380e-11 1.0000000e+00 3.6125293e-12 3.7078473e-15 1.7325012e-19], sampled 0.8879742379540512
[2019-03-26 14:32:55,877] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2211463.78308617 W.
[2019-03-26 14:33:17,917] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.06379504], dtype=float32), 0.06342626]
[2019-03-26 14:33:17,919] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [32.2, 67.0, 1.0, 2.0, 0.8072200999838381, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005981979181231, 6.9112, 168.9123159978471, 2025178.275931072, 1957936.932733955, 409623.1157210773]
[2019-03-26 14:33:17,920] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 14:33:17,924] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.9578675e-12 1.0000000e+00 1.3134572e-12 2.1567045e-15 6.2706598e-20], sampled 0.9085037077840298
[2019-03-26 14:33:17,925] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2025178.275931072 W.
[2019-03-26 14:33:28,002] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.06379504], dtype=float32), 0.06342626]
[2019-03-26 14:33:28,006] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.70888633333333, 89.16202939, 1.0, 2.0, 0.5802334922112017, 0.0, 2.0, 0.0, 1.0, 2.0, 1.002500684364774, 6.911200000000001, 6.9112, 168.9129359035391, 1622277.336200597, 1622277.336200596, 354009.2066756007]
[2019-03-26 14:33:28,007] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 14:33:28,010] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.0364797e-11 1.0000000e+00 8.6983320e-12 1.4762764e-14 1.5013130e-18], sampled 0.3776440307268393
[2019-03-26 14:33:37,526] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.06379504], dtype=float32), 0.06342626]
[2019-03-26 14:33:37,528] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.76134094166667, 92.73500234666666, 1.0, 2.0, 0.5162667306614361, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 721410.2631473773, 721410.2631473766, 186183.5694153454]
[2019-03-26 14:33:37,532] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 14:33:37,534] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.6791277e-11 1.0000000e+00 8.9830270e-12 1.4566519e-15 3.0138646e-20], sampled 0.1763694798237646
[2019-03-26 14:33:55,353] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.1701 3164000012.1395 1778.0000
[2019-03-26 14:33:55,523] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.1610 2927253227.7716 1338.0000
[2019-03-26 14:33:55,624] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7999.0502 3007584666.7691 1766.0000
[2019-03-26 14:33:55,749] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.6119 2842427357.4275 1131.0000
[2019-03-26 14:33:55,781] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.4676 2779124528.0117 933.0000
[2019-03-26 14:33:56,794] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 125000, evaluation results [125000.0, 7884.170123390672, 3164000012.13951, 1778.0, 8255.161016606155, 2927253227.7715816, 1338.0, 8661.467580702742, 2779124528.011676, 933.0, 7999.050242421542, 3007584666.769063, 1766.0, 8497.61193292354, 2842427357.427519, 1131.0]
[2019-03-26 14:33:57,101] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.2800423e-12 1.0000000e+00 9.7043571e-12 3.0273190e-15 2.6476798e-20], sum to 1.0000
[2019-03-26 14:33:57,102] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0468
[2019-03-26 14:33:57,103] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2052542.738031986 W.
[2019-03-26 14:33:57,107] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.0, 75.0, 1.0, 2.0, 0.4893219708323802, 1.0, 2.0, 0.4893219708323802, 1.0, 2.0, 0.8497904420873166, 6.911200000000001, 6.9112, 170.5573041426782, 2052542.738031986, 2052542.738031986, 407840.264529041], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4701000.0000, 
sim time next is 4701600.0000, 
raw observation next is [30.0, 75.0, 1.0, 2.0, 0.7095946789994025, 1.0, 2.0, 0.7095946789994025, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 1984279.108488922, 1984279.108488921, 378262.8124061315], 
processed observation next is [1.0, 0.43478260869565216, 0.6208530805687204, 0.75, 1.0, 1.0, 0.6501140710836175, 1.0, 1.0, 0.6501140710836175, 0.0, 0.5, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5511886412469228, 0.5511886412469226, 0.5645713618001962], 
reward next is 0.4354, 
noisyNet noise sample is [array([1.5198811], dtype=float32), -1.1673642]. 
=============================================
[2019-03-26 14:33:57,924] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.8763195e-11 1.0000000e+00 2.3138463e-11 2.9977180e-14 3.8596089e-17], sum to 1.0000
[2019-03-26 14:33:57,932] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8036
[2019-03-26 14:33:57,942] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2241858.355408113 W.
[2019-03-26 14:33:57,946] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 66.0, 1.0, 2.0, 0.5344082857158283, 1.0, 1.0, 0.5344082857158283, 1.0, 2.0, 0.92454337046104, 6.9112, 6.9112, 170.5573041426782, 2241858.355408113, 2241858.355408113, 439066.5012886858], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4713600.0000, 
sim time next is 4714200.0000, 
raw observation next is [31.0, 66.0, 1.0, 2.0, 0.8385286184278671, 1.0, 2.0, 0.8385286184278671, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2345198.222911709, 2345198.222911709, 439061.0875144213], 
processed observation next is [1.0, 0.5652173913043478, 0.6682464454976303, 0.66, 1.0, 1.0, 0.8054561667805628, 1.0, 1.0, 0.8054561667805628, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.651443950808808, 0.651443950808808, 0.6553150559916736], 
reward next is 0.3447, 
noisyNet noise sample is [array([0.8430185], dtype=float32), -2.186799]. 
=============================================
[2019-03-26 14:34:02,398] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8000, global step 127555: loss -133.3181
[2019-03-26 14:34:02,401] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 8000, global step 127556: learning rate 0.0000
[2019-03-26 14:34:02,979] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8000, global step 127796: loss -46.6228
[2019-03-26 14:34:02,981] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 8000, global step 127796: learning rate 0.0000
[2019-03-26 14:34:03,032] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8000, global step 127814: loss -140.3044
[2019-03-26 14:34:03,038] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 8000, global step 127814: learning rate 0.0000
[2019-03-26 14:34:03,180] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8000, global step 127871: loss -150.1478
[2019-03-26 14:34:03,185] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 8000, global step 127872: learning rate 0.0000
[2019-03-26 14:34:03,205] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8000, global step 127880: loss -136.6081
[2019-03-26 14:34:03,207] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 8000, global step 127880: learning rate 0.0000
[2019-03-26 14:34:03,265] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8000, global step 127899: loss -147.3835
[2019-03-26 14:34:03,266] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 8000, global step 127900: learning rate 0.0000
[2019-03-26 14:34:03,475] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8000, global step 127978: loss -78.9441
[2019-03-26 14:34:03,477] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 8000, global step 127978: learning rate 0.0000
[2019-03-26 14:34:03,647] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8000, global step 128050: loss -178.8535
[2019-03-26 14:34:03,648] A3C_AGENT_WORKER-Thread-22 INFO:Local step 8000, global step 128050: loss -104.3282
[2019-03-26 14:34:03,649] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 8000, global step 128050: learning rate 0.0000
[2019-03-26 14:34:03,650] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 8000, global step 128050: learning rate 0.0000
[2019-03-26 14:34:03,692] A3C_AGENT_WORKER-Thread-19 INFO:Local step 8000, global step 128067: loss -117.3244
[2019-03-26 14:34:03,695] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 8000, global step 128069: learning rate 0.0000
[2019-03-26 14:34:03,702] A3C_AGENT_WORKER-Thread-18 INFO:Local step 8000, global step 128071: loss -85.2872
[2019-03-26 14:34:03,704] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 8000, global step 128071: learning rate 0.0000
[2019-03-26 14:34:03,707] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8000, global step 128072: loss -138.6666
[2019-03-26 14:34:03,710] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 8000, global step 128072: learning rate 0.0000
[2019-03-26 14:34:03,838] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.7889301e-12 1.0000000e+00 3.5423864e-12 2.8566274e-13 6.8784495e-17], sum to 1.0000
[2019-03-26 14:34:03,847] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3820
[2019-03-26 14:34:03,854] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2716395.800687118 W.
[2019-03-26 14:34:03,860] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.58333333333333, 64.66666666666667, 1.0, 2.0, 0.6536288184514472, 1.0, 1.0, 0.6474044487399861, 1.0, 2.0, 1.03, 7.005094076116359, 6.9112, 170.5573041426782, 2716395.800687118, 2649135.654598149, 507080.6562868556], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4801800.0000, 
sim time next is 4802400.0000, 
raw observation next is [31.5, 65.0, 1.0, 2.0, 0.5781877028084298, 1.0, 2.0, 0.5781877028084298, 1.0, 2.0, 1.00412083018307, 6.911199999999999, 6.9112, 170.5573041426782, 2425692.530234257, 2425692.530234257, 473423.6916283831], 
processed observation next is [1.0, 0.6086956521739131, 0.6919431279620853, 0.65, 1.0, 1.0, 0.49179241302220456, 1.0, 1.0, 0.49179241302220456, 1.0, 1.0, 1.0050254026622805, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.673803480620627, 0.673803480620627, 0.7066025248184823], 
reward next is 0.2934, 
noisyNet noise sample is [array([1.7123445], dtype=float32), -1.6670406]. 
=============================================
[2019-03-26 14:34:03,878] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8000, global step 128149: loss -79.1758
[2019-03-26 14:34:03,880] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 8000, global step 128150: learning rate 0.0000
[2019-03-26 14:34:03,923] A3C_AGENT_WORKER-Thread-20 INFO:Local step 8000, global step 128170: loss -112.7805
[2019-03-26 14:34:03,925] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 8000, global step 128171: learning rate 0.0000
[2019-03-26 14:34:03,936] A3C_AGENT_WORKER-Thread-21 INFO:Local step 8000, global step 128177: loss -30.0062
[2019-03-26 14:34:03,938] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 8000, global step 128178: learning rate 0.0000
[2019-03-26 14:34:03,967] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8000, global step 128192: loss -113.9530
[2019-03-26 14:34:03,970] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 8000, global step 128194: learning rate 0.0000
[2019-03-26 14:34:06,819] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.5619650e-12 1.0000000e+00 5.1305436e-12 1.0491910e-15 1.6490010e-19], sum to 1.0000
[2019-03-26 14:34:06,828] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9616
[2019-03-26 14:34:06,838] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.83333333333333, 1.0, 2.0, 0.6571396177117861, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 918345.4412641564, 918345.441264157, 211864.4852656514], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4860600.0000, 
sim time next is 4861200.0000, 
raw observation next is [27.0, 85.66666666666667, 1.0, 2.0, 0.6381011400471721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 891728.2070959712, 891728.2070959718, 208050.6939751662], 
processed observation next is [1.0, 0.2608695652173913, 0.4786729857819906, 0.8566666666666667, 1.0, 1.0, 0.5639772771652676, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2477022797488809, 0.24770227974888107, 0.31052342384353165], 
reward next is 0.6895, 
noisyNet noise sample is [array([-0.50970143], dtype=float32), 0.36155978]. 
=============================================
[2019-03-26 14:34:07,963] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.9441922e-11 1.0000000e+00 1.2599657e-12 2.2211967e-15 7.9724663e-20], sum to 1.0000
[2019-03-26 14:34:07,973] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2363
[2019-03-26 14:34:07,981] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2183423.594753789 W.
[2019-03-26 14:34:07,984] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.16666666666667, 73.33333333333334, 1.0, 2.0, 0.9202802329904936, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.981719897383345, 6.9112, 168.9124793548924, 2183423.594753789, 2133394.493768121, 440611.563502692], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4871400.0000, 
sim time next is 4872000.0000, 
raw observation next is [29.33333333333334, 72.66666666666667, 1.0, 2.0, 0.7679468846059975, 1.0, 1.0, 0.7679468846059975, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2147616.193207493, 2147616.193207493, 404564.0573051776], 
processed observation next is [1.0, 0.391304347826087, 0.5892575039494474, 0.7266666666666667, 1.0, 1.0, 0.720417933260238, 1.0, 0.5, 0.720417933260238, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5965600536687481, 0.5965600536687481, 0.6038269512017577], 
reward next is 0.3962, 
noisyNet noise sample is [array([0.507502], dtype=float32), -0.23706768]. 
=============================================
[2019-03-26 14:34:07,993] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[65.35293 ]
 [65.81743 ]
 [66.35024 ]
 [67.392685]
 [67.898544]], R is [[64.48059845]
 [63.83579254]
 [63.26982498]
 [63.08842087]
 [62.92607498]].
[2019-03-26 14:34:08,064] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0585668e-10 1.0000000e+00 6.0044088e-11 3.9064888e-14 1.3730547e-18], sum to 1.0000
[2019-03-26 14:34:08,074] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0077
[2019-03-26 14:34:08,081] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2164457.660168432 W.
[2019-03-26 14:34:08,086] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.5, 72.0, 1.0, 2.0, 0.9067306995093548, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.985150629161968, 6.9112, 168.9125164089134, 2164457.660168432, 2111994.675348996, 436687.166032702], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4872600.0000, 
sim time next is 4873200.0000, 
raw observation next is [29.66666666666667, 71.33333333333333, 1.0, 2.0, 0.9171840812562386, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.984344998169549, 6.9112, 168.912461109427, 2179089.732517433, 2127198.305551048, 439652.0753117852], 
processed observation next is [1.0, 0.391304347826087, 0.6050552922590839, 0.7133333333333333, 1.0, 1.0, 0.9002217846460706, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.0073144998169548895, 0.0, 0.8294375125065775, 0.6053027034770647, 0.5908884182086244, 0.6561971273310228], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.07538404], dtype=float32), -1.9891742]. 
=============================================
[2019-03-26 14:34:09,766] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.0207414e-11 1.0000000e+00 2.1100947e-11 1.6516438e-13 4.4298261e-17], sum to 1.0000
[2019-03-26 14:34:09,775] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4459
[2019-03-26 14:34:09,780] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.33333333333334, 68.66666666666667, 1.0, 2.0, 0.4715642422000642, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 658925.4390232906, 658925.4390232901, 179262.4210338549], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4902000.0000, 
sim time next is 4902600.0000, 
raw observation next is [29.16666666666667, 69.33333333333333, 1.0, 2.0, 0.477786027618984, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 667621.9867698707, 667621.9867698707, 180190.1178127303], 
processed observation next is [1.0, 0.7391304347826086, 0.581358609794629, 0.6933333333333332, 1.0, 1.0, 0.3708265392999807, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18545055188051965, 0.18545055188051965, 0.2689404743473587], 
reward next is 0.7311, 
noisyNet noise sample is [array([-1.9460845], dtype=float32), 1.1862533]. 
=============================================
[2019-03-26 14:34:10,080] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.4462671e-12 1.0000000e+00 8.2517955e-13 2.8939699e-16 1.1037556e-19], sum to 1.0000
[2019-03-26 14:34:10,094] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0973
[2019-03-26 14:34:10,099] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.83333333333334, 1.0, 2.0, 0.4903505526481806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 685184.3639620292, 685184.3639620292, 182097.7699068118], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4914600.0000, 
sim time next is 4915200.0000, 
raw observation next is [27.0, 80.66666666666667, 1.0, 2.0, 0.4957283208447902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 692701.3618745023, 692701.3618745023, 182929.238097918], 
processed observation next is [1.0, 0.9130434782608695, 0.4786729857819906, 0.8066666666666668, 1.0, 1.0, 0.3924437600539641, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1924170449651395, 0.1924170449651395, 0.27302871357898206], 
reward next is 0.7270, 
noisyNet noise sample is [array([-0.36164102], dtype=float32), -0.9748311]. 
=============================================
[2019-03-26 14:34:19,898] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8500, global step 135471: loss 0.4790
[2019-03-26 14:34:19,901] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 8500, global step 135472: learning rate 0.0000
[2019-03-26 14:34:20,364] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8500, global step 135688: loss 0.7348
[2019-03-26 14:34:20,366] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 8500, global step 135689: learning rate 0.0000
[2019-03-26 14:34:20,455] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8500, global step 135727: loss 0.7289
[2019-03-26 14:34:20,457] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 8500, global step 135728: learning rate 0.0000
[2019-03-26 14:34:20,755] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8500, global step 135874: loss 0.7774
[2019-03-26 14:34:20,759] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 8500, global step 135876: learning rate 0.0000
[2019-03-26 14:34:20,782] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8500, global step 135884: loss 0.7889
[2019-03-26 14:34:20,786] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 8500, global step 135885: learning rate 0.0000
[2019-03-26 14:34:20,800] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8500, global step 135892: loss 0.7383
[2019-03-26 14:34:20,801] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 8500, global step 135892: learning rate 0.0000
[2019-03-26 14:34:20,997] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8500, global step 135982: loss 0.9338
[2019-03-26 14:34:21,000] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 8500, global step 135983: learning rate 0.0000
[2019-03-26 14:34:21,113] A3C_AGENT_WORKER-Thread-22 INFO:Local step 8500, global step 136040: loss 0.5530
[2019-03-26 14:34:21,116] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 8500, global step 136041: learning rate 0.0000
[2019-03-26 14:34:21,153] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8500, global step 136054: loss 0.8166
[2019-03-26 14:34:21,155] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 8500, global step 136054: learning rate 0.0000
[2019-03-26 14:34:21,187] A3C_AGENT_WORKER-Thread-18 INFO:Local step 8500, global step 136068: loss 0.7690
[2019-03-26 14:34:21,189] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 8500, global step 136070: learning rate 0.0000
[2019-03-26 14:34:21,240] A3C_AGENT_WORKER-Thread-19 INFO:Local step 8500, global step 136097: loss 0.7995
[2019-03-26 14:34:21,243] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 8500, global step 136097: learning rate 0.0000
[2019-03-26 14:34:21,401] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8500, global step 136171: loss 0.6718
[2019-03-26 14:34:21,404] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 8500, global step 136173: learning rate 0.0000
[2019-03-26 14:34:21,413] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8500, global step 136177: loss 0.6695
[2019-03-26 14:34:21,416] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 8500, global step 136177: learning rate 0.0000
[2019-03-26 14:34:21,462] A3C_AGENT_WORKER-Thread-20 INFO:Local step 8500, global step 136198: loss 0.9283
[2019-03-26 14:34:21,464] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 8500, global step 136198: learning rate 0.0000
[2019-03-26 14:34:21,472] A3C_AGENT_WORKER-Thread-21 INFO:Local step 8500, global step 136199: loss 0.9714
[2019-03-26 14:34:21,475] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 8500, global step 136199: learning rate 0.0000
[2019-03-26 14:34:21,601] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8500, global step 136263: loss 0.7400
[2019-03-26 14:34:21,606] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 8500, global step 136263: learning rate 0.0000
[2019-03-26 14:34:23,649] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.4625479e-12 1.0000000e+00 2.9810375e-12 3.9083726e-15 1.3836744e-20], sum to 1.0000
[2019-03-26 14:34:23,657] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0324
[2019-03-26 14:34:23,664] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 63.0, 1.0, 2.0, 0.55082529293436, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 769718.4977741354, 769718.4977741349, 191942.8620324664], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5154600.0000, 
sim time next is 5155200.0000, 
raw observation next is [32.0, 63.0, 1.0, 2.0, 0.5516185973084917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 770827.45667694, 770827.4566769394, 192079.1430813605], 
processed observation next is [0.0, 0.6956521739130435, 0.7156398104265403, 0.63, 1.0, 1.0, 0.45978144254035147, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21411873796581665, 0.21411873796581649, 0.2866852881811351], 
reward next is 0.7133, 
noisyNet noise sample is [array([-0.8776811], dtype=float32), -0.5787902]. 
=============================================
[2019-03-26 14:34:27,121] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.5783186e-12 1.0000000e+00 1.4420043e-14 1.5293010e-18 9.5849352e-23], sum to 1.0000
[2019-03-26 14:34:27,130] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4057
[2019-03-26 14:34:27,138] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.16666666666667, 73.33333333333334, 1.0, 2.0, 0.8752579471840831, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1223339.005476991, 1223339.00547699, 263221.7120277325], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5213400.0000, 
sim time next is 5214000.0000, 
raw observation next is [29.33333333333334, 72.66666666666667, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 9.037198697067522, 6.9112, 168.9010567260096, 2962863.311400098, 1454712.919962238, 309179.71382418], 
processed observation next is [1.0, 0.34782608695652173, 0.5892575039494474, 0.7266666666666667, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.2125998697067522, 0.0, 0.8293815117630488, 0.8230175865000272, 0.4040869222117328, 0.46146225943907465], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.46033856], dtype=float32), 0.25084087]. 
=============================================
[2019-03-26 14:34:27,154] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[74.77572]
 [74.74894]
 [74.82752]
 [74.62272]
 [74.14031]], R is [[74.0871048 ]
 [73.95336914]
 [73.85414124]
 [73.75626373]
 [73.66346741]].
[2019-03-26 14:34:27,245] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.6505833e-13 1.0000000e+00 1.9763262e-12 2.8285921e-16 7.5239121e-21], sum to 1.0000
[2019-03-26 14:34:27,256] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1159
[2019-03-26 14:34:27,260] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.8712444868087609, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1217726.216471143, 1217726.216471143, 262147.7242955908], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5197200.0000, 
sim time next is 5197800.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.8397750199891579, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1173717.47252946, 1173717.47252946, 253905.8636983623], 
processed observation next is [1.0, 0.13043478260869565, 0.4312796208530806, 0.89, 1.0, 1.0, 0.806957855408624, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3260326312581833, 0.3260326312581833, 0.37896397566919743], 
reward next is 0.6210, 
noisyNet noise sample is [array([-0.84863997], dtype=float32), -0.33926013]. 
=============================================
[2019-03-26 14:34:35,117] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.2210771e-12 1.0000000e+00 4.0636168e-14 8.7142067e-16 8.3115811e-21], sum to 1.0000
[2019-03-26 14:34:35,125] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4796
[2019-03-26 14:34:35,128] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.46666666666667, 66.33333333333334, 1.0, 2.0, 0.612995612768629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 856629.7976872203, 856629.7976872203, 203193.3872224316], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5337600.0000, 
sim time next is 5338200.0000, 
raw observation next is [33.23333333333333, 67.66666666666666, 1.0, 2.0, 0.6155263378929764, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 860167.7877810613, 860167.7877810613, 203675.4658724045], 
processed observation next is [1.0, 0.782608695652174, 0.7740916271721956, 0.6766666666666665, 1.0, 1.0, 0.5367787203529836, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23893549660585034, 0.23893549660585034, 0.3039932326453798], 
reward next is 0.6960, 
noisyNet noise sample is [array([0.33409488], dtype=float32), -0.41266802]. 
=============================================
[2019-03-26 14:34:36,801] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.1147271e-13 1.0000000e+00 9.4591910e-14 5.4101315e-17 1.4703252e-21], sum to 1.0000
[2019-03-26 14:34:36,813] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4360
[2019-03-26 14:34:36,818] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.4, 85.5, 1.0, 2.0, 0.6023928418127641, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 841807.099634622, 841807.099634622, 201192.820990167], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5362200.0000, 
sim time next is 5362800.0000, 
raw observation next is [29.36666666666667, 85.66666666666666, 1.0, 2.0, 0.6016665276916254, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 840791.718402235, 840791.718402235, 201057.0992892914], 
processed observation next is [1.0, 0.043478260869565216, 0.5908372827804109, 0.8566666666666666, 1.0, 1.0, 0.5200801538453318, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23355325511173194, 0.23355325511173194, 0.3000852228198379], 
reward next is 0.6999, 
noisyNet noise sample is [array([0.26852146], dtype=float32), -0.55119115]. 
=============================================
[2019-03-26 14:34:37,341] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9000, global step 143519: loss -243.0296
[2019-03-26 14:34:37,342] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 9000, global step 143520: learning rate 0.0000
[2019-03-26 14:34:37,908] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9000, global step 143777: loss -240.3705
[2019-03-26 14:34:37,909] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 9000, global step 143777: learning rate 0.0000
[2019-03-26 14:34:37,959] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9000, global step 143796: loss -188.3677
[2019-03-26 14:34:37,961] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 9000, global step 143796: learning rate 0.0000
[2019-03-26 14:34:38,063] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9000, global step 143850: loss -186.9130
[2019-03-26 14:34:38,064] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 9000, global step 143850: learning rate 0.0000
[2019-03-26 14:34:38,111] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9000, global step 143868: loss -182.0073
[2019-03-26 14:34:38,114] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 9000, global step 143868: learning rate 0.0000
[2019-03-26 14:34:38,232] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9000, global step 143930: loss -247.1835
[2019-03-26 14:34:38,234] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 9000, global step 143930: learning rate 0.0000
[2019-03-26 14:34:38,413] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9000, global step 144012: loss -205.8356
[2019-03-26 14:34:38,421] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 9000, global step 144012: learning rate 0.0000
[2019-03-26 14:34:38,435] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9000, global step 144021: loss -212.5703
[2019-03-26 14:34:38,437] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 9000, global step 144021: learning rate 0.0000
[2019-03-26 14:34:38,463] A3C_AGENT_WORKER-Thread-22 INFO:Local step 9000, global step 144030: loss -232.6836
[2019-03-26 14:34:38,465] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 9000, global step 144030: learning rate 0.0000
[2019-03-26 14:34:38,488] A3C_AGENT_WORKER-Thread-19 INFO:Local step 9000, global step 144036: loss -170.8077
[2019-03-26 14:34:38,492] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 9000, global step 144036: learning rate 0.0000
[2019-03-26 14:34:38,575] A3C_AGENT_WORKER-Thread-18 INFO:Local step 9000, global step 144084: loss -198.5207
[2019-03-26 14:34:38,576] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 9000, global step 144084: learning rate 0.0000
[2019-03-26 14:34:38,644] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9000, global step 144110: loss -246.2772
[2019-03-26 14:34:38,645] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 9000, global step 144110: learning rate 0.0000
[2019-03-26 14:34:38,789] A3C_AGENT_WORKER-Thread-21 INFO:Local step 9000, global step 144179: loss -192.3025
[2019-03-26 14:34:38,791] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 9000, global step 144179: learning rate 0.0000
[2019-03-26 14:34:38,816] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9000, global step 144189: loss -216.5214
[2019-03-26 14:34:38,820] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 9000, global step 144189: learning rate 0.0000
[2019-03-26 14:34:38,821] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9000, global step 144190: loss -182.5336
[2019-03-26 14:34:38,825] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 9000, global step 144191: learning rate 0.0000
[2019-03-26 14:34:38,921] A3C_AGENT_WORKER-Thread-20 INFO:Local step 9000, global step 144239: loss -261.0402
[2019-03-26 14:34:38,925] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 9000, global step 144239: learning rate 0.0000
[2019-03-26 14:34:44,216] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.1575511e-11 1.0000000e+00 7.8853552e-13 4.9409804e-13 1.4987281e-16], sum to 1.0000
[2019-03-26 14:34:44,222] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1320
[2019-03-26 14:34:44,228] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2917824.926123774 W.
[2019-03-26 14:34:44,233] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [35.61666666666667, 48.83333333333334, 1.0, 2.0, 0.7495308891869602, 1.0, 2.0, 0.6953554841077427, 1.0, 2.0, 1.03, 7.005101637945576, 6.9112, 170.5573041426782, 2917824.926123774, 2850559.363188941, 537428.8282873183], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5500200.0000, 
sim time next is 5500800.0000, 
raw observation next is [35.5, 49.0, 1.0, 2.0, 1.020205603966002, 1.0, 2.0, 1.020205603966002, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2853893.028254834, 2853893.028254834, 541311.6549491824], 
processed observation next is [1.0, 0.6956521739130435, 0.8815165876777251, 0.49, 1.0, 1.0, 1.0243441011638577, 1.0, 1.0, 1.0243441011638577, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7927480634041205, 0.7927480634041205, 0.8079278432077349], 
reward next is 0.1921, 
noisyNet noise sample is [array([1.0956166], dtype=float32), -1.9613767]. 
=============================================
[2019-03-26 14:34:51,443] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-26 14:34:51,444] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 14:34:51,445] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 14:34:51,447] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:34:51,447] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 14:34:51,449] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:34:51,448] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 14:34:51,450] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:34:51,452] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:34:51,453] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 14:34:51,455] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:34:51,473] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run7
[2019-03-26 14:34:51,473] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run7
[2019-03-26 14:34:51,474] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run7
[2019-03-26 14:34:51,532] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run7
[2019-03-26 14:34:51,555] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run7
[2019-03-26 14:35:30,506] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.06278605], dtype=float32), 0.061238624]
[2019-03-26 14:35:30,509] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.0, 100.0, 1.0, 2.0, 0.4305028345838982, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 624868.7322546768, 624868.7322546768, 176417.395474842]
[2019-03-26 14:35:30,512] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 14:35:30,516] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.0696410e-11 1.0000000e+00 1.7968075e-12 1.5394352e-15 1.3653187e-19], sampled 0.6498732775788671
[2019-03-26 14:35:37,819] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.06278605], dtype=float32), 0.061238624]
[2019-03-26 14:35:37,820] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.33333333333334, 87.33333333333334, 1.0, 2.0, 0.4599948506132508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 648857.8977596752, 648857.8977596757, 178354.138512402]
[2019-03-26 14:35:37,821] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 14:35:37,826] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.7381907e-11 1.0000000e+00 3.4810670e-12 3.3531106e-15 3.4780019e-19], sampled 0.7615345720244762
[2019-03-26 14:35:50,341] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.06278605], dtype=float32), 0.061238624]
[2019-03-26 14:35:50,342] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.55804299833333, 81.76195691666666, 1.0, 2.0, 0.5729027563823507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 800580.980505419, 800580.980505419, 195804.8540109018]
[2019-03-26 14:35:50,342] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 14:35:50,347] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0979580e-12 1.0000000e+00 6.7726207e-14 4.8741846e-17 1.9981226e-21], sampled 0.9775888033484075
[2019-03-26 14:36:04,608] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.06278605], dtype=float32), 0.061238624]
[2019-03-26 14:36:04,609] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [34.43677265000001, 57.94746644000001, 1.0, 2.0, 0.6117866767857946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 854939.6919688099, 854939.6919688092, 202961.7492478681]
[2019-03-26 14:36:04,610] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 14:36:04,615] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [8.3037752e-12 1.0000000e+00 6.0927261e-13 4.7557221e-16 3.2598836e-20], sampled 0.17441675079411856
[2019-03-26 14:36:12,287] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.06278605], dtype=float32), 0.061238624]
[2019-03-26 14:36:12,288] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [31.59563197333333, 66.11722506999999, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.351433944959666, 6.9112, 168.9109042824386, 1766282.149461956, 1453968.831758314, 311352.6920023043]
[2019-03-26 14:36:12,288] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 14:36:12,291] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [4.5415182e-12 1.0000000e+00 2.7325174e-13 5.4998193e-16 6.4009756e-20], sampled 0.5742073280546595
[2019-03-26 14:36:12,293] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1766282.149461956 W.
[2019-03-26 14:36:21,128] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.06278605], dtype=float32), 0.061238624]
[2019-03-26 14:36:21,129] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [33.83333333333334, 55.16666666666667, 1.0, 2.0, 0.9896147278044437, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 168.9129563628611, 1383278.425765745, 1383278.425765746, 295779.4901339857]
[2019-03-26 14:36:21,131] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 14:36:21,134] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.1879163e-12 1.0000000e+00 6.9940337e-14 9.1245704e-17 9.1547447e-21], sampled 0.2860394653191475
[2019-03-26 14:36:39,057] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.06278605], dtype=float32), 0.061238624]
[2019-03-26 14:36:39,058] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [21.979765665, 90.87670722, 1.0, 2.0, 0.3299301301311662, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 517150.2657805789, 517150.2657805789, 168236.9587735405]
[2019-03-26 14:36:39,061] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 14:36:39,064] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [7.089511e-11 1.000000e+00 6.912663e-12 7.598032e-15 9.676211e-19], sampled 0.8636032405756878
[2019-03-26 14:36:45,814] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.06278605], dtype=float32), 0.061238624]
[2019-03-26 14:36:45,817] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.5, 91.0, 1.0, 2.0, 0.5269769436579235, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 736381.4693973588, 736381.4693973588, 187930.8819400518]
[2019-03-26 14:36:45,818] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 14:36:45,822] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.7523412e-12 1.0000000e+00 1.1434189e-13 8.7343702e-17 4.2031797e-21], sampled 0.8707816091207154
[2019-03-26 14:36:45,863] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.9164 3164002230.9074 1778.0000
[2019-03-26 14:36:45,965] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7996.8169 3007604825.0712 1766.0000
[2019-03-26 14:36:46,039] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.2473 2779206260.6825 933.0000
[2019-03-26 14:36:46,192] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.1610 2927253227.7716 1338.0000
[2019-03-26 14:36:46,255] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.6119 2842427357.4275 1131.0000
[2019-03-26 14:36:47,271] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 150000, evaluation results [150000.0, 7884.916440885027, 3164002230.907359, 1778.0, 8255.161016606155, 2927253227.7715816, 1338.0, 8659.247307579999, 2779206260.682464, 933.0, 7996.816940778225, 3007604825.071238, 1766.0, 8497.61193292354, 2842427357.427519, 1131.0]
[2019-03-26 14:36:50,282] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9500, global step 151376: loss 0.0334
[2019-03-26 14:36:50,284] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 9500, global step 151376: learning rate 0.0000
[2019-03-26 14:36:51,014] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9500, global step 151708: loss 0.0163
[2019-03-26 14:36:51,019] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 9500, global step 151708: learning rate 0.0000
[2019-03-26 14:36:51,208] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9500, global step 151793: loss 0.0327
[2019-03-26 14:36:51,213] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 9500, global step 151795: learning rate 0.0000
[2019-03-26 14:36:51,269] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9500, global step 151820: loss 0.0256
[2019-03-26 14:36:51,272] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 9500, global step 151821: learning rate 0.0000
[2019-03-26 14:36:51,343] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9500, global step 151854: loss 0.0390
[2019-03-26 14:36:51,347] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 9500, global step 151855: learning rate 0.0000
[2019-03-26 14:36:51,435] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9500, global step 151894: loss 0.0384
[2019-03-26 14:36:51,437] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 9500, global step 151894: learning rate 0.0000
[2019-03-26 14:36:51,643] A3C_AGENT_WORKER-Thread-22 INFO:Local step 9500, global step 151992: loss 0.0290
[2019-03-26 14:36:51,645] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 9500, global step 151993: learning rate 0.0000
[2019-03-26 14:36:51,690] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9500, global step 152014: loss 0.0129
[2019-03-26 14:36:51,693] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 9500, global step 152015: learning rate 0.0000
[2019-03-26 14:36:51,708] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9500, global step 152021: loss 0.0387
[2019-03-26 14:36:51,716] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 9500, global step 152022: learning rate 0.0000
[2019-03-26 14:36:51,733] A3C_AGENT_WORKER-Thread-19 INFO:Local step 9500, global step 152033: loss 0.0108
[2019-03-26 14:36:51,734] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 9500, global step 152033: learning rate 0.0000
[2019-03-26 14:36:51,790] A3C_AGENT_WORKER-Thread-18 INFO:Local step 9500, global step 152057: loss 0.0378
[2019-03-26 14:36:51,791] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 9500, global step 152057: learning rate 0.0000
[2019-03-26 14:36:51,988] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9500, global step 152144: loss 0.0216
[2019-03-26 14:36:51,992] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 9500, global step 152144: learning rate 0.0000
[2019-03-26 14:36:52,194] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9500, global step 152237: loss 0.0096
[2019-03-26 14:36:52,195] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 9500, global step 152237: learning rate 0.0000
[2019-03-26 14:36:52,197] A3C_AGENT_WORKER-Thread-20 INFO:Local step 9500, global step 152237: loss 0.0085
[2019-03-26 14:36:52,202] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 9500, global step 152239: learning rate 0.0000
[2019-03-26 14:36:52,273] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9500, global step 152274: loss 0.0120
[2019-03-26 14:36:52,276] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 9500, global step 152274: learning rate 0.0000
[2019-03-26 14:36:52,373] A3C_AGENT_WORKER-Thread-21 INFO:Local step 9500, global step 152318: loss 0.0146
[2019-03-26 14:36:52,376] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 9500, global step 152318: learning rate 0.0000
[2019-03-26 14:36:57,391] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.37098814e-13 1.00000000e+00 2.64448802e-14 1.00343864e-16
 2.55141033e-21], sum to 1.0000
[2019-03-26 14:36:57,399] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1441
[2019-03-26 14:36:57,405] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.55, 90.66666666666667, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.188739033089167, 6.9112, 168.9112376706455, 1650783.513989526, 1453889.775349303, 311349.8983636082], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5799000.0000, 
sim time next is 5799600.0000, 
raw observation next is [26.5, 91.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.171421861461453, 6.9112, 168.9109475555088, 1638489.512062762, 1453881.36304749, 311349.8186891561], 
processed observation next is [1.0, 0.13043478260869565, 0.4549763033175356, 0.91, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.026022186146145286, 0.0, 0.8294300802639312, 0.4551359755729894, 0.4038559341798583, 0.46470122192411356], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.5595694], dtype=float32), -0.25831643]. 
=============================================
[2019-03-26 14:37:00,243] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.3500865e-12 1.0000000e+00 4.2859318e-14 1.2220002e-15 1.5163345e-19], sum to 1.0000
[2019-03-26 14:37:00,249] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1651
[2019-03-26 14:37:00,254] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.6, 72.16666666666667, 1.0, 2.0, 0.5496981651021107, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 768142.8895896821, 768142.8895896821, 191750.4461455335], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5854200.0000, 
sim time next is 5854800.0000, 
raw observation next is [30.4, 73.33333333333334, 1.0, 2.0, 0.5562784091882665, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 777341.4235484758, 777341.4235484758, 192884.3202355736], 
processed observation next is [1.0, 0.782608695652174, 0.6398104265402843, 0.7333333333333334, 1.0, 1.0, 0.46539567372080304, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21592817320790997, 0.21592817320790997, 0.2878870451277218], 
reward next is 0.7121, 
noisyNet noise sample is [array([-0.7503129], dtype=float32), 0.719348]. 
=============================================
[2019-03-26 14:37:02,321] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.7929243e-13 1.0000000e+00 2.1631231e-15 4.4116280e-18 1.4344677e-23], sum to 1.0000
[2019-03-26 14:37:02,335] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6838
[2019-03-26 14:37:02,341] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.75, 89.66666666666666, 1.0, 2.0, 0.5295487083832199, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 739976.4265306772, 739976.4265306767, 188355.3711950968], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5874600.0000, 
sim time next is 5875200.0000, 
raw observation next is [26.7, 90.0, 1.0, 2.0, 0.5293183546834279, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 739654.4246990532, 739654.4246990532, 188317.2765606468], 
processed observation next is [1.0, 0.0, 0.46445497630331756, 0.9, 1.0, 1.0, 0.43291368034147937, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20545956241640365, 0.20545956241640365, 0.2810705620308161], 
reward next is 0.7189, 
noisyNet noise sample is [array([0.55419827], dtype=float32), 1.2612036]. 
=============================================
[2019-03-26 14:37:03,533] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.8470431e-13 1.0000000e+00 2.2881116e-14 2.8473740e-17 1.9278902e-21], sum to 1.0000
[2019-03-26 14:37:03,543] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2740
[2019-03-26 14:37:03,551] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2145994.967887642 W.
[2019-03-26 14:37:03,555] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.03333333333333, 78.5, 1.0, 2.0, 0.8935404553190295, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 7.005987327761655, 6.9112, 168.9123931466989, 2145994.967887642, 2078749.799524394, 432260.7000765339], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5907000.0000, 
sim time next is 5907600.0000, 
raw observation next is [30.2, 78.0, 1.0, 2.0, 0.7787250425490562, 1.0, 1.0, 0.7787250425490562, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2177788.693087529, 2177788.693087529, 409654.0797107184], 
processed observation next is [1.0, 0.391304347826087, 0.6303317535545023, 0.78, 1.0, 1.0, 0.7334036657217544, 1.0, 0.5, 0.7334036657217544, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6049413036354248, 0.6049413036354248, 0.6114239995682365], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.88546914], dtype=float32), 1.8594514]. 
=============================================
[2019-03-26 14:37:07,647] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0556608e-11 1.0000000e+00 3.1841961e-14 9.1041265e-17 4.9220449e-21], sum to 1.0000
[2019-03-26 14:37:07,655] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6077
[2019-03-26 14:37:07,663] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.3, 91.5, 1.0, 2.0, 0.8767697159339759, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129564976088, 1225453.208459404, 1225453.208459404, 263626.620912572], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5970600.0000, 
sim time next is 5971200.0000, 
raw observation next is [26.26666666666667, 91.66666666666666, 1.0, 2.0, 0.7796612521139348, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129565104278, 1089655.931503817, 1089655.931503817, 238978.7797241175], 
processed observation next is [1.0, 0.08695652173913043, 0.44391785150079005, 0.9166666666666665, 1.0, 1.0, 0.7345316290529335, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451522869, 0.3026822031955047, 0.3026822031955047, 0.3566847458568918], 
reward next is 0.6433, 
noisyNet noise sample is [array([0.09094486], dtype=float32), 0.509429]. 
=============================================
[2019-03-26 14:37:07,796] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.1189547e-13 1.0000000e+00 1.6636043e-13 5.9314945e-17 5.5494757e-22], sum to 1.0000
[2019-03-26 14:37:07,804] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7824
[2019-03-26 14:37:07,807] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.05, 93.33333333333334, 1.0, 2.0, 0.6614707702820186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 924400.8138359442, 924400.8138359436, 212747.8110653872], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5980200.0000, 
sim time next is 5980800.0000, 
raw observation next is [26.2, 92.66666666666667, 1.0, 2.0, 0.6213281476404795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 868278.8456684981, 868278.8456684987, 204779.9012124394], 
processed observation next is [1.0, 0.21739130434782608, 0.44075829383886256, 0.9266666666666667, 1.0, 1.0, 0.543768852578891, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.24118856824124946, 0.24118856824124962, 0.3056416436006558], 
reward next is 0.6944, 
noisyNet noise sample is [array([-0.5730499], dtype=float32), 0.22308017]. 
=============================================
[2019-03-26 14:37:07,907] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10000, global step 159384: loss -323.9258
[2019-03-26 14:37:07,909] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 10000, global step 159384: learning rate 0.0000
[2019-03-26 14:37:08,689] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10000, global step 159740: loss -255.6065
[2019-03-26 14:37:08,691] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 10000, global step 159741: learning rate 0.0000
[2019-03-26 14:37:08,847] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10000, global step 159813: loss -358.7127
[2019-03-26 14:37:08,852] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 10000, global step 159814: learning rate 0.0000
[2019-03-26 14:37:08,935] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10000, global step 159855: loss -335.5000
[2019-03-26 14:37:08,936] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 10000, global step 159855: learning rate 0.0000
[2019-03-26 14:37:08,981] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10000, global step 159873: loss -306.1921
[2019-03-26 14:37:08,983] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 10000, global step 159873: learning rate 0.0000
[2019-03-26 14:37:09,012] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10000, global step 159885: loss -262.5139
[2019-03-26 14:37:09,014] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 10000, global step 159885: learning rate 0.0000
[2019-03-26 14:37:09,273] A3C_AGENT_WORKER-Thread-22 INFO:Local step 10000, global step 160010: loss -290.8996
[2019-03-26 14:37:09,274] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 10000, global step 160010: learning rate 0.0000
[2019-03-26 14:37:09,299] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10000, global step 160021: loss -248.1762
[2019-03-26 14:37:09,300] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 10000, global step 160021: learning rate 0.0000
[2019-03-26 14:37:09,311] A3C_AGENT_WORKER-Thread-19 INFO:Local step 10000, global step 160024: loss -342.1554
[2019-03-26 14:37:09,315] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 10000, global step 160025: learning rate 0.0000
[2019-03-26 14:37:09,327] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10000, global step 160034: loss -270.9190
[2019-03-26 14:37:09,330] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 10000, global step 160034: learning rate 0.0000
[2019-03-26 14:37:09,463] A3C_AGENT_WORKER-Thread-18 INFO:Local step 10000, global step 160097: loss -303.7928
[2019-03-26 14:37:09,464] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 10000, global step 160097: learning rate 0.0000
[2019-03-26 14:37:09,526] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.261084e-12 1.000000e+00 9.737313e-14 2.438678e-16 9.526953e-20], sum to 1.0000
[2019-03-26 14:37:09,532] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1477
[2019-03-26 14:37:09,539] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2492546.962415464 W.
[2019-03-26 14:37:09,544] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.0, 77.66666666666667, 1.0, 2.0, 0.5941072374006996, 1.0, 1.0, 0.5941072374006996, 1.0, 2.0, 1.03, 6.913187251940842, 6.9112, 170.5573041426782, 2492546.962415464, 2491123.413013998, 485851.4050320131], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5995200.0000, 
sim time next is 5995800.0000, 
raw observation next is [30.15, 77.0, 1.0, 2.0, 0.8621189614965472, 1.0, 2.0, 0.8621189614965472, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2411239.386773583, 2411239.386773582, 451249.8869611853], 
processed observation next is [1.0, 0.391304347826087, 0.6279620853080569, 0.77, 1.0, 1.0, 0.8338782668633099, 1.0, 1.0, 0.8338782668633099, 0.0, 0.5, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6697887185482175, 0.6697887185482172, 0.6735072939719183], 
reward next is 0.3265, 
noisyNet noise sample is [array([0.12256154], dtype=float32), 0.2044599]. 
=============================================
[2019-03-26 14:37:09,598] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10000, global step 160163: loss -200.5836
[2019-03-26 14:37:09,599] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 10000, global step 160163: learning rate 0.0000
[2019-03-26 14:37:09,600] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10000, global step 160164: loss -313.9050
[2019-03-26 14:37:09,603] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 10000, global step 160165: learning rate 0.0000
[2019-03-26 14:37:09,614] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0491566e-12 1.0000000e+00 7.4368354e-14 5.1419093e-15 5.3724719e-18], sum to 1.0000
[2019-03-26 14:37:09,626] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10000, global step 160173: loss -281.7794
[2019-03-26 14:37:09,627] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1109
[2019-03-26 14:37:09,628] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 10000, global step 160173: learning rate 0.0000
[2019-03-26 14:37:09,635] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2204522.51733933 W.
[2019-03-26 14:37:09,640] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.43333333333333, 80.16666666666667, 1.0, 2.0, 0.788274590230356, 1.0, 2.0, 0.788274590230356, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2204522.51733933, 2204522.51733933, 414200.6001517994], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6015000.0000, 
sim time next is 6015600.0000, 
raw observation next is [29.0, 79.0, 1.0, 2.0, 0.9744066326345451, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.995437335416156, 6.9112, 168.9124555843656, 2259179.976967893, 2199419.28922438, 455930.7733904777], 
processed observation next is [1.0, 0.6521739130434783, 0.5734597156398105, 0.79, 1.0, 1.0, 0.969164617631982, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.008423733541615607, 0.0, 0.8294374853759966, 0.6275499936021925, 0.6109498025623278, 0.6804936916275787], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0394824], dtype=float32), 1.4834704]. 
=============================================
[2019-03-26 14:37:09,765] A3C_AGENT_WORKER-Thread-20 INFO:Local step 10000, global step 160233: loss -302.7786
[2019-03-26 14:37:09,766] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 10000, global step 160233: learning rate 0.0000
[2019-03-26 14:37:09,801] A3C_AGENT_WORKER-Thread-21 INFO:Local step 10000, global step 160250: loss -374.1022
[2019-03-26 14:37:09,804] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 10000, global step 160250: learning rate 0.0000
[2019-03-26 14:37:16,055] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.8109372e-11 1.0000000e+00 1.2348488e-12 1.3616533e-13 1.5153537e-16], sum to 1.0000
[2019-03-26 14:37:16,066] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3949
[2019-03-26 14:37:16,073] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.13333333333333, 69.83333333333333, 1.0, 2.0, 0.2411874485398437, 1.0, 1.0, 0.2411874485398437, 1.0, 2.0, 0.4149953479385847, 6.911200000000001, 6.9112, 170.5573041426782, 1011210.029667858, 1011210.029667857, 282138.7550990768], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6109800.0000, 
sim time next is 6110400.0000, 
raw observation next is [29.96666666666667, 70.66666666666667, 1.0, 2.0, 0.4933440891895702, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 168.9129564956611, 689368.6969068163, 689368.6969068169, 182562.7998007334], 
processed observation next is [1.0, 0.7391304347826086, 0.6192733017377569, 0.7066666666666667, 1.0, 1.0, 0.3895711917946628, 0.0, 0.5, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399450797757, 0.19149130469633788, 0.19149130469633804, 0.2724817907473633], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.5263703], dtype=float32), 0.32007915]. 
=============================================
[2019-03-26 14:37:22,062] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.2436482e-12 1.0000000e+00 3.8478833e-14 2.2486131e-16 3.1427209e-21], sum to 1.0000
[2019-03-26 14:37:22,068] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6508
[2019-03-26 14:37:22,073] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.41666666666666, 91.00000000000001, 1.0, 2.0, 0.5217229452310012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 729037.1732101989, 729037.1732101989, 187069.8875459699], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6228600.0000, 
sim time next is 6229200.0000, 
raw observation next is [26.43333333333333, 91.0, 1.0, 2.0, 0.5218866625747017, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 729266.0245607866, 729266.0245607866, 187096.631130235], 
processed observation next is [0.0, 0.08695652173913043, 0.4518167456556081, 0.91, 1.0, 1.0, 0.42395983442735147, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2025738957113296, 0.2025738957113296, 0.2792487031794552], 
reward next is 0.7208, 
noisyNet noise sample is [array([-2.5974886], dtype=float32), 1.4531533]. 
=============================================
[2019-03-26 14:37:25,130] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10500, global step 167345: loss 0.0870
[2019-03-26 14:37:25,133] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 10500, global step 167345: learning rate 0.0000
[2019-03-26 14:37:25,945] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10500, global step 167722: loss 0.0543
[2019-03-26 14:37:25,951] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 10500, global step 167723: learning rate 0.0000
[2019-03-26 14:37:26,033] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10500, global step 167767: loss 0.0763
[2019-03-26 14:37:26,037] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 10500, global step 167767: learning rate 0.0000
[2019-03-26 14:37:26,039] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10500, global step 167768: loss 0.0862
[2019-03-26 14:37:26,043] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 10500, global step 167768: learning rate 0.0000
[2019-03-26 14:37:26,068] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10500, global step 167780: loss 0.0872
[2019-03-26 14:37:26,072] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 10500, global step 167783: learning rate 0.0000
[2019-03-26 14:37:26,265] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10500, global step 167873: loss 0.0575
[2019-03-26 14:37:26,266] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 10500, global step 167873: learning rate 0.0000
[2019-03-26 14:37:26,644] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10500, global step 168047: loss 0.0421
[2019-03-26 14:37:26,649] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 10500, global step 168049: learning rate 0.0000
[2019-03-26 14:37:26,691] A3C_AGENT_WORKER-Thread-22 INFO:Local step 10500, global step 168071: loss 0.0769
[2019-03-26 14:37:26,696] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 10500, global step 168072: learning rate 0.0000
[2019-03-26 14:37:26,707] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10500, global step 168079: loss 0.0879
[2019-03-26 14:37:26,708] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 10500, global step 168080: learning rate 0.0000
[2019-03-26 14:37:26,768] A3C_AGENT_WORKER-Thread-19 INFO:Local step 10500, global step 168106: loss 0.0691
[2019-03-26 14:37:26,773] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 10500, global step 168108: learning rate 0.0000
[2019-03-26 14:37:26,836] A3C_AGENT_WORKER-Thread-18 INFO:Local step 10500, global step 168136: loss 0.0746
[2019-03-26 14:37:26,839] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 10500, global step 168136: learning rate 0.0000
[2019-03-26 14:37:26,853] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10500, global step 168144: loss 0.0568
[2019-03-26 14:37:26,862] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 10500, global step 168147: learning rate 0.0000
[2019-03-26 14:37:26,862] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10500, global step 168147: loss 0.0585
[2019-03-26 14:37:26,864] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 10500, global step 168147: learning rate 0.0000
[2019-03-26 14:37:27,098] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10500, global step 168261: loss 0.0761
[2019-03-26 14:37:27,100] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 10500, global step 168262: learning rate 0.0000
[2019-03-26 14:37:27,121] A3C_AGENT_WORKER-Thread-20 INFO:Local step 10500, global step 168268: loss 0.0515
[2019-03-26 14:37:27,123] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 10500, global step 168268: learning rate 0.0000
[2019-03-26 14:37:27,126] A3C_AGENT_WORKER-Thread-21 INFO:Local step 10500, global step 168271: loss 0.0557
[2019-03-26 14:37:27,129] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 10500, global step 168271: learning rate 0.0000
[2019-03-26 14:37:29,210] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.5664336e-12 1.0000000e+00 4.2657899e-13 3.6986613e-17 2.7435675e-21], sum to 1.0000
[2019-03-26 14:37:29,219] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3611
[2019-03-26 14:37:29,224] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 63.0, 1.0, 2.0, 0.5250703621992528, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 733716.3506362874, 733716.3506362874, 187617.2523374262], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6354000.0000, 
sim time next is 6354600.0000, 
raw observation next is [30.95, 62.83333333333333, 1.0, 2.0, 0.5292061733555125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 739497.6111338534, 739497.611133854, 188298.0382992323], 
processed observation next is [0.0, 0.5652173913043478, 0.6658767772511848, 0.6283333333333333, 1.0, 1.0, 0.4327785221150752, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20541600309273705, 0.20541600309273722, 0.2810418482078094], 
reward next is 0.7190, 
noisyNet noise sample is [array([-1.0844239], dtype=float32), 0.6325983]. 
=============================================
[2019-03-26 14:37:33,557] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.0216379e-13 1.0000000e+00 1.5032064e-15 1.1024390e-18 1.3981581e-22], sum to 1.0000
[2019-03-26 14:37:33,564] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5122
[2019-03-26 14:37:33,569] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.73333333333334, 86.33333333333334, 1.0, 2.0, 0.7501327455663231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1048366.467428835, 1048366.467428835, 232036.8900300064], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6412800.0000, 
sim time next is 6413400.0000, 
raw observation next is [26.8, 86.0, 1.0, 2.0, 0.7433145999523197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1038832.939503701, 1038832.939503701, 230470.9086789227], 
processed observation next is [1.0, 0.21739130434782608, 0.4691943127962086, 0.86, 1.0, 1.0, 0.6907404818702647, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.28856470541769474, 0.28856470541769474, 0.3439864308640637], 
reward next is 0.6560, 
noisyNet noise sample is [array([0.7942712], dtype=float32), -0.44944552]. 
=============================================
[2019-03-26 14:37:38,031] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.938262e-14 1.000000e+00 2.104351e-15 9.634590e-19 2.847398e-23], sum to 1.0000
[2019-03-26 14:37:38,040] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9627
[2019-03-26 14:37:38,044] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.18333333333333, 92.16666666666667, 1.0, 2.0, 0.6882910113865879, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 961898.8885065397, 961898.8885065403, 218337.324987471], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6495000.0000, 
sim time next is 6495600.0000, 
raw observation next is [26.16666666666667, 92.33333333333334, 1.0, 2.0, 0.6693307651779183, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 935389.93940007, 935389.9394000694, 214363.7850902913], 
processed observation next is [1.0, 0.17391304347826086, 0.4391785150078992, 0.9233333333333335, 1.0, 1.0, 0.6016033315396606, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.25983053872224166, 0.2598305387222415, 0.31994594789595715], 
reward next is 0.6801, 
noisyNet noise sample is [array([-0.27955672], dtype=float32), -0.42560676]. 
=============================================
[2019-03-26 14:37:38,999] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.5944640e-11 1.0000000e+00 1.3149655e-13 1.5367048e-14 1.5054364e-18], sum to 1.0000
[2019-03-26 14:37:39,008] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1462
[2019-03-26 14:37:39,016] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2058124.347794635 W.
[2019-03-26 14:37:39,020] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.25, 56.5, 1.0, 2.0, 0.830760180922679, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.965703975683386, 6.9112, 168.9126318744184, 2058124.347794635, 2019457.425877375, 416883.716264352], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6521400.0000, 
sim time next is 6522000.0000, 
raw observation next is [31.3, 56.33333333333333, 1.0, 2.0, 0.7933928507953559, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.964257520557075, 6.9112, 168.9125959199487, 2005826.496967893, 1968185.746140332, 407551.728528244], 
processed observation next is [1.0, 0.4782608695652174, 0.6824644549763034, 0.5633333333333332, 1.0, 1.0, 0.7510757238498265, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.0053057520557074685, 0.0, 0.8294381744879555, 0.5571740269355259, 0.5467182628167588, 0.6082861619824538], 
reward next is 0.1264, 
noisyNet noise sample is [array([-0.6967426], dtype=float32), -1.4010606]. 
=============================================
[2019-03-26 14:37:39,040] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[58.407986]
 [59.15239 ]
 [59.87299 ]
 [60.131687]
 [60.38613 ]], R is [[57.66537857]
 [57.08872604]
 [56.94647598]
 [56.50186539]
 [55.93684769]].
[2019-03-26 14:37:41,643] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-26 14:37:41,646] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 14:37:41,646] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 14:37:41,647] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:37:41,648] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 14:37:41,647] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 14:37:41,648] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 14:37:41,651] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:37:41,653] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:37:41,650] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:37:41,653] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:37:41,670] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run8
[2019-03-26 14:37:41,687] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run8
[2019-03-26 14:37:41,688] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run8
[2019-03-26 14:37:41,705] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run8
[2019-03-26 14:37:41,724] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run8
[2019-03-26 14:38:04,672] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.06783068], dtype=float32), 0.06502908]
[2019-03-26 14:38:04,674] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.3, 82.0, 1.0, 2.0, 0.38326701905957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 577788.1199690475, 577788.1199690482, 172692.9188423491]
[2019-03-26 14:38:04,675] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 14:38:04,677] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [5.0470340e-12 1.0000000e+00 1.4663431e-13 1.9896318e-16 1.9967902e-20], sampled 0.48523633368466845
[2019-03-26 14:38:07,836] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.06783068], dtype=float32), 0.06502908]
[2019-03-26 14:38:07,839] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [24.1, 85.5, 1.0, 2.0, 0.4024663327855361, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 600731.8013350376, 600731.8013350376, 174608.9514784399]
[2019-03-26 14:38:07,840] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 14:38:07,843] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.5618806e-13 1.0000000e+00 4.7577205e-15 4.1423336e-18 1.8775844e-22], sampled 0.08525871252121486
[2019-03-26 14:38:10,881] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.06783068], dtype=float32), 0.06502908]
[2019-03-26 14:38:10,882] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [24.734140715, 94.960289715, 1.0, 2.0, 0.4716294685652482, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 659751.4719531834, 659751.4719531841, 179365.8724432726]
[2019-03-26 14:38:10,884] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 14:38:10,888] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.6003618e-12 1.0000000e+00 4.1256576e-14 3.5214468e-17 2.2885182e-21], sampled 0.5603927739349456
[2019-03-26 14:38:20,214] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.06783068], dtype=float32), 0.06502908]
[2019-03-26 14:38:20,215] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.75605397166667, 88.12023490499999, 1.0, 2.0, 0.5564623589122557, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 777598.5683127305, 777598.5683127305, 192915.4589206805]
[2019-03-26 14:38:20,216] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 14:38:20,217] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.3462778e-13 1.0000000e+00 6.6852160e-15 4.6355317e-18 2.1357461e-22], sampled 0.1953235693622637
[2019-03-26 14:38:24,723] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.06783068], dtype=float32), 0.06502908]
[2019-03-26 14:38:24,724] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.5, 71.0, 1.0, 2.0, 0.5211576170616965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 728246.9328478418, 728246.9328478423, 186980.1976902841]
[2019-03-26 14:38:24,726] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 14:38:24,731] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.6570458e-13 1.0000000e+00 3.2652934e-15 2.6786164e-18 1.1822007e-22], sampled 0.06612520167329972
[2019-03-26 14:38:26,440] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.06783068], dtype=float32), 0.06502908]
[2019-03-26 14:38:26,441] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [21.94237168333333, 99.41650580833334, 1.0, 2.0, 0.3858379328531232, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 584275.4714522845, 584275.4714522845, 173348.9172237159]
[2019-03-26 14:38:26,441] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 14:38:26,446] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.6867867e-13 1.0000000e+00 7.2402259e-15 6.0859044e-18 2.8727108e-22], sampled 0.26450997277980337
[2019-03-26 14:38:44,669] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.06783068], dtype=float32), 0.06502908]
[2019-03-26 14:38:44,671] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [36.2, 53.0, 1.0, 2.0, 0.9588658475819295, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005991157941692, 6.9112, 168.912315938229, 2237428.645497291, 2170180.790620022, 450913.97103725]
[2019-03-26 14:38:44,672] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 14:38:44,674] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [9.4068568e-13 1.0000000e+00 1.4803876e-14 3.3177375e-16 5.5343443e-20], sampled 0.45880838939802315
[2019-03-26 14:38:44,675] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2237428.645497291 W.
[2019-03-26 14:39:14,162] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.06783068], dtype=float32), 0.06502908]
[2019-03-26 14:39:14,163] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.31761418, 84.41678753000001, 1.0, 2.0, 0.9850480265207765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1376890.974355662, 1376890.974355662, 294407.7364779533]
[2019-03-26 14:39:14,167] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 14:39:14,171] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.5898609e-13 1.0000000e+00 7.7744767e-15 8.5918365e-18 4.2887442e-22], sampled 0.5848717520280975
[2019-03-26 14:39:35,255] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.9164 3164002230.9074 1778.0000
[2019-03-26 14:39:35,971] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.2953 3007596012.4260 1766.0000
[2019-03-26 14:39:36,044] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.6119 2842427357.4275 1131.0000
[2019-03-26 14:39:36,093] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.9767 2779197554.3421 933.0000
[2019-03-26 14:39:36,181] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8252.9307 2927401947.9059 1338.0000
[2019-03-26 14:39:37,202] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 175000, evaluation results [175000.0, 7884.916440885027, 3164002230.907359, 1778.0, 8252.930728401534, 2927401947.90586, 1338.0, 8659.97666076793, 2779197554.342144, 933.0, 7998.295259250187, 3007596012.4259605, 1766.0, 8497.61193292354, 2842427357.427519, 1131.0]
[2019-03-26 14:39:38,062] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11000, global step 175395: loss -328.4283
[2019-03-26 14:39:38,065] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 11000, global step 175396: learning rate 0.0000
[2019-03-26 14:39:38,841] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11000, global step 175745: loss -330.5006
[2019-03-26 14:39:38,845] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 11000, global step 175745: learning rate 0.0000
[2019-03-26 14:39:38,923] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11000, global step 175786: loss -431.9652
[2019-03-26 14:39:38,925] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 11000, global step 175786: learning rate 0.0000
[2019-03-26 14:39:38,996] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11000, global step 175819: loss -352.3240
[2019-03-26 14:39:38,999] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 11000, global step 175819: learning rate 0.0000
[2019-03-26 14:39:39,095] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11000, global step 175862: loss -380.7225
[2019-03-26 14:39:39,097] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 11000, global step 175862: learning rate 0.0000
[2019-03-26 14:39:39,252] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11000, global step 175933: loss -312.9691
[2019-03-26 14:39:39,254] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 11000, global step 175934: learning rate 0.0000
[2019-03-26 14:39:39,427] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11000, global step 176018: loss -414.8391
[2019-03-26 14:39:39,429] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 11000, global step 176018: learning rate 0.0000
[2019-03-26 14:39:39,445] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11000, global step 176024: loss -319.1341
[2019-03-26 14:39:39,448] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 11000, global step 176025: learning rate 0.0000
[2019-03-26 14:39:39,490] A3C_AGENT_WORKER-Thread-22 INFO:Local step 11000, global step 176043: loss -410.7510
[2019-03-26 14:39:39,491] A3C_AGENT_WORKER-Thread-19 INFO:Local step 11000, global step 176043: loss -325.3114
[2019-03-26 14:39:39,493] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 11000, global step 176044: learning rate 0.0000
[2019-03-26 14:39:39,493] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 11000, global step 176043: learning rate 0.0000
[2019-03-26 14:39:39,550] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11000, global step 176070: loss -310.2421
[2019-03-26 14:39:39,550] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 11000, global step 176070: learning rate 0.0000
[2019-03-26 14:39:39,582] A3C_AGENT_WORKER-Thread-18 INFO:Local step 11000, global step 176085: loss -391.6577
[2019-03-26 14:39:39,585] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 11000, global step 176086: learning rate 0.0000
[2019-03-26 14:39:39,636] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11000, global step 176109: loss -412.7587
[2019-03-26 14:39:39,639] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 11000, global step 176109: learning rate 0.0000
[2019-03-26 14:39:39,761] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11000, global step 176165: loss -436.3994
[2019-03-26 14:39:39,766] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 11000, global step 176165: learning rate 0.0000
[2019-03-26 14:39:39,934] A3C_AGENT_WORKER-Thread-20 INFO:Local step 11000, global step 176244: loss -378.6836
[2019-03-26 14:39:39,939] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 11000, global step 176244: learning rate 0.0000
[2019-03-26 14:39:39,947] A3C_AGENT_WORKER-Thread-21 INFO:Local step 11000, global step 176248: loss -363.7425
[2019-03-26 14:39:39,949] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 11000, global step 176249: learning rate 0.0000
[2019-03-26 14:39:40,354] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.65518163e-11 1.00000000e+00 1.04878996e-13 1.17633103e-13
 3.08943790e-18], sum to 1.0000
[2019-03-26 14:39:40,363] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5420
[2019-03-26 14:39:40,368] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 66.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.962275543973435, 6.9112, 168.9122790115192, 1490014.346994505, 1453779.74355042, 311350.8967232229], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6612000.0000, 
sim time next is 6612600.0000, 
raw observation next is [31.0, 66.0, 1.0, 2.0, 0.9963655422505654, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129149225747, 1392720.869904696, 1392720.869904696, 297821.0493258548], 
processed observation next is [1.0, 0.5217391304347826, 0.6682464454976303, 0.66, 1.0, 1.0, 0.9956211352416451, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294397409368893, 0.38686690830686, 0.38686690830686, 0.4445090288445594], 
reward next is 0.5555, 
noisyNet noise sample is [array([0.2213328], dtype=float32), 1.5442697]. 
=============================================
[2019-03-26 14:39:55,620] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11500, global step 183380: loss 0.3388
[2019-03-26 14:39:55,628] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 11500, global step 183380: learning rate 0.0000
[2019-03-26 14:39:56,201] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11500, global step 183653: loss 0.3444
[2019-03-26 14:39:56,205] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 11500, global step 183655: learning rate 0.0000
[2019-03-26 14:39:56,478] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11500, global step 183784: loss 0.3048
[2019-03-26 14:39:56,482] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 11500, global step 183784: learning rate 0.0000
[2019-03-26 14:39:56,527] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11500, global step 183803: loss 0.3289
[2019-03-26 14:39:56,530] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 11500, global step 183803: learning rate 0.0000
[2019-03-26 14:39:56,655] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11500, global step 183863: loss 0.3527
[2019-03-26 14:39:56,656] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 11500, global step 183863: learning rate 0.0000
[2019-03-26 14:39:56,776] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11500, global step 183916: loss 0.3853
[2019-03-26 14:39:56,780] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 11500, global step 183916: learning rate 0.0000
[2019-03-26 14:39:56,973] A3C_AGENT_WORKER-Thread-22 INFO:Local step 11500, global step 184005: loss 0.3187
[2019-03-26 14:39:56,975] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 11500, global step 184005: learning rate 0.0000
[2019-03-26 14:39:57,043] A3C_AGENT_WORKER-Thread-19 INFO:Local step 11500, global step 184042: loss 0.3365
[2019-03-26 14:39:57,046] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 11500, global step 184042: learning rate 0.0000
[2019-03-26 14:39:57,069] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11500, global step 184054: loss 0.2918
[2019-03-26 14:39:57,070] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 11500, global step 184054: learning rate 0.0000
[2019-03-26 14:39:57,150] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11500, global step 184089: loss 0.2921
[2019-03-26 14:39:57,151] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 11500, global step 184089: learning rate 0.0000
[2019-03-26 14:39:57,155] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11500, global step 184090: loss 0.3146
[2019-03-26 14:39:57,158] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 11500, global step 184091: learning rate 0.0000
[2019-03-26 14:39:57,223] A3C_AGENT_WORKER-Thread-18 INFO:Local step 11500, global step 184127: loss 0.3045
[2019-03-26 14:39:57,229] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 11500, global step 184127: learning rate 0.0000
[2019-03-26 14:39:57,268] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11500, global step 184144: loss 0.2556
[2019-03-26 14:39:57,272] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 11500, global step 184146: learning rate 0.0000
[2019-03-26 14:39:57,447] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11500, global step 184227: loss 0.2968
[2019-03-26 14:39:57,450] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 11500, global step 184227: learning rate 0.0000
[2019-03-26 14:39:57,525] A3C_AGENT_WORKER-Thread-20 INFO:Local step 11500, global step 184263: loss 0.2754
[2019-03-26 14:39:57,528] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 11500, global step 184264: learning rate 0.0000
[2019-03-26 14:39:57,724] A3C_AGENT_WORKER-Thread-21 INFO:Local step 11500, global step 184356: loss 0.3015
[2019-03-26 14:39:57,727] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 11500, global step 184357: learning rate 0.0000
[2019-03-26 14:40:08,673] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.5005991e-13 1.0000000e+00 4.9646016e-15 3.2788044e-19 3.3017038e-23], sum to 1.0000
[2019-03-26 14:40:08,681] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9966
[2019-03-26 14:40:08,687] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.15, 94.5, 1.0, 2.0, 0.5293945642474459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 753184.2030502071, 753184.2030502065, 190045.4234577006], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7101000.0000, 
sim time next is 7101600.0000, 
raw observation next is [24.1, 94.66666666666666, 1.0, 2.0, 0.5528481404135185, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 787519.6662528536, 787519.6662528529, 194206.4304038058], 
processed observation next is [1.0, 0.17391304347826086, 0.3412322274881518, 0.9466666666666665, 1.0, 1.0, 0.46126281977532346, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2187554628480149, 0.2187554628480147, 0.2898603438862773], 
reward next is 0.7101, 
noisyNet noise sample is [array([0.07653552], dtype=float32), -0.43418416]. 
=============================================
[2019-03-26 14:40:09,310] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0042635e-13 1.0000000e+00 2.0294166e-15 1.7886726e-16 4.0203240e-20], sum to 1.0000
[2019-03-26 14:40:09,322] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5398
[2019-03-26 14:40:09,330] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1706061.443058002 W.
[2019-03-26 14:40:09,333] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.26666666666667, 69.0, 1.0, 2.0, 0.6101761543743099, 0.0, 1.0, 0.0, 1.0, 1.0, 1.017412818550167, 6.911200000000001, 6.9112, 168.912956510431, 1706061.443058002, 1706061.443058001, 364593.7837384263], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7122000.0000, 
sim time next is 7122600.0000, 
raw observation next is [28.35, 68.5, 1.0, 2.0, 0.3982614653269216, 1.0, 1.0, 0.3982614653269216, 1.0, 2.0, 0.6683733981580573, 6.911200000000001, 6.9112, 170.5573041426782, 1670276.514692056, 1670276.514692055, 348595.4055045347], 
processed observation next is [1.0, 0.43478260869565216, 0.5426540284360191, 0.685, 1.0, 1.0, 0.2750138136468935, 1.0, 0.5, 0.2750138136468935, 1.0, 1.0, 0.5955773148268991, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.4639656985255711, 0.46396569852557085, 0.5202916500067682], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.05707879], dtype=float32), 1.0273675]. 
=============================================
[2019-03-26 14:40:11,373] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.7731869e-14 1.0000000e+00 7.4124244e-17 1.7158479e-19 1.1385780e-22], sum to 1.0000
[2019-03-26 14:40:11,383] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0727
[2019-03-26 14:40:11,389] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.75, 84.5, 1.0, 2.0, 0.4685609498154886, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 660048.8260676397, 660048.8260676397, 179503.4029037608], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7165800.0000, 
sim time next is 7166400.0000, 
raw observation next is [25.73333333333333, 84.66666666666667, 1.0, 2.0, 0.4683753990956585, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 659578.6357287432, 659578.6357287432, 179448.9864789623], 
processed observation next is [1.0, 0.9565217391304348, 0.41864139020537117, 0.8466666666666667, 1.0, 1.0, 0.35948843264537167, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18321628770242865, 0.18321628770242865, 0.26783430817755566], 
reward next is 0.7322, 
noisyNet noise sample is [array([-2.0119562], dtype=float32), 1.3237284]. 
=============================================
[2019-03-26 14:40:12,794] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12000, global step 191381: loss 0.0147
[2019-03-26 14:40:12,796] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 12000, global step 191381: learning rate 0.0000
[2019-03-26 14:40:13,271] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12000, global step 191600: loss 0.0120
[2019-03-26 14:40:13,272] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 12000, global step 191600: learning rate 0.0000
[2019-03-26 14:40:13,711] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12000, global step 191807: loss 0.0292
[2019-03-26 14:40:13,717] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 12000, global step 191809: learning rate 0.0000
[2019-03-26 14:40:13,733] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12000, global step 191815: loss 0.0148
[2019-03-26 14:40:13,736] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 12000, global step 191815: learning rate 0.0000
[2019-03-26 14:40:13,827] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12000, global step 191862: loss 0.0146
[2019-03-26 14:40:13,829] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 12000, global step 191862: learning rate 0.0000
[2019-03-26 14:40:14,037] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12000, global step 191955: loss 0.0226
[2019-03-26 14:40:14,044] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 12000, global step 191955: learning rate 0.0000
[2019-03-26 14:40:14,130] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12000, global step 191999: loss 0.0102
[2019-03-26 14:40:14,132] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 12000, global step 192000: learning rate 0.0000
[2019-03-26 14:40:14,246] A3C_AGENT_WORKER-Thread-22 INFO:Local step 12000, global step 192057: loss 0.0273
[2019-03-26 14:40:14,248] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 12000, global step 192057: learning rate 0.0000
[2019-03-26 14:40:14,281] A3C_AGENT_WORKER-Thread-19 INFO:Local step 12000, global step 192071: loss 0.0068
[2019-03-26 14:40:14,282] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 12000, global step 192071: learning rate 0.0000
[2019-03-26 14:40:14,312] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12000, global step 192087: loss 0.0098
[2019-03-26 14:40:14,315] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 12000, global step 192088: learning rate 0.0000
[2019-03-26 14:40:14,330] A3C_AGENT_WORKER-Thread-18 INFO:Local step 12000, global step 192094: loss 0.0148
[2019-03-26 14:40:14,332] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12000, global step 192095: loss 0.0186
[2019-03-26 14:40:14,334] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 12000, global step 192096: learning rate 0.0000
[2019-03-26 14:40:14,334] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 12000, global step 192096: learning rate 0.0000
[2019-03-26 14:40:14,338] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12000, global step 192098: loss 0.0262
[2019-03-26 14:40:14,342] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 12000, global step 192098: learning rate 0.0000
[2019-03-26 14:40:14,523] A3C_AGENT_WORKER-Thread-20 INFO:Local step 12000, global step 192193: loss 0.0253
[2019-03-26 14:40:14,527] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 12000, global step 192193: learning rate 0.0000
[2019-03-26 14:40:14,529] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12000, global step 192193: loss 0.0120
[2019-03-26 14:40:14,531] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 12000, global step 192193: learning rate 0.0000
[2019-03-26 14:40:14,664] A3C_AGENT_WORKER-Thread-21 INFO:Local step 12000, global step 192259: loss 0.0167
[2019-03-26 14:40:14,670] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 12000, global step 192259: learning rate 0.0000
[2019-03-26 14:40:26,141] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.9550936e-14 1.0000000e+00 7.0714239e-16 5.1900050e-18 6.6272457e-23], sum to 1.0000
[2019-03-26 14:40:26,151] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4273
[2019-03-26 14:40:26,157] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.96666666666667, 85.33333333333334, 1.0, 2.0, 0.2874920918785873, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 465074.6192721507, 465074.6192721507, 164610.5589123887], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7410000.0000, 
sim time next is 7410600.0000, 
raw observation next is [21.05, 85.0, 1.0, 2.0, 0.2848850733011434, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 460528.7235308647, 460528.7235308641, 164303.8204612862], 
processed observation next is [1.0, 0.782608695652174, 0.1966824644549764, 0.85, 1.0, 1.0, 0.13841575096523298, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12792464542524018, 0.12792464542524004, 0.2452295827780391], 
reward next is 0.7548, 
noisyNet noise sample is [array([-0.73100287], dtype=float32), -0.98548704]. 
=============================================
[2019-03-26 14:40:29,298] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.94097884e-12 1.00000000e+00 1.05323824e-13 1.25986630e-17
 2.98698711e-22], sum to 1.0000
[2019-03-26 14:40:29,306] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1132
[2019-03-26 14:40:29,314] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 93.66666666666667, 1.0, 2.0, 0.3452236390077541, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 532743.9537262849, 532743.9537262843, 169251.9696557469], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7461600.0000, 
sim time next is 7462200.0000, 
raw observation next is [22.1, 93.33333333333333, 1.0, 2.0, 0.3469143773739593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 534445.9834828508, 534445.9834828508, 169362.8886042231], 
processed observation next is [0.0, 0.34782608695652173, 0.24644549763033188, 0.9333333333333332, 1.0, 1.0, 0.2131498522577823, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14845721763412523, 0.14845721763412523, 0.2527804307525718], 
reward next is 0.7472, 
noisyNet noise sample is [array([0.17097649], dtype=float32), 0.15971209]. 
=============================================
[2019-03-26 14:40:29,891] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12500, global step 199384: loss 0.0088
[2019-03-26 14:40:29,896] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 12500, global step 199385: learning rate 0.0000
[2019-03-26 14:40:30,389] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12500, global step 199617: loss 0.0097
[2019-03-26 14:40:30,392] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 12500, global step 199617: learning rate 0.0000
[2019-03-26 14:40:30,806] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12500, global step 199812: loss 0.0150
[2019-03-26 14:40:30,807] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 12500, global step 199813: learning rate 0.0000
[2019-03-26 14:40:30,964] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12500, global step 199888: loss 0.0132
[2019-03-26 14:40:30,970] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 12500, global step 199889: learning rate 0.0000
[2019-03-26 14:40:31,005] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12500, global step 199905: loss 0.0114
[2019-03-26 14:40:31,007] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 12500, global step 199905: learning rate 0.0000
[2019-03-26 14:40:31,044] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12500, global step 199922: loss 0.0106
[2019-03-26 14:40:31,048] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 12500, global step 199923: learning rate 0.0000
[2019-03-26 14:40:31,214] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-26 14:40:31,216] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 14:40:31,218] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:40:31,218] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 14:40:31,218] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:40:31,219] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 14:40:31,220] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 14:40:31,221] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 14:40:31,223] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:40:31,224] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:40:31,224] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:40:31,237] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run9
[2019-03-26 14:40:31,253] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run9
[2019-03-26 14:40:31,256] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run9
[2019-03-26 14:40:31,256] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run9
[2019-03-26 14:40:31,294] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run9
[2019-03-26 14:40:36,204] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.07313439], dtype=float32), 0.06996343]
[2019-03-26 14:40:36,205] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.7, 59.0, 1.0, 2.0, 0.2783156983173344, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 451731.9895097881, 451731.9895097881, 163692.1112181604]
[2019-03-26 14:40:36,208] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 14:40:36,210] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.9897118e-12 1.0000000e+00 4.1994525e-14 2.9168661e-17 1.9479534e-21], sampled 0.10189348382423746
[2019-03-26 14:40:58,931] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.07313439], dtype=float32), 0.06996343]
[2019-03-26 14:40:58,932] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.43333333333333, 78.83333333333333, 1.0, 2.0, 0.5906535667287947, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9870156119149172, 6.9112, 6.9112, 168.9129449977219, 1661452.882144965, 1661452.882144965, 353752.4351098576]
[2019-03-26 14:40:58,933] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 14:40:58,936] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.0183511e-13 1.0000000e+00 3.0777150e-15 1.3172195e-17 2.0979645e-21], sampled 0.8348893921632711
[2019-03-26 14:40:58,937] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1661452.882144965 W.
[2019-03-26 14:41:11,655] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.07313439], dtype=float32), 0.06996343]
[2019-03-26 14:41:11,660] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [19.28486715333333, 93.597552055, 1.0, 2.0, 0.2576588881780831, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 423404.295778931, 423404.295778931, 161674.3903253102]
[2019-03-26 14:41:11,661] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 14:41:11,663] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0956338e-12 1.0000000e+00 2.1797280e-14 1.6218340e-17 9.9910089e-22], sampled 0.3062273842489833
[2019-03-26 14:41:21,308] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.07313439], dtype=float32), 0.06996343]
[2019-03-26 14:41:21,310] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [26.0, 86.0, 1.0, 2.0, 0.6233481470691591, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 871102.8639241923, 871102.8639241916, 205166.764000159]
[2019-03-26 14:41:21,311] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 14:41:21,314] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [9.2020799e-14 1.0000000e+00 1.5003935e-15 7.6599458e-19 2.6818611e-23], sampled 0.7685803551897976
[2019-03-26 14:41:37,919] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.07313439], dtype=float32), 0.06996343]
[2019-03-26 14:41:37,919] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [37.71666666666666, 45.33333333333333, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.05872709834223, 6.9112, 168.9118834515642, 2388434.28858922, 2283774.152416473, 475752.9348535587]
[2019-03-26 14:41:37,920] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 14:41:37,922] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.13196365e-13 1.00000000e+00 8.93853752e-16 5.14714129e-18
 8.11550918e-22], sampled 0.9557442490513541
[2019-03-26 14:41:37,925] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2388434.28858922 W.
[2019-03-26 14:41:46,594] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.07313439], dtype=float32), 0.06996343]
[2019-03-26 14:41:46,596] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.0, 76.0, 1.0, 2.0, 0.5724641325337737, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 799967.8116174395, 799967.8116174401, 195730.6057269087]
[2019-03-26 14:41:46,597] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 14:41:46,602] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.5825598e-13 1.0000000e+00 1.9155510e-15 2.8942775e-17 3.4558988e-21], sampled 0.6224137915387855
[2019-03-26 14:42:06,163] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.07313439], dtype=float32), 0.06996343]
[2019-03-26 14:42:06,165] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.3, 85.0, 1.0, 2.0, 0.5108819172072941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 713883.2140459766, 713883.2140459772, 185319.6803323884]
[2019-03-26 14:42:06,166] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 14:42:06,169] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.5103352e-13 1.0000000e+00 1.4854894e-15 6.2224368e-18 4.5009647e-22], sampled 0.5329746681312293
[2019-03-26 14:42:15,482] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.07313439], dtype=float32), 0.06996343]
[2019-03-26 14:42:15,484] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [33.7, 58.5, 1.0, 2.0, 0.8048733992967846, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1124911.136979024, 1124911.136979024, 245113.9788495815]
[2019-03-26 14:42:15,486] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 14:42:15,488] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.1738919e-14 1.0000000e+00 1.2080900e-16 7.1978536e-20 1.5127601e-24], sampled 0.4778306319424369
[2019-03-26 14:42:25,136] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.9164 3164002230.9074 1778.0000
[2019-03-26 14:42:25,341] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.4676 2779124528.0117 933.0000
[2019-03-26 14:42:25,485] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.6119 2842427357.4275 1131.0000
[2019-03-26 14:42:25,645] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.1610 2927253227.7716 1338.0000
[2019-03-26 14:42:25,684] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7999.0502 3007584666.7691 1766.0000
[2019-03-26 14:42:26,698] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 200000, evaluation results [200000.0, 7884.916440885027, 3164002230.907359, 1778.0, 8255.161016606155, 2927253227.7715816, 1338.0, 8661.467580702742, 2779124528.011676, 933.0, 7999.050242421542, 3007584666.769063, 1766.0, 8497.61193292354, 2842427357.427519, 1131.0]
[2019-03-26 14:42:26,721] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12500, global step 200014: loss 0.0176
[2019-03-26 14:42:26,725] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 12500, global step 200014: learning rate 0.0000
[2019-03-26 14:42:26,783] A3C_AGENT_WORKER-Thread-18 INFO:Local step 12500, global step 200042: loss 0.0023
[2019-03-26 14:42:26,791] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 12500, global step 200043: learning rate 0.0000
[2019-03-26 14:42:26,847] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12500, global step 200070: loss 0.0046
[2019-03-26 14:42:26,851] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 12500, global step 200070: learning rate 0.0000
[2019-03-26 14:42:26,854] A3C_AGENT_WORKER-Thread-22 INFO:Local step 12500, global step 200072: loss 0.0014
[2019-03-26 14:42:26,857] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 12500, global step 200072: learning rate 0.0000
[2019-03-26 14:42:26,878] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12500, global step 200084: loss 0.0105
[2019-03-26 14:42:26,883] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 12500, global step 200086: learning rate 0.0000
[2019-03-26 14:42:26,963] A3C_AGENT_WORKER-Thread-19 INFO:Local step 12500, global step 200125: loss 0.0051
[2019-03-26 14:42:26,965] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 12500, global step 200125: learning rate 0.0000
[2019-03-26 14:42:26,983] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12500, global step 200132: loss 0.0120
[2019-03-26 14:42:26,986] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 12500, global step 200133: learning rate 0.0000
[2019-03-26 14:42:27,119] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12500, global step 200195: loss 0.0142
[2019-03-26 14:42:27,122] A3C_AGENT_WORKER-Thread-20 INFO:Local step 12500, global step 200195: loss 0.0024
[2019-03-26 14:42:27,122] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 12500, global step 200195: learning rate 0.0000
[2019-03-26 14:42:27,125] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 12500, global step 200196: learning rate 0.0000
[2019-03-26 14:42:27,305] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.5621090e-14 1.0000000e+00 4.9760893e-16 5.1461961e-19 1.5369702e-23], sum to 1.0000
[2019-03-26 14:42:27,306] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7594
[2019-03-26 14:42:27,315] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.45, 85.33333333333334, 1.0, 2.0, 0.402064948367434, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 593435.8710656009, 593435.8710656002, 173736.6906591997], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7503000.0000, 
sim time next is 7503600.0000, 
raw observation next is [24.4, 85.66666666666667, 1.0, 2.0, 0.4026875036412299, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 594441.6762665659, 594441.6762665653, 173833.0508850024], 
processed observation next is [0.0, 0.8695652173913043, 0.3554502369668246, 0.8566666666666667, 1.0, 1.0, 0.28034638992919264, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16512268785182388, 0.1651226878518237, 0.2594523147537349], 
reward next is 0.7405, 
noisyNet noise sample is [array([-0.11441303], dtype=float32), -0.717395]. 
=============================================
[2019-03-26 14:42:27,497] A3C_AGENT_WORKER-Thread-21 INFO:Local step 12500, global step 200367: loss 0.0050
[2019-03-26 14:42:27,500] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 12500, global step 200367: learning rate 0.0000
[2019-03-26 14:42:29,893] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.0607807e-14 1.0000000e+00 1.7775251e-15 6.3712822e-19 5.8022329e-24], sum to 1.0000
[2019-03-26 14:42:29,904] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4039
[2019-03-26 14:42:29,909] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.66666666666666, 68.66666666666667, 1.0, 2.0, 0.4731625188551269, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 661159.4355417026, 661159.4355417031, 179498.237480394], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7558800.0000, 
sim time next is 7559400.0000, 
raw observation next is [28.83333333333334, 67.33333333333333, 1.0, 2.0, 0.4708101317188357, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 657871.3802175018, 657871.3802175024, 179149.1656465296], 
processed observation next is [0.0, 0.4782608695652174, 0.5655608214849924, 0.6733333333333333, 1.0, 1.0, 0.36242184544438033, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18274205006041716, 0.18274205006041733, 0.2673868143978054], 
reward next is 0.7326, 
noisyNet noise sample is [array([0.16201775], dtype=float32), -2.7525105]. 
=============================================
[2019-03-26 14:42:39,469] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.9120234e-13 1.0000000e+00 2.7058565e-15 3.6508861e-18 2.1761426e-22], sum to 1.0000
[2019-03-26 14:42:39,476] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2662
[2019-03-26 14:42:39,480] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.4, 85.0, 1.0, 2.0, 0.6652724666991984, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 929715.9836599164, 929715.9836599157, 213527.6294061075], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7718400.0000, 
sim time next is 7719000.0000, 
raw observation next is [27.6, 83.83333333333334, 1.0, 2.0, 0.8698121618601413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1215723.129822778, 1215723.129822777, 261768.3282773621], 
processed observation next is [1.0, 0.34782608695652173, 0.5071090047393366, 0.8383333333333334, 1.0, 1.0, 0.8431471829640257, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.33770086939521615, 0.3377008693952158, 0.3906989974288987], 
reward next is 0.6093, 
noisyNet noise sample is [array([0.5586825], dtype=float32), 1.0153979]. 
=============================================
[2019-03-26 14:42:39,497] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[73.99733]
 [73.89291]
 [73.78967]
 [73.67358]
 [73.62361]], R is [[74.0449295 ]
 [73.98578644]
 [73.9165802 ]
 [73.85663605]
 [73.81427765]].
[2019-03-26 14:42:43,001] A3C_AGENT_WORKER-Thread-10 INFO:Local step 13000, global step 207350: loss 0.0206
[2019-03-26 14:42:43,005] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 13000, global step 207352: learning rate 0.0000
[2019-03-26 14:42:43,574] A3C_AGENT_WORKER-Thread-9 INFO:Local step 13000, global step 207617: loss 0.0393
[2019-03-26 14:42:43,577] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 13000, global step 207617: learning rate 0.0000
[2019-03-26 14:42:44,053] A3C_AGENT_WORKER-Thread-13 INFO:Local step 13000, global step 207817: loss 0.0383
[2019-03-26 14:42:44,056] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 13000, global step 207817: learning rate 0.0000
[2019-03-26 14:42:44,181] A3C_AGENT_WORKER-Thread-12 INFO:Local step 13000, global step 207878: loss 0.0171
[2019-03-26 14:42:44,185] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 13000, global step 207879: learning rate 0.0000
[2019-03-26 14:42:44,206] A3C_AGENT_WORKER-Thread-14 INFO:Local step 13000, global step 207889: loss 0.0238
[2019-03-26 14:42:44,208] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 13000, global step 207889: learning rate 0.0000
[2019-03-26 14:42:44,420] A3C_AGENT_WORKER-Thread-15 INFO:Local step 13000, global step 207993: loss 0.0970
[2019-03-26 14:42:44,421] A3C_AGENT_WORKER-Thread-2 INFO:Local step 13000, global step 207993: loss 0.0847
[2019-03-26 14:42:44,423] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 13000, global step 207993: learning rate 0.0000
[2019-03-26 14:42:44,425] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 13000, global step 207993: learning rate 0.0000
[2019-03-26 14:42:44,458] A3C_AGENT_WORKER-Thread-18 INFO:Local step 13000, global step 208013: loss 0.0548
[2019-03-26 14:42:44,463] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 13000, global step 208013: learning rate 0.0000
[2019-03-26 14:42:44,553] A3C_AGENT_WORKER-Thread-17 INFO:Local step 13000, global step 208059: loss 0.0465
[2019-03-26 14:42:44,554] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 13000, global step 208059: learning rate 0.0000
[2019-03-26 14:42:44,625] A3C_AGENT_WORKER-Thread-3 INFO:Local step 13000, global step 208087: loss 0.0330
[2019-03-26 14:42:44,629] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 13000, global step 208088: learning rate 0.0000
[2019-03-26 14:42:44,630] A3C_AGENT_WORKER-Thread-16 INFO:Local step 13000, global step 208089: loss 0.0342
[2019-03-26 14:42:44,637] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 13000, global step 208089: learning rate 0.0000
[2019-03-26 14:42:44,659] A3C_AGENT_WORKER-Thread-22 INFO:Local step 13000, global step 208103: loss 0.0396
[2019-03-26 14:42:44,661] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 13000, global step 208103: learning rate 0.0000
[2019-03-26 14:42:44,664] A3C_AGENT_WORKER-Thread-19 INFO:Local step 13000, global step 208104: loss 0.0451
[2019-03-26 14:42:44,669] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 13000, global step 208106: learning rate 0.0000
[2019-03-26 14:42:44,690] A3C_AGENT_WORKER-Thread-20 INFO:Local step 13000, global step 208118: loss 0.0533
[2019-03-26 14:42:44,693] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 13000, global step 208119: learning rate 0.0000
[2019-03-26 14:42:44,912] A3C_AGENT_WORKER-Thread-11 INFO:Local step 13000, global step 208220: loss 0.0260
[2019-03-26 14:42:44,914] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 13000, global step 208220: learning rate 0.0000
[2019-03-26 14:42:45,051] A3C_AGENT_WORKER-Thread-21 INFO:Local step 13000, global step 208285: loss 0.0574
[2019-03-26 14:42:45,054] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 13000, global step 208287: learning rate 0.0000
[2019-03-26 14:42:50,771] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.2157415e-12 1.0000000e+00 8.4040048e-14 5.7838540e-14 7.7145557e-17], sum to 1.0000
[2019-03-26 14:42:50,777] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5311
[2019-03-26 14:42:50,783] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1964143.718522305 W.
[2019-03-26 14:42:50,788] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.76666666666667, 72.0, 1.0, 2.0, 0.4682671273163177, 1.0, 2.0, 0.4682671273163177, 1.0, 1.0, 0.8085488045428022, 6.911200000000001, 6.9112, 170.5573041426782, 1964143.718522305, 1964143.718522304, 393111.5104850751], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7905000.0000, 
sim time next is 7905600.0000, 
raw observation next is [29.8, 72.0, 1.0, 2.0, 0.5092880632868733, 1.0, 2.0, 0.5092880632868733, 1.0, 2.0, 0.8807270590734045, 6.9112, 6.9112, 170.5573041426782, 2136377.361850936, 2136377.361850936, 420939.7645527912], 
processed observation next is [1.0, 0.5217391304347826, 0.6113744075829385, 0.72, 1.0, 1.0, 0.4087807991408111, 1.0, 1.0, 0.4087807991408111, 1.0, 1.0, 0.8545451939919566, 0.0, 0.0, 0.8375144448122397, 0.5934381560697044, 0.5934381560697044, 0.6282683053026734], 
reward next is 0.3717, 
noisyNet noise sample is [array([-0.28129035], dtype=float32), 0.8389564]. 
=============================================
[2019-03-26 14:42:52,685] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 14:42:52,687] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:42:52,729] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run2
[2019-03-26 14:42:53,174] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 14:42:53,174] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:42:53,176] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run2
[2019-03-26 14:42:53,412] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 14:42:53,412] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:42:53,414] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run2
[2019-03-26 14:42:53,560] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 14:42:53,560] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:42:53,562] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run2
[2019-03-26 14:42:53,584] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 14:42:53,584] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:42:53,586] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run2
[2019-03-26 14:42:53,713] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 14:42:53,713] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:42:53,714] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run2
[2019-03-26 14:42:53,733] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 14:42:53,733] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:42:53,735] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run2
[2019-03-26 14:42:53,776] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 14:42:53,776] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:42:53,777] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run2
[2019-03-26 14:42:53,817] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 14:42:53,817] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:42:53,818] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run2
[2019-03-26 14:42:53,834] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 14:42:53,836] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:42:53,837] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run2
[2019-03-26 14:42:53,861] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 14:42:53,861] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:42:53,862] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run2
[2019-03-26 14:42:53,879] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 14:42:53,879] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:42:53,881] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run2
[2019-03-26 14:42:53,900] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 14:42:53,901] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:42:53,902] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run2
[2019-03-26 14:42:53,917] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 14:42:53,917] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:42:53,919] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run2
[2019-03-26 14:42:53,942] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 14:42:53,942] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:42:53,944] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run2
[2019-03-26 14:42:53,963] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 14:42:53,963] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:42:53,965] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run2
[2019-03-26 14:43:03,155] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.9312702e-12 1.0000000e+00 2.3432709e-14 3.3293239e-17 7.1839974e-21], sum to 1.0000
[2019-03-26 14:43:03,158] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9103
[2019-03-26 14:43:03,165] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.96666666666667, 96.0, 1.0, 2.0, 0.2910544883419042, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 468160.597263258, 468160.5972632574, 164832.3844922244], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 181200.0000, 
sim time next is 181800.0000, 
raw observation next is [19.95, 96.0, 1.0, 2.0, 0.2897101704510642, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 466149.7125251241, 466149.7125251241, 164693.7541414512], 
processed observation next is [0.0, 0.08695652173913043, 0.14454976303317538, 0.96, 1.0, 1.0, 0.14422912102537852, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1294860312569789, 0.1294860312569789, 0.24581157334544956], 
reward next is 0.7542, 
noisyNet noise sample is [array([0.04018781], dtype=float32), 0.86938727]. 
=============================================
[2019-03-26 14:43:06,956] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.1284164e-12 1.0000000e+00 2.5309412e-14 2.3708618e-17 2.0600406e-21], sum to 1.0000
[2019-03-26 14:43:06,964] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9503
[2019-03-26 14:43:06,972] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.06666666666667, 94.66666666666667, 1.0, 2.0, 0.2870589814165657, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 462308.2144084498, 462308.2144084498, 164430.5828139944], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 195600.0000, 
sim time next is 196200.0000, 
raw observation next is [20.1, 94.5, 1.0, 2.0, 0.288313258333764, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 464202.8945721302, 464202.8945721308, 164560.2537644077], 
processed observation next is [0.0, 0.2608695652173913, 0.15165876777251197, 0.945, 1.0, 1.0, 0.14254609437802887, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12894524849225839, 0.12894524849225855, 0.24561231905135478], 
reward next is 0.7544, 
noisyNet noise sample is [array([0.21941566], dtype=float32), -0.4097534]. 
=============================================
[2019-03-26 14:43:07,825] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.8607168e-13 1.0000000e+00 3.9852909e-15 6.3460557e-19 1.2192906e-22], sum to 1.0000
[2019-03-26 14:43:07,836] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0641
[2019-03-26 14:43:07,841] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333333, 88.66666666666666, 1.0, 2.0, 0.3008194031433185, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 479127.6619617537, 479127.6619617537, 165560.8652732381], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 240000.0000, 
sim time next is 240600.0000, 
raw observation next is [21.31666666666667, 88.83333333333334, 1.0, 2.0, 0.3006929564937792, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 478882.1058054178, 478882.1058054178, 165542.645426857], 
processed observation next is [0.0, 0.782608695652174, 0.20932069510268583, 0.8883333333333334, 1.0, 1.0, 0.15746139336599901, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1330228071681716, 0.1330228071681716, 0.24707857526396565], 
reward next is 0.7529, 
noisyNet noise sample is [array([0.9769919], dtype=float32), 1.7841641]. 
=============================================
[2019-03-26 14:43:10,288] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0703305e-13 1.0000000e+00 3.1988648e-15 6.7748735e-20 2.6812369e-23], sum to 1.0000
[2019-03-26 14:43:10,288] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2628
[2019-03-26 14:43:10,375] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 91.83333333333333, 1.0, 2.0, 0.285225199115697, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 458494.5264729814, 458494.5264729809, 164168.3022195481], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 258600.0000, 
sim time next is 259200.0000, 
raw observation next is [20.5, 92.0, 1.0, 2.0, 0.2855877156481978, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 458898.6671830605, 458898.6671830605, 164194.8710287105], 
processed observation next is [0.0, 0.0, 0.1706161137440759, 0.92, 1.0, 1.0, 0.13926230800987685, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1274718519952946, 0.1274718519952946, 0.24506697168464256], 
reward next is 0.7549, 
noisyNet noise sample is [array([-0.044581], dtype=float32), 0.56525517]. 
=============================================
[2019-03-26 14:43:14,118] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.7170158e-12 1.0000000e+00 1.6118756e-14 2.1321047e-17 2.6875052e-22], sum to 1.0000
[2019-03-26 14:43:14,124] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7602
[2019-03-26 14:43:14,132] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.23333333333333, 80.83333333333333, 1.0, 2.0, 0.2636482956071631, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 434520.2358408161, 434520.2358408161, 162264.0863842669], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 457800.0000, 
sim time next is 458400.0000, 
raw observation next is [20.26666666666667, 80.66666666666667, 1.0, 2.0, 0.24365008911439, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 401497.8336004322, 401497.8336004322, 160269.8607273031], 
processed observation next is [1.0, 0.30434782608695654, 0.15955766192733034, 0.8066666666666668, 1.0, 1.0, 0.08873504712577109, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.11152717600012006, 0.11152717600012006, 0.23920874735418374], 
reward next is 0.7608, 
noisyNet noise sample is [array([-0.19615322], dtype=float32), 0.5327323]. 
=============================================
[2019-03-26 14:43:22,609] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-26 14:43:22,610] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 14:43:22,611] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 14:43:22,611] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:43:22,612] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:43:22,613] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 14:43:22,612] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 14:43:22,616] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:43:22,615] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 14:43:22,617] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:43:22,621] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:43:22,637] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run10
[2019-03-26 14:43:22,656] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run10
[2019-03-26 14:43:22,657] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run10
[2019-03-26 14:43:22,657] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run10
[2019-03-26 14:43:22,707] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run10
[2019-03-26 14:43:28,619] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.07768101], dtype=float32), 0.0736729]
[2019-03-26 14:43:28,620] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [19.20513355, 89.14597938666665, 1.0, 2.0, 0.2450979635743965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 404055.2560912651, 404055.2560912656, 160404.0866438207]
[2019-03-26 14:43:28,621] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 14:43:28,626] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.2514233e-13 1.0000000e+00 3.7494371e-15 1.4692677e-18 6.7175526e-23], sampled 0.9152505276547248
[2019-03-26 14:43:31,221] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.07768101], dtype=float32), 0.0736729]
[2019-03-26 14:43:31,222] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [24.56666666666666, 55.0, 1.0, 2.0, 0.633009382082244, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1039117.682835463, 1039117.682835462, 222885.9367263796]
[2019-03-26 14:43:31,223] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 14:43:31,224] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [7.8613833e-14 1.0000000e+00 1.1413085e-15 4.9893296e-19 1.6975241e-23], sampled 0.9597142901745641
[2019-03-26 14:43:36,949] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.07768101], dtype=float32), 0.0736729]
[2019-03-26 14:43:36,954] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [21.7, 83.33333333333334, 1.0, 2.0, 0.2953547423128546, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 473647.7973442443, 473647.7973442437, 165208.9065330052]
[2019-03-26 14:43:36,955] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 14:43:36,961] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.5947555e-13 1.0000000e+00 3.8589796e-15 1.4618154e-18 9.2370317e-23], sampled 0.455097048223997
[2019-03-26 14:43:44,523] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.07768101], dtype=float32), 0.0736729]
[2019-03-26 14:43:44,527] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.889946285, 50.36006824, 1.0, 2.0, 0.3150461046230862, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 498822.2105140382, 498822.2105140382, 166949.4894486347]
[2019-03-26 14:43:44,529] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 14:43:44,530] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [4.7221839e-14 1.0000000e+00 5.7975879e-16 1.2925197e-19 3.7505500e-24], sampled 0.3612857981145807
[2019-03-26 14:43:45,171] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.07768101], dtype=float32), 0.0736729]
[2019-03-26 14:43:45,174] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.2, 88.0, 1.0, 2.0, 0.3212464011813297, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 502674.9943207598, 502674.9943207592, 167100.9012685133]
[2019-03-26 14:43:45,176] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 14:43:45,178] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.8343995e-13 1.0000000e+00 3.0260144e-15 1.1383066e-18 4.9659072e-23], sampled 0.6683907277502058
[2019-03-26 14:44:00,250] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.07768101], dtype=float32), 0.0736729]
[2019-03-26 14:44:00,252] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.40628786, 75.66224463333333, 1.0, 2.0, 0.4436814040857646, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 645231.6357866392, 645231.6357866385, 178467.4292780809]
[2019-03-26 14:44:00,253] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 14:44:00,256] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [9.56302400e-15 1.00000000e+00 1.06563964e-16 2.06991188e-20
 3.76383411e-25], sampled 0.6332992707741546
[2019-03-26 14:44:02,129] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.07768101], dtype=float32), 0.0736729]
[2019-03-26 14:44:02,132] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [30.6, 71.66666666666667, 1.0, 2.0, 0.5711602251134483, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 798145.03214763, 798145.03214763, 195495.6728119502]
[2019-03-26 14:44:02,132] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 14:44:02,134] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.7520346e-15 1.0000000e+00 2.5043489e-17 4.2033243e-21 5.6488672e-26], sampled 0.7904164564697228
[2019-03-26 14:44:21,040] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.07768101], dtype=float32), 0.0736729]
[2019-03-26 14:44:21,041] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [33.51666666666667, 59.16666666666666, 1.0, 2.0, 0.5972392031961148, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 834602.3757683362, 834602.3757683357, 200231.5413024475]
[2019-03-26 14:44:21,043] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 14:44:21,047] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [5.7637860e-15 1.0000000e+00 3.9630620e-17 4.3227315e-20 1.3274800e-24], sampled 0.8198713903109615
[2019-03-26 14:44:21,902] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.07768101], dtype=float32), 0.0736729]
[2019-03-26 14:44:21,904] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [35.9, 56.0, 1.0, 2.0, 0.9641288829591252, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1347631.83052825, 1347631.83052825, 288194.1992714242]
[2019-03-26 14:44:21,906] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 14:44:21,908] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.7789452e-15 1.0000000e+00 3.6913597e-17 2.7796813e-20 3.8752018e-25], sampled 0.37988151060907427
[2019-03-26 14:44:22,693] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.07768101], dtype=float32), 0.0736729]
[2019-03-26 14:44:22,695] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.5, 79.0, 1.0, 2.0, 0.5790931509731452, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 809234.8052758601, 809234.8052758608, 196915.0371758368]
[2019-03-26 14:44:22,696] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 14:44:22,698] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.1099214e-15 1.0000000e+00 2.1681271e-17 3.8788478e-21 6.5519003e-26], sampled 0.8659087772179103
[2019-03-26 14:44:27,492] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.07768101], dtype=float32), 0.0736729]
[2019-03-26 14:44:27,492] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [33.6, 58.5, 1.0, 2.0, 0.6014945468853169, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 840551.2907763097, 840551.2907763091, 201023.0707011558]
[2019-03-26 14:44:27,492] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 14:44:27,495] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [9.4140046e-16 1.0000000e+00 7.2868474e-18 9.8925571e-22 1.0281230e-26], sampled 0.832402165909341
[2019-03-26 14:44:40,421] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.07768101], dtype=float32), 0.0736729]
[2019-03-26 14:44:40,423] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [34.73590706333334, 69.59950673, 1.0, 2.0, 0.7582563866701142, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 7.005979376422111, 6.9112, 168.9115055646427, 1956653.241564193, 1889414.067458858, 397839.1649927495]
[2019-03-26 14:44:40,424] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 14:44:40,427] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.8140234e-14 1.0000000e+00 2.2650220e-16 1.6162985e-19 7.2045144e-24], sampled 0.0981968001089275
[2019-03-26 14:44:40,427] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1956653.241564193 W.
[2019-03-26 14:44:42,153] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.07768101], dtype=float32), 0.0736729]
[2019-03-26 14:44:42,155] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.96666666666667, 78.5, 1.0, 2.0, 0.5822848562401479, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 813696.6579454262, 813696.6579454262, 197492.1938883586]
[2019-03-26 14:44:42,156] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 14:44:42,161] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.4850135e-15 1.0000000e+00 9.4836687e-18 3.1007087e-21 3.5874618e-26], sampled 0.7654549817016019
[2019-03-26 14:45:13,607] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.07768101], dtype=float32), 0.0736729]
[2019-03-26 14:45:13,609] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.86666666666667, 82.33333333333333, 1.0, 2.0, 0.5749060989682596, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 803381.5334703416, 803381.533470341, 196163.5253534449]
[2019-03-26 14:45:13,610] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 14:45:13,614] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [4.3662795e-15 1.0000000e+00 4.1428097e-17 1.1950200e-20 2.7857782e-25], sampled 0.3058281875343549
[2019-03-26 14:45:16,435] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.7167 2779131942.0695 933.0000
[2019-03-26 14:45:17,062] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.9164 3164002230.9074 1778.0000
[2019-03-26 14:45:17,093] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.5588 3007666311.2491 1766.0000
[2019-03-26 14:45:17,105] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.6119 2842427357.4275 1131.0000
[2019-03-26 14:45:17,163] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.6679 2927328479.9021 1338.0000
[2019-03-26 14:45:18,177] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 225000, evaluation results [225000.0, 7884.916440885027, 3164002230.907359, 1778.0, 8253.667895353341, 2927328479.9020863, 1338.0, 8660.716715102415, 2779131942.069542, 933.0, 7997.558800637214, 3007666311.249115, 1766.0, 8497.61193292354, 2842427357.427519, 1131.0]
[2019-03-26 14:45:25,827] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.2262875e-14 1.0000000e+00 2.5217111e-16 2.0181952e-19 2.2959736e-24], sum to 1.0000
[2019-03-26 14:45:25,833] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0109
[2019-03-26 14:45:25,840] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.26666666666667, 86.0, 1.0, 2.0, 0.2169482358025774, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 361651.4476100616, 361651.4476100621, 157256.6847639962], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 603600.0000, 
sim time next is 604200.0000, 
raw observation next is [18.18333333333334, 86.5, 1.0, 2.0, 0.2164753084279003, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 360915.5059647441, 360915.5059647434, 157198.1531305439], 
processed observation next is [1.0, 1.0, 0.060821484992101514, 0.865, 1.0, 1.0, 0.05599434750349433, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.10025430721242891, 0.10025430721242871, 0.23462410915006554], 
reward next is 0.7654, 
noisyNet noise sample is [array([1.8621709], dtype=float32), -1.1239538]. 
=============================================
[2019-03-26 14:45:34,140] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.0682698e-14 1.0000000e+00 3.9478975e-17 1.5230649e-19 5.9294600e-24], sum to 1.0000
[2019-03-26 14:45:34,150] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5668
[2019-03-26 14:45:34,158] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.01666666666667, 77.16666666666667, 1.0, 2.0, 0.2526953037791749, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 415038.7934701332, 415038.7934701332, 161177.4105638153], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 762600.0000, 
sim time next is 763200.0000, 
raw observation next is [20.8, 79.0, 1.0, 2.0, 0.2538892108566228, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 416831.1548951771, 416831.1548951764, 161296.7499757389], 
processed observation next is [1.0, 0.8695652173913043, 0.1848341232227489, 0.79, 1.0, 1.0, 0.10107133838147325, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11578643191532698, 0.11578643191532678, 0.24074141787423717], 
reward next is 0.7593, 
noisyNet noise sample is [array([0.38976294], dtype=float32), -1.3404564]. 
=============================================
[2019-03-26 14:45:40,395] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.2593789e-15 1.0000000e+00 2.8200593e-16 7.0550810e-20 3.4971488e-25], sum to 1.0000
[2019-03-26 14:45:40,405] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7667
[2019-03-26 14:45:40,408] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.76666666666667, 86.5, 1.0, 2.0, 0.30570397604334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 485300.621686416, 485300.6216864154, 165978.5317422042], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 857400.0000, 
sim time next is 858000.0000, 
raw observation next is [21.73333333333333, 87.0, 1.0, 2.0, 0.3062337674882957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 485812.4309306119, 485812.4309306126, 166009.607308925], 
processed observation next is [0.0, 0.9565217391304348, 0.22906793048973137, 0.87, 1.0, 1.0, 0.1641370692630069, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13494789748072553, 0.13494789748072572, 0.247775533296903], 
reward next is 0.7522, 
noisyNet noise sample is [array([0.37069336], dtype=float32), 0.0068488806]. 
=============================================
[2019-03-26 14:45:40,435] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[81.836815]
 [81.77093 ]
 [81.72427 ]
 [81.680336]
 [81.63163 ]], R is [[81.82006073]
 [81.75413513]
 [81.68898773]
 [81.62471008]
 [81.56123352]].
[2019-03-26 14:45:42,787] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.0491526e-13 1.0000000e+00 7.2554598e-15 1.1693664e-18 1.8820079e-23], sum to 1.0000
[2019-03-26 14:45:42,794] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0996
[2019-03-26 14:45:42,801] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.1, 80.33333333333334, 1.0, 2.0, 0.2853998061894472, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 457698.5425917103, 457698.5425917097, 164106.6389629345], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 890400.0000, 
sim time next is 891000.0000, 
raw observation next is [22.2, 80.0, 1.0, 2.0, 0.287250080838597, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 460179.4505003898, 460179.4505003898, 164271.1997131335], 
processed observation next is [0.0, 0.30434782608695654, 0.2511848341232228, 0.8, 1.0, 1.0, 0.14126515763686384, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.12782762513899718, 0.12782762513899718, 0.2451808950942291], 
reward next is 0.7548, 
noisyNet noise sample is [array([-1.2457336], dtype=float32), 1.156154]. 
=============================================
[2019-03-26 14:45:42,818] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[76.21496 ]
 [76.19183 ]
 [76.153435]
 [76.13326 ]
 [76.11458 ]], R is [[76.23868561]
 [76.23136902]
 [76.22426605]
 [76.21734619]
 [76.21051788]].
[2019-03-26 14:45:43,872] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.2332124e-13 1.0000000e+00 9.1759206e-16 3.9013782e-19 7.3988377e-24], sum to 1.0000
[2019-03-26 14:45:43,884] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3952
[2019-03-26 14:45:43,892] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666667, 77.33333333333333, 1.0, 2.0, 0.3232193547300174, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 505436.0950720437, 505436.095072043, 167302.1162418337], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 928200.0000, 
sim time next is 928800.0000, 
raw observation next is [23.6, 78.0, 1.0, 2.0, 0.3240325173460962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 506330.6217864238, 506330.6217864231, 167360.0045710331], 
processed observation next is [0.0, 0.782608695652174, 0.3175355450236968, 0.78, 1.0, 1.0, 0.18558134620011593, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14064739494067327, 0.14064739494067308, 0.24979105159855686], 
reward next is 0.7502, 
noisyNet noise sample is [array([-0.54506767], dtype=float32), -1.1082567]. 
=============================================
[2019-03-26 14:45:45,467] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.6665993e-14 1.0000000e+00 3.7381364e-17 4.3694843e-20 3.3431314e-25], sum to 1.0000
[2019-03-26 14:45:45,476] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8463
[2019-03-26 14:45:45,481] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.85, 93.66666666666667, 1.0, 2.0, 0.3388323423950056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 524726.7692014374, 524726.7692014374, 168662.9569256562], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 946200.0000, 
sim time next is 946800.0000, 
raw observation next is [21.8, 94.0, 1.0, 2.0, 0.3380691997389883, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 523681.2813667222, 523681.2813667222, 168583.7487958096], 
processed observation next is [0.0, 1.0, 0.23222748815165886, 0.94, 1.0, 1.0, 0.20249301173372083, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14546702260186728, 0.14546702260186728, 0.25161753551613375], 
reward next is 0.7484, 
noisyNet noise sample is [array([-1.0301325], dtype=float32), -1.052533]. 
=============================================
[2019-03-26 14:45:49,354] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.4503450e-15 1.0000000e+00 1.1214511e-16 1.7432999e-20 1.0698592e-24], sum to 1.0000
[2019-03-26 14:45:49,361] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2585
[2019-03-26 14:45:49,369] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 96.0, 1.0, 2.0, 0.5202789958299762, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 804925.5168352509, 804925.5168352509, 196103.687232592], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1003800.0000, 
sim time next is 1004400.0000, 
raw observation next is [21.6, 96.0, 1.0, 2.0, 0.6037050698019224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 934008.8718070281, 934008.8718070281, 212330.1906743973], 
processed observation next is [1.0, 0.6521739130434783, 0.22274881516587688, 0.96, 1.0, 1.0, 0.5225362286770149, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2594469088352856, 0.2594469088352856, 0.31691073234984674], 
reward next is 0.6831, 
noisyNet noise sample is [array([-1.0796679], dtype=float32), 0.17560406]. 
=============================================
[2019-03-26 14:45:50,529] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.2426943e-14 1.0000000e+00 8.6598551e-17 4.5986460e-20 3.8081885e-24], sum to 1.0000
[2019-03-26 14:45:50,539] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0946
[2019-03-26 14:45:50,543] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.96666666666667, 97.66666666666666, 1.0, 2.0, 0.3647809916978575, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 555219.2460212935, 555219.2460212935, 170890.4417163264], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1032000.0000, 
sim time next is 1032600.0000, 
raw observation next is [21.98333333333333, 97.83333333333334, 1.0, 2.0, 0.3643513155949491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 553924.9319534462, 553924.9319534457, 170759.8298645259], 
processed observation next is [1.0, 0.9565217391304348, 0.24091627172195884, 0.9783333333333334, 1.0, 1.0, 0.23415821156017963, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15386803665373508, 0.1538680366537349, 0.2548654177082476], 
reward next is 0.7451, 
noisyNet noise sample is [array([0.04759987], dtype=float32), -0.2790387]. 
=============================================
[2019-03-26 14:45:52,363] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.5442184e-13 1.0000000e+00 5.0059234e-16 1.3255511e-18 3.2144131e-22], sum to 1.0000
[2019-03-26 14:45:52,371] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8416
[2019-03-26 14:45:52,380] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.6, 96.0, 1.0, 2.0, 0.3138780027763934, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 497627.6762690705, 497627.6762690711, 166872.076501545], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1052400.0000, 
sim time next is 1053000.0000, 
raw observation next is [20.45, 96.0, 1.0, 2.0, 0.3037749950522163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 483253.8769236712, 483253.8769236712, 165847.8171561614], 
processed observation next is [1.0, 0.17391304347826086, 0.16824644549763035, 0.96, 1.0, 1.0, 0.16117469283399552, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1342371880343531, 0.1342371880343531, 0.24753405545695734], 
reward next is 0.7525, 
noisyNet noise sample is [array([1.4617281], dtype=float32), -1.520623]. 
=============================================
[2019-03-26 14:45:52,404] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[76.442986]
 [76.46866 ]
 [76.54376 ]
 [76.58464 ]
 [76.6602  ]], R is [[76.29566956]
 [76.28365326]
 [76.26573181]
 [76.25383759]
 [76.24143982]].
[2019-03-26 14:45:52,870] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.9763551e-14 1.0000000e+00 5.7265039e-16 6.3508994e-19 1.7549606e-23], sum to 1.0000
[2019-03-26 14:45:52,878] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5352
[2019-03-26 14:45:52,888] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.4, 80.66666666666667, 1.0, 2.0, 0.5576904688059529, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 887560.08459213, 887560.0845921306, 205384.0907203791], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1075200.0000, 
sim time next is 1075800.0000, 
raw observation next is [22.5, 79.83333333333334, 1.0, 2.0, 0.5622992693613524, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 895154.3881350044, 895154.3881350044, 206318.6851149811], 
processed observation next is [1.0, 0.43478260869565216, 0.2654028436018958, 0.7983333333333335, 1.0, 1.0, 0.47264972212211137, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2486539967041679, 0.2486539967041679, 0.30793833599250914], 
reward next is 0.6921, 
noisyNet noise sample is [array([0.05960787], dtype=float32), 1.0283651]. 
=============================================
[2019-03-26 14:45:54,113] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.9405765e-15 1.0000000e+00 7.4117137e-18 1.9128298e-20 1.1643242e-24], sum to 1.0000
[2019-03-26 14:45:54,121] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0037
[2019-03-26 14:45:54,126] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.4, 68.5, 1.0, 2.0, 0.3274634663966315, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 507092.6825191187, 507092.6825191187, 167277.5082861377], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1099800.0000, 
sim time next is 1100400.0000, 
raw observation next is [25.26666666666667, 69.0, 1.0, 2.0, 0.3304070660160498, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 512324.9343247216, 512324.9343247223, 167705.3275194789], 
processed observation next is [1.0, 0.7391304347826086, 0.3965244865718801, 0.69, 1.0, 1.0, 0.19326152532054192, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14231248175686712, 0.1423124817568673, 0.2503064589842968], 
reward next is 0.7497, 
noisyNet noise sample is [array([1.781054], dtype=float32), 0.25032967]. 
=============================================
[2019-03-26 14:45:54,490] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.5542289e-14 1.0000000e+00 6.7504794e-17 3.5809922e-20 3.1278838e-25], sum to 1.0000
[2019-03-26 14:45:54,499] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4927
[2019-03-26 14:45:54,506] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.46666666666667, 72.0, 1.0, 2.0, 0.3296099892819256, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 515132.1048108037, 515132.1048108043, 168041.358064677], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1104000.0000, 
sim time next is 1104600.0000, 
raw observation next is [24.33333333333334, 72.5, 1.0, 2.0, 0.3301714180145942, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 516698.9302897274, 516698.9302897268, 168180.979037402], 
processed observation next is [1.0, 0.782608695652174, 0.35229067930489766, 0.725, 1.0, 1.0, 0.19297761206577616, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14352748063603538, 0.14352748063603524, 0.25101638662298803], 
reward next is 0.7490, 
noisyNet noise sample is [array([-1.4151251], dtype=float32), 0.0908682]. 
=============================================
[2019-03-26 14:45:58,417] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.8073495e-16 1.0000000e+00 1.4370564e-18 3.6096130e-21 2.6702094e-26], sum to 1.0000
[2019-03-26 14:45:58,426] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5699
[2019-03-26 14:45:58,433] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.6, 59.66666666666666, 1.0, 2.0, 0.9932054985899973, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1511620.455253242, 1511620.455253242, 315129.8249189805], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1176000.0000, 
sim time next is 1176600.0000, 
raw observation next is [27.6, 59.33333333333334, 1.0, 2.0, 0.9917971786540183, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1512080.254822638, 1512080.254822638, 315012.3284870182], 
processed observation next is [1.0, 0.6086956521739131, 0.5071090047393366, 0.5933333333333334, 1.0, 1.0, 0.9901170827156847, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.4200222930062883, 0.4200222930062883, 0.4701676544582361], 
reward next is 0.5298, 
noisyNet noise sample is [array([-0.10786696], dtype=float32), -0.999676]. 
=============================================
[2019-03-26 14:46:00,316] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.9137513e-14 1.0000000e+00 5.1391612e-16 1.8134653e-19 6.0451888e-23], sum to 1.0000
[2019-03-26 14:46:00,324] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9325
[2019-03-26 14:46:00,330] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.2, 78.0, 1.0, 2.0, 0.3582388996383469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 551037.1222666402, 551037.1222666402, 170710.5296477101], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1198800.0000, 
sim time next is 1199400.0000, 
raw observation next is [24.08333333333334, 78.66666666666667, 1.0, 2.0, 0.358055639261249, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 550841.4673749172, 550841.4673749172, 170696.5097147721], 
processed observation next is [1.0, 0.9130434782608695, 0.34044233807267016, 0.7866666666666667, 1.0, 1.0, 0.2265730593509024, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15301151871525479, 0.15301151871525479, 0.25477091002204794], 
reward next is 0.7452, 
noisyNet noise sample is [array([-0.5600334], dtype=float32), 0.53555185]. 
=============================================
[2019-03-26 14:46:00,996] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.7521840e-15 1.0000000e+00 4.0521712e-17 3.2425467e-19 6.2165340e-24], sum to 1.0000
[2019-03-26 14:46:01,009] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6822
[2019-03-26 14:46:01,016] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 87.66666666666667, 1.0, 2.0, 0.3536174830784391, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 546127.3581518098, 546127.3581518098, 170362.154002153], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1208400.0000, 
sim time next is 1209000.0000, 
raw observation next is [22.65, 87.83333333333334, 1.0, 2.0, 0.3526292549418842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 545029.5503396417, 545029.5503396412, 170282.855050377], 
processed observation next is [1.0, 1.0, 0.2725118483412322, 0.8783333333333334, 1.0, 1.0, 0.22003524691793275, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15139709731656714, 0.151397097316567, 0.25415351500056266], 
reward next is 0.7458, 
noisyNet noise sample is [array([1.8524613], dtype=float32), 0.36042178]. 
=============================================
[2019-03-26 14:46:01,025] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[76.43795]
 [76.3771 ]
 [76.31282]
 [76.25419]
 [76.17715]], R is [[76.47460938]
 [76.45558929]
 [76.43725586]
 [76.41862488]
 [76.39997864]].
[2019-03-26 14:46:12,416] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-26 14:46:12,417] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 14:46:12,419] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 14:46:12,420] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 14:46:12,420] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:46:12,422] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 14:46:12,422] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:46:12,424] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 14:46:12,426] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:46:12,429] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:46:12,424] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:46:12,443] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run11
[2019-03-26 14:46:12,461] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run11
[2019-03-26 14:46:12,462] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run11
[2019-03-26 14:46:12,493] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run11
[2019-03-26 14:46:12,493] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run11
[2019-03-26 14:46:35,300] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.07494228], dtype=float32), 0.07132951]
[2019-03-26 14:46:35,301] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [23.78333333333333, 93.0, 1.0, 2.0, 0.5805537141125687, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 845239.3399023708, 845239.3399023708, 201495.8420055374]
[2019-03-26 14:46:35,302] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 14:46:35,304] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.1575615e-14 1.0000000e+00 2.2890915e-16 1.1321524e-19 3.8339737e-24], sampled 0.47689516738146054
[2019-03-26 14:46:44,795] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.07494228], dtype=float32), 0.07132951]
[2019-03-26 14:46:44,797] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.40984834833333, 88.65309355333332, 1.0, 2.0, 0.7444308104901066, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.991668943722855, 6.9112, 168.9124169156171, 1937305.047109113, 1880217.791271441, 395120.0001546913]
[2019-03-26 14:46:44,798] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 14:46:44,802] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.16834895e-12 1.00000000e+00 1.11315384e-14 1.23157452e-16
 4.35208381e-20], sampled 0.7930755295972525
[2019-03-26 14:46:44,803] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1937305.047109113 W.
[2019-03-26 14:46:59,141] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.07494228], dtype=float32), 0.07132951]
[2019-03-26 14:46:59,142] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [31.05, 61.5, 1.0, 2.0, 0.5259104711299625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 734890.6977858727, 734890.6977858722, 187754.5643587696]
[2019-03-26 14:46:59,144] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 14:46:59,147] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.1790214e-14 1.0000000e+00 1.0825821e-16 3.9140022e-20 1.0274968e-24], sampled 0.7816044574701276
[2019-03-26 14:47:27,972] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.07494228], dtype=float32), 0.07132951]
[2019-03-26 14:47:27,973] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.29851371666667, 69.427973355, 1.0, 2.0, 0.5060044257386099, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 707065.360428796, 707065.360428796, 184542.2821352733]
[2019-03-26 14:47:27,977] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 14:47:27,980] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.5248826e-14 1.0000000e+00 1.2657729e-16 5.6909309e-20 2.0335223e-24], sampled 0.24489886975498065
[2019-03-26 14:47:38,000] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.07494228], dtype=float32), 0.07132951]
[2019-03-26 14:47:38,001] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [30.12141320166667, 83.40315154166667, 1.0, 2.0, 0.9503350503601765, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005990701141396, 6.9112, 168.9123159437383, 2225488.856965184, 2158241.326154343, 448405.8512491074]
[2019-03-26 14:47:38,002] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 14:47:38,004] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.2694767e-14 1.0000000e+00 3.0126521e-16 9.3951195e-19 6.2320895e-23], sampled 0.04340036588189833
[2019-03-26 14:47:38,005] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2225488.856965184 W.
[2019-03-26 14:47:52,721] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.07494228], dtype=float32), 0.07132951]
[2019-03-26 14:47:52,722] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.2, 70.33333333333334, 1.0, 2.0, 0.5218430860897018, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 729205.1114161616, 729205.1114161616, 187088.3936533613]
[2019-03-26 14:47:52,724] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 14:47:52,728] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.0702705e-14 1.0000000e+00 3.2582864e-16 1.1574586e-19 3.9407665e-24], sampled 0.012028046800123593
[2019-03-26 14:47:58,630] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.07494228], dtype=float32), 0.07132951]
[2019-03-26 14:47:58,631] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [20.71755109333333, 86.17511735333333, 1.0, 2.0, 0.2884316022616115, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 466949.4701657282, 466949.4701657288, 164734.9349271431]
[2019-03-26 14:47:58,632] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 14:47:58,634] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [4.8514057e-13 1.0000000e+00 8.2964963e-15 5.7406492e-18 4.1225414e-22], sampled 0.5108276213410633
[2019-03-26 14:48:02,184] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.07494228], dtype=float32), 0.07132951]
[2019-03-26 14:48:02,186] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.35538332333333, 59.09235037000001, 1.0, 2.0, 0.6240207454619748, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 925739.0202706448, 925739.0202706448, 212115.79796741]
[2019-03-26 14:48:02,188] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 14:48:02,191] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.5105127e-14 1.0000000e+00 2.6669449e-16 1.4477080e-19 5.3684608e-24], sampled 0.32127935866119894
[2019-03-26 14:48:06,549] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.9878 2779131868.1217 933.0000
[2019-03-26 14:48:06,729] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.3130 3007656030.3370 1766.0000
[2019-03-26 14:48:06,869] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.5144 2842492707.2201 1131.0000
[2019-03-26 14:48:06,875] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.6842 2927317744.9770 1338.0000
[2019-03-26 14:48:06,896] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.9164 3164002230.9074 1778.0000
[2019-03-26 14:48:07,912] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 250000, evaluation results [250000.0, 7884.916440885027, 3164002230.907359, 1778.0, 8253.684239900658, 2927317744.977035, 1338.0, 8659.98775396918, 2779131868.121704, 933.0, 7998.312951428424, 3007656030.3370423, 1766.0, 8497.514395919725, 2842492707.2200756, 1131.0]
[2019-03-26 14:48:13,731] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.76465448e-14 1.00000000e+00 2.85010308e-16 3.08968244e-20
 1.17130935e-24], sum to 1.0000
[2019-03-26 14:48:13,738] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8975
[2019-03-26 14:48:13,743] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.1, 91.0, 1.0, 2.0, 0.3421657492197361, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 531002.4731346571, 531002.4731346571, 169197.6043721182], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1551600.0000, 
sim time next is 1552200.0000, 
raw observation next is [22.06666666666667, 91.00000000000001, 1.0, 2.0, 0.3411531859773741, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 529851.4239202309, 529851.4239202302, 169116.6463757893], 
processed observation next is [0.0, 1.0, 0.2448657187993683, 0.9100000000000001, 1.0, 1.0, 0.20620865780406517, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14718095108895304, 0.14718095108895285, 0.2524129050384915], 
reward next is 0.7476, 
noisyNet noise sample is [array([-0.04324618], dtype=float32), -0.6411547]. 
=============================================
[2019-03-26 14:48:15,840] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.9234445e-16 1.0000000e+00 7.8351156e-17 4.0272930e-20 5.5171088e-25], sum to 1.0000
[2019-03-26 14:48:15,847] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9447
[2019-03-26 14:48:15,852] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.96666666666667, 91.0, 1.0, 2.0, 0.3377897578458568, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 526031.0911237993, 526031.0911237986, 168849.4054492384], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1554000.0000, 
sim time next is 1554600.0000, 
raw observation next is [21.93333333333333, 91.0, 1.0, 2.0, 0.3364177975018898, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 524356.4498101684, 524356.4498101678, 168728.6747441574], 
processed observation next is [0.0, 1.0, 0.23854660347551332, 0.91, 1.0, 1.0, 0.2005033704842046, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14565456939171342, 0.14565456939171328, 0.2518338429017275], 
reward next is 0.7482, 
noisyNet noise sample is [array([0.67313147], dtype=float32), 1.2875513]. 
=============================================
[2019-03-26 14:48:31,365] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.5394972e-14 1.0000000e+00 3.6259072e-16 3.0063120e-18 9.8078571e-23], sum to 1.0000
[2019-03-26 14:48:31,377] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5883
[2019-03-26 14:48:31,381] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.13333333333333, 91.33333333333334, 1.0, 2.0, 0.8218425929990477, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1191510.566723731, 1191510.566723732, 255367.1571649751], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1848000.0000, 
sim time next is 1848600.0000, 
raw observation next is [24.25, 91.0, 1.0, 2.0, 0.8637238646207229, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1248636.462475907, 1248636.462475906, 266115.14753887], 
processed observation next is [1.0, 0.391304347826087, 0.3483412322274882, 0.91, 1.0, 1.0, 0.8358118850852083, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.34684346179886305, 0.3468434617988628, 0.39718678737144775], 
reward next is 0.6028, 
noisyNet noise sample is [array([0.17940193], dtype=float32), 0.09436907]. 
=============================================
[2019-03-26 14:48:32,055] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.4266008e-12 1.0000000e+00 1.6475055e-14 8.8876636e-18 8.9089957e-22], sum to 1.0000
[2019-03-26 14:48:32,063] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6715
[2019-03-26 14:48:32,069] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.31666666666667, 91.66666666666667, 1.0, 2.0, 0.4840337286073762, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 722343.5373102932, 722343.5373102926, 186838.6230784724], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1840200.0000, 
sim time next is 1840800.0000, 
raw observation next is [23.43333333333333, 91.33333333333334, 1.0, 2.0, 0.4285184590579332, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 637823.9111242497, 637823.9111242504, 178076.8735267251], 
processed observation next is [1.0, 0.30434782608695654, 0.30963665086887826, 0.9133333333333334, 1.0, 1.0, 0.3114680229613652, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17717330864562492, 0.1771733086456251, 0.26578637839809716], 
reward next is 0.7342, 
noisyNet noise sample is [array([0.14784937], dtype=float32), 1.6262308]. 
=============================================
[2019-03-26 14:48:33,536] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.5764265e-15 1.0000000e+00 2.6990408e-16 2.7741849e-19 5.5049392e-24], sum to 1.0000
[2019-03-26 14:48:33,544] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8275
[2019-03-26 14:48:33,549] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 98.0, 1.0, 2.0, 0.4427695656611675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 636530.7489122464, 636530.7489122457, 177409.2802272631], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1983600.0000, 
sim time next is 1984200.0000, 
raw observation next is [23.56666666666667, 97.83333333333334, 1.0, 2.0, 0.4458249436070488, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 639476.8617077165, 639476.8617077158, 177668.092980041], 
processed observation next is [1.0, 1.0, 0.31595576619273325, 0.9783333333333334, 1.0, 1.0, 0.33231920916511903, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1776324615854768, 0.1776324615854766, 0.2651762581791657], 
reward next is 0.7348, 
noisyNet noise sample is [array([-0.902614], dtype=float32), 0.65250546]. 
=============================================
[2019-03-26 14:48:36,643] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.0480723e-13 1.0000000e+00 9.3005668e-16 2.0978235e-18 1.7903875e-22], sum to 1.0000
[2019-03-26 14:48:36,656] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3522
[2019-03-26 14:48:36,660] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 83.0, 1.0, 2.0, 0.4865390156703512, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 698938.4954897553, 698938.4954897553, 183945.1048319371], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1929600.0000, 
sim time next is 1930200.0000, 
raw observation next is [25.55, 82.83333333333334, 1.0, 2.0, 0.5465004769424989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 784310.8514507177, 784310.8514507182, 193833.0144228241], 
processed observation next is [1.0, 0.34782608695652173, 0.40995260663507116, 0.8283333333333335, 1.0, 1.0, 0.45361503246084206, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21786412540297712, 0.21786412540297728, 0.28930300660123004], 
reward next is 0.7107, 
noisyNet noise sample is [array([-0.34793562], dtype=float32), 0.68100655]. 
=============================================
[2019-03-26 14:48:37,184] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.5693081e-14 1.0000000e+00 1.8295895e-15 1.2473944e-17 9.2702885e-22], sum to 1.0000
[2019-03-26 14:48:37,195] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2409
[2019-03-26 14:48:37,200] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.03333333333333, 85.66666666666667, 1.0, 2.0, 0.4394978405363881, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 633579.5679291823, 633579.5679291817, 177160.6749761763], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1927200.0000, 
sim time next is 1927800.0000, 
raw observation next is [25.15, 85.0, 1.0, 2.0, 0.4617548412313747, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 665063.6750821503, 665063.6750821503, 180356.1605871358], 
processed observation next is [1.0, 0.30434782608695654, 0.3909952606635071, 0.85, 1.0, 1.0, 0.3515118569052708, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18473990974504173, 0.18473990974504173, 0.26918829938378475], 
reward next is 0.7308, 
noisyNet noise sample is [array([0.04941906], dtype=float32), 1.39228]. 
=============================================
[2019-03-26 14:48:44,592] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.366007e-15 1.000000e+00 2.765840e-17 8.548282e-20 8.841579e-24], sum to 1.0000
[2019-03-26 14:48:44,604] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1813
[2019-03-26 14:48:44,610] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.96666666666667, 91.66666666666666, 1.0, 2.0, 0.4765954530357104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 665957.8466101834, 665957.8466101841, 180009.9954166866], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2065200.0000, 
sim time next is 2065800.0000, 
raw observation next is [24.93333333333333, 91.83333333333333, 1.0, 2.0, 0.476418763859153, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 665710.8773785756, 665710.8773785762, 179983.5260085615], 
processed observation next is [0.0, 0.9130434782608695, 0.38072669826224315, 0.9183333333333333, 1.0, 1.0, 0.3691792335652446, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18491968816071544, 0.1849196881607156, 0.26863212837098727], 
reward next is 0.7314, 
noisyNet noise sample is [array([1.5153265], dtype=float32), -1.1086326]. 
=============================================
[2019-03-26 14:48:45,857] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0967314e-12 1.0000000e+00 2.1087063e-15 1.1507190e-18 4.2215123e-22], sum to 1.0000
[2019-03-26 14:48:45,868] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9103
[2019-03-26 14:48:45,872] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.7, 87.33333333333334, 1.0, 2.0, 0.5081910074468077, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 710121.8019849282, 710121.8019849276, 184889.9440347315], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2103600.0000, 
sim time next is 2104200.0000, 
raw observation next is [26.9, 86.5, 1.0, 2.0, 0.5107083068985722, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 713640.5373868372, 713640.5373868379, 185291.4615950815], 
processed observation next is [0.0, 0.34782608695652173, 0.4739336492890995, 0.865, 1.0, 1.0, 0.41049193602237605, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19823348260745477, 0.19823348260745496, 0.2765544202911664], 
reward next is 0.7234, 
noisyNet noise sample is [array([0.144827], dtype=float32), 0.522592]. 
=============================================
[2019-03-26 14:48:46,344] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.2317127e-15 1.0000000e+00 3.2714116e-17 3.8254938e-20 3.7793312e-24], sum to 1.0000
[2019-03-26 14:48:46,349] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5109
[2019-03-26 14:48:46,353] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.7, 77.0, 1.0, 2.0, 0.5650146126120394, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 789553.8996732334, 789553.8996732334, 194409.2909536631], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2138400.0000, 
sim time next is 2139000.0000, 
raw observation next is [29.53333333333333, 77.83333333333334, 1.0, 2.0, 0.5632618569419116, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 787103.6837038591, 787103.6837038591, 194101.4101277471], 
processed observation next is [0.0, 0.782608695652174, 0.598736176935229, 0.7783333333333334, 1.0, 1.0, 0.47380946619507414, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21863991213996087, 0.21863991213996087, 0.2897035972055927], 
reward next is 0.7103, 
noisyNet noise sample is [array([1.2125186], dtype=float32), 0.3371393]. 
=============================================
[2019-03-26 14:48:46,368] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[77.09189 ]
 [77.067535]
 [77.04292 ]
 [77.01671 ]
 [76.98469 ]], R is [[77.07086945]
 [77.01000214]
 [76.94965363]
 [76.88970184]
 [76.82976532]].
[2019-03-26 14:48:46,845] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.2462781e-14 1.0000000e+00 1.0327593e-15 1.9487136e-19 1.7859459e-23], sum to 1.0000
[2019-03-26 14:48:46,856] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2897
[2019-03-26 14:48:46,862] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.6, 75.66666666666666, 1.0, 2.0, 0.5443626739206694, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 760684.4562303623, 760684.4562303616, 190839.4769303292], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2112000.0000, 
sim time next is 2112600.0000, 
raw observation next is [29.8, 74.83333333333334, 1.0, 2.0, 0.5460826286472423, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 763088.7591808831, 763088.7591808836, 191132.0399709794], 
processed observation next is [0.0, 0.43478260869565216, 0.6113744075829385, 0.7483333333333334, 1.0, 1.0, 0.45311160077981, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21196909977246753, 0.21196909977246767, 0.285271701449223], 
reward next is 0.7147, 
noisyNet noise sample is [array([0.09429675], dtype=float32), 0.8464491]. 
=============================================
[2019-03-26 14:48:50,298] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.1032054e-13 1.0000000e+00 3.3647947e-16 6.2716436e-19 8.5111106e-23], sum to 1.0000
[2019-03-26 14:48:50,305] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2709
[2019-03-26 14:48:50,310] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.25, 94.16666666666667, 1.0, 2.0, 1.030350846668959, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1440257.792198818, 1440257.792198818, 308307.3099489983], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2167800.0000, 
sim time next is 2168400.0000, 
raw observation next is [25.2, 94.33333333333334, 1.0, 2.0, 1.001253187031836, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1399557.328591492, 1399557.328591492, 299305.3428096813], 
processed observation next is [1.0, 0.08695652173913043, 0.3933649289099526, 0.9433333333333335, 1.0, 1.0, 1.0015098638937783, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.38876592460874776, 0.38876592460874776, 0.4467243922532557], 
reward next is 0.5533, 
noisyNet noise sample is [array([-0.70071644], dtype=float32), 0.35909125]. 
=============================================
[2019-03-26 14:48:51,081] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.5700522e-13 1.0000000e+00 1.5717632e-15 2.1418531e-18 1.6077125e-21], sum to 1.0000
[2019-03-26 14:48:51,089] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6791
[2019-03-26 14:48:51,095] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.2, 90.33333333333334, 1.0, 2.0, 0.6942852340193061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 970279.7476539674, 970279.7476539667, 219615.0888536948], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2182800.0000, 
sim time next is 2183400.0000, 
raw observation next is [26.4, 89.5, 1.0, 2.0, 0.7177656982018268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1003109.739681735, 1003109.739681735, 224725.4000877046], 
processed observation next is [1.0, 0.2608695652173913, 0.45023696682464454, 0.895, 1.0, 1.0, 0.6599586725323214, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2786415943560375, 0.2786415943560375, 0.3354110449070218], 
reward next is 0.6646, 
noisyNet noise sample is [array([-0.95716214], dtype=float32), -0.23512249]. 
=============================================
[2019-03-26 14:48:52,799] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.3734851e-12 1.0000000e+00 1.6088408e-14 1.2133055e-14 1.9721227e-17], sum to 1.0000
[2019-03-26 14:48:52,805] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8672
[2019-03-26 14:48:52,811] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.46666666666667, 69.33333333333334, 1.0, 2.0, 0.5354434108178041, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.9129565104265, 748216.418474874, 748216.418474874, 189339.0108116676], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2222400.0000, 
sim time next is 2223000.0000, 
raw observation next is [31.3, 70.0, 1.0, 2.0, 0.5267523491967909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 736067.5192266386, 736067.5192266379, 187897.6687013372], 
processed observation next is [1.0, 0.7391304347826086, 0.6824644549763034, 0.7, 1.0, 1.0, 0.4298221074660131, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20446319978517738, 0.20446319978517719, 0.2804442816437869], 
reward next is 0.7196, 
noisyNet noise sample is [array([0.4147893], dtype=float32), 0.34477141]. 
=============================================
[2019-03-26 14:48:52,816] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.2296271e-11 1.0000000e+00 3.5873400e-14 5.7107707e-14 1.6659103e-16], sum to 1.0000
[2019-03-26 14:48:52,827] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0054
[2019-03-26 14:48:52,831] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[50.58579 ]
 [49.16456 ]
 [48.432014]
 [47.88281 ]
 [47.640736]], R is [[52.37422943]
 [51.85048676]
 [51.33198166]
 [50.81866074]
 [50.3104744 ]].
[2019-03-26 14:48:52,836] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2524443.331873314 W.
[2019-03-26 14:48:52,842] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.7, 66.33333333333334, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.247285807610893, 6.9112, 168.9112544648375, 2524443.331873314, 2286014.895313502, 475466.7353703632], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2208000.0000, 
sim time next is 2208600.0000, 
raw observation next is [31.8, 66.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 8.355460101115924, 6.9112, 168.9044775876832, 3310789.597671661, 2286233.206576839, 472595.4837366864], 
processed observation next is [1.0, 0.5652173913043478, 0.7061611374407584, 0.66, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.14442601011159234, 0.0, 0.8293983097599433, 0.919663777131017, 0.6350647796046776, 0.7053663936368454], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1563089], dtype=float32), 0.39330408]. 
=============================================
[2019-03-26 14:48:55,098] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.3799493e-14 1.0000000e+00 2.9606777e-16 2.0898990e-19 1.3914009e-22], sum to 1.0000
[2019-03-26 14:48:55,105] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0302
[2019-03-26 14:48:55,110] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.45, 78.83333333333333, 1.0, 2.0, 0.6725429737793114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 939880.9882351824, 939880.988235183, 215027.8458054866], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2271000.0000, 
sim time next is 2271600.0000, 
raw observation next is [27.6, 78.0, 1.0, 2.0, 0.6397260890291292, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 893999.9828443662, 893999.9828443662, 208370.7297452536], 
processed observation next is [1.0, 0.30434782608695654, 0.5071090047393366, 0.78, 1.0, 1.0, 0.5659350470230472, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2483333285678795, 0.2483333285678795, 0.3110010891720203], 
reward next is 0.6890, 
noisyNet noise sample is [array([0.85042834], dtype=float32), -0.5927482]. 
=============================================
[2019-03-26 14:48:56,927] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.8639904e-13 1.0000000e+00 7.9440408e-15 4.4462332e-16 1.1734993e-19], sum to 1.0000
[2019-03-26 14:48:56,933] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4909
[2019-03-26 14:48:56,939] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1958071.773404024 W.
[2019-03-26 14:48:56,943] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.16666666666667, 68.33333333333334, 1.0, 2.0, 0.7592700206931049, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.98493319443215, 6.9112, 168.9125227221046, 1958071.773404024, 1905763.041908469, 398795.9765507025], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2280000.0000, 
sim time next is 2280600.0000, 
raw observation next is [30.35, 67.5, 1.0, 2.0, 0.8250959591964484, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.983945730810526, 6.9112, 168.9124638273871, 2050196.761182639, 1998588.586561294, 414933.0271798245], 
processed observation next is [1.0, 0.391304347826087, 0.637440758293839, 0.675, 1.0, 1.0, 0.7892722399957209, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.0072745730810526155, 0.0, 0.8294375258530059, 0.5694991003285108, 0.5551634962670261, 0.6193030256415291], 
reward next is 0.0170, 
noisyNet noise sample is [array([-0.06997462], dtype=float32), -0.46938825]. 
=============================================
[2019-03-26 14:48:58,140] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1647749e-13 1.0000000e+00 1.6528892e-16 1.6934286e-17 4.1272304e-22], sum to 1.0000
[2019-03-26 14:48:58,144] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2377
[2019-03-26 14:48:58,146] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.95, 77.5, 1.0, 2.0, 0.5752929894162296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 803922.383998383, 803922.383998383, 196233.4834917669], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2320200.0000, 
sim time next is 2320800.0000, 
raw observation next is [29.86666666666667, 77.66666666666667, 1.0, 2.0, 0.5745063385012651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 802822.6916874194, 802822.6916874194, 196092.6855707108], 
processed observation next is [1.0, 0.8695652173913043, 0.6145339652448659, 0.7766666666666667, 1.0, 1.0, 0.48735703433887356, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2230063032465054, 0.2230063032465054, 0.29267565010553853], 
reward next is 0.7073, 
noisyNet noise sample is [array([-0.453922], dtype=float32), -0.82274246]. 
=============================================
[2019-03-26 14:49:00,246] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-26 14:49:00,248] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 14:49:00,250] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:49:00,251] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 14:49:00,253] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 14:49:00,254] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 14:49:00,254] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:49:00,256] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 14:49:00,255] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:49:00,259] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:49:00,258] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:49:00,274] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run12
[2019-03-26 14:49:00,292] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run12
[2019-03-26 14:49:00,293] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run12
[2019-03-26 14:49:00,293] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run12
[2019-03-26 14:49:00,355] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run12
[2019-03-26 14:49:42,048] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.07055176], dtype=float32), 0.06661398]
[2019-03-26 14:49:42,050] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [21.0, 94.0, 1.0, 2.0, 0.3081062899933056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 487217.4252841523, 487217.425284153, 166080.1343062757]
[2019-03-26 14:49:42,051] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 14:49:42,055] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.9840878e-12 1.0000000e+00 2.3361040e-14 5.8364620e-17 1.0572761e-20], sampled 0.6819140933402766
[2019-03-26 14:49:45,507] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.07055176], dtype=float32), 0.06661398]
[2019-03-26 14:49:45,509] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.5, 94.0, 1.0, 2.0, 0.5079358463610264, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 709765.1329730997, 709765.1329730991, 184848.7147648245]
[2019-03-26 14:49:45,510] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 14:49:45,512] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [6.2697460e-14 1.0000000e+00 4.2251983e-16 8.5615360e-19 6.3763267e-23], sampled 0.23330076644561037
[2019-03-26 14:49:58,502] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.07055176], dtype=float32), 0.06661398]
[2019-03-26 14:49:58,503] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.0, 93.16666666666667, 1.0, 2.0, 0.771459003842464, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1078186.635213228, 1078186.635213228, 237027.3450362605]
[2019-03-26 14:49:58,504] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 14:49:58,507] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.7955593e-14 1.0000000e+00 4.9847905e-16 7.1389285e-19 5.6610855e-23], sampled 0.229823245579738
[2019-03-26 14:50:18,404] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.07055176], dtype=float32), 0.06661398]
[2019-03-26 14:50:18,406] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [35.83333333333334, 52.33333333333334, 1.0, 2.0, 0.9086127771361349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1269986.58957815, 1269986.58957815, 272322.7758461298]
[2019-03-26 14:50:18,408] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 14:50:18,410] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.2416354e-14 1.0000000e+00 1.2909891e-16 3.5182478e-19 2.1504850e-23], sampled 0.1581714967645701
[2019-03-26 14:50:38,309] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.07055176], dtype=float32), 0.06661398]
[2019-03-26 14:50:38,310] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.329624775, 58.090663045, 1.0, 2.0, 0.3770527907320419, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 570407.5705992158, 570407.5705992165, 172100.0743606806]
[2019-03-26 14:50:38,312] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 14:50:38,315] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.4561653e-12 1.0000000e+00 1.5566229e-14 4.0825043e-17 4.8998641e-21], sampled 0.36006654969997676
[2019-03-26 14:50:53,341] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8495.3428 2842484086.3466 1131.0000
[2019-03-26 14:50:53,812] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.1610 2927253227.7716 1338.0000
[2019-03-26 14:50:54,155] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.1685 3164067279.4129 1778.0000
[2019-03-26 14:50:54,207] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.2473 2779197326.4671 933.0000
[2019-03-26 14:50:54,280] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7999.0502 3007584666.7691 1766.0000
[2019-03-26 14:50:55,298] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 275000, evaluation results [275000.0, 7884.168455680242, 3164067279.4128904, 1778.0, 8255.161016606155, 2927253227.7715816, 1338.0, 8659.247307079566, 2779197326.467062, 933.0, 7999.050242421542, 3007584666.769063, 1766.0, 8495.34275661312, 2842484086.346593, 1131.0]
[2019-03-26 14:50:55,351] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.7360061e-13 1.0000000e+00 1.1713722e-16 1.8022870e-18 1.2706698e-22], sum to 1.0000
[2019-03-26 14:50:55,359] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4502
[2019-03-26 14:50:55,366] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.5, 82.0, 1.0, 2.0, 0.7319434201240673, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1022933.284611925, 1022933.284611925, 227889.9815868014], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2344800.0000, 
sim time next is 2345400.0000, 
raw observation next is [27.45, 82.0, 1.0, 2.0, 0.7306106543892296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1021069.771913284, 1021069.771913284, 227589.8395192572], 
processed observation next is [1.0, 0.13043478260869565, 0.5, 0.82, 1.0, 1.0, 0.6754345233605176, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2836304921981344, 0.2836304921981344, 0.33968632764068235], 
reward next is 0.6603, 
noisyNet noise sample is [array([-1.1782616], dtype=float32), -0.64291525]. 
=============================================
[2019-03-26 14:50:56,840] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.90430045e-16 1.00000000e+00 8.26111233e-18 1.05528206e-19
 3.67695736e-23], sum to 1.0000
[2019-03-26 14:50:56,846] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2213
[2019-03-26 14:50:56,849] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.75, 94.0, 1.0, 2.0, 0.551534643858489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 770710.0982300511, 770710.0982300511, 192064.3922580315], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2503800.0000, 
sim time next is 2504400.0000, 
raw observation next is [26.73333333333333, 94.0, 1.0, 2.0, 0.5508428459820665, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 769743.0351386375, 769743.035138637, 191945.510242919], 
processed observation next is [1.0, 1.0, 0.4660347551342811, 0.94, 1.0, 1.0, 0.4588468023880318, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21381750976073263, 0.2138175097607325, 0.2864858361834612], 
reward next is 0.7135, 
noisyNet noise sample is [array([-0.74325925], dtype=float32), 1.4349563]. 
=============================================
[2019-03-26 14:51:06,257] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.5786751e-13 1.0000000e+00 1.9479064e-16 2.4112389e-18 4.2662426e-22], sum to 1.0000
[2019-03-26 14:51:06,268] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8811
[2019-03-26 14:51:06,272] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.48333333333333, 93.16666666666666, 1.0, 2.0, 0.7783651110863742, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1087843.514641576, 1087843.514641576, 238669.8148637448], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2533800.0000, 
sim time next is 2534400.0000, 
raw observation next is [26.5, 93.0, 1.0, 2.0, 0.7620022220373106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1064963.264275522, 1064963.264275522, 234797.8168785044], 
processed observation next is [1.0, 0.34782608695652173, 0.4549763033175356, 0.93, 1.0, 1.0, 0.713255689201579, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2958231289654228, 0.2958231289654228, 0.3504445028037379], 
reward next is 0.6496, 
noisyNet noise sample is [array([1.3524351], dtype=float32), 0.9354161]. 
=============================================
[2019-03-26 14:51:06,353] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.3373321e-11 1.0000000e+00 3.9780955e-13 4.9551373e-13 4.5085743e-16], sum to 1.0000
[2019-03-26 14:51:06,364] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6654
[2019-03-26 14:51:06,375] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2031567.126212747 W.
[2019-03-26 14:51:06,382] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.2, 81.33333333333333, 1.0, 2.0, 0.4843261651146821, 1.0, 2.0, 0.4843261651146821, 1.0, 1.0, 0.8361223579156681, 6.911199999999999, 6.9112, 170.5573041426782, 2031567.126212747, 2031567.126212747, 403606.3293053225], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2544000.0000, 
sim time next is 2544600.0000, 
raw observation next is [28.3, 80.66666666666667, 1.0, 2.0, 0.7318633917688809, 1.0, 2.0, 0.7318633917688809, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2046609.831321588, 2046609.831321588, 388061.5157004682], 
processed observation next is [1.0, 0.43478260869565216, 0.5402843601895735, 0.8066666666666668, 1.0, 1.0, 0.6769438455046758, 1.0, 1.0, 0.6769438455046758, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5685027309226633, 0.5685027309226633, 0.579196292090251], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.3266641], dtype=float32), 0.5070043]. 
=============================================
[2019-03-26 14:51:08,367] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.7175328e-12 1.0000000e+00 4.0835306e-14 5.3971327e-14 9.3705038e-17], sum to 1.0000
[2019-03-26 14:51:08,374] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7688
[2019-03-26 14:51:08,378] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.7, 79.0, 1.0, 2.0, 0.522806852253863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 730552.3073473206, 730552.3073473212, 187248.0963012429], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2570400.0000, 
sim time next is 2571000.0000, 
raw observation next is [28.6, 79.66666666666667, 1.0, 2.0, 0.5319290492692991, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 743303.811515374, 743303.8115153746, 188750.7687660228], 
processed observation next is [1.0, 0.782608695652174, 0.5545023696682465, 0.7966666666666667, 1.0, 1.0, 0.4360590955051796, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20647328097649278, 0.20647328097649295, 0.2817175653224221], 
reward next is 0.7183, 
noisyNet noise sample is [array([-1.8335514], dtype=float32), -1.6122115]. 
=============================================
[2019-03-26 14:51:08,390] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[50.339592]
 [48.8761  ]
 [46.90054 ]
 [45.903324]
 [44.027477]], R is [[51.74126434]
 [51.9443779 ]
 [52.14699554]
 [52.34905624]
 [52.55160522]].
[2019-03-26 14:51:13,079] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.6734616e-14 1.0000000e+00 6.1812984e-17 1.9174553e-19 1.5769043e-22], sum to 1.0000
[2019-03-26 14:51:13,087] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0545
[2019-03-26 14:51:13,092] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 89.0, 1.0, 2.0, 0.4196727544789652, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 617079.4322294805, 617079.4322294812, 175885.7840774528], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2660400.0000, 
sim time next is 2661000.0000, 
raw observation next is [23.83333333333333, 89.83333333333334, 1.0, 2.0, 0.4151983863922045, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 612542.7685328014, 612542.768532802, 175511.5393493354], 
processed observation next is [0.0, 0.8260869565217391, 0.32859399684044216, 0.8983333333333334, 1.0, 1.0, 0.2954197426412103, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17015076903688928, 0.17015076903688944, 0.26195752141691847], 
reward next is 0.7380, 
noisyNet noise sample is [array([0.06421808], dtype=float32), 0.018811213]. 
=============================================
[2019-03-26 14:51:13,104] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[74.82697 ]
 [74.860176]
 [74.88777 ]
 [74.91213 ]
 [74.92871 ]], R is [[74.79917145]
 [74.78865814]
 [74.77759552]
 [74.76595306]
 [74.75356293]].
[2019-03-26 14:51:15,804] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.5372161e-13 1.0000000e+00 3.3401656e-15 1.8734028e-18 5.7641366e-23], sum to 1.0000
[2019-03-26 14:51:15,811] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2861
[2019-03-26 14:51:15,816] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 97.66666666666667, 1.0, 2.0, 0.462076859757189, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 650915.6321728296, 650915.632172829, 178546.2408703369], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2695800.0000, 
sim time next is 2696400.0000, 
raw observation next is [24.0, 98.0, 1.0, 2.0, 0.4638759431771568, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 652221.4458027497, 652221.4458027504, 178652.3929667745], 
processed observation next is [0.0, 0.21739130434782608, 0.3364928909952607, 0.98, 1.0, 1.0, 0.35406740141826126, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18117262383409716, 0.18117262383409732, 0.26664536263697686], 
reward next is 0.7334, 
noisyNet noise sample is [array([0.9322453], dtype=float32), 0.38136226]. 
=============================================
[2019-03-26 14:51:18,603] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.2098739e-13 1.0000000e+00 5.8808725e-16 1.3183902e-18 1.7232829e-23], sum to 1.0000
[2019-03-26 14:51:18,610] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7540
[2019-03-26 14:51:18,620] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.3900876994207442, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 582070.2072966028, 582070.2072966034, 172894.7167615541], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2743200.0000, 
sim time next is 2743800.0000, 
raw observation next is [23.0, 94.00000000000001, 1.0, 2.0, 0.3919668394299962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 584875.186179163, 584875.186179163, 173149.4248793958], 
processed observation next is [0.0, 0.782608695652174, 0.28909952606635075, 0.9400000000000002, 1.0, 1.0, 0.26742992702409185, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16246532949421197, 0.16246532949421197, 0.258431977431934], 
reward next is 0.7416, 
noisyNet noise sample is [array([0.52074146], dtype=float32), 0.40280664]. 
=============================================
[2019-03-26 14:51:23,517] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.10203138e-15 1.00000000e+00 1.09146005e-16 2.01213765e-19
 1.83656064e-23], sum to 1.0000
[2019-03-26 14:51:23,526] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8571
[2019-03-26 14:51:23,530] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 89.0, 1.0, 2.0, 0.4113506259202543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 606088.3237429457, 606088.3237429451, 174881.5591191078], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2836800.0000, 
sim time next is 2837400.0000, 
raw observation next is [23.83333333333333, 89.83333333333334, 1.0, 2.0, 0.40969293241241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 604490.5301258386, 604490.5301258386, 174756.7883453504], 
processed observation next is [1.0, 0.8695652173913043, 0.32859399684044216, 0.8983333333333334, 1.0, 1.0, 0.2887866655571205, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1679140361460663, 0.1679140361460663, 0.26083102738111996], 
reward next is 0.7392, 
noisyNet noise sample is [array([0.79565334], dtype=float32), -0.1364053]. 
=============================================
[2019-03-26 14:51:26,101] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.4360968e-13 1.0000000e+00 2.3975213e-15 3.4784545e-18 3.2368568e-22], sum to 1.0000
[2019-03-26 14:51:26,112] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4617
[2019-03-26 14:51:26,116] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.3448394295254273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 531217.893419224, 531217.8934192245, 169099.5435714672], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2869200.0000, 
sim time next is 2869800.0000, 
raw observation next is [22.0, 94.00000000000001, 1.0, 2.0, 0.3835916465584336, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 590912.58056965, 590912.5805696495, 174189.2145948113], 
processed observation next is [1.0, 0.21739130434782608, 0.2417061611374408, 0.9400000000000002, 1.0, 1.0, 0.257339333202932, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16414238349156945, 0.1641423834915693, 0.2599839023803154], 
reward next is 0.7400, 
noisyNet noise sample is [array([1.6275443], dtype=float32), -0.30420497]. 
=============================================
[2019-03-26 14:51:34,589] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.9563802e-13 1.0000000e+00 1.6250188e-15 3.7577934e-18 9.3302106e-22], sum to 1.0000
[2019-03-26 14:51:34,596] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4297
[2019-03-26 14:51:34,601] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.3136293636407088, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 499421.3290167285, 499421.3290167285, 167037.5342275142], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3033000.0000, 
sim time next is 3033600.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.3152831036555155, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 502062.4358846961, 502062.4358846961, 167234.1481452631], 
processed observation next is [1.0, 0.08695652173913043, 0.1469194312796209, 1.0, 1.0, 1.0, 0.1750398839223078, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1394617877457489, 0.1394617877457489, 0.24960320618695986], 
reward next is 0.7504, 
noisyNet noise sample is [array([-0.15605699], dtype=float32), -1.697372]. 
=============================================
[2019-03-26 14:51:40,126] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.6861525e-14 1.0000000e+00 2.5729094e-16 5.9891485e-19 3.8781043e-23], sum to 1.0000
[2019-03-26 14:51:40,134] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4847
[2019-03-26 14:51:40,142] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.00000000000001, 1.0, 2.0, 0.3906318431671744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 582883.0890230265, 582883.0890230272, 172968.4333349663], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3114600.0000, 
sim time next is 3115200.0000, 
raw observation next is [23.0, 94.0, 1.0, 2.0, 0.3905625685332892, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 582779.8404165438, 582779.8404165438, 172959.0723565096], 
processed observation next is [1.0, 0.043478260869565216, 0.28909952606635075, 0.94, 1.0, 1.0, 0.26573803437745686, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1618832890045955, 0.1618832890045955, 0.2581478691888203], 
reward next is 0.7419, 
noisyNet noise sample is [array([-0.37332186], dtype=float32), -0.0061414093]. 
=============================================
[2019-03-26 14:51:42,596] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.6791498e-13 1.0000000e+00 6.7572625e-15 2.6208706e-19 8.9879467e-23], sum to 1.0000
[2019-03-26 14:51:42,605] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0532
[2019-03-26 14:51:42,609] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 83.0, 1.0, 2.0, 0.4210350578213153, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 616474.9472071078, 616474.9472071084, 175755.7255499691], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3303600.0000, 
sim time next is 3304200.0000, 
raw observation next is [25.0, 83.0, 1.0, 2.0, 0.4209428935094727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 616340.1499663205, 616340.1499663205, 175742.8214674003], 
processed observation next is [0.0, 0.21739130434782608, 0.38388625592417064, 0.83, 1.0, 1.0, 0.30234083555358165, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1712055972128668, 0.1712055972128668, 0.26230271860806015], 
reward next is 0.7377, 
noisyNet noise sample is [array([0.4211235], dtype=float32), -0.9060581]. 
=============================================
[2019-03-26 14:51:46,694] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.3222945e-13 1.0000000e+00 1.3875993e-16 8.4454737e-19 3.8291816e-23], sum to 1.0000
[2019-03-26 14:51:46,704] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6680
[2019-03-26 14:51:46,710] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.5, 74.5, 1.0, 2.0, 0.5357670944871656, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 748668.886054139, 748668.886054139, 189390.4782181815], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3234600.0000, 
sim time next is 3235200.0000, 
raw observation next is [29.66666666666667, 73.0, 1.0, 2.0, 0.5341717959314043, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 746438.8684780421, 746438.8684780427, 189123.865751679], 
processed observation next is [0.0, 0.43478260869565216, 0.6050552922590839, 0.73, 1.0, 1.0, 0.4387611999173545, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20734413013278946, 0.20734413013278963, 0.2822744264950433], 
reward next is 0.7177, 
noisyNet noise sample is [array([-1.6483978], dtype=float32), 0.08900071]. 
=============================================
[2019-03-26 14:51:48,540] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.5226804e-13 1.0000000e+00 1.6225156e-16 2.2975401e-18 7.4807435e-24], sum to 1.0000
[2019-03-26 14:51:48,547] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8454
[2019-03-26 14:51:48,552] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.66666666666667, 79.0, 1.0, 2.0, 0.5115656084541126, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 714838.8946300927, 714838.8946300927, 185427.6951711184], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3277200.0000, 
sim time next is 3277800.0000, 
raw observation next is [27.5, 79.0, 1.0, 2.0, 0.5074617159312806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 709102.3847715318, 709102.3847715311, 184773.0094002295], 
processed observation next is [0.0, 0.9565217391304348, 0.5023696682464456, 0.79, 1.0, 1.0, 0.4065803806400971, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19697288465875884, 0.19697288465875865, 0.27578061104511864], 
reward next is 0.7242, 
noisyNet noise sample is [array([0.15305288], dtype=float32), 0.57676417]. 
=============================================
[2019-03-26 14:51:48,983] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.6683042e-15 1.0000000e+00 2.0083667e-17 8.5427401e-20 3.6068685e-24], sum to 1.0000
[2019-03-26 14:51:48,993] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0932
[2019-03-26 14:51:49,000] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 79.0, 1.0, 2.0, 0.5180707140281979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 723931.9355733166, 723931.9355733166, 186475.836349417], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3274800.0000, 
sim time next is 3275400.0000, 
raw observation next is [28.0, 79.0, 1.0, 2.0, 0.5175730678558684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 723236.3073694353, 723236.3073694347, 186395.2683746903], 
processed observation next is [0.0, 0.9130434782608695, 0.5260663507109005, 0.79, 1.0, 1.0, 0.41876273235646794, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2008989742692876, 0.20089897426928743, 0.2782018930965527], 
reward next is 0.7218, 
noisyNet noise sample is [array([0.69714123], dtype=float32), 0.83841014]. 
=============================================
[2019-03-26 14:51:49,658] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-26 14:51:49,659] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 14:51:49,659] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 14:51:49,661] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:51:49,660] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 14:51:49,663] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:51:49,662] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 14:51:49,663] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:51:49,666] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:51:49,661] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 14:51:49,668] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:51:49,682] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run13
[2019-03-26 14:51:49,699] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run13
[2019-03-26 14:51:49,716] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run13
[2019-03-26 14:51:49,719] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run13
[2019-03-26 14:51:49,760] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run13
[2019-03-26 14:51:58,077] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.07464983], dtype=float32), 0.07020905]
[2019-03-26 14:51:58,079] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [18.78485496, 84.576566895, 1.0, 2.0, 0.2194868923396019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 365407.3518904432, 365407.3518904426, 157613.951540749]
[2019-03-26 14:51:58,080] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 14:51:58,084] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.0534165e-12 1.0000000e+00 1.9918969e-14 4.5560655e-17 5.3870755e-21], sampled 0.3032759332446542
[2019-03-26 14:52:23,812] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.07464983], dtype=float32), 0.07020905]
[2019-03-26 14:52:23,813] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.9, 77.66666666666666, 1.0, 2.0, 0.5762160637791944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 805212.7898215837, 805212.7898215842, 196398.7064164983]
[2019-03-26 14:52:23,815] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 14:52:23,818] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.3368832e-14 1.0000000e+00 5.1340447e-17 1.1831184e-19 5.0618593e-24], sampled 0.14937501800722008
[2019-03-26 14:52:26,791] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.07464983], dtype=float32), 0.07020905]
[2019-03-26 14:52:26,793] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.83435739666667, 91.91933720833333, 1.0, 2.0, 0.5450793134432206, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 761686.2368902738, 761686.2368902738, 190960.4615779515]
[2019-03-26 14:52:26,794] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 14:52:26,798] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.7878626e-14 1.0000000e+00 9.0669378e-17 2.1087021e-19 6.5261642e-24], sampled 0.014494493930806374
[2019-03-26 14:52:28,552] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.07464983], dtype=float32), 0.07020905]
[2019-03-26 14:52:28,553] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [24.93916297, 92.531355065, 1.0, 2.0, 0.471098187019391, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 659102.0824809582, 659102.0824809575, 179298.9747654367]
[2019-03-26 14:52:28,554] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 14:52:28,557] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [9.8904649e-14 1.0000000e+00 5.3995365e-16 7.8485388e-19 4.4750252e-23], sampled 0.2823197374411728
[2019-03-26 14:52:29,914] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.07464983], dtype=float32), 0.07020905]
[2019-03-26 14:52:29,915] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.63333333333333, 84.0, 1.0, 2.0, 0.5480615243307994, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 765855.0391517433, 765855.039151744, 191467.7494535259]
[2019-03-26 14:52:29,915] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 14:52:29,917] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0743388e-14 1.0000000e+00 4.0085232e-17 6.8091518e-20 2.5526233e-24], sampled 0.23173160063060516
[2019-03-26 14:52:31,948] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.07464983], dtype=float32), 0.07020905]
[2019-03-26 14:52:31,950] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [22.60818583, 84.71673749499999, 1.0, 2.0, 0.3356372986051104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 527035.4122588489, 527035.4122588489, 169033.0197088526]
[2019-03-26 14:52:31,952] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 14:52:31,955] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.0429075e-13 1.0000000e+00 2.9352529e-15 5.5136150e-18 4.7914715e-22], sampled 0.7295407908195155
[2019-03-26 14:53:00,370] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.07464983], dtype=float32), 0.07020905]
[2019-03-26 14:53:00,372] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.27469524, 83.26677692, 1.0, 2.0, 1.005217124602172, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9128725708879, 1405101.810203403, 1405101.810203403, 300520.7193096515]
[2019-03-26 14:53:00,374] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 14:53:00,377] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0558188e-13 1.0000000e+00 7.8741914e-16 3.1941046e-18 2.5311578e-22], sampled 0.1117990448359778
[2019-03-26 14:53:03,631] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.07464983], dtype=float32), 0.07020905]
[2019-03-26 14:53:03,633] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.96666666666667, 84.16666666666666, 1.0, 2.0, 0.6176874537830651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 863189.0681828854, 863189.068182886, 204087.6219543088]
[2019-03-26 14:53:03,634] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 14:53:03,637] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [8.2314611e-15 1.0000000e+00 2.8480365e-17 3.8658948e-20 1.3322741e-24], sampled 0.5733243030760686
[2019-03-26 14:53:03,666] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.07464983], dtype=float32), 0.07020905]
[2019-03-26 14:53:03,667] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.15670942666667, 82.81410889666665, 1.0, 2.0, 0.5848573973032472, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 817292.9620495257, 817292.9620495251, 197958.4600410078]
[2019-03-26 14:53:03,668] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 14:53:03,670] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.9012434e-14 1.0000000e+00 7.6282861e-17 1.2037548e-19 4.5611792e-24], sampled 0.5543975030894669
[2019-03-26 14:53:09,275] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.07464983], dtype=float32), 0.07020905]
[2019-03-26 14:53:09,277] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [31.77718139833333, 66.727817975, 1.0, 2.0, 0.7093078972382995, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 991284.0669859238, 991284.0669859244, 222870.1474153267]
[2019-03-26 14:53:09,278] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 14:53:09,282] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [7.0872832e-14 1.0000000e+00 2.7041630e-16 1.2013791e-18 1.0823227e-22], sampled 0.6488680536616259
[2019-03-26 14:53:25,970] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.07464983], dtype=float32), 0.07020905]
[2019-03-26 14:53:25,972] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [30.032973425, 65.01686121, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.965677577358613, 6.9112, 168.9127143027474, 1492429.606648316, 1453781.393715136, 311348.2639917561]
[2019-03-26 14:53:25,975] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 14:53:25,979] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.5324334e-14 1.0000000e+00 7.8314999e-17 2.0532719e-19 2.0691586e-23], sampled 0.6553588699869187
[2019-03-26 14:53:42,734] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.07464983], dtype=float32), 0.07020905]
[2019-03-26 14:53:42,737] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [25.3, 69.0, 1.0, 2.0, 0.3383789026923228, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 524500.383042982, 524500.3830429825, 168659.0773286789]
[2019-03-26 14:53:42,739] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 14:53:42,744] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [7.10814871e-13 1.00000000e+00 5.57985072e-15 1.16158666e-17
 1.08007139e-21], sampled 0.8358123140547525
[2019-03-26 14:53:43,631] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.9164 3164002230.9074 1778.0000
[2019-03-26 14:53:43,650] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.3130 3007656030.3370 1766.0000
[2019-03-26 14:53:43,718] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.3694 2779190338.1949 933.0000
[2019-03-26 14:53:43,719] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.0653 2927317329.7462 1338.0000
[2019-03-26 14:53:43,730] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.6119 2842427357.4275 1131.0000
[2019-03-26 14:53:44,747] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 300000, evaluation results [300000.0, 7884.916440885027, 3164002230.907359, 1778.0, 8255.065342017213, 2927317329.746172, 1338.0, 8661.369356548688, 2779190338.194891, 933.0, 7998.312951428424, 3007656030.3370423, 1766.0, 8497.61193292354, 2842427357.427519, 1131.0]
[2019-03-26 14:53:55,064] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.3039170e-15 1.0000000e+00 2.3302262e-17 9.0136827e-19 2.2323920e-23], sum to 1.0000
[2019-03-26 14:53:55,076] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6060
[2019-03-26 14:53:55,081] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.5117892573419964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 715151.5167799335, 715151.516779934, 185463.7158761521], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3453600.0000, 
sim time next is 3454200.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.5108681047745739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 713863.9066937568, 713863.9066937568, 185316.3543068274], 
processed observation next is [1.0, 1.0, 0.4786729857819906, 0.84, 1.0, 1.0, 0.41068446358382393, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19829552963715466, 0.19829552963715466, 0.2765915735922797], 
reward next is 0.7234, 
noisyNet noise sample is [array([-1.5488132], dtype=float32), -2.0898104]. 
=============================================
[2019-03-26 14:53:55,715] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.6239802e-14 1.0000000e+00 5.7786244e-15 3.9071144e-18 3.3062430e-22], sum to 1.0000
[2019-03-26 14:53:55,724] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5907
[2019-03-26 14:53:55,731] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.6487600454747424, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 906630.0822340903, 906630.0822340903, 210170.5499065353], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3470400.0000, 
sim time next is 3471000.0000, 
raw observation next is [27.0, 79.00000000000001, 1.0, 2.0, 0.6908483189325079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 965474.3956512511, 965474.3956512511, 218878.8560032139], 
processed observation next is [1.0, 0.17391304347826086, 0.4786729857819906, 0.7900000000000001, 1.0, 1.0, 0.6275280950994071, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2681873321253475, 0.2681873321253475, 0.3266848597062894], 
reward next is 0.6733, 
noisyNet noise sample is [array([0.72876716], dtype=float32), -1.0310309]. 
=============================================
[2019-03-26 14:53:55,758] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[72.2519  ]
 [72.082954]
 [71.92143 ]
 [71.78058 ]
 [71.67957 ]], R is [[72.27940369]
 [72.24291992]
 [72.18629456]
 [72.13324738]
 [72.0954895 ]].
[2019-03-26 14:53:58,161] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.8760184e-12 1.0000000e+00 1.0554806e-13 1.5142755e-13 3.7785107e-16], sum to 1.0000
[2019-03-26 14:53:58,167] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1991
[2019-03-26 14:53:58,175] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2563994.545132751 W.
[2019-03-26 14:53:58,181] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.5, 63.0, 1.0, 2.0, 0.9166793434166005, 1.0, 2.0, 0.9166793434166005, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2563994.545132751, 2563994.545132751, 480673.5873336931], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3515400.0000, 
sim time next is 3516000.0000, 
raw observation next is [32.33333333333334, 64.33333333333333, 1.0, 2.0, 0.6010680184005173, 1.0, 2.0, 0.6010680184005173, 1.0, 1.0, 1.03, 6.926776687741427, 6.9112, 170.5573041426782, 2521780.037772515, 2510621.822724185, 488365.8473747869], 
processed observation next is [1.0, 0.6956521739130435, 0.7314375987361774, 0.6433333333333333, 1.0, 1.0, 0.5193590583138762, 1.0, 1.0, 0.5193590583138762, 1.0, 0.5, 1.0365853658536586, 0.001557668774142673, 0.0, 0.8375144448122397, 0.7004944549368097, 0.6973949507567181, 0.7289042498131147], 
reward next is 0.1932, 
noisyNet noise sample is [array([1.0881658], dtype=float32), 1.0119655]. 
=============================================
[2019-03-26 14:53:58,192] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[48.532787]
 [48.079594]
 [47.83295 ]
 [47.15256 ]
 [47.14211 ]], R is [[46.88669586]
 [46.70040512]
 [46.23340225]
 [45.77106857]
 [45.31335831]].
[2019-03-26 14:53:59,547] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.2392808e-14 1.0000000e+00 1.2871143e-16 4.8794284e-18 2.2940673e-22], sum to 1.0000
[2019-03-26 14:53:59,553] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1558
[2019-03-26 14:53:59,557] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 79.0, 1.0, 2.0, 0.519240429844908, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 725567.0093477033, 725567.0093477033, 186665.4998872212], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3540600.0000, 
sim time next is 3541200.0000, 
raw observation next is [28.0, 79.0, 1.0, 2.0, 0.5192310005660238, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 725553.8287288164, 725553.828728817, 186663.9693649771], 
processed observation next is [1.0, 1.0, 0.5260663507109005, 0.79, 1.0, 1.0, 0.42076024164581177, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20154273020244898, 0.20154273020244917, 0.27860293935071206], 
reward next is 0.7214, 
noisyNet noise sample is [array([1.8323392], dtype=float32), 0.0017609169]. 
=============================================
[2019-03-26 14:54:00,106] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.5612704e-14 1.0000000e+00 1.7520646e-15 7.8197635e-18 6.2472548e-22], sum to 1.0000
[2019-03-26 14:54:00,117] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8471
[2019-03-26 14:54:00,124] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.83333333333334, 74.83333333333334, 1.0, 2.0, 0.4918174229934308, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 687234.7373787031, 687234.7373787038, 182323.7222424673], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3546600.0000, 
sim time next is 3547200.0000, 
raw observation next is [27.66666666666667, 75.66666666666667, 1.0, 2.0, 0.4897845331431168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 684393.1898831101, 684393.1898831107, 182010.8014198265], 
processed observation next is [1.0, 0.043478260869565216, 0.5102685624012641, 0.7566666666666667, 1.0, 1.0, 0.385282570051948, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19010921941197503, 0.1901092194119752, 0.2716579125669052], 
reward next is 0.7283, 
noisyNet noise sample is [array([-0.58475065], dtype=float32), -0.9551443]. 
=============================================
[2019-03-26 14:54:05,346] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.9737297e-13 1.0000000e+00 1.1144578e-15 2.0237171e-17 1.0545285e-21], sum to 1.0000
[2019-03-26 14:54:05,356] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9125
[2019-03-26 14:54:05,359] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 80.66666666666667, 1.0, 2.0, 0.4974998686123532, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 695177.6276825194, 695177.62768252, 183204.9238889904], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3634800.0000, 
sim time next is 3635400.0000, 
raw observation next is [27.0, 79.83333333333334, 1.0, 2.0, 0.4936814575882907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 689840.2678328209, 689840.2678328209, 182611.5835546549], 
processed observation next is [1.0, 0.043478260869565216, 0.4786729857819906, 0.7983333333333335, 1.0, 1.0, 0.3899776597449286, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19162229662022803, 0.19162229662022803, 0.2725546023203805], 
reward next is 0.7274, 
noisyNet noise sample is [array([-0.68657184], dtype=float32), 0.599208]. 
=============================================
[2019-03-26 14:54:06,356] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.5021797e-12 1.0000000e+00 1.5839819e-15 8.7868041e-17 3.4910230e-22], sum to 1.0000
[2019-03-26 14:54:06,362] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2854
[2019-03-26 14:54:06,367] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.33333333333334, 72.66666666666667, 1.0, 2.0, 0.8337723696138105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1165323.222125652, 1165323.222125652, 252366.6801738021], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3655200.0000, 
sim time next is 3655800.0000, 
raw observation next is [28.5, 72.0, 1.0, 2.0, 0.8874003259451771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1240320.195969404, 1240320.195969404, 266492.5916803419], 
processed observation next is [1.0, 0.30434782608695654, 0.5497630331753555, 0.72, 1.0, 1.0, 0.864337742102623, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3445333877692789, 0.3445333877692789, 0.3977501368363312], 
reward next is 0.6022, 
noisyNet noise sample is [array([0.46345234], dtype=float32), 0.20029162]. 
=============================================
[2019-03-26 14:54:12,531] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.1219644e-13 1.0000000e+00 2.7022155e-15 5.4250761e-16 3.4149622e-19], sum to 1.0000
[2019-03-26 14:54:12,540] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4861
[2019-03-26 14:54:12,544] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 66.0, 1.0, 2.0, 0.5365075531008595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 749703.9514058627, 749703.9514058627, 189514.2663557047], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3783600.0000, 
sim time next is 3784200.0000, 
raw observation next is [30.83333333333334, 67.5, 1.0, 2.0, 0.5378671673391603, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 751604.5188493406, 751604.5188493399, 189742.479166377], 
processed observation next is [1.0, 0.8260869565217391, 0.6603475513428123, 0.675, 1.0, 1.0, 0.4432134546254943, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20877903301370573, 0.20877903301370554, 0.2831977300990701], 
reward next is 0.7168, 
noisyNet noise sample is [array([-1.0624399], dtype=float32), -1.5569385]. 
=============================================
[2019-03-26 14:54:12,915] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.7313188e-10 1.0000000e+00 7.1268420e-13 2.0199363e-11 2.9604111e-13], sum to 1.0000
[2019-03-26 14:54:12,922] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1727
[2019-03-26 14:54:12,928] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2478628.563890193 W.
[2019-03-26 14:54:12,932] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [33.83333333333334, 66.33333333333333, 1.0, 2.0, 0.5907930258190347, 1.0, 2.0, 0.5907930258190347, 1.0, 2.0, 1.026012107608471, 6.9112, 6.9112, 170.5573041426782, 2478628.563890193, 2478628.563890193, 483609.2103946556], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3761400.0000, 
sim time next is 3762000.0000, 
raw observation next is [34.0, 67.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 7.781473786522035, 6.9112, 168.9081857816414, 2901632.119264893, 2284247.380322916, 474140.8790941412], 
processed observation next is [1.0, 0.5652173913043478, 0.8104265402843602, 0.67, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.08702737865220352, 0.0, 0.8294165186898967, 0.8060089220180258, 0.63451316120081, 0.7076729538718525], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2232238], dtype=float32), -0.3802959]. 
=============================================
[2019-03-26 14:54:12,951] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[40.96834 ]
 [41.907127]
 [43.04959 ]
 [44.3545  ]
 [44.243793]], R is [[41.00074005]
 [40.868927  ]
 [40.74673462]
 [40.33926773]
 [40.21276855]].
[2019-03-26 14:54:17,259] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.3449662e-14 1.0000000e+00 7.2261503e-16 5.1854530e-18 3.0004399e-22], sum to 1.0000
[2019-03-26 14:54:17,270] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6521
[2019-03-26 14:54:17,278] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [34.66666666666667, 60.66666666666667, 1.0, 2.0, 0.6211640916239537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 868049.490890921, 868049.4908909217, 204755.9348768251], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3849600.0000, 
sim time next is 3850200.0000, 
raw observation next is [34.75, 60.5, 1.0, 2.0, 0.6203133274136174, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 866860.1001569517, 866860.1001569517, 204592.3819506234], 
processed observation next is [0.0, 0.5652173913043478, 0.8459715639810427, 0.605, 1.0, 1.0, 0.5425461776067679, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2407944722658199, 0.2407944722658199, 0.3053617641054081], 
reward next is 0.6946, 
noisyNet noise sample is [array([-0.9527943], dtype=float32), 0.4142358]. 
=============================================
[2019-03-26 14:54:23,088] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.2048811e-13 1.0000000e+00 3.4527845e-16 2.7406007e-18 6.0296198e-23], sum to 1.0000
[2019-03-26 14:54:23,098] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6284
[2019-03-26 14:54:23,101] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [34.83333333333334, 57.16666666666667, 1.0, 2.0, 0.6454933096432228, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 902062.941015724, 902062.9410157233, 209525.4743143821], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3946200.0000, 
sim time next is 3946800.0000, 
raw observation next is [34.66666666666667, 58.33333333333334, 1.0, 2.0, 0.6080301507260163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 849688.0446379943, 849688.0446379943, 202251.8993186689], 
processed observation next is [0.0, 0.6956521739130435, 0.8420221169036337, 0.5833333333333335, 1.0, 1.0, 0.5277471695494172, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2360244568438873, 0.2360244568438873, 0.3018685064457745], 
reward next is 0.6981, 
noisyNet noise sample is [array([-0.06618172], dtype=float32), -0.45642915]. 
=============================================
[2019-03-26 14:54:23,359] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0009423e-12 1.0000000e+00 1.4924189e-15 2.7476892e-17 1.4772571e-21], sum to 1.0000
[2019-03-26 14:54:23,366] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0421
[2019-03-26 14:54:23,375] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [35.0, 56.0, 1.0, 2.0, 0.6044566303036362, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 844692.26445254, 844692.26445254, 201579.2819213372], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3935400.0000, 
sim time next is 3936000.0000, 
raw observation next is [35.0, 56.0, 1.0, 2.0, 0.5973702957298898, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 834785.6409243108, 834785.6409243108, 200257.6478620151], 
processed observation next is [0.0, 0.5652173913043478, 0.8578199052132701, 0.56, 1.0, 1.0, 0.5149039707589033, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23188490025675298, 0.23188490025675298, 0.29889201173435087], 
reward next is 0.7011, 
noisyNet noise sample is [array([0.4964076], dtype=float32), 0.7205496]. 
=============================================
[2019-03-26 14:54:23,386] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[73.70132 ]
 [73.686745]
 [73.681625]
 [73.665146]
 [73.634995]], R is [[73.67691803]
 [73.63928223]
 [73.60469818]
 [73.57069397]
 [73.53721619]].
[2019-03-26 14:54:23,657] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.2833006e-14 1.0000000e+00 4.4063175e-16 1.4096806e-18 1.3522702e-22], sum to 1.0000
[2019-03-26 14:54:23,667] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0336
[2019-03-26 14:54:23,671] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [34.0, 62.5, 1.0, 2.0, 0.626238150094815, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 875143.1856992028, 875143.1856992021, 205735.8527295734], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3949800.0000, 
sim time next is 3950400.0000, 
raw observation next is [34.0, 62.00000000000001, 1.0, 2.0, 0.6138143539392955, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 857774.4083206037, 857774.4083206031, 203348.1752246291], 
processed observation next is [0.0, 0.7391304347826086, 0.8104265402843602, 0.6200000000000001, 1.0, 1.0, 0.5347160890834886, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.23827066897794547, 0.2382706689779453, 0.3035047391412375], 
reward next is 0.6965, 
noisyNet noise sample is [array([0.5727123], dtype=float32), -0.5745476]. 
=============================================
[2019-03-26 14:54:33,748] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.0204347e-11 1.0000000e+00 9.9951663e-14 1.3088813e-11 1.7600227e-15], sum to 1.0000
[2019-03-26 14:54:33,757] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9373
[2019-03-26 14:54:33,762] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.16666666666666, 70.33333333333334, 1.0, 2.0, 0.6158563985383035, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 860629.2181754233, 860629.2181754233, 203739.5945333088], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4125000.0000, 
sim time next is 4125600.0000, 
raw observation next is [33.0, 71.0, 1.0, 2.0, 0.6219712885236781, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 869177.9746105764, 869177.9746105757, 204912.5457719013], 
processed observation next is [1.0, 0.782608695652174, 0.7630331753554502, 0.71, 1.0, 1.0, 0.5445437211128652, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.24143832628071568, 0.2414383262807155, 0.3058396205550766], 
reward next is 0.6942, 
noisyNet noise sample is [array([-0.8187178], dtype=float32), 0.12106098]. 
=============================================
[2019-03-26 14:54:37,231] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.3581366e-08 1.0000000e+00 3.2412368e-11 3.9896686e-09 1.6365184e-11], sum to 1.0000
[2019-03-26 14:54:37,238] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9212
[2019-03-26 14:54:37,243] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2714440.912865439 W.
[2019-03-26 14:54:37,248] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [35.66666666666667, 54.0, 1.0, 2.0, 0.6526980044417023, 1.0, 2.0, 0.6469390417351139, 1.0, 1.0, 1.03, 7.005094002734092, 6.9112, 170.5573041426782, 2714440.912865439, 2647180.819343173, 506804.4916941272], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4189200.0000, 
sim time next is 4189800.0000, 
raw observation next is [35.83333333333333, 53.5, 1.0, 2.0, 0.9645695522426098, 1.0, 2.0, 0.9645695522426098, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2698090.311495224, 2698090.311495223, 507949.6318144888], 
processed observation next is [1.0, 0.4782608695652174, 0.8973143759873615, 0.535, 1.0, 1.0, 0.957312713545313, 1.0, 1.0, 0.957312713545313, 0.0, 0.5, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.7494695309708955, 0.7494695309708953, 0.7581337788275953], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.1220737], dtype=float32), -0.5747614]. 
=============================================
[2019-03-26 14:54:39,612] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-26 14:54:39,614] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 14:54:39,614] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 14:54:39,615] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 14:54:39,616] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 14:54:39,617] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:54:39,617] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:54:39,615] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:54:39,617] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 14:54:39,618] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:54:39,619] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:54:39,635] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run14
[2019-03-26 14:54:39,636] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run14
[2019-03-26 14:54:39,651] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run14
[2019-03-26 14:54:39,653] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run14
[2019-03-26 14:54:39,715] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run14
[2019-03-26 14:55:15,008] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.07012409], dtype=float32), 0.06360349]
[2019-03-26 14:55:15,010] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.6, 91.5, 1.0, 2.0, 0.4731612297393932, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 671620.3294236748, 671620.3294236754, 180841.7233162574]
[2019-03-26 14:55:15,010] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 14:55:15,013] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [8.3578278e-13 1.0000000e+00 2.7478702e-15 7.5696152e-17 1.6025018e-21], sampled 0.9584874789882138
[2019-03-26 14:55:49,731] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.07012409], dtype=float32), 0.06360349]
[2019-03-26 14:55:49,731] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [31.87292646, 72.70576691, 1.0, 2.0, 0.599826364515529, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 838219.1895978533, 838219.1895978533, 200714.8597182889]
[2019-03-26 14:55:49,733] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 14:55:49,734] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [9.7160756e-13 1.0000000e+00 3.3624483e-15 8.9781396e-17 1.9891335e-21], sampled 0.06989179083351771
[2019-03-26 14:55:59,901] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.07012409], dtype=float32), 0.06360349]
[2019-03-26 14:55:59,902] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.76666666666667, 90.0, 1.0, 2.0, 0.5384643945517558, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 752439.3674601886, 752439.367460188, 189841.7069438901]
[2019-03-26 14:55:59,904] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 14:55:59,909] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [4.4369383e-13 1.0000000e+00 1.3528579e-15 3.8230193e-17 6.7286094e-22], sampled 0.2112665037332987
[2019-03-26 14:56:18,195] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.07012409], dtype=float32), 0.06360349]
[2019-03-26 14:56:18,196] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.61437369333333, 47.93677376333333, 1.0, 2.0, 0.2945406238597647, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 473459.9156894538, 473459.9156894544, 165200.7747598]
[2019-03-26 14:56:18,198] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 14:56:18,200] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.5414097e-11 1.0000000e+00 8.8875115e-14 2.0055896e-15 7.5186944e-20], sampled 0.4538815039090133
[2019-03-26 14:56:19,308] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.07012409], dtype=float32), 0.06360349]
[2019-03-26 14:56:19,309] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.76666666666667, 72.0, 1.0, 2.0, 0.549095747241264, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 767300.7726579368, 767300.7726579361, 191645.0808192833]
[2019-03-26 14:56:19,311] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 14:56:19,314] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.4515537e-12 1.0000000e+00 5.6140539e-15 9.7064616e-17 2.0008152e-21], sampled 0.8213687371087668
[2019-03-26 14:56:33,217] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7996.8169 3007604825.0712 1766.0000
[2019-03-26 14:56:33,304] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.7167 2779131942.0695 933.0000
[2019-03-26 14:56:33,408] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.1684 3164027848.4855 1778.0000
[2019-03-26 14:56:33,466] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.0653 2927317329.7462 1338.0000
[2019-03-26 14:56:33,551] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.6119 2842427357.4275 1131.0000
[2019-03-26 14:56:34,566] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 325000, evaluation results [325000.0, 7884.16835844559, 3164027848.485504, 1778.0, 8255.065342017213, 2927317329.746172, 1338.0, 8660.716715102415, 2779131942.069542, 933.0, 7996.816940778225, 3007604825.071238, 1766.0, 8497.61193292354, 2842427357.427519, 1131.0]
[2019-03-26 14:56:37,333] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.4829593e-09 1.0000000e+00 9.2127542e-11 4.6487923e-08 5.3922045e-10], sum to 1.0000
[2019-03-26 14:56:37,340] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2728
[2019-03-26 14:56:37,347] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 3437362.376763312 W.
[2019-03-26 14:56:37,353] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [38.0, 47.0, 1.0, 2.0, 0.9968155816987803, 1.0, 2.0, 0.8189978303636527, 1.0, 1.0, 1.03, 7.005121147468668, 6.9112, 170.5573041426782, 3437362.376763312, 3370082.838363491, 631491.6616453939], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4290000.0000, 
sim time next is 4290600.0000, 
raw observation next is [38.0, 46.0, 1.0, 2.0, 0.8571112443067193, 1.0, 2.0, 0.7491456616676221, 1.0, 2.0, 1.03, 7.005110123503014, 6.9112, 170.5573041426782, 3143821.34708386, 3076549.705599064, 575546.2923005059], 
processed observation next is [1.0, 0.6521739130434783, 1.0, 0.46, 1.0, 1.0, 0.8278448726586979, 1.0, 1.0, 0.6977658574308699, 1.0, 1.0, 1.0365853658536586, 0.00939101235030142, 0.0, 0.8375144448122397, 0.8732837075232944, 0.8545971404441844, 0.8590243168664268], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.19303912], dtype=float32), 0.060644243]. 
=============================================
[2019-03-26 14:56:37,949] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.8468491e-12 1.0000000e+00 1.0818112e-14 3.4888139e-14 1.0847223e-18], sum to 1.0000
[2019-03-26 14:56:37,957] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9672
[2019-03-26 14:56:37,963] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [36.0, 50.0, 1.0, 2.0, 0.5702680169259311, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 796897.7837683539, 796897.7837683539, 195338.9931550254], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4301400.0000, 
sim time next is 4302000.0000, 
raw observation next is [36.0, 50.0, 1.0, 2.0, 0.5713963860043857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 798475.1697896112, 798475.169789612, 195539.38747306], 
processed observation next is [1.0, 0.8260869565217391, 0.9052132701421801, 0.5, 1.0, 1.0, 0.48361010361974177, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.221798658274892, 0.2217986582748922, 0.2918498320493433], 
reward next is 0.7082, 
noisyNet noise sample is [array([-0.02599673], dtype=float32), -1.0700963]. 
=============================================
[2019-03-26 14:56:37,971] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[51.852802]
 [50.63448 ]
 [48.81946 ]
 [46.581497]
 [44.907825]], R is [[53.61022949]
 [53.78257751]
 [53.95332718]
 [54.12205887]
 [54.2886734 ]].
[2019-03-26 14:56:41,177] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.0244810e-10 1.0000000e+00 3.2270887e-13 2.1429835e-12 1.9902401e-15], sum to 1.0000
[2019-03-26 14:56:41,183] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5237
[2019-03-26 14:56:41,189] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 89.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.019217092028796, 6.9112, 168.9122249080843, 1530438.117782574, 1453807.406943296, 311355.8210526179], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4335000.0000, 
sim time next is 4335600.0000, 
raw observation next is [29.0, 89.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.408407804026254, 6.9112, 168.9100699928259, 1806726.823566978, 1453996.522654952, 311355.9088151161], 
processed observation next is [1.0, 0.17391304347826086, 0.5734597156398105, 0.89, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0497207804026254, 0.0, 0.8294257710294082, 0.5018685621019383, 0.4038879229597089, 0.4647103116643524], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.0428072], dtype=float32), 0.42840093]. 
=============================================
[2019-03-26 14:56:47,434] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.6910171e-12 1.0000000e+00 7.4758425e-15 9.1961044e-16 2.3866188e-21], sum to 1.0000
[2019-03-26 14:56:47,446] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4395
[2019-03-26 14:56:47,452] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.83333333333334, 79.0, 1.0, 2.0, 0.6108858615684686, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 853680.3441971155, 853680.3441971162, 202792.2240623315], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4438200.0000, 
sim time next is 4438800.0000, 
raw observation next is [31.0, 79.0, 1.0, 2.0, 0.6172868673671312, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 862629.0402382638, 862629.0402382644, 204011.4484585144], 
processed observation next is [0.0, 0.391304347826087, 0.6682464454976303, 0.79, 1.0, 1.0, 0.538899840201363, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.23961917784396217, 0.23961917784396233, 0.30449469919181255], 
reward next is 0.6955, 
noisyNet noise sample is [array([1.2764223], dtype=float32), -0.7484141]. 
=============================================
[2019-03-26 14:56:51,461] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2391624e-11 1.0000000e+00 8.5801612e-14 3.0800744e-16 4.7953506e-21], sum to 1.0000
[2019-03-26 14:56:51,468] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4092
[2019-03-26 14:56:51,476] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 88.16666666666667, 1.0, 2.0, 0.4983186439381167, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 696322.1120910884, 696322.1120910884, 183332.8751632916], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4510200.0000, 
sim time next is 4510800.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.5025154840471426, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 702188.4758776496, 702188.4758776496, 183990.9712561955], 
processed observation next is [0.0, 0.21739130434782608, 0.4312796208530806, 0.89, 1.0, 1.0, 0.40062106511703927, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19505235441045823, 0.19505235441045823, 0.27461338993462014], 
reward next is 0.7254, 
noisyNet noise sample is [array([0.3335227], dtype=float32), -2.420003]. 
=============================================
[2019-03-26 14:56:53,381] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.1283087e-13 1.0000000e+00 1.8939132e-15 1.7358967e-17 5.6527369e-22], sum to 1.0000
[2019-03-26 14:56:53,390] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8719
[2019-03-26 14:56:53,396] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.33333333333333, 54.33333333333333, 1.0, 2.0, 0.5366833990020478, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 749949.7613754357, 749949.7613754357, 189543.3848459643], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4542000.0000, 
sim time next is 4542600.0000, 
raw observation next is [33.66666666666667, 52.16666666666667, 1.0, 2.0, 0.5310261909823446, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 742041.7401686083, 742041.7401686077, 188600.2116308676], 
processed observation next is [0.0, 0.5652173913043478, 0.7946287519747238, 0.5216666666666667, 1.0, 1.0, 0.43497131443655973, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20612270560239118, 0.20612270560239102, 0.2814928531803994], 
reward next is 0.7185, 
noisyNet noise sample is [array([0.8993493], dtype=float32), -1.8587439]. 
=============================================
[2019-03-26 14:56:57,003] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.5795563e-10 1.0000000e+00 3.3751565e-12 1.2944870e-10 1.4984445e-13], sum to 1.0000
[2019-03-26 14:56:57,014] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1679
[2019-03-26 14:56:57,021] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2533941.50699144 W.
[2019-03-26 14:56:57,026] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [34.16666666666667, 62.5, 1.0, 2.0, 0.9059456651043564, 1.0, 2.0, 0.9059456651043564, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2533941.50699144, 2533941.50699144, 474756.3939967329], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4626600.0000, 
sim time next is 4627200.0000, 
raw observation next is [34.33333333333334, 62.00000000000001, 1.0, 2.0, 1.008845247164987, 1.0, 2.0, 1.008845247164987, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2822078.004760294, 2822078.004760294, 534361.4738933126], 
processed observation next is [1.0, 0.5652173913043478, 0.8262243285939973, 0.6200000000000001, 1.0, 1.0, 1.0106569242951648, 1.0, 1.0, 1.0106569242951648, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7839105568778595, 0.7839105568778595, 0.7975544386467353], 
reward next is 0.2024, 
noisyNet noise sample is [array([-0.304692], dtype=float32), -1.0879856]. 
=============================================
[2019-03-26 14:57:04,258] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.8427642e-12 1.0000000e+00 6.8658212e-15 7.8773461e-16 3.8857641e-21], sum to 1.0000
[2019-03-26 14:57:04,271] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2173
[2019-03-26 14:57:04,276] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.16666666666666, 87.33333333333334, 1.0, 2.0, 0.7132153483236026, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 996747.4373574523, 996747.4373574523, 223723.5666201256], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4864200.0000, 
sim time next is 4864800.0000, 
raw observation next is [27.33333333333334, 85.66666666666667, 1.0, 2.0, 0.6910342311826162, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 965734.3298855813, 965734.3298855813, 218921.6578950011], 
processed observation next is [1.0, 0.30434782608695654, 0.4944707740916275, 0.8566666666666667, 1.0, 1.0, 0.6277520857621882, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2682595360793281, 0.2682595360793281, 0.3267487431268673], 
reward next is 0.6733, 
noisyNet noise sample is [array([-0.79443794], dtype=float32), 0.51980066]. 
=============================================
[2019-03-26 14:57:12,942] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.23798988e-09 1.00000000e+00 1.95180521e-11 3.71470188e-10
 1.03272886e-13], sum to 1.0000
[2019-03-26 14:57:12,949] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2604
[2019-03-26 14:57:12,953] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.66666666666667, 67.33333333333334, 1.0, 2.0, 0.4704480831322498, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129565104281, 657365.3267543977, 657365.3267543977, 179097.3829318434], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4900800.0000, 
sim time next is 4901400.0000, 
raw observation next is [29.5, 68.0, 1.0, 2.0, 0.4640638059721343, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 648441.7420562332, 648441.7420562332, 178159.288024535], 
processed observation next is [1.0, 0.7391304347826086, 0.5971563981042655, 0.68, 1.0, 1.0, 0.3542937421351016, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18012270612673145, 0.18012270612673145, 0.2659093851112463], 
reward next is 0.7341, 
noisyNet noise sample is [array([-0.01534026], dtype=float32), -1.2580022]. 
=============================================
[2019-03-26 14:57:16,638] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.6233594e-13 1.0000000e+00 1.5476196e-15 9.0256999e-17 4.4953369e-22], sum to 1.0000
[2019-03-26 14:57:16,645] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9171
[2019-03-26 14:57:16,648] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.16666666666667, 72.66666666666667, 1.0, 2.0, 1.018820496292723, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1424129.483488284, 1424129.483488284, 304711.7909942135], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4954200.0000, 
sim time next is 4954800.0000, 
raw observation next is [29.33333333333334, 71.33333333333334, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 9.410357623260555, 6.9112, 168.8985381075596, 3227705.609209482, 1454868.519119384, 308148.565598272], 
processed observation next is [1.0, 0.34782608695652173, 0.5892575039494474, 0.7133333333333334, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.24991576232605556, 0.0, 0.8293691441934308, 0.8965848914470783, 0.4041301441998289, 0.4599232322362269], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.04891475], dtype=float32), -0.06603049]. 
=============================================
[2019-03-26 14:57:18,261] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.1524440e-09 1.0000000e+00 1.0514214e-10 2.2636222e-09 2.7018073e-12], sum to 1.0000
[2019-03-26 14:57:18,273] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8255
[2019-03-26 14:57:18,280] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2122435.510028468 W.
[2019-03-26 14:57:18,285] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.83333333333334, 63.0, 1.0, 2.0, 0.8767086137139501, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.978126363081209, 6.9112, 168.9125015827543, 2122435.510028468, 2074955.772506961, 428656.3644822806], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4979400.0000, 
sim time next is 4980000.0000, 
raw observation next is [30.86666666666667, 63.00000000000001, 1.0, 2.0, 0.7313282978706772, 1.0, 1.0, 0.7313282978706772, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2045112.046658989, 2045112.046658989, 387819.1321889916], 
processed observation next is [1.0, 0.6521739130434783, 0.6619273301737759, 0.6300000000000001, 1.0, 1.0, 0.6762991540610569, 1.0, 0.5, 0.6762991540610569, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5680866796274969, 0.5680866796274969, 0.5788345256552113], 
reward next is 0.4212, 
noisyNet noise sample is [array([-0.4177791], dtype=float32), 1.9284807]. 
=============================================
[2019-03-26 14:57:18,297] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[37.544064]
 [36.798035]
 [36.154354]
 [37.485497]
 [38.1442  ]], R is [[37.78582764]
 [37.43355179]
 [37.05921555]
 [37.05638123]
 [37.05049133]].
[2019-03-26 14:57:21,714] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.3717580e-12 1.0000000e+00 4.7947613e-15 6.0983206e-16 1.0302693e-21], sum to 1.0000
[2019-03-26 14:57:21,721] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0802
[2019-03-26 14:57:21,727] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666667, 89.0, 1.0, 2.0, 0.4911405031623354, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 686288.5466313515, 686288.5466313515, 182219.3397804183], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5023200.0000, 
sim time next is 5023800.0000, 
raw observation next is [25.5, 89.0, 1.0, 2.0, 0.4876549488271359, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 681416.4922489817, 681416.4922489817, 181683.9927220132], 
processed observation next is [0.0, 0.13043478260869565, 0.40758293838862564, 0.89, 1.0, 1.0, 0.38271680581582634, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18928235895805048, 0.18928235895805048, 0.27117013839106446], 
reward next is 0.7288, 
noisyNet noise sample is [array([-0.41532508], dtype=float32), 0.69016695]. 
=============================================
[2019-03-26 14:57:28,545] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.5484248e-13 1.0000000e+00 9.7062077e-16 5.4674349e-17 4.4176794e-23], sum to 1.0000
[2019-03-26 14:57:28,554] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1093
[2019-03-26 14:57:28,558] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.66666666666667, 64.0, 1.0, 2.0, 0.5497218410204334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 768175.986051796, 768175.9860517967, 191753.2879752476], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5156400.0000, 
sim time next is 5157000.0000, 
raw observation next is [31.5, 64.5, 1.0, 2.0, 0.5469941449358731, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 764362.9584741134, 764362.9584741141, 191286.8474243076], 
processed observation next is [0.0, 0.6956521739130435, 0.6919431279620853, 0.645, 1.0, 1.0, 0.45420981317575065, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21232304402058705, 0.21232304402058724, 0.28550275734971287], 
reward next is 0.7145, 
noisyNet noise sample is [array([0.58482164], dtype=float32), -0.14453009]. 
=============================================
[2019-03-26 14:57:28,570] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[76.38949]
 [76.37577]
 [76.34076]
 [76.3167 ]
 [76.28184]], R is [[76.3440094 ]
 [76.29436493]
 [76.24369812]
 [76.19458008]
 [76.14614868]].
[2019-03-26 14:57:29,355] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-26 14:57:29,357] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 14:57:29,358] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 14:57:29,358] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 14:57:29,359] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 14:57:29,360] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 14:57:29,361] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:57:29,360] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:57:29,363] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:57:29,363] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:57:29,359] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:57:29,380] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run15
[2019-03-26 14:57:29,396] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run15
[2019-03-26 14:57:29,416] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run15
[2019-03-26 14:57:29,417] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run15
[2019-03-26 14:57:29,450] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run15
[2019-03-26 14:57:32,854] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.07826064], dtype=float32), 0.06865512]
[2019-03-26 14:57:32,855] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [21.89678323166667, 94.74842924666669, 1.0, 2.0, 0.3765524284388229, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 574314.4695740738, 574314.4695740745, 172577.0324265143]
[2019-03-26 14:57:32,856] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 14:57:32,860] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.41851309e-12 1.00000000e+00 1.06440566e-14 4.45837698e-16
 1.37858959e-21], sampled 0.19016106109601305
[2019-03-26 14:57:45,048] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.07826064], dtype=float32), 0.06865512]
[2019-03-26 14:57:45,052] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [21.65, 82.5, 1.0, 2.0, 0.2928275364306444, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 470887.5936870574, 470887.593687058, 165021.4646470098]
[2019-03-26 14:57:45,053] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 14:57:45,055] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [7.0687141e-12 1.0000000e+00 3.1045428e-14 7.6846593e-16 2.2241406e-21], sampled 0.03484690877632546
[2019-03-26 14:58:02,044] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.07826064], dtype=float32), 0.06865512]
[2019-03-26 14:58:02,046] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [31.59634563, 66.59292370333333, 1.0, 2.0, 0.6934685810411958, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 969137.9353910635, 969137.9353910635, 219444.195705855]
[2019-03-26 14:58:02,048] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 14:58:02,051] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.6649660e-13 1.0000000e+00 5.5772302e-16 2.0428752e-17 2.2717115e-23], sampled 0.9171073537877669
[2019-03-26 14:58:02,647] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.07826064], dtype=float32), 0.06865512]
[2019-03-26 14:58:02,649] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.32294098666667, 91.38580569, 1.0, 2.0, 0.6126748705206885, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 856181.3962565799, 856181.3962565799, 203130.0646316416]
[2019-03-26 14:58:02,649] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 14:58:02,652] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.5773866e-13 1.0000000e+00 8.7566600e-16 3.7396339e-17 6.6205499e-23], sampled 0.27609143923750834
[2019-03-26 14:59:00,114] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.07826064], dtype=float32), 0.06865512]
[2019-03-26 14:59:00,116] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.31788863, 57.62215844, 1.0, 2.0, 0.435350624837725, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 636873.5771671908, 636873.5771671908, 177725.722627966]
[2019-03-26 14:59:00,117] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 14:59:00,119] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0076198e-12 1.0000000e+00 2.6900483e-15 6.6286059e-17 9.4161978e-23], sampled 0.0889156461441385
[2019-03-26 14:59:10,985] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.07826064], dtype=float32), 0.06865512]
[2019-03-26 14:59:10,985] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.42708173666666, 78.74294420333334, 1.0, 2.0, 0.5151120855769086, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 763279.4327791577, 763279.4327791577, 191417.6733371905]
[2019-03-26 14:59:10,987] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 14:59:10,990] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.5158511e-12 1.0000000e+00 4.7123115e-15 1.2317577e-16 2.2769267e-22], sampled 0.5152198638042239
[2019-03-26 14:59:22,892] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.6119 2842427357.4275 1131.0000
[2019-03-26 14:59:23,254] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.1701 3164024398.2340 1778.0000
[2019-03-26 14:59:23,416] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.3694 2779190338.1949 933.0000
[2019-03-26 14:59:23,449] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.6685 2927411015.0961 1338.0000
[2019-03-26 14:59:23,577] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7999.0502 3007584666.7691 1766.0000
[2019-03-26 14:59:24,594] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 350000, evaluation results [350000.0, 7884.17012812901, 3164024398.2339783, 1778.0, 8253.66851019716, 2927411015.0960665, 1338.0, 8661.369356548688, 2779190338.194891, 933.0, 7999.050242421542, 3007584666.769063, 1766.0, 8497.61193292354, 2842427357.427519, 1131.0]
[2019-03-26 14:59:25,327] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.4867074e-09 1.0000000e+00 1.1233208e-11 9.4172350e-09 2.2946490e-11], sum to 1.0000
[2019-03-26 14:59:25,339] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4385
[2019-03-26 14:59:25,348] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2898607.402413543 W.
[2019-03-26 14:59:25,353] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [36.06666666666666, 52.5, 1.0, 2.0, 0.7403819346765849, 1.0, 2.0, 0.6907810068525551, 1.0, 2.0, 1.03, 7.005100916450018, 6.9112, 170.5573041426782, 2898607.402413543, 2831342.356315327, 534387.480303869], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5309400.0000, 
sim time next is 5310000.0000, 
raw observation next is [36.4, 51.0, 1.0, 2.0, 1.013625042072214, 1.0, 2.0, 1.013625042072214, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2835463.866507696, 2835463.866507695, 537278.2064487841], 
processed observation next is [1.0, 0.4782608695652174, 0.924170616113744, 0.51, 1.0, 1.0, 1.0164157133400167, 1.0, 1.0, 1.0164157133400167, 0.0, 0.5, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.7876288518076934, 0.787628851807693, 0.8019077708190807], 
reward next is 0.1981, 
noisyNet noise sample is [array([1.2935017], dtype=float32), 0.5214402]. 
=============================================
[2019-03-26 14:59:25,374] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[36.664387]
 [37.90407 ]
 [39.022526]
 [40.811348]
 [42.361446]], R is [[36.69157028]
 [36.32465363]
 [35.96140671]
 [35.60179138]
 [35.24577332]].
[2019-03-26 14:59:29,706] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.1519904e-13 1.0000000e+00 1.6476650e-15 2.9985627e-15 4.5516090e-21], sum to 1.0000
[2019-03-26 14:59:29,714] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9693
[2019-03-26 14:59:29,719] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.6, 86.66666666666667, 1.0, 2.0, 0.5773297826347883, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 806769.7079644799, 806769.7079644799, 196598.8073998505], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5276400.0000, 
sim time next is 5277000.0000, 
raw observation next is [28.6, 86.83333333333333, 1.0, 2.0, 0.5786719237302794, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 808645.950957457, 808645.950957457, 196840.0829238772], 
processed observation next is [1.0, 0.043478260869565216, 0.5545023696682465, 0.8683333333333333, 1.0, 1.0, 0.4923758117232282, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22462387526596025, 0.22462387526596025, 0.2937911685431003], 
reward next is 0.7062, 
noisyNet noise sample is [array([-1.6288025], dtype=float32), 0.46443763]. 
=============================================
[2019-03-26 14:59:29,734] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[66.83983 ]
 [66.87717 ]
 [66.987625]
 [67.06807 ]
 [67.27722 ]], R is [[66.86404419]
 [66.90196991]
 [66.93972015]
 [66.97738647]
 [67.01506042]].
[2019-03-26 14:59:30,141] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.4949201e-12 1.0000000e+00 1.2675130e-15 1.3582713e-16 8.9024738e-22], sum to 1.0000
[2019-03-26 14:59:30,151] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3475
[2019-03-26 14:59:30,155] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.5, 83.5, 1.0, 2.0, 0.5571331071696386, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 778536.2130984041, 778536.2130984041, 193031.930663615], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5268600.0000, 
sim time next is 5269200.0000, 
raw observation next is [28.5, 83.66666666666667, 1.0, 2.0, 0.5578692833215395, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 779565.3210560099, 779565.3210560093, 193159.8345184762], 
processed observation next is [1.0, 1.0, 0.5497630331753555, 0.8366666666666667, 1.0, 1.0, 0.4673123895440235, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2165459225155583, 0.21654592251555813, 0.2882982604753376], 
reward next is 0.7117, 
noisyNet noise sample is [array([1.3045726], dtype=float32), 0.2145943]. 
=============================================
[2019-03-26 14:59:32,043] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.2420512e-12 1.0000000e+00 2.0881592e-14 1.8148540e-14 4.6055277e-20], sum to 1.0000
[2019-03-26 14:59:32,052] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0750
[2019-03-26 14:59:32,056] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.6, 87.0, 1.0, 2.0, 0.9857881139295678, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.9129565104309, 1377926.133029666, 1377926.133029666, 294629.1731730126], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5280600.0000, 
sim time next is 5281200.0000, 
raw observation next is [28.6, 87.0, 1.0, 2.0, 0.9612548849433319, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1343612.096018051, 1343612.096018051, 287346.5377230672], 
processed observation next is [1.0, 0.13043478260869565, 0.5545023696682465, 0.87, 1.0, 1.0, 0.9533191384859421, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3732255822272364, 0.3732255822272364, 0.42887542943741375], 
reward next is 0.5711, 
noisyNet noise sample is [array([0.981619], dtype=float32), -0.8951684]. 
=============================================
[2019-03-26 14:59:33,149] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.9115052e-12 1.0000000e+00 1.8819015e-14 1.8977543e-14 3.4318217e-19], sum to 1.0000
[2019-03-26 14:59:33,158] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0817
[2019-03-26 14:59:33,168] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2518165.226687071 W.
[2019-03-26 14:59:33,173] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.83333333333333, 73.66666666666667, 1.0, 2.0, 0.9003109395059847, 1.0, 2.0, 0.9003109395059847, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2518165.226687071, 2518165.22668707, 471671.2712503975], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5301600.0000, 
sim time next is 5302200.0000, 
raw observation next is [32.16666666666667, 71.83333333333333, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 8.0259225337138, 6.9112, 168.9067422210627, 3075200.920128295, 2284407.483198267, 473478.7091269688], 
processed observation next is [1.0, 0.34782608695652173, 0.7235387045813588, 0.7183333333333333, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.11147225337137998, 0.0, 0.8294094301465903, 0.8542224778134153, 0.6345576342217408, 0.7066846404880132], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5007842], dtype=float32), 0.3794705]. 
=============================================
[2019-03-26 14:59:35,604] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.7275775e-12 1.0000000e+00 5.2693310e-15 7.8815882e-15 3.7232165e-20], sum to 1.0000
[2019-03-26 14:59:35,611] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3896
[2019-03-26 14:59:35,621] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.25, 73.5, 1.0, 2.0, 0.6236263006865378, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 871491.7314012394, 871491.7314012387, 205231.2299993737], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5340600.0000, 
sim time next is 5341200.0000, 
raw observation next is [32.0, 75.0, 1.0, 2.0, 0.6245572213472688, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 872793.1887043887, 872793.1887043887, 205411.2944045779], 
processed observation next is [1.0, 0.8260869565217391, 0.7156398104265403, 0.75, 1.0, 1.0, 0.5476593028280347, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.24244255241788573, 0.24244255241788573, 0.30658402149937], 
reward next is 0.6934, 
noisyNet noise sample is [array([1.2451086], dtype=float32), -1.0601455]. 
=============================================
[2019-03-26 14:59:43,565] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9954578e-09 9.9999988e-01 1.3208797e-10 1.4020408e-07 3.3617557e-11], sum to 1.0000
[2019-03-26 14:59:43,574] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9502
[2019-03-26 14:59:43,584] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2903894.198868714 W.
[2019-03-26 14:59:43,588] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [36.76666666666667, 48.0, 1.0, 2.0, 0.7428988526062834, 1.0, 2.0, 0.6920394658174042, 1.0, 2.0, 1.03, 7.005101114934431, 6.9112, 170.5573041426782, 2903894.198868714, 2836629.01058804, 535220.9857937876], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5492400.0000, 
sim time next is 5493000.0000, 
raw observation next is [36.88333333333333, 47.0, 1.0, 2.0, 0.7317386232571733, 1.0, 2.0, 0.6864593511428494, 1.0, 2.0, 1.03, 7.005100234850355, 6.9112, 170.5573041426782, 2880452.261612726, 2813187.703772075, 531541.0285989232], 
processed observation next is [1.0, 0.5652173913043478, 0.9470774091627172, 0.47, 1.0, 1.0, 0.6767935219965944, 1.0, 1.0, 0.6222401820998186, 1.0, 1.0, 1.0365853658536586, 0.009390023485035481, 0.0, 0.8375144448122397, 0.8001256282257572, 0.7814410288255764, 0.793344818804363], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.31452927], dtype=float32), -0.13324201]. 
=============================================
[2019-03-26 14:59:43,603] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[30.364868]
 [30.931322]
 [31.398565]
 [30.6799  ]
 [29.607693]], R is [[29.51760674]
 [29.22243118]
 [28.9302063 ]
 [28.64090538]
 [28.71874619]].
[2019-03-26 14:59:45,639] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.0513681e-13 1.0000000e+00 3.2112607e-16 1.2923695e-15 1.5310440e-21], sum to 1.0000
[2019-03-26 14:59:45,653] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9676
[2019-03-26 14:59:45,660] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.25, 84.0, 1.0, 2.0, 0.9526288836298518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1331547.379096038, 1331547.379096038, 284826.1462349914], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5556600.0000, 
sim time next is 5557200.0000, 
raw observation next is [28.43333333333333, 83.33333333333334, 1.0, 2.0, 0.8754328606615432, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1223583.621110263, 1223583.621110263, 263270.877240783], 
processed observation next is [1.0, 0.30434782608695654, 0.546603475513428, 0.8333333333333335, 1.0, 1.0, 0.849919109230775, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.33988433919729527, 0.33988433919729527, 0.3929416078220642], 
reward next is 0.6071, 
noisyNet noise sample is [array([-1.2545499], dtype=float32), -0.9098929]. 
=============================================
[2019-03-26 14:59:51,126] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.6270427e-13 1.0000000e+00 1.5728248e-15 2.6541063e-16 4.1178421e-22], sum to 1.0000
[2019-03-26 14:59:51,138] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9713
[2019-03-26 14:59:51,147] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [34.0, 53.0, 1.0, 2.0, 0.5359444086305802, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 748916.7481963548, 748916.7481963541, 189420.552626323], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5756400.0000, 
sim time next is 5757000.0000, 
raw observation next is [33.81666666666667, 53.83333333333334, 1.0, 2.0, 0.5579740119941156, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 779711.722389029, 779711.722389029, 193177.2254882831], 
processed observation next is [0.0, 0.6521739130434783, 0.8017377567140602, 0.5383333333333334, 1.0, 1.0, 0.4674385686676091, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21658658955250806, 0.21658658955250806, 0.28832421714669115], 
reward next is 0.7117, 
noisyNet noise sample is [array([-0.631814], dtype=float32), -0.25515816]. 
=============================================
[2019-03-26 14:59:51,156] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[71.48439 ]
 [71.460495]
 [71.43359 ]
 [71.40564 ]
 [71.38491 ]], R is [[71.52680969]
 [71.52882385]
 [71.53214264]
 [71.53652954]
 [71.54212952]].
[2019-03-26 14:59:53,553] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.6775461e-12 1.0000000e+00 1.3451858e-14 3.8874048e-16 5.5794049e-22], sum to 1.0000
[2019-03-26 14:59:53,564] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7542
[2019-03-26 14:59:53,571] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.75, 65.33333333333334, 1.0, 2.0, 0.5579412373779853, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 779665.906399961, 779665.9063999616, 193172.5295775913], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5658600.0000, 
sim time next is 5659200.0000, 
raw observation next is [31.8, 65.0, 1.0, 2.0, 0.5583092521566168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 780180.358338228, 780180.358338228, 193236.4637166237], 
processed observation next is [0.0, 0.5217391304347826, 0.7061611374407584, 0.65, 1.0, 1.0, 0.4678424724778515, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21671676620506333, 0.21671676620506333, 0.2884126324128712], 
reward next is 0.7116, 
noisyNet noise sample is [array([-1.6168581], dtype=float32), -0.45563933]. 
=============================================
[2019-03-26 15:00:10,790] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.2389437e-13 1.0000000e+00 1.7592575e-15 2.9387697e-16 4.9532341e-22], sum to 1.0000
[2019-03-26 15:00:10,797] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1821
[2019-03-26 15:00:10,803] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.05, 91.5, 1.0, 2.0, 0.5514018941620689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 770524.5275837607, 770524.5275837613, 192041.4645244369], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5959800.0000, 
sim time next is 5960400.0000, 
raw observation next is [27.0, 91.33333333333334, 1.0, 2.0, 0.5486649305677026, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 766698.5365819472, 766698.5365819478, 191572.0490867477], 
processed observation next is [1.0, 1.0, 0.4786729857819906, 0.9133333333333334, 1.0, 1.0, 0.45622280791289466, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21297181571720755, 0.21297181571720772, 0.28592843147275776], 
reward next is 0.7141, 
noisyNet noise sample is [array([1.1033114], dtype=float32), 0.14038584]. 
=============================================
[2019-03-26 15:00:17,173] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.5138405e-12 1.0000000e+00 2.2627261e-15 3.1133157e-16 2.4870252e-22], sum to 1.0000
[2019-03-26 15:00:17,180] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6806
[2019-03-26 15:00:17,188] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.1, 93.0, 1.0, 2.0, 0.6839299149466307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 955801.4363278971, 955801.4363278977, 217414.0147875368], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6063600.0000, 
sim time next is 6064200.0000, 
raw observation next is [26.1, 93.0, 1.0, 2.0, 0.7299022786947874, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1020079.30127493, 1020079.30127493, 227431.2087076436], 
processed observation next is [1.0, 0.17391304347826086, 0.4360189573459717, 0.93, 1.0, 1.0, 0.6745810586684186, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.28335536146525836, 0.28335536146525836, 0.3394495652352889], 
reward next is 0.6606, 
noisyNet noise sample is [array([0.4813419], dtype=float32), 0.4493527]. 
=============================================
[2019-03-26 15:00:19,279] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.9804564e-09 1.0000000e+00 1.1234472e-11 1.8723693e-08 1.4546107e-12], sum to 1.0000
[2019-03-26 15:00:19,286] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9928
[2019-03-26 15:00:19,293] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2474760.047391124 W.
[2019-03-26 15:00:19,296] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.0, 65.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.163362963070194, 6.9112, 168.9116322350585, 2474760.047391124, 2295868.36512918, 476134.8134750656], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6091200.0000, 
sim time next is 6091800.0000, 
raw observation next is [31.01666666666667, 65.0, 1.0, 2.0, 0.8112363611801262, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.987468529737754, 6.9112, 168.9122971825167, 2030799.256862868, 1976691.948107772, 411317.257928736], 
processed observation next is [1.0, 0.5217391304347826, 0.6690363349131123, 0.65, 1.0, 1.0, 0.7725739291326822, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.007626852973775388, 0.0, 0.8294367075504019, 0.56411090468413, 0.5490810966966033, 0.6139063551175163], 
reward next is 0.0048, 
noisyNet noise sample is [array([0.9408329], dtype=float32), -0.22569387]. 
=============================================
[2019-03-26 15:00:19,553] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-26 15:00:19,556] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 15:00:19,557] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 15:00:19,558] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 15:00:19,560] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:00:19,560] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 15:00:19,560] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:00:19,559] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:00:19,561] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 15:00:19,575] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:00:19,575] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run16
[2019-03-26 15:00:19,576] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:00:19,598] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run16
[2019-03-26 15:00:19,598] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run16
[2019-03-26 15:00:19,613] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run16
[2019-03-26 15:00:19,647] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run16
[2019-03-26 15:00:47,661] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.07810551], dtype=float32), 0.065637924]
[2019-03-26 15:00:47,663] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.44083028, 80.14487927, 1.0, 2.0, 0.7329999328938693, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1024410.534520291, 1024410.534520291, 228132.5247173667]
[2019-03-26 15:00:47,664] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 15:00:47,668] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.3334121e-12 1.0000000e+00 7.2309797e-15 7.5030655e-16 2.8685825e-22], sampled 0.4146553851042286
[2019-03-26 15:00:50,221] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.07810551], dtype=float32), 0.065637924]
[2019-03-26 15:00:50,221] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.70112670166667, 74.48546383833333, 1.0, 2.0, 0.5444049072616693, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 760743.4936182126, 760743.4936182126, 190843.8316336174]
[2019-03-26 15:00:50,222] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 15:00:50,226] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.78057504e-12 1.00000000e+00 4.95400772e-15 3.35657716e-16
 1.03098434e-22], sampled 0.8596091018733717
[2019-03-26 15:00:59,008] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.07810551], dtype=float32), 0.065637924]
[2019-03-26 15:00:59,009] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.1, 67.0, 1.0, 2.0, 0.6617882067009979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 924844.622183735, 924844.6221837356, 212812.4383369125]
[2019-03-26 15:00:59,011] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:00:59,014] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.0172863e-12 1.0000000e+00 6.1179661e-15 5.2931004e-16 2.1193277e-22], sampled 0.1842512130463111
[2019-03-26 15:01:16,614] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.07810551], dtype=float32), 0.065637924]
[2019-03-26 15:01:16,616] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [34.0, 60.00000000000001, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 8.896190318055048, 6.9112, 168.9015517442391, 3693103.020948978, 2284977.652298467, 470787.2850159312]
[2019-03-26 15:01:16,617] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:01:16,622] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.2838506e-09 1.0000000e+00 1.5546998e-11 9.6740405e-10 5.5433516e-14], sampled 0.7396110042150879
[2019-03-26 15:01:16,623] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 0, 1] for the demand 3693103.020948978 W.
[2019-03-26 15:01:32,616] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.07810551], dtype=float32), 0.065637924]
[2019-03-26 15:01:32,617] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [30.2, 77.0, 1.0, 2.0, 0.5984152809031427, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 836246.5137404572, 836246.5137404572, 200450.0751113109]
[2019-03-26 15:01:32,618] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 15:01:32,622] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [5.4392065e-13 1.0000000e+00 1.1676120e-15 1.1187251e-16 2.3257344e-23], sampled 0.6960691118832759
[2019-03-26 15:01:39,213] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.07810551], dtype=float32), 0.065637924]
[2019-03-26 15:01:39,214] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [30.15243416, 80.66271835333333, 1.0, 2.0, 0.8719440266563965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1218704.514655144, 1218704.514655144, 262341.7852490819]
[2019-03-26 15:01:39,215] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 15:01:39,220] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.4331767e-12 1.0000000e+00 4.1931354e-15 4.4161786e-16 1.4736541e-22], sampled 0.21994885085611415
[2019-03-26 15:01:40,723] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.07810551], dtype=float32), 0.065637924]
[2019-03-26 15:01:40,724] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [28.26666666666667, 94.33333333333334, 1.0, 2.0, 0.6211657339153837, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 868051.7868588066, 868051.7868588066, 204754.888106096]
[2019-03-26 15:01:40,725] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:01:40,727] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.6725955e-13 1.0000000e+00 7.2426256e-16 6.7164968e-17 1.2081272e-23], sampled 0.18606412761630686
[2019-03-26 15:02:12,880] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8252.1880 2927394094.8332 1338.0000
[2019-03-26 15:02:13,331] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.6185 2779263580.8788 933.0000
[2019-03-26 15:02:13,352] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.1994 3007723883.0599 1766.0000
[2019-03-26 15:02:13,373] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8495.3918 2842522585.5351 1131.0000
[2019-03-26 15:02:13,383] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.9164 3164002230.9074 1778.0000
[2019-03-26 15:02:14,394] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 375000, evaluation results [375000.0, 7884.916440885027, 3164002230.907359, 1778.0, 8252.187983601876, 2927394094.833209, 1338.0, 8660.61847634223, 2779263580.878825, 933.0, 7998.199413945561, 3007723883.0599356, 1766.0, 8495.391843046742, 2842522585.5351014, 1131.0]
[2019-03-26 15:02:16,202] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.1237316e-12 1.0000000e+00 4.2098540e-14 3.1948545e-14 3.7083046e-20], sum to 1.0000
[2019-03-26 15:02:16,208] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3840
[2019-03-26 15:02:16,214] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.2, 86.0, 1.0, 2.0, 0.5259561978209946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 734954.6169261284, 734954.616926129, 187762.9799009111], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6120000.0000, 
sim time next is 6120600.0000, 
raw observation next is [27.2, 86.0, 1.0, 2.0, 0.5261270172167318, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 735193.3971707496, 735193.3971707496, 187791.0509652534], 
processed observation next is [1.0, 0.8695652173913043, 0.4881516587677725, 0.86, 1.0, 1.0, 0.42906869544184556, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.204220388102986, 0.204220388102986, 0.28028515069440807], 
reward next is 0.7197, 
noisyNet noise sample is [array([0.14868712], dtype=float32), -0.06943462]. 
=============================================
[2019-03-26 15:02:16,815] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.5023119e-12 1.0000000e+00 1.3778577e-15 2.9113097e-16 2.0865580e-22], sum to 1.0000
[2019-03-26 15:02:16,827] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9823
[2019-03-26 15:02:16,836] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.3, 87.0, 1.0, 2.0, 0.5357726194560292, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 748676.6092421319, 748676.6092421325, 189390.8111641897], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6130800.0000, 
sim time next is 6131400.0000, 
raw observation next is [27.26666666666667, 87.33333333333333, 1.0, 2.0, 0.5352399445195771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 747931.999209393, 747931.9992093937, 189301.8224338974], 
processed observation next is [1.0, 1.0, 0.4913112164297, 0.8733333333333333, 1.0, 1.0, 0.44004812592720133, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20775888866927586, 0.20775888866927605, 0.282540033483429], 
reward next is 0.7175, 
noisyNet noise sample is [array([1.4511667], dtype=float32), 0.55738384]. 
=============================================
[2019-03-26 15:02:19,928] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.6212295e-08 9.9999976e-01 4.0454276e-10 2.5834441e-07 2.7355233e-11], sum to 1.0000
[2019-03-26 15:02:19,943] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7511
[2019-03-26 15:02:19,952] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2229655.450031407 W.
[2019-03-26 15:02:19,956] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.63333333333333, 69.0, 1.0, 2.0, 0.9533120281883509, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.996421668211563, 6.9112, 168.9124496819924, 2229655.450031407, 2169196.446908283, 449631.957440207], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6183600.0000, 
sim time next is 6184200.0000, 
raw observation next is [30.71666666666667, 68.5, 1.0, 2.0, 0.8022102602284489, 1.0, 1.0, 0.8022102602284489, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2243531.803599854, 2243531.803599854, 420947.8515452304], 
processed observation next is [1.0, 0.5652173913043478, 0.6548183254344393, 0.685, 1.0, 1.0, 0.7616991087089745, 1.0, 0.5, 0.7616991087089745, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6232032787777372, 0.6232032787777372, 0.6282803754406424], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8060228], dtype=float32), -1.8374627]. 
=============================================
[2019-03-26 15:02:20,053] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.6582671e-10 1.0000000e+00 2.1788242e-12 3.5480820e-11 4.8366989e-16], sum to 1.0000
[2019-03-26 15:02:20,064] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8280
[2019-03-26 15:02:20,073] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.41666666666666, 79.50000000000001, 1.0, 2.0, 0.5292441657337011, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 739550.7190805513, 739550.7190805506, 188305.4077223027], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6199800.0000, 
sim time next is 6200400.0000, 
raw observation next is [28.33333333333334, 80.0, 1.0, 2.0, 0.5292859431617035, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 739609.1179921674, 739609.1179921674, 188312.3025866876], 
processed observation next is [1.0, 0.782608695652174, 0.5418641390205374, 0.8, 1.0, 1.0, 0.43287463031530543, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20544697722004648, 0.20544697722004648, 0.281063138189086], 
reward next is 0.7189, 
noisyNet noise sample is [array([-0.82528436], dtype=float32), 1.5900581]. 
=============================================
[2019-03-26 15:02:21,953] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.9488261e-12 1.0000000e+00 3.2023463e-14 3.6826435e-15 1.9424477e-21], sum to 1.0000
[2019-03-26 15:02:21,958] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3124
[2019-03-26 15:02:21,962] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.41666666666666, 91.00000000000001, 1.0, 2.0, 0.5217229452310012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 729037.1732101989, 729037.1732101989, 187069.8875459699], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6228600.0000, 
sim time next is 6229200.0000, 
raw observation next is [26.43333333333333, 91.0, 1.0, 2.0, 0.5218866625747017, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 729266.0245607866, 729266.0245607866, 187096.631130235], 
processed observation next is [0.0, 0.08695652173913043, 0.4518167456556081, 0.91, 1.0, 1.0, 0.42395983442735147, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2025738957113296, 0.2025738957113296, 0.2792487031794552], 
reward next is 0.7208, 
noisyNet noise sample is [array([-0.56963235], dtype=float32), -0.9422729]. 
=============================================
[2019-03-26 15:02:24,718] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.0535221e-12 1.0000000e+00 9.4783300e-15 5.0211114e-15 7.5489778e-22], sum to 1.0000
[2019-03-26 15:02:24,727] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0966
[2019-03-26 15:02:24,731] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.83333333333333, 80.5, 1.0, 2.0, 0.7271063113007177, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1016169.910760151, 1016169.910760152, 226803.8923243423], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6421800.0000, 
sim time next is 6422400.0000, 
raw observation next is [27.9, 80.0, 1.0, 2.0, 0.7369009601951348, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1029865.093325775, 1029865.093325775, 229010.8452252608], 
processed observation next is [1.0, 0.34782608695652173, 0.5213270142180094, 0.8, 1.0, 1.0, 0.6830132050543793, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2860736370349375, 0.2860736370349375, 0.34180723167949373], 
reward next is 0.6582, 
noisyNet noise sample is [array([-0.5986305], dtype=float32), 0.64325404]. 
=============================================
[2019-03-26 15:02:24,953] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.2199713e-12 1.0000000e+00 5.5074853e-15 1.6653447e-16 2.7898435e-23], sum to 1.0000
[2019-03-26 15:02:24,965] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5454
[2019-03-26 15:02:24,970] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.3, 85.0, 1.0, 2.0, 0.5282064399111439, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 738100.1267763721, 738100.1267763727, 188133.333147824], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6304800.0000, 
sim time next is 6305400.0000, 
raw observation next is [27.3, 85.0, 1.0, 2.0, 0.5277452520860603, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 737455.4527830102, 737455.4527830096, 188057.2809282167], 
processed observation next is [0.0, 1.0, 0.4928909952606636, 0.85, 1.0, 1.0, 0.4310183760073015, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2048487368841695, 0.20484873688416935, 0.2806825088480846], 
reward next is 0.7193, 
noisyNet noise sample is [array([0.27223715], dtype=float32), -0.08356598]. 
=============================================
[2019-03-26 15:02:29,767] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.2201243e-12 1.0000000e+00 6.0629733e-15 1.8643721e-16 5.0066695e-23], sum to 1.0000
[2019-03-26 15:02:29,779] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9174
[2019-03-26 15:02:29,785] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.43333333333333, 75.66666666666667, 1.0, 2.0, 0.5180286488138364, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 723873.1352450701, 723873.1352450701, 186468.7692289273], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6372600.0000, 
sim time next is 6373200.0000, 
raw observation next is [28.36666666666667, 76.33333333333334, 1.0, 2.0, 0.5198048218945126, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 726355.9391702501, 726355.9391702507, 186756.9989314036], 
processed observation next is [0.0, 0.782608695652174, 0.543443917851501, 0.7633333333333334, 1.0, 1.0, 0.42145159264399107, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2017655386584028, 0.20176553865840297, 0.2787417894498561], 
reward next is 0.7213, 
noisyNet noise sample is [array([0.2720093], dtype=float32), -0.18716931]. 
=============================================
[2019-03-26 15:02:30,091] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.3457562e-12 1.0000000e+00 5.3463318e-15 6.4013303e-16 2.4163616e-23], sum to 1.0000
[2019-03-26 15:02:30,098] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0037
[2019-03-26 15:02:30,101] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 63.0, 1.0, 2.0, 0.5250897365125621, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 733743.4330258347, 733743.433025834, 187620.4260151756], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6364800.0000, 
sim time next is 6365400.0000, 
raw observation next is [30.65, 64.5, 1.0, 2.0, 0.535164047575894, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 747825.9052312032, 747825.9052312026, 189288.0137192084], 
processed observation next is [0.0, 0.6956521739130435, 0.6516587677725119, 0.645, 1.0, 1.0, 0.43995668382637826, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20772941811977866, 0.2077294181197785, 0.28251942346150505], 
reward next is 0.7175, 
noisyNet noise sample is [array([-1.1473005], dtype=float32), -1.0612128]. 
=============================================
[2019-03-26 15:02:33,193] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.9318778e-12 1.0000000e+00 2.3549022e-14 4.1731192e-14 4.8560058e-21], sum to 1.0000
[2019-03-26 15:02:33,205] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0388
[2019-03-26 15:02:33,207] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.95, 73.66666666666667, 1.0, 2.0, 0.4850318140300224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 677749.9294035789, 677749.9294035796, 181284.0457140137], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6552600.0000, 
sim time next is 6553200.0000, 
raw observation next is [27.9, 74.33333333333334, 1.0, 2.0, 0.4874215611961167, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 681090.2673966298, 681090.2673966304, 181648.7144888597], 
processed observation next is [1.0, 0.8695652173913043, 0.5213270142180094, 0.7433333333333334, 1.0, 1.0, 0.3824356158989357, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18919174094350827, 0.18919174094350844, 0.2711174843117309], 
reward next is 0.7289, 
noisyNet noise sample is [array([0.17636672], dtype=float32), 0.9398646]. 
=============================================
[2019-03-26 15:02:39,879] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.7657509e-09 1.0000000e+00 1.9501865e-11 4.8877385e-10 6.9586882e-15], sum to 1.0000
[2019-03-26 15:02:39,885] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5327
[2019-03-26 15:02:39,891] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.3, 67.0, 1.0, 2.0, 0.4775000144673006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 667222.2081572149, 667222.2081572142, 180146.5940536036], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6544800.0000, 
sim time next is 6545400.0000, 
raw observation next is [29.18333333333333, 67.5, 1.0, 2.0, 0.4822364814289826, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 673842.6860054275, 673842.6860054282, 180860.1301192263], 
processed observation next is [1.0, 0.782608695652174, 0.5821484992101105, 0.675, 1.0, 1.0, 0.3761885318421478, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18717852389039652, 0.18717852389039671, 0.2699404927152631], 
reward next is 0.7301, 
noisyNet noise sample is [array([-0.8140069], dtype=float32), 0.56634045]. 
=============================================
[2019-03-26 15:02:42,824] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.0701136e-12 1.0000000e+00 1.9489937e-14 2.2239267e-15 1.3349827e-21], sum to 1.0000
[2019-03-26 15:02:42,831] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2928
[2019-03-26 15:02:42,836] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.93333333333333, 91.66666666666666, 1.0, 2.0, 0.7026311555265342, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 981948.7591616382, 981948.7591616388, 221412.5333054489], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6579600.0000, 
sim time next is 6580200.0000, 
raw observation next is [25.91666666666666, 91.83333333333333, 1.0, 2.0, 0.6900972663872862, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 964424.3080547536, 964424.3080547536, 218720.6287760917], 
processed observation next is [1.0, 0.13043478260869565, 0.4273301737756712, 0.9183333333333333, 1.0, 1.0, 0.6266232125148026, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2678956411263204, 0.2678956411263204, 0.32644869966580853], 
reward next is 0.6736, 
noisyNet noise sample is [array([1.8271308], dtype=float32), -0.84000987]. 
=============================================
[2019-03-26 15:02:48,326] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.5279631e-12 1.0000000e+00 3.9240007e-14 2.9432138e-15 2.9863393e-21], sum to 1.0000
[2019-03-26 15:02:48,336] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5587
[2019-03-26 15:02:48,339] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.01666666666667, 94.16666666666667, 1.0, 2.0, 0.5159751547977751, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 721002.6885459501, 721002.6885459494, 186135.2218646462], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6673800.0000, 
sim time next is 6674400.0000, 
raw observation next is [25.1, 94.0, 1.0, 2.0, 0.5193463287648424, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 725715.0390567803, 725715.0390567797, 186680.9908676649], 
processed observation next is [1.0, 0.2608695652173913, 0.38862559241706174, 0.94, 1.0, 1.0, 0.4208991912829427, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20158751084910564, 0.20158751084910548, 0.2786283445786043], 
reward next is 0.7214, 
noisyNet noise sample is [array([-0.9038794], dtype=float32), -0.06717835]. 
=============================================
[2019-03-26 15:02:56,286] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.5009196e-11 1.0000000e+00 3.1814642e-14 1.3535033e-15 2.6331124e-22], sum to 1.0000
[2019-03-26 15:02:56,297] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3448
[2019-03-26 15:02:56,300] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.66666666666666, 52.66666666666667, 1.0, 2.0, 0.4683991813756679, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 655373.9722792763, 655373.972279277, 178905.9571989406], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6957600.0000, 
sim time next is 6958200.0000, 
raw observation next is [31.83333333333333, 52.33333333333334, 1.0, 2.0, 0.471694100601146, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 659106.9488606076, 659106.9488606076, 179279.9763761303], 
processed observation next is [0.0, 0.5217391304347826, 0.7077409162717218, 0.5233333333333334, 1.0, 1.0, 0.3634868681941518, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.183085263572391, 0.183085263572391, 0.2675820542927318], 
reward next is 0.7324, 
noisyNet noise sample is [array([2.6146457], dtype=float32), -0.62610346]. 
=============================================
[2019-03-26 15:03:02,106] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.5098497e-12 1.0000000e+00 8.0067738e-15 1.1773758e-15 2.6910639e-23], sum to 1.0000
[2019-03-26 15:03:02,115] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7775
[2019-03-26 15:03:02,122] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.3, 75.83333333333334, 1.0, 2.0, 0.4289399245452645, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 622872.2189962886, 622872.218996288, 176230.1622233329], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6937800.0000, 
sim time next is 6938400.0000, 
raw observation next is [26.5, 74.66666666666667, 1.0, 2.0, 0.430541564149567, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 624812.9897712702, 624812.9897712702, 176408.8813876651], 
processed observation next is [0.0, 0.30434782608695654, 0.4549763033175356, 0.7466666666666667, 1.0, 1.0, 0.3139054989753819, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17355916382535283, 0.17355916382535283, 0.2632968378920375], 
reward next is 0.7367, 
noisyNet noise sample is [array([-0.07320252], dtype=float32), 0.12933856]. 
=============================================
[2019-03-26 15:03:09,219] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-26 15:03:09,220] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 15:03:09,220] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:03:09,221] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 15:03:09,223] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:03:09,223] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 15:03:09,225] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 15:03:09,226] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:03:09,227] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 15:03:09,228] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:03:09,229] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:03:09,249] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run17
[2019-03-26 15:03:09,250] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run17
[2019-03-26 15:03:09,266] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run17
[2019-03-26 15:03:09,267] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run17
[2019-03-26 15:03:09,298] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run17
[2019-03-26 15:03:11,357] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08244485], dtype=float32), 0.068252295]
[2019-03-26 15:03:11,360] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.5, 90.0, 1.0, 2.0, 0.3810260201994432, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 586932.2282260108, 586932.2282260101, 173833.5239642372]
[2019-03-26 15:03:11,362] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:03:11,364] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [8.0358090e-12 1.0000000e+00 2.5184548e-14 1.5149037e-15 4.5759622e-22], sampled 0.2235408146839578
[2019-03-26 15:03:11,895] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08244485], dtype=float32), 0.068252295]
[2019-03-26 15:03:11,896] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.78333333333333, 96.0, 1.0, 2.0, 0.8757011245039606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1304635.5303332, 1304635.5303332, 274777.8038964959]
[2019-03-26 15:03:11,898] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:03:11,901] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.5037734e-13 1.0000000e+00 1.2287454e-15 1.4187400e-16 1.2347171e-23], sampled 0.3619444128731203
[2019-03-26 15:03:34,134] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08244485], dtype=float32), 0.068252295]
[2019-03-26 15:03:34,135] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [23.9, 89.0, 1.0, 2.0, 0.4215177632871042, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 623304.8735194353, 623304.8735194353, 176574.8017098883]
[2019-03-26 15:03:34,138] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:03:34,140] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.2762165e-12 1.0000000e+00 2.9527162e-15 2.8751096e-16 3.4385633e-23], sampled 0.07821346176993405
[2019-03-26 15:03:58,275] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08244485], dtype=float32), 0.068252295]
[2019-03-26 15:03:58,277] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [26.06666666666667, 85.66666666666666, 1.0, 2.0, 0.6331577219716835, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 884817.0431930262, 884817.0431930268, 207075.7592922167]
[2019-03-26 15:03:58,279] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:03:58,283] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.4729843e-12 1.0000000e+00 7.4996068e-15 6.2961997e-16 8.8419210e-23], sampled 0.9132239378577581
[2019-03-26 15:04:00,457] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08244485], dtype=float32), 0.068252295]
[2019-03-26 15:04:00,457] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.0, 74.0, 1.0, 2.0, 0.5245965319221539, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 733054.0070592929, 733054.0070592923, 187539.6007289533]
[2019-03-26 15:04:00,459] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:04:00,461] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [6.7982230e-13 1.0000000e+00 1.8118854e-15 3.2657652e-16 2.8752418e-23], sampled 0.6392433555521716
[2019-03-26 15:04:08,063] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08244485], dtype=float32), 0.068252295]
[2019-03-26 15:04:08,064] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [31.38366382, 59.19741636000001, 1.0, 2.0, 0.4907596208147343, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 685756.1540410263, 685756.1540410263, 182162.1531426921]
[2019-03-26 15:04:08,065] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 15:04:08,069] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.9255847e-11 1.0000000e+00 4.9326259e-14 1.9538109e-13 2.1332821e-19], sampled 0.3889877333347167
[2019-03-26 15:04:14,628] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08244485], dtype=float32), 0.068252295]
[2019-03-26 15:04:14,630] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.72888510333333, 78.26797088333333, 1.0, 2.0, 0.4649520437677661, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 673548.2556791584, 673548.2556791584, 181322.0975385863]
[2019-03-26 15:04:14,632] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 15:04:14,635] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [5.9780967e-13 1.0000000e+00 1.1749844e-15 9.8962433e-17 7.1702692e-24], sampled 0.9481775973625117
[2019-03-26 15:05:02,760] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7999.0142 3007608811.4011 1766.0000
[2019-03-26 15:05:02,785] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.6842 2927317744.9770 1338.0000
[2019-03-26 15:05:02,952] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.9164 3164002230.9074 1778.0000
[2019-03-26 15:05:02,993] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.7746 2842563444.1824 1131.0000
[2019-03-26 15:05:03,032] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.9878 2779190307.3385 933.0000
[2019-03-26 15:05:04,046] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 400000, evaluation results [400000.0, 7884.916440885027, 3164002230.907359, 1778.0, 8253.684239900658, 2927317744.977035, 1338.0, 8659.987755389953, 2779190307.3384666, 933.0, 7999.014205657292, 3007608811.4011106, 1766.0, 8496.774567725599, 2842563444.1823883, 1131.0]
[2019-03-26 15:05:04,219] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.6492899e-10 1.0000000e+00 3.3184469e-12 1.8212024e-11 4.2637823e-16], sum to 1.0000
[2019-03-26 15:05:04,222] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.5247517e-09 1.0000000e+00 5.1661026e-11 4.6533142e-09 2.1455099e-13], sum to 1.0000
[2019-03-26 15:05:04,227] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1323
[2019-03-26 15:05:04,228] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2602
[2019-03-26 15:05:04,233] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1832737.019295795 W.
[2019-03-26 15:05:04,236] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1708988.358622465 W.
[2019-03-26 15:05:04,239] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.76666666666667, 58.16666666666667, 1.0, 2.0, 0.6576566418621501, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.948269075324971, 6.9112, 168.9127031018577, 1832737.019295795, 1806438.98089436, 379474.1891359804], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7035000.0000, 
sim time next is 7035600.0000, 
raw observation next is [29.93333333333334, 57.33333333333334, 1.0, 2.0, 0.6929061421647849, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.948236962557433, 6.9112, 168.9127057816261, 1883053.95100352, 1856778.694053582, 387021.1444315028], 
processed observation next is [1.0, 0.43478260869565216, 0.6176935229067935, 0.5733333333333335, 1.0, 1.0, 0.630007400198536, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.003703696255743338, 0.0, 0.8294387139590865, 0.5230705419454222, 0.5157718594593284, 0.5776434991514967], 
reward next is 0.2372, 
noisyNet noise sample is [array([0.17286594], dtype=float32), -0.020572785]. 
=============================================
[2019-03-26 15:05:04,242] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.6, 47.66666666666667, 1.0, 2.0, 0.4034648772476741, 1.0, 1.0, 0.4034648772476741, 1.0, 1.0, 0.6760476093308028, 6.911199999999999, 6.9112, 170.5573041426782, 1708988.358622465, 1708988.358622465, 352666.6098240995], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7044600.0000, 
sim time next is 7045200.0000, 
raw observation next is [31.7, 47.0, 1.0, 2.0, 0.620160830711667, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.940302550008289, 6.9112, 168.9127644919094, 1788294.474094366, 1767648.146956577, 373289.3083861957], 
processed observation next is [1.0, 0.5652173913043478, 0.7014218009478673, 0.47, 1.0, 1.0, 0.5423624466405627, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.0029102550008288652, 0.0, 0.8294390022534551, 0.4967484650262128, 0.4910133741546047, 0.5571482214719339], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.10547675], dtype=float32), -0.25089142]. 
=============================================
[2019-03-26 15:05:04,609] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.5798238e-09 1.0000000e+00 4.2707279e-11 2.7052713e-09 7.7010128e-14], sum to 1.0000
[2019-03-26 15:05:04,619] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4019
[2019-03-26 15:05:04,628] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1840680.637307119 W.
[2019-03-26 15:05:04,634] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [32.11666666666667, 44.5, 1.0, 2.0, 0.6509975022781007, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.941187326932977, 6.9112, 168.9127226841747, 1840680.637307119, 1819406.624946387, 380288.1740842888], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7048200.0000, 
sim time next is 7048800.0000, 
raw observation next is [32.2, 44.0, 1.0, 2.0, 0.6479234929393504, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.937759208500767, 6.9112, 168.9127732175683, 1844454.031804907, 1825612.035643129, 380648.335542875], 
processed observation next is [1.0, 0.6086956521739131, 0.7251184834123224, 0.44, 1.0, 1.0, 0.5758114372763257, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.0026559208500766653, 0.0, 0.8294390451004349, 0.5123483421680297, 0.5071144543453135, 0.5681318440938433], 
reward next is 0.2991, 
noisyNet noise sample is [array([-0.9264387], dtype=float32), -1.5908523]. 
=============================================
[2019-03-26 15:05:15,276] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.4586769e-10 1.0000000e+00 6.6591340e-13 1.7303452e-11 1.4999291e-16], sum to 1.0000
[2019-03-26 15:05:15,284] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8484
[2019-03-26 15:05:15,293] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2011466.989330577 W.
[2019-03-26 15:05:15,298] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.75, 90.83333333333334, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.69560003222043, 6.9112, 168.9086426943757, 2011466.989330577, 1455000.821289112, 311485.4020289482], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7221000.0000, 
sim time next is 7221600.0000, 
raw observation next is [24.9, 89.0, 1.0, 2.0, 0.6097888742855146, 1.0, 1.0, 0.6097888742855146, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1704964.528572845, 1704964.528572845, 337881.452366901], 
processed observation next is [1.0, 0.6086956521739131, 0.3791469194312796, 0.89, 1.0, 1.0, 0.5298661135970055, 1.0, 0.5, 0.5298661135970055, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.4736012579369014, 0.4736012579369014, 0.5043006751744791], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3749312], dtype=float32), -0.22290617]. 
=============================================
[2019-03-26 15:05:17,303] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.6299295e-13 1.0000000e+00 1.5799627e-15 2.8726868e-16 2.8903737e-23], sum to 1.0000
[2019-03-26 15:05:17,308] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8020
[2019-03-26 15:05:17,317] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.26666666666667, 90.66666666666667, 1.0, 2.0, 0.3510720950930421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 542896.435930813, 542896.4359308124, 170114.1408661366], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7255200.0000, 
sim time next is 7255800.0000, 
raw observation next is [22.25, 90.5, 1.0, 2.0, 0.3492429228341323, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 540633.8206291805, 540633.8206291811, 169943.5434723931], 
processed observation next is [1.0, 1.0, 0.2535545023696683, 0.905, 1.0, 1.0, 0.21595532871582201, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15017606128588348, 0.15017606128588365, 0.25364707980954193], 
reward next is 0.7464, 
noisyNet noise sample is [array([0.0370952], dtype=float32), -0.28207818]. 
=============================================
[2019-03-26 15:05:29,248] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.1717198e-12 1.0000000e+00 2.9232703e-14 3.0399314e-16 4.1534288e-24], sum to 1.0000
[2019-03-26 15:05:29,255] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4409
[2019-03-26 15:05:29,262] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 85.33333333333334, 1.0, 2.0, 0.3808493784763535, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 571294.8606072556, 571294.8606072556, 172026.3435429578], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7473000.0000, 
sim time next is 7473600.0000, 
raw observation next is [24.1, 85.0, 1.0, 2.0, 0.3838705267360344, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 574791.6780117674, 574791.6780117681, 172304.2200867445], 
processed observation next is [0.0, 0.5217391304347826, 0.3412322274881518, 0.85, 1.0, 1.0, 0.2576753334169089, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15966435500326873, 0.15966435500326892, 0.25717047774140966], 
reward next is 0.7428, 
noisyNet noise sample is [array([-0.7678304], dtype=float32), -0.15004219]. 
=============================================
[2019-03-26 15:05:37,367] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0341801e-12 1.0000000e+00 4.3962797e-15 3.8942620e-16 1.4583076e-24], sum to 1.0000
[2019-03-26 15:05:37,376] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3507
[2019-03-26 15:05:37,381] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.06666666666667, 92.5, 1.0, 2.0, 0.4824780337637555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 674180.3210257734, 674180.3210257734, 180896.1693598697], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7599000.0000, 
sim time next is 7599600.0000, 
raw observation next is [25.0, 93.0, 1.0, 2.0, 0.4821006713018027, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 673652.8544986771, 673652.8544986764, 180839.0448999551], 
processed observation next is [0.0, 1.0, 0.38388625592417064, 0.93, 1.0, 1.0, 0.3760249051828948, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1871257929162992, 0.187125792916299, 0.26990902223873897], 
reward next is 0.7301, 
noisyNet noise sample is [array([-0.9694163], dtype=float32), 0.26203722]. 
=============================================
[2019-03-26 15:05:37,406] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.33540965e-11 1.00000000e+00 1.15448507e-14 2.47596815e-15
 5.07510849e-22], sum to 1.0000
[2019-03-26 15:05:37,417] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5634
[2019-03-26 15:05:37,425] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.8, 91.0, 1.0, 2.0, 0.5626204026534609, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 794781.8612301777, 794781.861230177, 195089.2512603661], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7632000.0000, 
sim time next is 7632600.0000, 
raw observation next is [25.06666666666667, 89.33333333333334, 1.0, 2.0, 0.5538310938006488, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 780730.8434152335, 780730.843415233, 193333.0884085688], 
processed observation next is [1.0, 0.34782608695652173, 0.38704581358609813, 0.8933333333333334, 1.0, 1.0, 0.46244710096463704, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21686967872645377, 0.2168696787264536, 0.2885568483709982], 
reward next is 0.7114, 
noisyNet noise sample is [array([0.06308564], dtype=float32), -0.29545557]. 
=============================================
[2019-03-26 15:05:39,291] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.5251148e-11 1.0000000e+00 2.5913116e-14 5.4281217e-15 7.4015305e-21], sum to 1.0000
[2019-03-26 15:05:39,300] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6252
[2019-03-26 15:05:39,308] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.7, 85.66666666666667, 1.0, 2.0, 0.5095597186048926, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 712035.0144809416, 712035.0144809422, 185107.3575488465], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7672800.0000, 
sim time next is 7673400.0000, 
raw observation next is [26.55, 86.5, 1.0, 2.0, 0.5077434834523744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 709496.244525124, 709496.244525124, 184818.1776674127], 
processed observation next is [1.0, 0.8260869565217391, 0.4573459715639811, 0.865, 1.0, 1.0, 0.40691985958117394, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19708229014586776, 0.19708229014586776, 0.2758480263692727], 
reward next is 0.7242, 
noisyNet noise sample is [array([-0.26687783], dtype=float32), -1.4122955]. 
=============================================
[2019-03-26 15:05:41,795] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.6645608e-12 1.0000000e+00 9.5099116e-15 1.3816420e-15 3.5508465e-21], sum to 1.0000
[2019-03-26 15:05:41,803] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6971
[2019-03-26 15:05:41,811] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.4, 87.33333333333333, 1.0, 2.0, 0.50606117955779, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 707144.6917831568, 707144.6917831575, 184551.185786542], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7674000.0000, 
sim time next is 7674600.0000, 
raw observation next is [26.25, 88.16666666666667, 1.0, 2.0, 0.5049603361901578, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 705605.917185019, 705605.9171850183, 184376.9016848402], 
processed observation next is [1.0, 0.8260869565217391, 0.4431279620853081, 0.8816666666666667, 1.0, 1.0, 0.4035666701086238, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19600164366250528, 0.19600164366250508, 0.2751894054997615], 
reward next is 0.7248, 
noisyNet noise sample is [array([-0.6734174], dtype=float32), -1.087505]. 
=============================================
[2019-03-26 15:05:45,741] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.1848727e-12 1.0000000e+00 1.3271571e-15 6.7725620e-16 6.7425835e-23], sum to 1.0000
[2019-03-26 15:05:45,748] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7217
[2019-03-26 15:05:45,754] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.4, 85.0, 1.0, 2.0, 0.4936117968912466, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 689742.8966346796, 689742.8966346796, 182601.2012829777], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7783200.0000, 
sim time next is 7783800.0000, 
raw observation next is [26.35, 85.33333333333334, 1.0, 2.0, 0.9537145800155455, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1333065.875792265, 1333065.875792265, 285137.617281171], 
processed observation next is [1.0, 0.08695652173913043, 0.4478672985781992, 0.8533333333333334, 1.0, 1.0, 0.9442344337536693, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.37029607660896247, 0.37029607660896247, 0.4255785332554791], 
reward next is 0.5744, 
noisyNet noise sample is [array([-0.4853406], dtype=float32), 2.9453878]. 
=============================================
[2019-03-26 15:05:48,943] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.2349185e-13 1.0000000e+00 5.2302770e-16 3.9926690e-16 2.6929329e-23], sum to 1.0000
[2019-03-26 15:05:48,955] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8427
[2019-03-26 15:05:48,962] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.43333333333333, 87.0, 1.0, 2.0, 0.6000041060912813, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 838467.6701831887, 838467.6701831882, 200739.903915613], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7798800.0000, 
sim time next is 7799400.0000, 
raw observation next is [26.55, 86.5, 1.0, 2.0, 0.591526285397432, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 826615.8435479895, 826615.8435479889, 199171.7784399833], 
processed observation next is [1.0, 0.2608695652173913, 0.4573459715639811, 0.865, 1.0, 1.0, 0.5078629944547374, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22961551209666375, 0.2296155120966636, 0.29727131110445265], 
reward next is 0.7027, 
noisyNet noise sample is [array([-1.2675875], dtype=float32), -0.046101924]. 
=============================================
[2019-03-26 15:05:50,488] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.2217027e-08 9.9999988e-01 1.8601684e-10 1.2569934e-07 8.8716541e-11], sum to 1.0000
[2019-03-26 15:05:50,495] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7116
[2019-03-26 15:05:50,504] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2195666.232008616 W.
[2019-03-26 15:05:50,507] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.26666666666667, 67.66666666666667, 1.0, 2.0, 0.5234073845035501, 1.0, 1.0, 0.5234073845035501, 1.0, 2.0, 0.8974195398487732, 6.9112, 6.9112, 170.5573041426782, 2195666.232008616, 2195666.232008616, 429499.1666252482], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7836000.0000, 
sim time next is 7836600.0000, 
raw observation next is [30.08333333333333, 68.83333333333333, 1.0, 2.0, 0.9428812770221752, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.987203131683001, 6.9112, 168.912443323189, 2215056.57454847, 2161137.500922753, 446915.200929656], 
processed observation next is [1.0, 0.6956521739130435, 0.6248025276461293, 0.6883333333333332, 1.0, 1.0, 0.9311822614725002, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.0076003131683000545, 0.0, 0.8294374251680063, 0.6152934929301305, 0.6003159724785425, 0.6670376133278447], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.2115692], dtype=float32), -0.5804766]. 
=============================================
[2019-03-26 15:05:50,694] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:05:50,695] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:05:50,722] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run3
[2019-03-26 15:05:51,092] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.1169187e-08 1.0000000e+00 1.9077094e-10 5.7011778e-08 1.5993037e-11], sum to 1.0000
[2019-03-26 15:05:51,099] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7228
[2019-03-26 15:05:51,106] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2080741.850320731 W.
[2019-03-26 15:05:51,110] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.45, 66.5, 1.0, 2.0, 0.8469200374161919, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.982917968854459, 6.9112, 168.9124693120634, 2080741.850320731, 2029862.801625071, 420594.4447195387], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7835400.0000, 
sim time next is 7836000.0000, 
raw observation next is [30.26666666666667, 67.66666666666667, 1.0, 2.0, 0.5138927670375543, 1.0, 1.0, 0.5138927670375543, 1.0, 2.0, 0.8840584249490907, 6.9112, 6.9112, 170.5573041426782, 2155712.752493873, 2155712.752493873, 423316.40902483], 
processed observation next is [1.0, 0.6956521739130435, 0.6334913112164299, 0.6766666666666667, 1.0, 1.0, 0.4143286349850051, 1.0, 0.5, 0.4143286349850051, 1.0, 1.0, 0.858607835303769, 0.0, 0.0, 0.8375144448122397, 0.5988090979149646, 0.5988090979149646, 0.6318155358579551], 
reward next is 0.3682, 
noisyNet noise sample is [array([2.5281067], dtype=float32), -1.3971906]. 
=============================================
[2019-03-26 15:05:51,123] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[35.5968  ]
 [34.657784]
 [34.094067]
 [35.28371 ]
 [35.012894]], R is [[34.38739395]
 [34.0571785 ]
 [33.71660614]
 [33.73538971]
 [33.7566452 ]].
[2019-03-26 15:05:55,924] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:05:55,925] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:05:55,959] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run3
[2019-03-26 15:05:56,435] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:05:56,436] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:05:56,461] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run3
[2019-03-26 15:05:56,647] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:05:56,647] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:05:56,649] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run3
[2019-03-26 15:05:56,891] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:05:56,891] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:05:56,894] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run3
[2019-03-26 15:05:57,162] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:05:57,162] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:05:57,172] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run3
[2019-03-26 15:05:57,198] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:05:57,199] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:05:57,203] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:05:57,203] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:05:57,208] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run3
[2019-03-26 15:05:57,227] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run3
[2019-03-26 15:05:57,377] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:05:57,378] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:05:57,381] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run3
[2019-03-26 15:05:57,505] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:05:57,505] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:05:57,510] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run3
[2019-03-26 15:05:57,526] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:05:57,526] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:05:57,534] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run3
[2019-03-26 15:05:57,551] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:05:57,552] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:05:57,552] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:05:57,558] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:05:57,559] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run3
[2019-03-26 15:05:57,558] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run3
[2019-03-26 15:05:57,575] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:05:57,574] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:05:57,595] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:05:57,596] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run3
[2019-03-26 15:05:57,594] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:05:57,616] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:05:57,623] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run3
[2019-03-26 15:05:57,591] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:05:57,661] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run3
[2019-03-26 15:05:58,906] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-26 15:05:58,912] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 15:05:58,913] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 15:05:58,913] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:05:58,914] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:05:58,914] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 15:05:58,915] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 15:05:58,916] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:05:58,917] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run18
[2019-03-26 15:05:58,917] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:05:58,931] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 15:05:58,931] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:05:58,933] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run18
[2019-03-26 15:05:58,959] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run18
[2019-03-26 15:05:58,986] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run18
[2019-03-26 15:05:59,003] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run18
[2019-03-26 15:06:31,502] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08483768], dtype=float32), 0.069765516]
[2019-03-26 15:06:31,503] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.73526067166667, 69.89867623666667, 1.0, 2.0, 0.6227327951338236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 870242.5831335688, 870242.5831335688, 205048.3626956589]
[2019-03-26 15:06:31,504] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 15:06:31,507] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.4175878e-12 1.0000000e+00 2.3034671e-15 2.7275665e-16 2.3523506e-23], sampled 0.16055068914198478
[2019-03-26 15:06:40,261] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08483768], dtype=float32), 0.069765516]
[2019-03-26 15:06:40,262] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [20.00391335666667, 96.03166465333332, 1.0, 2.0, 0.3010020715768376, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 480951.7955528609, 480951.7955528616, 165710.7291784787]
[2019-03-26 15:06:40,263] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 15:06:40,265] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.7475083e-12 1.0000000e+00 2.6400416e-15 2.9969603e-16 2.9690251e-23], sampled 0.1993200008208098
[2019-03-26 15:06:46,152] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08483768], dtype=float32), 0.069765516]
[2019-03-26 15:06:46,154] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.81666666666667, 65.0, 1.0, 2.0, 0.7443641568944642, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.983924294982083, 6.9112, 168.912464311633, 1937211.769179173, 1885618.801680024, 395365.6971313007]
[2019-03-26 15:06:46,155] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:06:46,158] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [4.2919862e-10 1.0000000e+00 1.8613238e-12 6.1240930e-12 4.6881550e-17], sampled 0.9536542165556713
[2019-03-26 15:06:46,160] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1937211.769179173 W.
[2019-03-26 15:06:52,675] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08483768], dtype=float32), 0.069765516]
[2019-03-26 15:06:52,675] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [32.40000000000001, 65.0, 1.0, 2.0, 0.5812879355489666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 812303.0080624546, 812303.0080624552, 197311.8408425355]
[2019-03-26 15:06:52,676] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:06:52,679] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.6398201e-12 1.0000000e+00 2.6119631e-15 2.3551693e-16 1.9528769e-23], sampled 0.912574761617549
[2019-03-26 15:07:51,857] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.3273 2927391892.5307 1338.0000
[2019-03-26 15:07:51,988] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.4676 2779124528.0117 933.0000
[2019-03-26 15:07:52,110] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.6119 2842427357.4275 1131.0000
[2019-03-26 15:07:52,163] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7882.6701 3164128525.6280 1778.0000
[2019-03-26 15:07:52,347] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.5735 3007608940.6579 1766.0000
[2019-03-26 15:07:53,365] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 425000, evaluation results [425000.0, 7882.6701280147, 3164128525.6279716, 1778.0, 8254.327253941756, 2927391892.530706, 1338.0, 8661.467580702742, 2779124528.011676, 933.0, 7997.573463137595, 3007608940.657916, 1766.0, 8497.61193292354, 2842427357.427519, 1131.0]
[2019-03-26 15:07:57,472] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.7215292e-13 1.0000000e+00 2.7040612e-15 1.0185764e-15 9.8862895e-23], sum to 1.0000
[2019-03-26 15:07:57,482] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9598
[2019-03-26 15:07:57,487] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 86.33333333333334, 1.0, 2.0, 0.3523763629921491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 544875.285667902, 544875.2856679014, 170276.4894332824], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 78000.0000, 
sim time next is 78600.0000, 
raw observation next is [22.76666666666667, 86.66666666666666, 1.0, 2.0, 0.3517301414491896, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 544213.7421216262, 544213.7421216267, 170230.8915424977], 
processed observation next is [1.0, 0.9130434782608695, 0.2780410742496052, 0.8666666666666666, 1.0, 1.0, 0.21895197764962604, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15117048392267393, 0.1511704839226741, 0.25407595752611595], 
reward next is 0.7459, 
noisyNet noise sample is [array([-0.2124495], dtype=float32), 1.1669589]. 
=============================================
[2019-03-26 15:07:58,182] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.3911680e-12 1.0000000e+00 4.8467674e-15 6.4674828e-15 6.9277805e-22], sum to 1.0000
[2019-03-26 15:07:58,195] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0482
[2019-03-26 15:07:58,198] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.3, 89.0, 1.0, 2.0, 0.3449381809840169, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 536190.0994677328, 536190.0994677328, 169640.2261771646], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 88800.0000, 
sim time next is 89400.0000, 
raw observation next is [22.3, 89.0, 1.0, 2.0, 0.3446370056566652, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 535723.0073958393, 535723.0073958393, 169602.3903136275], 
processed observation next is [1.0, 0.0, 0.25592417061611383, 0.89, 1.0, 1.0, 0.21040603091164484, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14881194649884424, 0.14881194649884424, 0.2531378959904888], 
reward next is 0.7469, 
noisyNet noise sample is [array([0.43740866], dtype=float32), 0.094936885]. 
=============================================
[2019-03-26 15:08:03,988] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.3008623e-11 1.0000000e+00 1.6812852e-14 3.2459425e-16 2.4632964e-23], sum to 1.0000
[2019-03-26 15:08:04,001] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9788
[2019-03-26 15:08:04,006] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.96666666666667, 95.16666666666667, 1.0, 2.0, 0.2839274654622069, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 457631.5982186428, 457631.5982186428, 164112.6145293539], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 193800.0000, 
sim time next is 194400.0000, 
raw observation next is [20.0, 95.0, 1.0, 2.0, 0.2840934983540028, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 457777.1928452512, 457777.1928452512, 164122.4723999876], 
processed observation next is [0.0, 0.2608695652173913, 0.1469194312796209, 0.95, 1.0, 1.0, 0.13746204620964195, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1271603313459031, 0.1271603313459031, 0.24495891402983225], 
reward next is 0.7550, 
noisyNet noise sample is [array([-1.1297189], dtype=float32), -0.13255775]. 
=============================================
[2019-03-26 15:08:05,251] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.8442315e-13 1.0000000e+00 6.2703647e-15 5.5158505e-16 1.5896533e-23], sum to 1.0000
[2019-03-26 15:08:05,258] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7013
[2019-03-26 15:08:05,264] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.46666666666667, 93.0, 1.0, 2.0, 0.2929322179929746, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 469890.6680970922, 469890.6680970922, 164946.9693351423], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 204000.0000, 
sim time next is 204600.0000, 
raw observation next is [20.48333333333333, 93.0, 1.0, 2.0, 0.292651773939553, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 469284.2277431712, 469284.2277431712, 164903.6525903517], 
processed observation next is [0.0, 0.34782608695652173, 0.16982622432859393, 0.93, 1.0, 1.0, 0.14777322161391926, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13035672992865868, 0.13035672992865868, 0.24612485461246522], 
reward next is 0.7539, 
noisyNet noise sample is [array([2.0065615], dtype=float32), 0.7873685]. 
=============================================
[2019-03-26 15:08:12,942] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.2003632e-13 1.0000000e+00 2.0970507e-15 3.1304527e-16 1.4566126e-23], sum to 1.0000
[2019-03-26 15:08:12,952] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2410
[2019-03-26 15:08:12,959] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.56666666666667, 86.16666666666667, 1.0, 2.0, 0.2663470661482746, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 432854.9023929001, 432854.9023928994, 162455.0226345912], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 346200.0000, 
sim time next is 346800.0000, 
raw observation next is [20.53333333333333, 86.33333333333334, 1.0, 2.0, 0.2654771746370886, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 431528.6926698316, 431528.692669831, 162369.0579879229], 
processed observation next is [1.0, 0.0, 0.17219589257503945, 0.8633333333333334, 1.0, 1.0, 0.11503274052661275, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11986908129717545, 0.11986908129717527, 0.24234187759391476], 
reward next is 0.7577, 
noisyNet noise sample is [array([-0.02400989], dtype=float32), 1.5659155]. 
=============================================
[2019-03-26 15:08:14,488] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.1728248e-12 1.0000000e+00 9.4927321e-15 3.8062162e-15 6.8670799e-22], sum to 1.0000
[2019-03-26 15:08:14,503] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4418
[2019-03-26 15:08:14,510] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.8, 73.0, 1.0, 2.0, 0.4791762917907562, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 773024.1119324766, 773024.1119324766, 191641.6318986931], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 394200.0000, 
sim time next is 394800.0000, 
raw observation next is [22.83333333333333, 73.0, 1.0, 2.0, 0.5187384732909831, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 836339.7480974811, 836339.7480974811, 198703.6201582337], 
processed observation next is [1.0, 0.5652173913043478, 0.2812006319115322, 0.73, 1.0, 1.0, 0.42016683529034105, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23231659669374474, 0.23231659669374474, 0.2965725674003488], 
reward next is 0.7034, 
noisyNet noise sample is [array([-0.418873], dtype=float32), 2.1042964]. 
=============================================
[2019-03-26 15:08:16,085] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.3718731e-12 1.0000000e+00 1.0050749e-15 3.8498616e-16 8.6458007e-23], sum to 1.0000
[2019-03-26 15:08:16,096] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0599
[2019-03-26 15:08:16,103] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.43333333333333, 72.16666666666667, 1.0, 2.0, 0.4887070843447773, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 794751.4259406975, 794751.4259406975, 193622.5392612843], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 385800.0000, 
sim time next is 386400.0000, 
raw observation next is [22.46666666666667, 72.33333333333334, 1.0, 2.0, 0.4855222838000752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 788872.5015319347, 788872.5015319347, 193032.9468206623], 
processed observation next is [1.0, 0.4782608695652174, 0.2638230647709322, 0.7233333333333334, 1.0, 1.0, 0.3801473298796087, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2191312504255374, 0.2191312504255374, 0.2881088758517348], 
reward next is 0.7119, 
noisyNet noise sample is [array([-0.8017775], dtype=float32), -0.45685598]. 
=============================================
[2019-03-26 15:08:16,337] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.5111456e-13 1.0000000e+00 2.5227517e-15 1.0038794e-15 3.1287120e-22], sum to 1.0000
[2019-03-26 15:08:16,346] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8231
[2019-03-26 15:08:16,353] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.68333333333333, 73.0, 1.0, 2.0, 0.3120328401531444, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 504413.3474573876, 504413.3474573876, 167408.9133559373], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 391800.0000, 
sim time next is 392400.0000, 
raw observation next is [22.7, 73.0, 1.0, 2.0, 0.3208786493000252, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 518560.6218782662, 518560.6218782662, 168467.3340876571], 
processed observation next is [1.0, 0.5652173913043478, 0.27488151658767773, 0.73, 1.0, 1.0, 0.18178150518075323, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14404461718840728, 0.14404461718840728, 0.2514437822203837], 
reward next is 0.7486, 
noisyNet noise sample is [array([-0.948677], dtype=float32), 0.2397819]. 
=============================================
[2019-03-26 15:08:19,233] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.5121869e-12 1.0000000e+00 1.2223645e-14 4.6098085e-16 2.2395311e-23], sum to 1.0000
[2019-03-26 15:08:19,244] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5379
[2019-03-26 15:08:19,248] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.13333333333333, 61.33333333333334, 1.0, 2.0, 0.2899116500588187, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 463928.3928886835, 463928.3928886829, 164523.2570659499], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 818400.0000, 
sim time next is 819000.0000, 
raw observation next is [25.1, 61.5, 1.0, 2.0, 0.2897228075243004, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 463660.3177618643, 463660.3177618649, 164505.1470210628], 
processed observation next is [0.0, 0.4782608695652174, 0.38862559241706174, 0.615, 1.0, 1.0, 0.14424434641481976, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12879453271162897, 0.12879453271162913, 0.24553007018069073], 
reward next is 0.7545, 
noisyNet noise sample is [array([1.1836607], dtype=float32), -1.4553088]. 
=============================================
[2019-03-26 15:08:19,266] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[76.20504]
 [76.2161 ]
 [76.21056]
 [76.2215 ]
 [76.23137]], R is [[76.19309235]
 [76.18560028]
 [76.17815399]
 [76.17072296]
 [76.16326904]].
[2019-03-26 15:08:23,369] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.1731213e-13 1.0000000e+00 1.2025869e-15 2.8760421e-16 2.7403324e-23], sum to 1.0000
[2019-03-26 15:08:23,378] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4667
[2019-03-26 15:08:23,388] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.15, 85.5, 1.0, 2.0, 0.2350162099216474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 389299.1388566919, 389299.1388566919, 159325.0359620243], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 513000.0000, 
sim time next is 513600.0000, 
raw observation next is [19.06666666666666, 86.0, 1.0, 2.0, 0.2341557513240907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 387957.2324333502, 387957.2324333495, 159236.4573550978], 
processed observation next is [1.0, 0.9565217391304348, 0.10268562401263795, 0.86, 1.0, 1.0, 0.07729608593263938, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.10776589789815283, 0.10776589789815263, 0.23766635426134], 
reward next is 0.7623, 
noisyNet noise sample is [array([-0.8173948], dtype=float32), 0.64355505]. 
=============================================
[2019-03-26 15:08:26,258] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.0419441e-13 1.0000000e+00 8.5164345e-16 1.9358025e-16 2.5334074e-23], sum to 1.0000
[2019-03-26 15:08:26,266] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7358
[2019-03-26 15:08:26,275] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.35, 55.5, 1.0, 2.0, 0.6145650588639401, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1010260.390179418, 1010260.390179418, 218778.4486695058], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 559800.0000, 
sim time next is 560400.0000, 
raw observation next is [24.56666666666666, 55.0, 1.0, 2.0, 0.633009382082244, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1039117.682835463, 1039117.682835462, 222885.9367263796], 
processed observation next is [1.0, 0.4782608695652174, 0.3633491311216427, 0.55, 1.0, 1.0, 0.5578426290147518, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2886438007876286, 0.28864380078762836, 0.3326655772035516], 
reward next is 0.6673, 
noisyNet noise sample is [array([-1.3769288], dtype=float32), 0.6220075]. 
=============================================
[2019-03-26 15:08:29,247] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.3953786e-13 1.0000000e+00 2.7938484e-15 9.2665341e-16 8.1385707e-23], sum to 1.0000
[2019-03-26 15:08:29,255] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6734
[2019-03-26 15:08:29,263] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.18333333333333, 91.16666666666667, 1.0, 2.0, 0.245768296161783, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 410712.8942951671, 410712.8942951671, 159480.1815492728], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 612600.0000, 
sim time next is 613200.0000, 
raw observation next is [17.16666666666667, 91.33333333333334, 1.0, 2.0, 0.2182630173528393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 364737.7274437897, 364737.7274437897, 156963.1787796891], 
processed observation next is [1.0, 0.08695652173913043, 0.012638230647709612, 0.9133333333333334, 1.0, 1.0, 0.05814821367811961, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1013160354010527, 0.1013160354010527, 0.23427340116371506], 
reward next is 0.7657, 
noisyNet noise sample is [array([1.249796], dtype=float32), 0.24827883]. 
=============================================
[2019-03-26 15:08:38,829] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.7089766e-13 1.0000000e+00 5.8979921e-16 1.4545467e-16 3.4820570e-23], sum to 1.0000
[2019-03-26 15:08:38,839] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8380
[2019-03-26 15:08:38,844] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.86666666666667, 86.0, 1.0, 2.0, 0.2584411073714396, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 424435.3483623351, 424435.3483623351, 161754.2466904261], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 771600.0000, 
sim time next is 772200.0000, 
raw observation next is [19.8, 86.5, 1.0, 2.0, 0.258234329483531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 424123.4588135988, 424123.4588135988, 161733.2039684664], 
processed observation next is [1.0, 0.9565217391304348, 0.13744075829383895, 0.865, 1.0, 1.0, 0.10630642106449514, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.11781207189266633, 0.11781207189266633, 0.2413928417439797], 
reward next is 0.7586, 
noisyNet noise sample is [array([-0.7417197], dtype=float32), -0.9331726]. 
=============================================
[2019-03-26 15:08:41,507] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.3861631e-12 1.0000000e+00 3.9030982e-15 1.0141482e-16 9.5630539e-24], sum to 1.0000
[2019-03-26 15:08:41,518] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4417
[2019-03-26 15:08:41,522] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.96666666666667, 62.16666666666667, 1.0, 2.0, 0.28930423503913, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 463132.4665881591, 463132.4665881597, 164470.3522888233], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 821400.0000, 
sim time next is 822000.0000, 
raw observation next is [24.93333333333333, 62.33333333333334, 1.0, 2.0, 0.2889146941406687, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 462546.0055829607, 462546.0055829613, 164430.3787668172], 
processed observation next is [0.0, 0.5217391304347826, 0.38072669826224315, 0.6233333333333334, 1.0, 1.0, 0.143270715832131, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1284850015508224, 0.1284850015508226, 0.24541847577136894], 
reward next is 0.7546, 
noisyNet noise sample is [array([0.9129131], dtype=float32), -1.000544]. 
=============================================
[2019-03-26 15:08:41,536] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[77.05486 ]
 [77.05061 ]
 [77.06543 ]
 [77.082985]
 [77.09981 ]], R is [[77.0266037 ]
 [77.01086426]
 [76.99523926]
 [76.97978973]
 [76.96448517]].
[2019-03-26 15:08:44,400] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.5438492e-12 1.0000000e+00 2.8416475e-15 1.8286885e-16 2.2578021e-23], sum to 1.0000
[2019-03-26 15:08:44,413] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2352
[2019-03-26 15:08:44,419] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.3, 89.0, 1.0, 2.0, 0.2999799249130229, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 477609.8224887764, 477609.8224887764, 165449.7052868117], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 867600.0000, 
sim time next is 868200.0000, 
raw observation next is [21.26666666666667, 89.0, 1.0, 2.0, 0.2990876043078745, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 476476.1412247525, 476476.1412247518, 165373.5491908529], 
processed observation next is [0.0, 0.043478260869565216, 0.2069510268562403, 0.89, 1.0, 1.0, 0.1555272341058729, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13235448367354236, 0.13235448367354216, 0.24682619282216853], 
reward next is 0.7532, 
noisyNet noise sample is [array([0.12512124], dtype=float32), 0.5027761]. 
=============================================
[2019-03-26 15:08:46,587] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.0892094e-12 1.0000000e+00 1.6483417e-14 1.0443234e-15 3.8767137e-23], sum to 1.0000
[2019-03-26 15:08:46,596] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1525
[2019-03-26 15:08:46,600] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.33333333333334, 69.33333333333334, 1.0, 2.0, 0.3050095486539309, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 483001.4010990513, 483001.401099052, 165788.3073961246], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 911400.0000, 
sim time next is 912000.0000, 
raw observation next is [24.46666666666667, 68.66666666666667, 1.0, 2.0, 0.3056662332113999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 483761.929607147, 483761.929607147, 165837.4167795269], 
processed observation next is [0.0, 0.5652173913043478, 0.3586097946287521, 0.6866666666666668, 1.0, 1.0, 0.16345329302578301, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13437831377976306, 0.13437831377976306, 0.24751853250675654], 
reward next is 0.7525, 
noisyNet noise sample is [array([-0.61146355], dtype=float32), -0.93659]. 
=============================================
[2019-03-26 15:08:46,617] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[76.673546]
 [76.66045 ]
 [76.66315 ]
 [76.66565 ]
 [76.66515 ]], R is [[76.65420532]
 [76.64022064]
 [76.6264801 ]
 [76.61304474]
 [76.59989166]].
[2019-03-26 15:08:46,811] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.4351083e-12 1.0000000e+00 7.4879152e-15 4.7512974e-16 2.4953106e-23], sum to 1.0000
[2019-03-26 15:08:46,818] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9547
[2019-03-26 15:08:46,826] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.05, 73.5, 1.0, 2.0, 0.3166512713863182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 497365.1924567967, 497365.1924567967, 166751.2736341544], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 924600.0000, 
sim time next is 925200.0000, 
raw observation next is [24.0, 74.0, 1.0, 2.0, 0.3174580353314876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 498329.8766802831, 498329.8766802831, 166815.7604252182], 
processed observation next is [0.0, 0.7391304347826086, 0.3364928909952607, 0.74, 1.0, 1.0, 0.17766028353191274, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1384249657445231, 0.1384249657445231, 0.24897874690331076], 
reward next is 0.7510, 
noisyNet noise sample is [array([0.07140575], dtype=float32), -0.05541901]. 
=============================================
[2019-03-26 15:08:47,340] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.6884521e-12 1.0000000e+00 1.9855916e-15 7.6896993e-17 1.6658098e-22], sum to 1.0000
[2019-03-26 15:08:47,347] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0249
[2019-03-26 15:08:47,352] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.05, 73.5, 1.0, 2.0, 0.3166512713863182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 497365.1924567967, 497365.1924567967, 166751.2736341544], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 924600.0000, 
sim time next is 925200.0000, 
raw observation next is [24.0, 74.0, 1.0, 2.0, 0.3174580353314876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 498329.8766802831, 498329.8766802831, 166815.7604252182], 
processed observation next is [0.0, 0.7391304347826086, 0.3364928909952607, 0.74, 1.0, 1.0, 0.17766028353191274, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1384249657445231, 0.1384249657445231, 0.24897874690331076], 
reward next is 0.7510, 
noisyNet noise sample is [array([0.7705133], dtype=float32), -0.8905051]. 
=============================================
[2019-03-26 15:08:48,231] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-26 15:08:48,232] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 15:08:48,232] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:08:48,233] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 15:08:48,234] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 15:08:48,236] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 15:08:48,236] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:08:48,237] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:08:48,237] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 15:08:48,237] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:08:48,239] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:08:48,264] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run19
[2019-03-26 15:08:48,264] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run19
[2019-03-26 15:08:48,281] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run19
[2019-03-26 15:08:48,297] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run19
[2019-03-26 15:08:48,328] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run19
[2019-03-26 15:08:51,978] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08886773], dtype=float32), 0.07343302]
[2019-03-26 15:08:51,981] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [19.02864648333333, 96.20040441333335, 1.0, 2.0, 0.2595413361259573, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 425140.4138189092, 425140.4138189086, 161860.6661542112]
[2019-03-26 15:08:51,983] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 15:08:51,986] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.2197856e-12 1.0000000e+00 3.6044505e-15 1.0428182e-16 9.8312264e-24], sampled 0.07210477759104439
[2019-03-26 15:08:58,374] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08886773], dtype=float32), 0.07343302]
[2019-03-26 15:08:58,375] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.7, 49.0, 1.0, 2.0, 0.436459150622089, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 695722.1925819723, 695722.1925819723, 183997.2639956062]
[2019-03-26 15:08:58,376] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:08:58,379] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.2793386e-12 1.0000000e+00 2.0393813e-15 1.9865300e-16 1.5792453e-23], sampled 0.7509373249878654
[2019-03-26 15:09:25,858] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08886773], dtype=float32), 0.07343302]
[2019-03-26 15:09:25,859] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [26.56666666666667, 81.33333333333334, 1.0, 2.0, 0.502012338895083, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 701485.1753954184, 701485.1753954184, 183910.6042737384]
[2019-03-26 15:09:25,859] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:09:25,862] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.7713113e-13 1.0000000e+00 3.0122614e-16 2.1928727e-17 7.9395162e-25], sampled 0.10954746133991067
[2019-03-26 15:09:50,831] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08886773], dtype=float32), 0.07343302]
[2019-03-26 15:09:50,831] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [30.20372442, 88.57745799, 1.0, 2.0, 0.6479883504553016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 905551.1930612475, 905551.1930612469, 210027.8162561717]
[2019-03-26 15:09:50,833] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 15:09:50,835] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.5948748e-13 1.0000000e+00 5.9538274e-16 4.6583305e-17 2.3852316e-24], sampled 0.5194234569729571
[2019-03-26 15:10:41,021] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.6842 2927317744.9770 1338.0000
[2019-03-26 15:10:41,180] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.7281 2779199535.5119 933.0000
[2019-03-26 15:10:41,458] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.9559 3007647868.8583 1766.0000
[2019-03-26 15:10:41,512] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7883.4154 3164020870.7600 1778.0000
[2019-03-26 15:10:41,567] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.5752 2842451949.6408 1131.0000
[2019-03-26 15:10:42,585] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 450000, evaluation results [450000.0, 7883.415427042078, 3164020870.760028, 1778.0, 8253.684239900658, 2927317744.977035, 1338.0, 8660.728066421085, 2779199535.5119066, 933.0, 7998.955910945021, 3007647868.858331, 1766.0, 8497.575228127671, 2842451949.640752, 1131.0]
[2019-03-26 15:10:49,450] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.3413286e-13 1.0000000e+00 1.2184300e-15 1.3123251e-16 7.3737927e-23], sum to 1.0000
[2019-03-26 15:10:49,455] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4029
[2019-03-26 15:10:49,461] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.7, 95.0, 1.0, 2.0, 0.3039220776018907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 482782.5477320247, 482782.5477320247, 165802.0199202272], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1063200.0000, 
sim time next is 1063800.0000, 
raw observation next is [20.75, 95.0, 1.0, 2.0, 0.3074585171128207, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 487850.8660610176, 487850.8660610176, 166159.7398412576], 
processed observation next is [1.0, 0.30434782608695654, 0.18246445497630337, 0.95, 1.0, 1.0, 0.16561267122026588, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1355141294613938, 0.1355141294613938, 0.24799961170336957], 
reward next is 0.7520, 
noisyNet noise sample is [array([0.7137379], dtype=float32), 1.1416867]. 
=============================================
[2019-03-26 15:10:51,820] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.3910886e-12 1.0000000e+00 1.7617960e-15 4.2620445e-15 3.7348772e-22], sum to 1.0000
[2019-03-26 15:10:51,826] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4986
[2019-03-26 15:10:51,830] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.35, 82.0, 1.0, 2.0, 0.3103949106922713, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 492663.1602369188, 492663.1602369188, 166514.7629283872], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1114200.0000, 
sim time next is 1114800.0000, 
raw observation next is [22.23333333333333, 82.66666666666667, 1.0, 2.0, 0.3105179619863199, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 493141.9930866007, 493141.9930866014, 166554.6920804694], 
processed observation next is [1.0, 0.9130434782608695, 0.25276461295418634, 0.8266666666666667, 1.0, 1.0, 0.16929874938110834, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1369838869685002, 0.1369838869685004, 0.248589092657417], 
reward next is 0.7514, 
noisyNet noise sample is [array([2.1750782], dtype=float32), 0.8626394]. 
=============================================
[2019-03-26 15:10:54,271] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.3459777e-13 1.0000000e+00 2.3512645e-16 5.7622632e-17 2.1918959e-23], sum to 1.0000
[2019-03-26 15:10:54,280] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7962
[2019-03-26 15:10:54,287] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.8, 68.5, 1.0, 2.0, 0.7205659639855024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1104329.640723859, 1104329.640723859, 237746.4048036471], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1163400.0000, 
sim time next is 1164000.0000, 
raw observation next is [25.9, 68.0, 1.0, 2.0, 0.7555342417727281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1157401.346422818, 1157401.346422819, 246436.3579432446], 
processed observation next is [1.0, 0.4782608695652174, 0.42654028436018954, 0.68, 1.0, 1.0, 0.7054629418948531, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.32150037400633835, 0.3215003740063386, 0.36781545961678297], 
reward next is 0.6322, 
noisyNet noise sample is [array([-0.5848723], dtype=float32), 1.476977]. 
=============================================
[2019-03-26 15:10:54,301] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[72.73074 ]
 [72.661095]
 [72.62794 ]
 [72.53672 ]
 [72.45827 ]], R is [[72.74031067]
 [72.6580658 ]
 [72.56496429]
 [72.44398499]
 [72.33255768]].
[2019-03-26 15:10:56,203] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.2601603e-12 1.0000000e+00 1.0532573e-15 3.8988847e-16 1.9944891e-22], sum to 1.0000
[2019-03-26 15:10:56,210] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5301
[2019-03-26 15:10:56,217] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 85.33333333333334, 1.0, 2.0, 0.3554413071659422, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 547751.2515474142, 547751.2515474149, 170464.3484644801], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1204800.0000, 
sim time next is 1205400.0000, 
raw observation next is [23.0, 86.16666666666666, 1.0, 2.0, 0.3560965178943104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 548579.436239281, 548579.436239281, 170528.3612299317], 
processed observation next is [1.0, 0.9565217391304348, 0.28909952606635075, 0.8616666666666666, 1.0, 1.0, 0.22421267216181975, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1523831767331336, 0.1523831767331336, 0.2545199421342264], 
reward next is 0.7455, 
noisyNet noise sample is [array([0.06747377], dtype=float32), 1.4116457]. 
=============================================
[2019-03-26 15:11:04,203] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.5700013e-12 1.0000000e+00 6.3797348e-15 2.1976316e-15 1.1935342e-21], sum to 1.0000
[2019-03-26 15:11:04,209] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5374
[2019-03-26 15:11:04,213] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.93333333333333, 93.16666666666667, 1.0, 2.0, 0.3151404346517996, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 500459.3537640856, 500459.3537640856, 167096.4078086852], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1361400.0000, 
sim time next is 1362000.0000, 
raw observation next is [20.96666666666667, 93.33333333333334, 1.0, 2.0, 0.3179549541097438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 504321.7038382572, 504321.7038382572, 167376.3973238359], 
processed observation next is [1.0, 0.782608695652174, 0.1927330173775673, 0.9333333333333335, 1.0, 1.0, 0.178258980855113, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14008936217729365, 0.14008936217729365, 0.24981551839378494], 
reward next is 0.7502, 
noisyNet noise sample is [array([-2.2094982], dtype=float32), 0.4793486]. 
=============================================
[2019-03-26 15:11:04,224] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[71.504745]
 [71.491356]
 [71.543495]
 [71.64502 ]
 [71.66411 ]], R is [[71.46147919]
 [71.49746704]
 [71.53394318]
 [71.57065582]
 [71.6075592 ]].
[2019-03-26 15:11:06,815] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.1793825e-12 1.0000000e+00 1.8930536e-15 2.4510809e-17 5.8518463e-24], sum to 1.0000
[2019-03-26 15:11:06,826] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4860
[2019-03-26 15:11:06,831] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.43333333333333, 94.66666666666666, 1.0, 2.0, 0.3737201578384591, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 566450.1328268448, 566450.1328268448, 171786.3868790344], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1460400.0000, 
sim time next is 1461000.0000, 
raw observation next is [22.36666666666667, 94.83333333333333, 1.0, 2.0, 0.3716634034496848, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 564164.5981793643, 564164.5981793636, 171613.0683750689], 
processed observation next is [0.0, 0.9130434782608695, 0.2590837282780413, 0.9483333333333333, 1.0, 1.0, 0.24296795596347565, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15671238838315676, 0.15671238838315657, 0.2561389080224909], 
reward next is 0.7439, 
noisyNet noise sample is [array([-0.62029135], dtype=float32), 0.63613397]. 
=============================================
[2019-03-26 15:11:06,845] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[77.02652 ]
 [76.99845 ]
 [76.96891 ]
 [76.946655]
 [76.907646]], R is [[77.02649689]
 [76.99983215]
 [76.97317505]
 [76.94651031]
 [76.9198761 ]].
[2019-03-26 15:11:11,207] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.3066056e-13 1.0000000e+00 2.6337346e-15 3.7144001e-16 5.7840481e-23], sum to 1.0000
[2019-03-26 15:11:11,215] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9845
[2019-03-26 15:11:11,221] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.46666666666667, 59.33333333333334, 1.0, 2.0, 0.3557121950948179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 544564.9627604837, 544564.9627604837, 170091.8296220152], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1505400.0000, 
sim time next is 1506000.0000, 
raw observation next is [27.73333333333333, 57.66666666666667, 1.0, 2.0, 0.3526441832612439, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 540634.1755224256, 540634.1755224256, 169789.5666963984], 
processed observation next is [0.0, 0.43478260869565216, 0.513428120063191, 0.5766666666666667, 1.0, 1.0, 0.2200532328448722, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15017615986734043, 0.15017615986734043, 0.25341726372596773], 
reward next is 0.7466, 
noisyNet noise sample is [array([0.8705252], dtype=float32), -0.06382752]. 
=============================================
[2019-03-26 15:11:11,243] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[75.3094  ]
 [75.343834]
 [75.39061 ]
 [75.43201 ]
 [75.46628 ]], R is [[75.24677277]
 [75.24044037]
 [75.23388672]
 [75.22731018]
 [75.22064209]].
[2019-03-26 15:11:13,171] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.5908984e-13 1.0000000e+00 2.7977092e-15 2.1384276e-15 1.7833394e-22], sum to 1.0000
[2019-03-26 15:11:13,180] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0776
[2019-03-26 15:11:13,185] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.9, 60.16666666666667, 1.0, 2.0, 0.3436552026726148, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 531968.7533513719, 531968.7533513724, 169237.7290554589], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1530600.0000, 
sim time next is 1531200.0000, 
raw observation next is [26.7, 61.33333333333334, 1.0, 2.0, 0.3442932109901564, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 532754.3317517109, 532754.3317517109, 169295.4518580275], 
processed observation next is [0.0, 0.7391304347826086, 0.46445497630331756, 0.6133333333333334, 1.0, 1.0, 0.20999182047006798, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14798731437547524, 0.14798731437547524, 0.25267977889257837], 
reward next is 0.7473, 
noisyNet noise sample is [array([-0.13987803], dtype=float32), 1.0127491]. 
=============================================
[2019-03-26 15:11:15,042] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.18094922e-12 1.00000000e+00 3.89867666e-16 1.00704707e-16
 4.07332707e-24], sum to 1.0000
[2019-03-26 15:11:15,048] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8813
[2019-03-26 15:11:15,054] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.85, 87.0, 1.0, 2.0, 0.3522002160636193, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 542915.4779411874, 542915.4779411874, 170067.4820511354], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1546200.0000, 
sim time next is 1546800.0000, 
raw observation next is [22.76666666666667, 87.33333333333334, 1.0, 2.0, 0.3513499718735951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 542205.6223511685, 542205.6223511692, 170026.0508090299], 
processed observation next is [0.0, 0.9130434782608695, 0.2780410742496052, 0.8733333333333334, 1.0, 1.0, 0.21849394201637967, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1506126728753246, 0.1506126728753248, 0.2537702250881043], 
reward next is 0.7462, 
noisyNet noise sample is [array([0.7633911], dtype=float32), 0.5703802]. 
=============================================
[2019-03-26 15:11:18,758] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.6404605e-14 1.0000000e+00 8.8983193e-17 3.9077124e-17 1.2529464e-23], sum to 1.0000
[2019-03-26 15:11:18,766] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2775
[2019-03-26 15:11:18,773] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.03333333333333, 96.0, 1.0, 2.0, 0.39572206576622, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 584570.6059960261, 584570.6059960267, 172933.9716455378], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1617600.0000, 
sim time next is 1618200.0000, 
raw observation next is [23.05, 96.0, 1.0, 2.0, 0.3934647885725295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 580937.2404520125, 580937.2404520125, 172591.8668708229], 
processed observation next is [1.0, 0.7391304347826086, 0.2914691943127963, 0.96, 1.0, 1.0, 0.2692346850271439, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16137145568111458, 0.16137145568111458, 0.2575998012997357], 
reward next is 0.7424, 
noisyNet noise sample is [array([-0.68494344], dtype=float32), -0.38164857]. 
=============================================
[2019-03-26 15:11:18,814] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.5789648e-12 1.0000000e+00 6.3529927e-16 1.6809444e-15 2.5001425e-22], sum to 1.0000
[2019-03-26 15:11:18,823] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4218
[2019-03-26 15:11:18,828] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.16666666666666, 98.66666666666667, 1.0, 2.0, 0.4261304639980308, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 618681.8734099894, 618681.8734099901, 175820.1844354518], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1644000.0000, 
sim time next is 1644600.0000, 
raw observation next is [23.18333333333333, 98.83333333333333, 1.0, 2.0, 0.4276244205896276, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 619928.9886196837, 619928.9886196837, 175914.8479870278], 
processed observation next is [1.0, 0.0, 0.29778830963665076, 0.9883333333333333, 1.0, 1.0, 0.31039086818027417, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.172202496838801, 0.172202496838801, 0.2625594746075042], 
reward next is 0.7374, 
noisyNet noise sample is [array([1.181533], dtype=float32), 0.5548417]. 
=============================================
[2019-03-26 15:11:22,556] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.7771811e-13 1.0000000e+00 1.3856958e-15 4.1992320e-16 3.1353909e-22], sum to 1.0000
[2019-03-26 15:11:22,568] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8247
[2019-03-26 15:11:22,572] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.43333333333333, 90.0, 1.0, 2.0, 0.9086910339732761, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1270096.036179465, 1270096.036179465, 272336.1166628831], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1678800.0000, 
sim time next is 1679400.0000, 
raw observation next is [25.55, 89.5, 1.0, 2.0, 0.9582083846393582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1339351.106769004, 1339351.106769004, 286447.7388908998], 
processed observation next is [1.0, 0.43478260869565216, 0.40995260663507116, 0.895, 1.0, 1.0, 0.9496486561919978, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.37204197410250106, 0.37204197410250106, 0.42753393864313405], 
reward next is 0.5725, 
noisyNet noise sample is [array([-0.19506814], dtype=float32), -0.13221158]. 
=============================================
[2019-03-26 15:11:24,231] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.6989322e-09 1.0000000e+00 2.0823872e-11 2.2428728e-09 4.5915805e-13], sum to 1.0000
[2019-03-26 15:11:24,242] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6761
[2019-03-26 15:11:24,253] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1953761.575764384 W.
[2019-03-26 15:11:24,257] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.9, 74.0, 1.0, 2.0, 0.7561901210086684, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.979298900614204, 6.9112, 168.9124948938697, 1953761.575764384, 1905450.00391483, 398252.2697209338], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1702800.0000, 
sim time next is 1703400.0000, 
raw observation next is [28.78333333333333, 74.66666666666667, 1.0, 2.0, 0.3385470827256557, 1.0, 1.0, 0.3385470827256557, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 946240.0627368275, 946240.0627368275, 257754.4192760932], 
processed observation next is [1.0, 0.7391304347826086, 0.5631911532385465, 0.7466666666666667, 1.0, 1.0, 0.20306877436825987, 1.0, 0.5, 0.20306877436825987, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.262844461871341, 0.262844461871341, 0.3847080884717809], 
reward next is 0.6153, 
noisyNet noise sample is [array([0.5967819], dtype=float32), -0.05066349]. 
=============================================
[2019-03-26 15:11:25,140] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.8047098e-13 1.0000000e+00 5.7499916e-16 6.5393993e-16 4.6499743e-22], sum to 1.0000
[2019-03-26 15:11:25,151] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6914
[2019-03-26 15:11:25,158] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 94.0, 1.0, 2.0, 0.5047705006445073, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 705340.5625705486, 705340.5625705493, 184347.0012442233], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1726200.0000, 
sim time next is 1726800.0000, 
raw observation next is [25.43333333333334, 94.0, 1.0, 2.0, 0.503261366934298, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 703231.0780435816, 703231.0780435816, 184108.6900725193], 
processed observation next is [1.0, 1.0, 0.40442338072669864, 0.94, 1.0, 1.0, 0.4015197191979494, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1953419661232171, 0.1953419661232171, 0.27478908966047655], 
reward next is 0.7252, 
noisyNet noise sample is [array([1.1301851], dtype=float32), -0.8861089]. 
=============================================
[2019-03-26 15:11:27,321] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0818268e-12 1.0000000e+00 2.5232519e-15 2.8280757e-15 1.4780801e-21], sum to 1.0000
[2019-03-26 15:11:27,333] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7649
[2019-03-26 15:11:27,342] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.1, 88.0, 1.0, 2.0, 0.4644061241375815, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 658324.6432128618, 658324.6432128613, 179418.0188848631], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1890000.0000, 
sim time next is 1890600.0000, 
raw observation next is [25.03333333333333, 88.33333333333334, 1.0, 2.0, 0.4619212663082412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 655440.5529497884, 655440.5529497884, 179131.7906215914], 
processed observation next is [1.0, 0.9130434782608695, 0.38546603475513425, 0.8833333333333334, 1.0, 1.0, 0.3517123690460738, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18206682026383011, 0.18206682026383011, 0.2673608815247633], 
reward next is 0.7326, 
noisyNet noise sample is [array([-1.4845695], dtype=float32), 1.3763138]. 
=============================================
[2019-03-26 15:11:28,352] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.5915128e-12 1.0000000e+00 3.2724760e-15 7.5090250e-15 1.4200791e-21], sum to 1.0000
[2019-03-26 15:11:28,364] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5434
[2019-03-26 15:11:28,370] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.46666666666667, 89.33333333333333, 1.0, 2.0, 0.614719867487512, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 973577.7416708786, 973577.741670878, 216801.584699802], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1780800.0000, 
sim time next is 1781400.0000, 
raw observation next is [21.23333333333333, 90.66666666666667, 1.0, 2.0, 0.6036693233599966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 957533.1192305534, 957533.1192305528, 214559.1078550541], 
processed observation next is [1.0, 0.6086956521739131, 0.2053712480252764, 0.9066666666666667, 1.0, 1.0, 0.5224931606746946, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.26598142200848707, 0.2659814220084869, 0.3202374744105285], 
reward next is 0.6798, 
noisyNet noise sample is [array([1.6651484], dtype=float32), 2.25548]. 
=============================================
[2019-03-26 15:11:33,977] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-26 15:11:33,979] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 15:11:33,979] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:11:33,980] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 15:11:33,981] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 15:11:33,983] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 15:11:33,982] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 15:11:33,983] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:11:33,984] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:11:33,985] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:11:33,986] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:11:34,002] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run20
[2019-03-26 15:11:34,003] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run20
[2019-03-26 15:11:34,036] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run20
[2019-03-26 15:11:34,054] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run20
[2019-03-26 15:11:34,077] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run20
[2019-03-26 15:11:55,519] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08612666], dtype=float32), 0.07080731]
[2019-03-26 15:11:55,520] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [21.7, 94.16666666666667, 1.0, 2.0, 0.3344629297533469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 519782.143610795, 519782.1436107944, 168324.9827685973]
[2019-03-26 15:11:55,520] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:11:55,522] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.0837182e-12 1.0000000e+00 9.2193268e-15 5.5155556e-16 7.2950897e-23], sampled 0.32354117508256386
[2019-03-26 15:12:24,206] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08612666], dtype=float32), 0.07080731]
[2019-03-26 15:12:24,209] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.53423853666667, 81.51794769, 1.0, 2.0, 0.5604677550818393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 783197.7585196188, 783197.7585196188, 193611.5499403023]
[2019-03-26 15:12:24,210] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 15:12:24,213] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [6.414026e-13 1.000000e+00 6.236773e-16 1.355740e-16 1.179079e-23], sampled 0.5782957635562406
[2019-03-26 15:12:40,126] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08612666], dtype=float32), 0.07080731]
[2019-03-26 15:12:40,127] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [33.16666666666667, 52.5, 1.0, 2.0, 0.5182381421022404, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 724165.9728228068, 724165.9728228068, 186503.0829329576]
[2019-03-26 15:12:40,129] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:12:40,131] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.4224897e-12 1.0000000e+00 3.5238828e-15 8.4558664e-16 1.8513472e-22], sampled 0.9884300876717984
[2019-03-26 15:12:46,130] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08612666], dtype=float32), 0.07080731]
[2019-03-26 15:12:46,131] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.1, 85.0, 1.0, 2.0, 0.602325928963617, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 841713.5559752929, 841713.5559752935, 201179.2965309031]
[2019-03-26 15:12:46,133] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 15:12:46,137] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.7820496e-12 1.0000000e+00 2.4722685e-15 2.6199251e-16 2.5929512e-23], sampled 0.07333274774016774
[2019-03-26 15:12:52,818] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08612666], dtype=float32), 0.07080731]
[2019-03-26 15:12:52,820] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.89674469833334, 99.96022716833335, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 14.08006333512553, 6.9112, 178.5745026244913, 6833369.444794026, 1456629.386091453, 289079.0314303546]
[2019-03-26 15:12:52,825] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 15:12:52,829] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.8049345e-12 1.0000000e+00 1.7718519e-15 6.9497714e-16 9.9609782e-23], sampled 0.181043776566149
[2019-03-26 15:12:52,830] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 0, 1] for the demand 6833369.444794026 W.
[2019-03-26 15:13:04,462] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08612666], dtype=float32), 0.07080731]
[2019-03-26 15:13:04,466] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.9, 72.0, 1.0, 2.0, 0.5143807941019103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 718774.0400198154, 718774.0400198147, 185879.6017012107]
[2019-03-26 15:13:04,467] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:13:04,470] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.5198231e-12 1.0000000e+00 1.8800781e-15 2.7179797e-16 2.7407508e-23], sampled 0.8253046912241124
[2019-03-26 15:13:26,487] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7999.0502 3007584666.7691 1766.0000
[2019-03-26 15:13:26,755] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.9767 2779197554.3421 933.0000
[2019-03-26 15:13:26,821] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7883.4187 3164091655.5782 1778.0000
[2019-03-26 15:13:26,839] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8252.9283 2927337462.9924 1338.0000
[2019-03-26 15:13:26,967] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.6119 2842427357.4275 1131.0000
[2019-03-26 15:13:27,982] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 475000, evaluation results [475000.0, 7883.418744825709, 3164091655.5781918, 1778.0, 8252.928343486019, 2927337462.992419, 1338.0, 8659.97666076793, 2779197554.342144, 933.0, 7999.050242421542, 3007584666.769063, 1766.0, 8497.61193292354, 2842427357.427519, 1131.0]
[2019-03-26 15:13:36,213] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.0471860e-13 1.0000000e+00 2.6145550e-15 2.6053341e-16 9.5486595e-23], sum to 1.0000
[2019-03-26 15:13:36,222] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7948
[2019-03-26 15:13:36,226] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 94.16666666666667, 1.0, 2.0, 0.5021788138397962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 701717.8754074966, 701717.8754074973, 183938.4756841463], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2015400.0000, 
sim time next is 2016000.0000, 
raw observation next is [25.6, 94.0, 1.0, 2.0, 0.5037625457317685, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 703931.6310894974, 703931.6310894967, 184188.0953561375], 
processed observation next is [0.0, 0.34782608695652173, 0.4123222748815167, 0.94, 1.0, 1.0, 0.40212354907441983, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19553656419152704, 0.19553656419152685, 0.27490760500916045], 
reward next is 0.7251, 
noisyNet noise sample is [array([1.1872822], dtype=float32), -1.4398093]. 
=============================================
[2019-03-26 15:13:36,255] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[75.35908 ]
 [75.338715]
 [75.31632 ]
 [75.2937  ]
 [75.27821 ]], R is [[75.35074615]
 [75.3227005 ]
 [75.29540253]
 [75.26908875]
 [75.24381256]].
[2019-03-26 15:13:39,741] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.6613706e-13 1.0000000e+00 3.3848281e-15 8.7752190e-16 2.5302697e-22], sum to 1.0000
[2019-03-26 15:13:39,753] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2165
[2019-03-26 15:13:39,760] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.33333333333334, 95.66666666666667, 1.0, 2.0, 0.4675708701703993, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 655868.527327139, 655868.5273271385, 178997.5540942362], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2079600.0000, 
sim time next is 2080200.0000, 
raw observation next is [24.31666666666667, 95.83333333333333, 1.0, 2.0, 0.467735033285475, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 655960.7706544079, 655960.7706544073, 179003.9712951069], 
processed observation next is [0.0, 0.043478260869565216, 0.3515007898894157, 0.9583333333333333, 1.0, 1.0, 0.35871690757286145, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18221132518178, 0.18221132518177982, 0.2671701064106073], 
reward next is 0.7328, 
noisyNet noise sample is [array([-0.28345385], dtype=float32), -0.13823737]. 
=============================================
[2019-03-26 15:13:39,913] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.73475589e-12 1.00000000e+00 4.90857838e-15 6.83534677e-16
 1.20110565e-23], sum to 1.0000
[2019-03-26 15:13:39,921] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0410
[2019-03-26 15:13:39,925] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.36666666666667, 80.66666666666667, 1.0, 2.0, 0.5318864316745767, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 743244.2379628149, 743244.2379628143, 188743.5019594662], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2108400.0000, 
sim time next is 2109000.0000, 
raw observation next is [28.58333333333333, 79.83333333333334, 1.0, 2.0, 0.5350387497770641, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 747650.7553564993, 747650.7553564986, 189268.6785206307], 
processed observation next is [0.0, 0.391304347826087, 0.5537124802527644, 0.7983333333333335, 1.0, 1.0, 0.4398057226229688, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20768076537680538, 0.2076807653768052, 0.2824905649561652], 
reward next is 0.7175, 
noisyNet noise sample is [array([0.8022773], dtype=float32), 1.4806058]. 
=============================================
[2019-03-26 15:13:39,937] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[73.62936 ]
 [73.623405]
 [73.61603 ]
 [73.61429 ]
 [73.59355 ]], R is [[73.61172485]
 [73.59390259]
 [73.57719421]
 [73.56147766]
 [73.54653168]].
[2019-03-26 15:13:46,307] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.4295763e-12 1.0000000e+00 1.8777200e-15 1.1374186e-15 5.0356523e-22], sum to 1.0000
[2019-03-26 15:13:46,314] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9367
[2019-03-26 15:13:46,320] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2228224.112181839 W.
[2019-03-26 15:13:46,327] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.6, 80.5, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 8.002168712470443, 6.9112, 168.9068116577663, 2228224.112181839, 1454281.515446444, 311351.5265186779], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2190600.0000, 
sim time next is 2191200.0000, 
raw observation next is [28.7, 80.0, 1.0, 2.0, 0.830653877667532, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 6.992287826217517, 6.9112, 168.9115890716168, 2057975.578589973, 2000449.549550765, 416069.1796334838], 
processed observation next is [1.0, 0.34782608695652173, 0.5592417061611374, 0.8, 1.0, 1.0, 0.7959685273102795, 0.0, 1.0, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.008108782621751676, 0.0, 0.8294332304017087, 0.5716598829416591, 0.5556804304307681, 0.6209987755723639], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.21854116], dtype=float32), 0.18849611]. 
=============================================
[2019-03-26 15:13:58,790] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.8274568e-13 1.0000000e+00 2.7825848e-15 1.6250971e-14 2.3957130e-21], sum to 1.0000
[2019-03-26 15:13:58,798] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6129
[2019-03-26 15:13:58,811] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.7, 80.0, 1.0, 2.0, 0.547345142276322, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 764853.6144725318, 764853.6144725311, 191346.5895854059], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2424600.0000, 
sim time next is 2425200.0000, 
raw observation next is [28.66666666666667, 80.0, 1.0, 2.0, 0.5460045881397166, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 762979.6672249587, 762979.6672249594, 191118.0150135912], 
processed observation next is [1.0, 0.043478260869565216, 0.5576619273301741, 0.8, 1.0, 1.0, 0.45301757607194776, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2119387964513774, 0.2119387964513776, 0.28525076867700183], 
reward next is 0.7147, 
noisyNet noise sample is [array([-1.6273409], dtype=float32), -2.012181]. 
=============================================
[2019-03-26 15:13:58,907] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.5335031e-08 9.9999905e-01 4.0959924e-10 9.9262661e-07 1.1848932e-10], sum to 1.0000
[2019-03-26 15:13:58,915] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7188
[2019-03-26 15:13:58,924] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.93333333333334, 61.66666666666667, 1.0, 2.0, 0.5308474467815556, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 168.9129565022191, 741791.880609342, 741791.8806093414, 188573.9080292544], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2395200.0000, 
sim time next is 2395800.0000, 
raw observation next is [32.8, 62.5, 1.0, 2.0, 0.526307922254489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.9129565104289, 735446.2757093902, 735446.2757093909, 187824.6118621059], 
processed observation next is [1.0, 0.7391304347826086, 0.7535545023696681, 0.625, 1.0, 1.0, 0.4292866533186614, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451522924, 0.20429063214149726, 0.20429063214149745, 0.2803352415852327], 
reward next is 0.7197, 
noisyNet noise sample is [array([-0.02199586], dtype=float32), 0.9312558]. 
=============================================
[2019-03-26 15:14:01,600] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.1926618e-12 1.0000000e+00 1.3198672e-14 6.9972053e-15 4.8226476e-21], sum to 1.0000
[2019-03-26 15:14:01,607] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3068
[2019-03-26 15:14:01,610] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.65, 84.5, 1.0, 2.0, 0.8090034999362989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1130686.541939168, 1130686.541939169, 246132.8662682403], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2442600.0000, 
sim time next is 2443200.0000, 
raw observation next is [27.66666666666666, 84.66666666666667, 1.0, 2.0, 0.7717248340943025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1078558.346710952, 1078558.346710952, 237088.8691639467], 
processed observation next is [1.0, 0.2608695652173913, 0.5102685624012636, 0.8466666666666667, 1.0, 1.0, 0.7249696796316897, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.29959954075304224, 0.29959954075304224, 0.35386398382678613], 
reward next is 0.6461, 
noisyNet noise sample is [array([0.5308707], dtype=float32), 0.88105386]. 
=============================================
[2019-03-26 15:14:09,165] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.8604467e-12 1.0000000e+00 5.0541452e-15 3.3039743e-14 5.9462537e-21], sum to 1.0000
[2019-03-26 15:14:09,173] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6776
[2019-03-26 15:14:09,180] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.76666666666667, 84.33333333333334, 1.0, 2.0, 0.5410689179681824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 756080.1716485576, 756080.1716485576, 190280.7610229312], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2576400.0000, 
sim time next is 2577000.0000, 
raw observation next is [27.68333333333334, 84.66666666666667, 1.0, 2.0, 0.5394514929958127, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 753819.2085097961, 753819.2085097961, 190008.0673911301], 
processed observation next is [1.0, 0.8260869565217391, 0.511058451816746, 0.8466666666666667, 1.0, 1.0, 0.44512228071784665, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20939422458605447, 0.20939422458605447, 0.28359413043452253], 
reward next is 0.7164, 
noisyNet noise sample is [array([0.7651588], dtype=float32), -0.9614058]. 
=============================================
[2019-03-26 15:14:09,194] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[63.759155]
 [62.88115 ]
 [61.63323 ]
 [60.299217]
 [58.876247]], R is [[64.51918793]
 [64.58999634]
 [64.66007996]
 [64.72970581]
 [64.79903412]].
[2019-03-26 15:14:12,619] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.2427958e-12 1.0000000e+00 1.5506334e-15 1.7084962e-16 2.1591819e-23], sum to 1.0000
[2019-03-26 15:14:12,630] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2589
[2019-03-26 15:14:12,638] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 84.0, 1.0, 2.0, 0.4770567381362009, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 666730.5403852839, 666730.5403852839, 180095.5526592168], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2629800.0000, 
sim time next is 2630400.0000, 
raw observation next is [26.0, 84.0, 1.0, 2.0, 0.47695265418527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 666584.9123931888, 666584.9123931894, 180079.941457943], 
processed observation next is [0.0, 0.43478260869565216, 0.4312796208530806, 0.84, 1.0, 1.0, 0.36982247492201203, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18516247566477467, 0.18516247566477484, 0.2687760320267806], 
reward next is 0.7312, 
noisyNet noise sample is [array([-0.8139359], dtype=float32), 2.5589068]. 
=============================================
[2019-03-26 15:14:14,526] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.4399777e-13 1.0000000e+00 8.2273761e-16 6.8342218e-17 2.3582703e-24], sum to 1.0000
[2019-03-26 15:14:14,535] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7234
[2019-03-26 15:14:14,539] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.3966616096263242, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 591877.1983858881, 591877.1983858881, 173790.0738845282], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2667000.0000, 
sim time next is 2667600.0000, 
raw observation next is [23.0, 94.0, 1.0, 2.0, 0.3964040475273459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 591492.9742238744, 591492.9742238751, 173754.7312613747], 
processed observation next is [0.0, 0.9130434782608695, 0.28909952606635075, 0.94, 1.0, 1.0, 0.2727759608763204, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1643036039510762, 0.1643036039510764, 0.25933541979309654], 
reward next is 0.7407, 
noisyNet noise sample is [array([-0.66484857], dtype=float32), -0.74749285]. 
=============================================
[2019-03-26 15:14:22,414] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.5657049e-13 1.0000000e+00 4.7186586e-16 3.5913964e-16 1.7171745e-22], sum to 1.0000
[2019-03-26 15:14:22,422] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0649
[2019-03-26 15:14:22,427] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666666, 84.66666666666666, 1.0, 2.0, 0.6201661007753495, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 969315.0156245605, 969315.0156245598, 216795.5202452995], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2803200.0000, 
sim time next is 2803800.0000, 
raw observation next is [22.83333333333334, 83.83333333333334, 1.0, 2.0, 0.6308305894617209, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 984582.2578313979, 984582.2578313986, 218975.0354149518], 
processed observation next is [1.0, 0.43478260869565216, 0.2812006319115327, 0.8383333333333334, 1.0, 1.0, 0.5552175776647239, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2734950716198328, 0.27349507161983294, 0.3268284110670922], 
reward next is 0.6732, 
noisyNet noise sample is [array([0.88934], dtype=float32), -0.43711382]. 
=============================================
[2019-03-26 15:14:22,977] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-26 15:14:22,979] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 15:14:22,981] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:14:22,981] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 15:14:22,982] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 15:14:22,982] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 15:14:22,983] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:14:22,983] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 15:14:22,984] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:14:22,983] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:14:22,985] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:14:22,993] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run21
[2019-03-26 15:14:23,010] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run21
[2019-03-26 15:14:23,025] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run21
[2019-03-26 15:14:23,044] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run21
[2019-03-26 15:14:23,045] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run21
[2019-03-26 15:14:54,066] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08740545], dtype=float32), 0.070030466]
[2019-03-26 15:14:54,068] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.6, 85.33333333333334, 1.0, 2.0, 0.4268186290308171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 625966.5367292212, 625966.5367292218, 176698.1733626773]
[2019-03-26 15:14:54,069] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:14:54,073] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.1488606e-12 1.0000000e+00 1.2565126e-15 1.1974820e-16 6.9993096e-24], sampled 0.8801111684872696
[2019-03-26 15:14:56,648] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08740545], dtype=float32), 0.070030466]
[2019-03-26 15:14:56,649] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.6, 77.0, 1.0, 2.0, 0.4253359690608279, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 628853.8789733605, 628853.8789733605, 177106.8904232432]
[2019-03-26 15:14:56,651] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:14:56,658] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.3065959e-12 1.0000000e+00 1.5114058e-15 2.1798880e-16 1.6137324e-23], sampled 0.40706639416279355
[2019-03-26 15:15:00,062] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08740545], dtype=float32), 0.070030466]
[2019-03-26 15:15:00,063] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.36666666666667, 63.0, 1.0, 2.0, 0.6847157379778789, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 956900.1295449181, 956900.1295449181, 217578.596879991]
[2019-03-26 15:15:00,064] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:15:00,067] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0226952e-12 1.0000000e+00 1.1257636e-15 2.5790118e-16 1.9242440e-23], sampled 0.8352166272821941
[2019-03-26 15:15:05,268] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08740545], dtype=float32), 0.070030466]
[2019-03-26 15:15:05,270] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [21.0, 94.0, 1.0, 2.0, 0.3156460998602504, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 499135.6107977011, 499135.6107977018, 166960.6386087717]
[2019-03-26 15:15:05,271] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:15:05,272] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.1107881e-12 1.0000000e+00 1.2104710e-15 1.3160249e-16 8.3395803e-24], sampled 0.022521017837324964
[2019-03-26 15:15:06,334] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08740545], dtype=float32), 0.070030466]
[2019-03-26 15:15:06,336] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [20.0, 100.0, 1.0, 2.0, 0.3039678834542239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 484051.0362989192, 484051.0362989186, 165912.9389391483]
[2019-03-26 15:15:06,340] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:15:06,343] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.1701219e-12 1.0000000e+00 1.3164875e-15 1.4032170e-16 8.7157005e-24], sampled 0.5565476686823181
[2019-03-26 15:15:21,676] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08740545], dtype=float32), 0.070030466]
[2019-03-26 15:15:21,679] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.92712479333333, 74.95112040333333, 1.0, 2.0, 0.599859918555357, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 838266.0977375524, 838266.0977375524, 200717.1347030679]
[2019-03-26 15:15:21,679] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 15:15:21,681] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.2164372e-12 1.0000000e+00 1.6470932e-15 4.0201174e-16 2.8991197e-23], sampled 0.40228456070536645
[2019-03-26 15:15:33,182] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08740545], dtype=float32), 0.070030466]
[2019-03-26 15:15:33,184] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [32.13193045833334, 60.235076225, 1.0, 2.0, 0.710367019792096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 992764.9218460742, 992764.9218460736, 223099.4571043288]
[2019-03-26 15:15:33,185] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 15:15:33,188] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.1528072e-12 1.0000000e+00 1.3119755e-15 2.1508619e-16 1.7356398e-23], sampled 0.8790122767008844
[2019-03-26 15:15:51,755] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08740545], dtype=float32), 0.070030466]
[2019-03-26 15:15:51,757] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.9, 71.0, 1.0, 2.0, 0.5428061026253254, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 758508.5496023786, 758508.5496023786, 190574.2937850009]
[2019-03-26 15:15:51,758] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:15:51,760] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [9.4271899e-13 1.0000000e+00 9.9709362e-16 2.1191563e-16 1.4906092e-23], sampled 0.2336789822552816
[2019-03-26 15:15:54,052] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08740545], dtype=float32), 0.070030466]
[2019-03-26 15:15:54,055] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.6, 66.0, 1.0, 2.0, 0.5661826775494628, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 791186.7666566967, 791186.7666566967, 194614.7048024947]
[2019-03-26 15:15:54,056] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:15:54,058] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [8.1192312e-13 1.0000000e+00 8.0833704e-16 1.2285620e-16 6.7469798e-24], sampled 0.3216848616099317
[2019-03-26 15:15:56,821] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08740545], dtype=float32), 0.070030466]
[2019-03-26 15:15:56,822] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.96666666666667, 85.00000000000001, 1.0, 2.0, 0.5611144523427875, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 784101.786960688, 784101.7869606885, 193724.3948046263]
[2019-03-26 15:15:56,822] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:15:56,825] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [5.8795579e-13 1.0000000e+00 5.6865155e-16 1.0995338e-16 6.3268475e-24], sampled 0.005732679810119379
[2019-03-26 15:16:12,524] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08740545], dtype=float32), 0.070030466]
[2019-03-26 15:16:12,526] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.4, 81.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.261215597505549, 6.9112, 168.9107117625563, 1704686.851123876, 1456377.039572709, 311741.9463651126]
[2019-03-26 15:16:12,527] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:16:12,531] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.2409002e-12 1.0000000e+00 1.6963852e-15 2.4585645e-16 1.6635420e-23], sampled 0.38381830707603715
[2019-03-26 15:16:12,534] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1704686.851123876 W.
[2019-03-26 15:16:16,776] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.9689 2927381913.5140 1338.0000
[2019-03-26 15:16:16,887] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.1321 2842451957.6633 1131.0000
[2019-03-26 15:16:16,970] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7883.4188 3164134907.6624 1778.0000
[2019-03-26 15:16:17,064] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.5482 3007598461.8516 1766.0000
[2019-03-26 15:16:17,096] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.4676 2779124528.0117 933.0000
[2019-03-26 15:16:18,111] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 500000, evaluation results [500000.0, 7883.418813853433, 3164134907.662386, 1778.0, 8254.968948333817, 2927381913.5140486, 1338.0, 8661.467580702742, 2779124528.011676, 933.0, 7997.5482316611515, 3007598461.8515944, 1766.0, 8496.132105234119, 2842451957.6632614, 1131.0]
[2019-03-26 15:16:19,648] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.2814437e-12 1.0000000e+00 4.3875341e-15 7.5743560e-16 7.0442825e-24], sum to 1.0000
[2019-03-26 15:16:19,661] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3589
[2019-03-26 15:16:19,666] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 89.0, 1.0, 2.0, 0.4554664323995708, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 644889.3542668258, 644889.3542668258, 178005.615019745], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3214200.0000, 
sim time next is 3214800.0000, 
raw observation next is [25.0, 89.0, 1.0, 2.0, 0.4551870254107773, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 644494.1438965485, 644494.1438965485, 177965.0173941553], 
processed observation next is [0.0, 0.21739130434782608, 0.38388625592417064, 0.89, 1.0, 1.0, 0.3435988257961173, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1790261510823746, 0.1790261510823746, 0.2656194289465004], 
reward next is 0.7344, 
noisyNet noise sample is [array([-0.05818864], dtype=float32), -1.6062093]. 
=============================================
[2019-03-26 15:16:22,582] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.2090178e-13 1.0000000e+00 2.8782495e-15 3.7336086e-15 2.6988062e-22], sum to 1.0000
[2019-03-26 15:16:22,592] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7315
[2019-03-26 15:16:22,598] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.3022952447846516, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 481388.7555171007, 481388.7555171007, 165721.4112967301], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2941200.0000, 
sim time next is 2941800.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.3024168540965771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 481582.4135163953, 481582.4135163959, 165735.312117779], 
processed observation next is [1.0, 0.043478260869565216, 0.1469194312796209, 1.0, 1.0, 1.0, 0.15953837842961094, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13377289264344314, 0.1337728926434433, 0.24736613748922237], 
reward next is 0.7526, 
noisyNet noise sample is [array([-0.54416865], dtype=float32), 1.9123958]. 
=============================================
[2019-03-26 15:16:26,106] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.6475037e-12 1.0000000e+00 8.8055368e-15 1.3209898e-15 1.5502730e-22], sum to 1.0000
[2019-03-26 15:16:26,114] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3559
[2019-03-26 15:16:26,119] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.3368404410383452, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 523209.2688497411, 523209.2688497411, 168588.2257081255], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2963400.0000, 
sim time next is 2964000.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.3355473044568527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 521168.9336773183, 521168.9336773177, 168425.7389128151], 
processed observation next is [1.0, 0.30434782608695654, 0.19431279620853087, 1.0, 1.0, 1.0, 0.19945458368295507, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14476914824369952, 0.14476914824369935, 0.2513816998698733], 
reward next is 0.7486, 
noisyNet noise sample is [array([-0.51510525], dtype=float32), 0.0036399097]. 
=============================================
[2019-03-26 15:16:26,139] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[71.93459 ]
 [71.8905  ]
 [71.857346]
 [71.83156 ]
 [71.80883 ]], R is [[71.99495697]
 [72.02338409]
 [72.05236053]
 [72.08194733]
 [72.11180115]].
[2019-03-26 15:16:29,801] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.2927350e-13 1.0000000e+00 3.0251819e-16 1.7199594e-16 8.4409111e-24], sum to 1.0000
[2019-03-26 15:16:29,810] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5343
[2019-03-26 15:16:29,817] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.3039678834542239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 484051.0362989192, 484051.0362989186, 165912.9389391483], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3010800.0000, 
sim time next is 3011400.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.3041065107829917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 484272.064722271, 484272.064722271, 165928.8890831842], 
processed observation next is [1.0, 0.8695652173913043, 0.1469194312796209, 1.0, 1.0, 1.0, 0.16157410937709846, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13452001797840862, 0.13452001797840862, 0.24765505833311077], 
reward next is 0.7523, 
noisyNet noise sample is [array([-1.5595524], dtype=float32), -1.8156275]. 
=============================================
[2019-03-26 15:16:33,248] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.2115582e-12 1.0000000e+00 2.2612061e-16 2.4311545e-16 7.7411224e-23], sum to 1.0000
[2019-03-26 15:16:33,256] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9705
[2019-03-26 15:16:33,263] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.528905150777884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 789127.4283128334, 789127.4283128334, 194454.328277644], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3069600.0000, 
sim time next is 3070200.0000, 
raw observation next is [23.0, 94.0, 1.0, 2.0, 0.540977909640847, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 807130.6990653153, 807130.6990653153, 196616.662729004], 
processed observation next is [1.0, 0.5217391304347826, 0.28909952606635075, 0.94, 1.0, 1.0, 0.4469613369166831, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2242029719625876, 0.2242029719625876, 0.2934577055656776], 
reward next is 0.7065, 
noisyNet noise sample is [array([1.8274356], dtype=float32), 0.26684552]. 
=============================================
[2019-03-26 15:16:34,132] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.9474491e-12 1.0000000e+00 1.5710559e-15 9.7682334e-17 1.7021400e-24], sum to 1.0000
[2019-03-26 15:16:34,140] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4819
[2019-03-26 15:16:34,145] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 89.0, 1.0, 2.0, 0.4564397554793406, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 646267.9345350269, 646267.9345350263, 178147.4588664022], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3216000.0000, 
sim time next is 3216600.0000, 
raw observation next is [25.0, 89.0, 1.0, 2.0, 0.4566762021398829, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 646602.4204941794, 646602.4204941794, 178181.9071402132], 
processed observation next is [0.0, 0.21739130434782608, 0.38388625592417064, 0.89, 1.0, 1.0, 0.3453930146263649, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17961178347060539, 0.17961178347060539, 0.26594314498539284], 
reward next is 0.7341, 
noisyNet noise sample is [array([-0.44001862], dtype=float32), 0.9433099]. 
=============================================
[2019-03-26 15:16:55,737] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.0239539e-12 1.0000000e+00 2.5830795e-15 5.7347895e-16 8.2552363e-22], sum to 1.0000
[2019-03-26 15:16:55,745] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3405
[2019-03-26 15:16:55,751] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.5081282849349131, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 710034.1272554488, 710034.1272554483, 184879.5362175215], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3458400.0000, 
sim time next is 3459000.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.5079801494223136, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 709827.0606249967, 709827.060624996, 184855.9818521896], 
processed observation next is [1.0, 0.0, 0.4786729857819906, 0.84, 1.0, 1.0, 0.4072049993039923, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19717418350694352, 0.19717418350694332, 0.27590445052565615], 
reward next is 0.7241, 
noisyNet noise sample is [array([-0.10086676], dtype=float32), -0.84291863]. 
=============================================
[2019-03-26 15:16:55,768] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[67.98075 ]
 [68.2178  ]
 [68.518616]
 [68.90517 ]
 [69.22861 ]], R is [[67.75712585]
 [67.80361176]
 [67.84959412]
 [67.89505768]
 [67.94001007]].
[2019-03-26 15:16:55,864] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.7334519e-12 1.0000000e+00 3.1300243e-15 1.2255201e-15 3.5100516e-22], sum to 1.0000
[2019-03-26 15:16:55,876] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6372
[2019-03-26 15:16:55,882] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333333, 84.83333333333333, 1.0, 2.0, 0.5074331952403807, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 709062.5180404293, 709062.5180404286, 184768.9709951507], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3460200.0000, 
sim time next is 3460800.0000, 
raw observation next is [26.66666666666667, 85.66666666666667, 1.0, 2.0, 0.5068390298243134, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 708231.9833506766, 708231.983350676, 184674.5551597565], 
processed observation next is [1.0, 0.043478260869565216, 0.4628751974723541, 0.8566666666666667, 1.0, 1.0, 0.4058301564148354, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19673110648629905, 0.1967311064862989, 0.275633664417547], 
reward next is 0.7244, 
noisyNet noise sample is [array([0.00700362], dtype=float32), -1.3248103]. 
=============================================
[2019-03-26 15:16:59,150] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.4999073e-11 1.0000000e+00 6.8671307e-15 1.4809913e-15 2.6591148e-22], sum to 1.0000
[2019-03-26 15:16:59,156] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1847
[2019-03-26 15:16:59,161] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666667, 80.66666666666667, 1.0, 2.0, 0.5959326189443598, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 832775.7947019509, 832775.7947019509, 199982.5151668325], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3562800.0000, 
sim time next is 3563400.0000, 
raw observation next is [26.83333333333333, 79.83333333333334, 1.0, 2.0, 0.6021312725522473, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 841441.4278245873, 841441.4278245867, 201135.2269374539], 
processed observation next is [1.0, 0.21739130434782608, 0.470774091627172, 0.7983333333333335, 1.0, 1.0, 0.5206400874123461, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.23373372995127425, 0.2337337299512741, 0.3002018312499312], 
reward next is 0.6998, 
noisyNet noise sample is [array([1.80514], dtype=float32), 0.2069832]. 
=============================================
[2019-03-26 15:17:08,310] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.5355332e-08 9.9999952e-01 6.2142519e-10 4.1793811e-07 7.8674480e-12], sum to 1.0000
[2019-03-26 15:17:08,316] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1784
[2019-03-26 15:17:08,322] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2636017.999130961 W.
[2019-03-26 15:17:08,328] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.5, 66.5, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.403661944142673, 6.9112, 168.9092869132778, 2636017.999130961, 2286656.136699287, 475150.1543401424], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3666600.0000, 
sim time next is 3667200.0000, 
raw observation next is [31.66666666666666, 65.33333333333334, 1.0, 2.0, 0.8874549929690669, 1.0, 1.0, 0.8874549929690669, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2482171.492653423, 2482171.492653423, 464692.7115156798], 
processed observation next is [1.0, 0.43478260869565216, 0.6998420221169034, 0.6533333333333334, 1.0, 1.0, 0.8644036059868276, 1.0, 0.5, 0.8644036059868276, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6894920812926175, 0.6894920812926175, 0.6935712112174325], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8990245], dtype=float32), 0.7983779]. 
=============================================
[2019-03-26 15:17:12,398] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.6620026e-10 1.0000000e+00 2.0315936e-11 7.8113283e-10 4.6737317e-15], sum to 1.0000
[2019-03-26 15:17:12,408] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8297
[2019-03-26 15:17:12,419] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1929506.31106013 W.
[2019-03-26 15:17:12,422] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.66666666666667, 64.16666666666666, 1.0, 2.0, 0.6900250943428013, 1.0, 2.0, 0.6900250943428013, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1929506.31106013, 1929506.31106013, 369878.9848552969], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3750600.0000, 
sim time next is 3751200.0000, 
raw observation next is [31.0, 63.0, 1.0, 2.0, 0.8293537971302521, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.981700357458952, 6.9112, 168.9125372003013, 2056155.982567745, 2006140.726709682, 416089.4215162066], 
processed observation next is [1.0, 0.43478260869565216, 0.6682464454976303, 0.63, 1.0, 1.0, 0.7944021652171712, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.007050035745895222, 0.0, 0.8294378861476048, 0.5711544396021514, 0.5572613129749117, 0.6210289873376218], 
reward next is 0.0265, 
noisyNet noise sample is [array([0.3297941], dtype=float32), -1.7257799]. 
=============================================
[2019-03-26 15:17:13,330] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-26 15:17:13,332] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 15:17:13,333] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:17:13,334] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 15:17:13,334] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:17:13,335] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 15:17:13,335] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 15:17:13,337] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:17:13,337] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:17:13,338] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 15:17:13,339] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:17:13,353] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run22
[2019-03-26 15:17:13,374] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run22
[2019-03-26 15:17:13,374] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run22
[2019-03-26 15:17:13,418] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run22
[2019-03-26 15:17:13,435] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run22
[2019-03-26 15:18:21,864] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0852028], dtype=float32), 0.06633518]
[2019-03-26 15:18:21,867] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [33.5, 62.0, 1.0, 2.0, 1.006008368208893, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1406208.549927793, 1406208.549927794, 300766.6945157929]
[2019-03-26 15:18:21,869] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 15:18:21,873] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0903199e-12 1.0000000e+00 2.3461678e-15 7.4524050e-16 1.9283295e-23], sampled 0.560196503139086
[2019-03-26 15:19:06,196] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.2605 3007618784.0356 1766.0000
[2019-03-26 15:19:06,360] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7883.4154 3163997799.2143 1778.0000
[2019-03-26 15:19:06,383] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.1610 2927253227.7716 1338.0000
[2019-03-26 15:19:06,482] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.6119 2842427357.4275 1131.0000
[2019-03-26 15:19:06,556] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.3694 2779190338.1949 933.0000
[2019-03-26 15:19:07,569] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 525000, evaluation results [525000.0, 7883.415429661524, 3163997799.214286, 1778.0, 8255.161016606155, 2927253227.7715816, 1338.0, 8661.369356548688, 2779190338.194891, 933.0, 7998.26053894139, 3007618784.0355844, 1766.0, 8497.61193292354, 2842427357.427519, 1131.0]
[2019-03-26 15:19:09,616] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.0771815e-12 1.0000000e+00 5.1528439e-16 5.5071880e-16 1.5321693e-24], sum to 1.0000
[2019-03-26 15:19:09,623] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4275
[2019-03-26 15:19:09,635] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.5, 65.0, 1.0, 2.0, 0.6095542188354509, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 851818.6984207645, 851818.698420764, 202540.3727720526], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3839400.0000, 
sim time next is 3840000.0000, 
raw observation next is [33.66666666666666, 64.33333333333334, 1.0, 2.0, 0.61085831285765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 853641.8308752733, 853641.8308752733, 202787.2533705028], 
processed observation next is [0.0, 0.43478260869565216, 0.7946287519747232, 0.6433333333333334, 1.0, 1.0, 0.5311545938043976, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23712273079868704, 0.23712273079868704, 0.30266754234403404], 
reward next is 0.6973, 
noisyNet noise sample is [array([1.5306821], dtype=float32), 0.3241887]. 
=============================================
[2019-03-26 15:19:09,660] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[70.32137 ]
 [70.32038 ]
 [70.325836]
 [70.31893 ]
 [70.32721 ]], R is [[70.32073975]
 [70.31523132]
 [70.30963898]
 [70.30264282]
 [70.29907227]].
[2019-03-26 15:19:15,954] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.1360191e-13 1.0000000e+00 5.3208762e-16 1.6863836e-16 1.1228420e-24], sum to 1.0000
[2019-03-26 15:19:15,964] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9721
[2019-03-26 15:19:15,972] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 84.0, 1.0, 2.0, 0.5823400120669868, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 813773.7633415911, 813773.7633415911, 197501.9384960767], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3887400.0000, 
sim time next is 3888000.0000, 
raw observation next is [29.0, 84.0, 1.0, 2.0, 0.5827663419174642, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 814369.7537258837, 814369.753725883, 197579.1329577842], 
processed observation next is [0.0, 0.0, 0.5734597156398105, 0.84, 1.0, 1.0, 0.4973088456836918, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22621382047941213, 0.22621382047941194, 0.2948942282952003], 
reward next is 0.7051, 
noisyNet noise sample is [array([0.9666715], dtype=float32), -0.10682046]. 
=============================================
[2019-03-26 15:19:15,983] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[72.26338 ]
 [72.23476 ]
 [72.19318 ]
 [72.154015]
 [72.1158  ]], R is [[71.87844086]
 [71.86488342]
 [71.85155487]
 [71.8383255 ]
 [71.82499695]].
[2019-03-26 15:19:17,909] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.6192449e-13 1.0000000e+00 4.6891795e-15 4.9968803e-16 2.7657986e-24], sum to 1.0000
[2019-03-26 15:19:17,919] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5699
[2019-03-26 15:19:17,923] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [35.0, 56.0, 1.0, 2.0, 0.5959703130598959, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 832828.4903472299, 832828.4903472299, 199998.3037417744], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3936600.0000, 
sim time next is 3937200.0000, 
raw observation next is [35.0, 56.0, 1.0, 2.0, 0.5949985974412098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 831470.0515206032, 831470.0515206032, 199818.6365383166], 
processed observation next is [0.0, 0.5652173913043478, 0.8578199052132701, 0.56, 1.0, 1.0, 0.5120465029412166, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23096390320016758, 0.23096390320016758, 0.29823677095271134], 
reward next is 0.7018, 
noisyNet noise sample is [array([-0.10940719], dtype=float32), -1.0540578]. 
=============================================
[2019-03-26 15:19:21,193] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.6489934e-09 9.9999988e-01 1.3869154e-10 1.4526555e-07 2.1272423e-13], sum to 1.0000
[2019-03-26 15:19:21,203] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7952
[2019-03-26 15:19:21,210] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 79.0, 1.0, 2.0, 0.5521428835214475, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 771560.3561623346, 771560.3561623346, 192171.672756546], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4038000.0000, 
sim time next is 4038600.0000, 
raw observation next is [30.0, 79.0, 1.0, 2.0, 0.5584471145349333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 780373.07774915, 780373.07774915, 193262.2750067194], 
processed observation next is [1.0, 0.7391304347826086, 0.6208530805687204, 0.79, 1.0, 1.0, 0.4680085717288353, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2167702993747639, 0.2167702993747639, 0.2884511567264469], 
reward next is 0.7115, 
noisyNet noise sample is [array([0.0971313], dtype=float32), -0.2249062]. 
=============================================
[2019-03-26 15:19:21,523] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.5679581e-11 1.0000000e+00 5.3715740e-13 3.8295922e-11 1.3081959e-17], sum to 1.0000
[2019-03-26 15:19:21,531] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5950
[2019-03-26 15:19:21,541] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2052362.533200363 W.
[2019-03-26 15:19:21,546] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.0, 89.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.754425147401236, 6.9112, 168.9086912352809, 2052362.533200363, 1454164.697730641, 311356.0814222858], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4338600.0000, 
sim time next is 4339200.0000, 
raw observation next is [29.0, 89.0, 1.0, 2.0, 0.400499910853276, 1.0, 1.0, 0.400499910853276, 1.0, 1.0, 0.6955358978077072, 6.9112, 6.9112, 170.5573041426782, 1679671.732167421, 1679671.732167421, 353166.7530972062], 
processed observation next is [1.0, 0.21739130434782608, 0.5734597156398105, 0.89, 1.0, 1.0, 0.27771073596780244, 1.0, 0.5, 0.27771073596780244, 1.0, 0.5, 0.6287023143996429, 0.0, 0.0, 0.8375144448122397, 0.46657548115761693, 0.46657548115761693, 0.5271145568615018], 
reward next is 0.4729, 
noisyNet noise sample is [array([1.3627863], dtype=float32), -1.3290228]. 
=============================================
[2019-03-26 15:19:25,026] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.4497313e-08 9.9999964e-01 3.0494579e-10 2.9944644e-07 3.4088168e-12], sum to 1.0000
[2019-03-26 15:19:25,034] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4072
[2019-03-26 15:19:25,043] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2837745.73610544 W.
[2019-03-26 15:19:25,050] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [35.0, 60.0, 1.0, 2.0, 0.7114063770808738, 1.0, 2.0, 0.6762932280546995, 1.0, 2.0, 1.03, 7.00509863155543, 6.9112, 170.5573041426782, 2837745.73610544, 2770482.326770161, 524957.2662671043], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4183200.0000, 
sim time next is 4183800.0000, 
raw observation next is [35.0, 59.33333333333333, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 7.848759296218318, 6.9112, 170.5573041426782, 3581723.977166739, 2910112.115811747, 548289.0101622274], 
processed observation next is [1.0, 0.43478260869565216, 0.8578199052132701, 0.5933333333333333, 1.0, 1.0, 1.0481927710843375, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.2195121951219512, 0.09375592962183177, 0.0, 0.8375144448122397, 0.9949233269907608, 0.8083644766143742, 0.8183418062122798], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0888063], dtype=float32), 0.42057103]. 
=============================================
[2019-03-26 15:19:27,496] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.7594142e-09 1.0000000e+00 6.6097898e-11 1.5621033e-08 9.2449879e-14], sum to 1.0000
[2019-03-26 15:19:27,506] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9986
[2019-03-26 15:19:27,513] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2618755.2287307 W.
[2019-03-26 15:19:27,519] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 79.0, 1.0, 2.0, 0.9362368873091144, 1.0, 2.0, 0.9362368873091144, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2618755.2287307, 2618755.228730701, 491656.530054388], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4096800.0000, 
sim time next is 4097400.0000, 
raw observation next is [31.16666666666667, 77.66666666666667, 1.0, 2.0, 0.9261382252376159, 1.0, 2.0, 0.9261382252376159, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2590478.902076389, 2590478.902076389, 485961.9110690233], 
processed observation next is [1.0, 0.43478260869565216, 0.6761453396524489, 0.7766666666666667, 1.0, 1.0, 0.9110099099248384, 1.0, 1.0, 0.9110099099248384, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.719577472798997, 0.719577472798997, 0.7253162851776467], 
reward next is 0.2747, 
noisyNet noise sample is [array([1.1251348], dtype=float32), 0.41723698]. 
=============================================
[2019-03-26 15:19:33,984] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.3595457e-12 1.0000000e+00 2.0423757e-14 4.3787771e-13 2.0362812e-21], sum to 1.0000
[2019-03-26 15:19:33,990] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4966
[2019-03-26 15:19:33,995] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.66666666666667, 63.66666666666667, 1.0, 2.0, 0.6021277200999823, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 841436.4615245695, 841436.4615245695, 201144.1869816601], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4216800.0000, 
sim time next is 4217400.0000, 
raw observation next is [33.5, 65.5, 1.0, 2.0, 0.6084434744291457, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 850265.8725331981, 850265.8725331975, 202330.8089788183], 
processed observation next is [1.0, 0.8260869565217391, 0.7867298578199052, 0.655, 1.0, 1.0, 0.5282451499146333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.23618496459255503, 0.23618496459255486, 0.30198628205793776], 
reward next is 0.6980, 
noisyNet noise sample is [array([-0.65117395], dtype=float32), 1.4980634]. 
=============================================
[2019-03-26 15:19:48,422] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.6689402e-08 9.9998128e-01 4.5416049e-09 1.8629773e-05 4.5879280e-11], sum to 1.0000
[2019-03-26 15:19:48,435] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0446
[2019-03-26 15:19:48,446] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2351471.917391536 W.
[2019-03-26 15:19:48,454] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 66.0, 1.0, 2.0, 0.5605131182819123, 1.0, 1.0, 0.5605131182819123, 1.0, 2.0, 0.9708837198818271, 6.9112, 6.9112, 170.5573041426782, 2351471.917391536, 2351471.917391536, 458993.7103668828], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4806000.0000, 
sim time next is 4806600.0000, 
raw observation next is [31.16666666666667, 65.5, 1.0, 2.0, 0.848713910383738, 1.0, 2.0, 0.848713910383738, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2373711.518927835, 2373711.518927835, 444280.814820751], 
processed observation next is [1.0, 0.6521739130434783, 0.6761453396524489, 0.655, 1.0, 1.0, 0.8177276028719734, 1.0, 1.0, 0.8177276028719734, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6593643108132875, 0.6593643108132875, 0.663105693762315], 
reward next is 0.3369, 
noisyNet noise sample is [array([0.8740215], dtype=float32), 2.1079328]. 
=============================================
[2019-03-26 15:19:48,760] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.7399718e-10 1.0000000e+00 1.6420110e-12 5.4091676e-11 5.9366753e-18], sum to 1.0000
[2019-03-26 15:19:48,769] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9080
[2019-03-26 15:19:48,773] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 94.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.063425602820189, 6.9112, 168.9119086393763, 1561822.298591707, 1453828.886703928, 311352.3229919619], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4593600.0000, 
sim time next is 4594200.0000, 
raw observation next is [27.0, 94.00000000000001, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.089152852833367, 6.9112, 168.9115903853049, 1580086.245406023, 1453841.387986141, 311352.3000704614], 
processed observation next is [1.0, 0.17391304347826086, 0.4786729857819906, 0.9400000000000002, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.017795285283336692, 0.0, 0.8294332368525187, 0.4389128459461175, 0.4038448299961503, 0.4647049254783006], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.22404471], dtype=float32), -0.038825314]. 
=============================================
[2019-03-26 15:19:56,768] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.9455146e-09 1.0000000e+00 8.2322475e-11 2.8700150e-08 2.9530753e-16], sum to 1.0000
[2019-03-26 15:19:56,777] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8422
[2019-03-26 15:19:56,781] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 70.0, 1.0, 2.0, 0.5362768573771253, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 749381.4685201133, 749381.4685201133, 189477.537203997], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4643400.0000, 
sim time next is 4644000.0000, 
raw observation next is [31.0, 70.0, 1.0, 2.0, 0.5436324995674433, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 759663.7563861161, 759663.7563861156, 190716.6130713642], 
processed observation next is [1.0, 0.782608695652174, 0.6682464454976303, 0.7, 1.0, 1.0, 0.4501596380330642, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21101771010725448, 0.2110177101072543, 0.2846516613005436], 
reward next is 0.7153, 
noisyNet noise sample is [array([0.2780118], dtype=float32), 0.61342084]. 
=============================================
[2019-03-26 15:19:56,792] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[38.9402  ]
 [35.124195]
 [31.134047]
 [27.398026]
 [23.226276]], R is [[42.58193588]
 [42.8733139 ]
 [43.163414  ]
 [43.45348358]
 [43.73892975]].
[2019-03-26 15:20:02,168] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-26 15:20:02,171] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 15:20:02,172] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 15:20:02,173] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 15:20:02,174] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:20:02,173] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 15:20:02,174] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:20:02,175] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 15:20:02,176] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:20:02,177] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:20:02,180] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:20:02,192] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run23
[2019-03-26 15:20:02,211] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run23
[2019-03-26 15:20:02,212] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run23
[2019-03-26 15:20:02,226] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run23
[2019-03-26 15:20:02,244] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run23
[2019-03-26 15:20:04,045] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08900957], dtype=float32), 0.066730745]
[2019-03-26 15:20:04,046] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [27.46666666666667, 69.0, 1.0, 2.0, 0.4394113572183014, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 637279.0568481021, 637279.0568481027, 177628.3042109599]
[2019-03-26 15:20:04,046] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 15:20:04,049] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.2989748e-13 1.0000000e+00 1.0466965e-15 1.9329247e-16 7.7872552e-26], sampled 0.3218436515420148
[2019-03-26 15:20:28,762] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08900957], dtype=float32), 0.066730745]
[2019-03-26 15:20:28,762] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [22.59333030333334, 93.50289592666667, 1.0, 2.0, 0.3800200375980258, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 575975.9789284723, 575975.9789284723, 172622.996995874]
[2019-03-26 15:20:28,765] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 15:20:28,767] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.0246904e-13 1.0000000e+00 1.2589643e-15 1.2362674e-16 7.9563999e-26], sampled 0.8452715117558628
[2019-03-26 15:20:43,078] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08900957], dtype=float32), 0.066730745]
[2019-03-26 15:20:43,080] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.43333333333333, 72.33333333333333, 1.0, 2.0, 0.6999145412150967, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 978150.4582664549, 978150.4582664549, 220826.4717527237]
[2019-03-26 15:20:43,083] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 15:20:43,085] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [4.4887943e-13 1.0000000e+00 2.3738416e-15 3.5524541e-16 2.8800471e-25], sampled 0.18649494408951905
[2019-03-26 15:20:47,678] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08900957], dtype=float32), 0.066730745]
[2019-03-26 15:20:47,680] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.50897423333333, 87.15223642833332, 1.0, 2.0, 0.7560902604506434, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1056696.681455876, 1056696.681455876, 233421.5280787961]
[2019-03-26 15:20:47,681] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 15:20:47,684] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.2775014e-13 1.0000000e+00 1.5244515e-15 2.0038298e-16 1.3896748e-25], sampled 0.8950316305029781
[2019-03-26 15:20:56,583] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08900957], dtype=float32), 0.066730745]
[2019-03-26 15:20:56,585] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [34.35791158333333, 73.23340316666668, 1.0, 2.0, 0.6969562007349421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 974014.1974546477, 974014.1974546477, 220202.3372773424]
[2019-03-26 15:20:56,587] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 15:20:56,592] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.7056382e-13 1.0000000e+00 1.7927380e-15 1.6991497e-16 1.1525469e-25], sampled 0.20800498086792785
[2019-03-26 15:21:26,370] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08900957], dtype=float32), 0.066730745]
[2019-03-26 15:21:26,371] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.79054745, 72.60377806, 1.0, 2.0, 0.5500427559913462, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 768624.5917802049, 768624.5917802056, 191807.6406288851]
[2019-03-26 15:21:26,372] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 15:21:26,375] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.7850509e-11 1.0000000e+00 3.3635036e-13 5.2152952e-12 1.4546049e-20], sampled 0.8308714117350873
[2019-03-26 15:21:50,278] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08900957], dtype=float32), 0.066730745]
[2019-03-26 15:21:50,278] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.7, 67.0, 1.0, 2.0, 0.5710421030939586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 797979.9052473458, 797979.9052473458, 195475.2896976702]
[2019-03-26 15:21:50,279] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:21:50,282] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.7548011e-13 1.0000000e+00 1.6977964e-15 1.9170926e-16 1.2203635e-25], sampled 0.6428775380206823
[2019-03-26 15:21:54,638] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.1701 3164000012.1395 1778.0000
[2019-03-26 15:21:54,657] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.9559 3007647868.8583 1766.0000
[2019-03-26 15:21:54,987] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.8724 2842497929.8887 1131.0000
[2019-03-26 15:21:55,198] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8252.9283 2927272965.6207 1338.0000
[2019-03-26 15:21:55,269] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.7897 2779322429.0906 933.0000
[2019-03-26 15:21:56,287] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 550000, evaluation results [550000.0, 7884.170123390672, 3164000012.13951, 1778.0, 8252.928342174982, 2927272965.6207337, 1338.0, 8659.789741210254, 2779322429.090567, 933.0, 7998.955910945021, 3007647868.858331, 1766.0, 8496.87235025343, 2842497929.888741, 1131.0]
[2019-03-26 15:21:58,146] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.3456379e-08 9.9987125e-01 1.8245620e-08 1.2863736e-04 6.0219739e-11], sum to 1.0000
[2019-03-26 15:21:58,154] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4619
[2019-03-26 15:21:58,161] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.83333333333334, 70.0, 1.0, 2.0, 0.2561871253406685, 1.0, 2.0, 0.2561871253406685, 1.0, 2.0, 0.4449123143397573, 6.9112, 6.9112, 170.5573041426782, 1074129.641629851, 1074129.641629851, 287578.1806382518], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4727400.0000, 
sim time next is 4728000.0000, 
raw observation next is [30.66666666666667, 70.0, 1.0, 2.0, 0.5168445327871388, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.912956510431, 722217.9349582015, 722217.9349582015, 186280.350630835], 
processed observation next is [1.0, 0.7391304347826086, 0.6524486571879939, 0.7, 1.0, 1.0, 0.417884979261613, 0.0, 0.5, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20061609304394484, 0.20061609304394484, 0.2780303740758731], 
reward next is 0.7220, 
noisyNet noise sample is [array([-1.1172911], dtype=float32), 1.0521897]. 
=============================================
[2019-03-26 15:21:58,172] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[21.684803]
 [20.963867]
 [22.319698]
 [21.021711]
 [20.215338]], R is [[25.75723267]
 [26.07043839]
 [26.11727715]
 [26.18646812]
 [26.24513817]].
[2019-03-26 15:22:07,033] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.7023954e-13 1.0000000e+00 8.4129176e-15 2.2399857e-14 1.6678300e-24], sum to 1.0000
[2019-03-26 15:22:07,042] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5894
[2019-03-26 15:22:07,047] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.33333333333333, 77.33333333333333, 1.0, 2.0, 0.5206245008709525, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 727501.7203321003, 727501.7203320996, 186890.6140350714], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4995600.0000, 
sim time next is 4996200.0000, 
raw observation next is [28.16666666666667, 78.16666666666667, 1.0, 2.0, 0.5190113034278284, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 725246.7274278646, 725246.7274278653, 186628.4037743669], 
processed observation next is [1.0, 0.8260869565217391, 0.5339652448657191, 0.7816666666666667, 1.0, 1.0, 0.42049554629858843, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20145742428551794, 0.20145742428551813, 0.27854985637965207], 
reward next is 0.7215, 
noisyNet noise sample is [array([3.1675098], dtype=float32), 0.45166916]. 
=============================================
[2019-03-26 15:22:12,136] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.6574668e-09 9.9999952e-01 6.1775934e-10 4.3414445e-07 7.9813563e-14], sum to 1.0000
[2019-03-26 15:22:12,145] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7783
[2019-03-26 15:22:12,155] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1937228.94232351 W.
[2019-03-26 15:22:12,160] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.56666666666667, 64.16666666666667, 1.0, 2.0, 0.6927843473276367, 1.0, 2.0, 0.6927843473276367, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1937228.94232351, 1937228.94232351, 371045.6203198943], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4974600.0000, 
sim time next is 4975200.0000, 
raw observation next is [30.6, 64.0, 1.0, 2.0, 0.5019865378720729, 1.0, 2.0, 0.5019865378720729, 1.0, 1.0, 0.8594479552027057, 6.9112, 6.9112, 170.5573041426782, 2105718.592179465, 2105718.592179465, 414268.3255781503], 
processed observation next is [1.0, 0.6086956521739131, 0.6492890995260664, 0.64, 1.0, 1.0, 0.39998378056876255, 1.0, 1.0, 0.39998378056876255, 1.0, 0.5, 0.8285950673203728, 0.0, 0.0, 0.8375144448122397, 0.5849218311609625, 0.5849218311609625, 0.6183109336987318], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9964851], dtype=float32), 0.08740227]. 
=============================================
[2019-03-26 15:22:13,793] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.0391464e-10 1.0000000e+00 7.8565201e-12 6.4575889e-10 9.2321231e-18], sum to 1.0000
[2019-03-26 15:22:13,802] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8016
[2019-03-26 15:22:13,807] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.83333333333333, 70.66666666666667, 1.0, 2.0, 0.5175459498903098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 723198.4008884656, 723198.4008884649, 186391.9799378255], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4990200.0000, 
sim time next is 4990800.0000, 
raw observation next is [29.66666666666667, 71.33333333333334, 1.0, 2.0, 0.5206798587619019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 727579.1019253226, 727579.1019253231, 186900.4308882074], 
processed observation next is [1.0, 0.782608695652174, 0.6050552922590839, 0.7133333333333334, 1.0, 1.0, 0.4225058539300023, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20210530609036736, 0.20210530609036753, 0.2789558669973245], 
reward next is 0.7210, 
noisyNet noise sample is [array([-0.53178823], dtype=float32), -0.23290426]. 
=============================================
[2019-03-26 15:22:17,132] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.474759e-13 1.000000e+00 4.275968e-15 9.081303e-17 9.721202e-26], sum to 1.0000
[2019-03-26 15:22:17,141] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9023
[2019-03-26 15:22:17,145] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 66.0, 1.0, 2.0, 0.5090546872603902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 711329.0709204307, 711329.0709204313, 185026.9719908704], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5044200.0000, 
sim time next is 5044800.0000, 
raw observation next is [30.0, 66.0, 1.0, 2.0, 0.5069270928919654, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 708355.0793879728, 708355.0793879734, 184688.7124087242], 
processed observation next is [0.0, 0.391304347826087, 0.6208530805687204, 0.66, 1.0, 1.0, 0.4059362564963438, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19676529982999244, 0.1967652998299926, 0.2756547946398869], 
reward next is 0.7243, 
noisyNet noise sample is [array([0.9600173], dtype=float32), -1.0474412]. 
=============================================
[2019-03-26 15:22:23,687] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.5617820e-13 1.0000000e+00 4.9642203e-16 3.1265604e-17 4.4345739e-26], sum to 1.0000
[2019-03-26 15:22:23,693] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4368
[2019-03-26 15:22:23,698] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 63.0, 1.0, 2.0, 0.5736702554996205, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 801653.8974371125, 801653.8974371132, 195941.9700258927], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5152200.0000, 
sim time next is 5152800.0000, 
raw observation next is [32.0, 63.00000000000001, 1.0, 2.0, 0.5535319987922865, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 773502.2022834525, 773502.2022834532, 192408.6116957248], 
processed observation next is [0.0, 0.6521739130434783, 0.7156398104265403, 0.6300000000000001, 1.0, 1.0, 0.4620867455328753, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2148617228565146, 0.21486172285651478, 0.2871770323816788], 
reward next is 0.7128, 
noisyNet noise sample is [array([0.6092905], dtype=float32), 0.78089017]. 
=============================================
[2019-03-26 15:22:24,186] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.13451424e-13 1.00000000e+00 9.00173783e-16 1.81541289e-16
 3.22035728e-27], sum to 1.0000
[2019-03-26 15:22:24,196] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1431
[2019-03-26 15:22:24,203] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 79.0, 1.0, 2.0, 0.5215470822073178, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 728791.3441453838, 728791.3441453838, 187040.6993559272], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5172000.0000, 
sim time next is 5172600.0000, 
raw observation next is [28.0, 79.0, 1.0, 2.0, 0.5219545979481395, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 729360.9876476666, 729360.9876476672, 187107.1495156563], 
processed observation next is [0.0, 0.8695652173913043, 0.5260663507109005, 0.79, 1.0, 1.0, 0.4240416842748668, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20260027434657404, 0.2026002743465742, 0.2792644022621736], 
reward next is 0.7207, 
noisyNet noise sample is [array([-0.7773011], dtype=float32), 1.883975]. 
=============================================
[2019-03-26 15:22:29,460] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.3918773e-07 9.9873811e-01 3.7976292e-08 1.2618039e-03 1.3341449e-10], sum to 1.0000
[2019-03-26 15:22:29,468] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8497
[2019-03-26 15:22:29,481] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2526205.677648971 W.
[2019-03-26 15:22:29,484] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.16666666666667, 69.5, 1.0, 2.0, 0.6021218074620481, 1.0, 2.0, 0.6021218074620481, 1.0, 2.0, 1.03, 6.928834013131838, 6.9112, 170.5573041426782, 2526205.677648971, 2513573.716736843, 488748.7528089192], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5244600.0000, 
sim time next is 5245200.0000, 
raw observation next is [31.0, 70.0, 1.0, 2.0, 0.669588538831003, 1.0, 2.0, 0.6553843089297641, 1.0, 2.0, 1.03, 7.005095334363107, 6.9112, 170.5573041426782, 2749914.748232656, 2682653.700810359, 511894.5396486418], 
processed observation next is [1.0, 0.7391304347826086, 0.6682464454976303, 0.7, 1.0, 1.0, 0.6019139022060277, 1.0, 1.0, 0.584800372204535, 1.0, 1.0, 1.0365853658536586, 0.009389533436310682, 0.0, 0.8375144448122397, 0.7638652078424045, 0.745181583558433, 0.764021700968122], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5917806], dtype=float32), 0.5101123]. 
=============================================
[2019-03-26 15:22:34,668] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.5059736e-14 1.0000000e+00 6.9949071e-16 5.3977243e-16 1.5782681e-25], sum to 1.0000
[2019-03-26 15:22:34,675] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7732
[2019-03-26 15:22:34,684] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.86666666666667, 84.0, 1.0, 2.0, 0.6128122521157372, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 856373.4573172141, 856373.4573172141, 203157.3513647149], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5353800.0000, 
sim time next is 5354400.0000, 
raw observation next is [29.83333333333333, 84.0, 1.0, 2.0, 0.6110621381928617, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 853926.7803851445, 853926.7803851451, 202825.1450226855], 
processed observation next is [1.0, 1.0, 0.6129541864139019, 0.84, 1.0, 1.0, 0.5314001664974237, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.23720188344031792, 0.2372018834403181, 0.30272409704878434], 
reward next is 0.6973, 
noisyNet noise sample is [array([0.8446722], dtype=float32), 1.093549]. 
=============================================
[2019-03-26 15:22:38,709] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.1406919e-12 1.0000000e+00 1.1133487e-15 4.4795502e-16 1.9845885e-26], sum to 1.0000
[2019-03-26 15:22:38,715] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0739
[2019-03-26 15:22:38,721] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.56666666666666, 60.33333333333334, 1.0, 2.0, 0.5521515385808276, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 771572.4550705901, 771572.4550705901, 192170.8571111246], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5761200.0000, 
sim time next is 5761800.0000, 
raw observation next is [32.4, 61.5, 1.0, 2.0, 0.5521724500911104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 771601.6872731918, 771601.687273191, 192174.6469133919], 
processed observation next is [0.0, 0.6956521739130435, 0.7345971563981042, 0.615, 1.0, 1.0, 0.46044873504953054, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21433380202033103, 0.21433380202033084, 0.2868278312140177], 
reward next is 0.7132, 
noisyNet noise sample is [array([-0.8865482], dtype=float32), 0.038761694]. 
=============================================
[2019-03-26 15:22:51,458] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-26 15:22:51,460] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 15:22:51,460] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:22:51,461] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 15:22:51,462] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 15:22:51,463] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:22:51,464] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 15:22:51,465] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 15:22:51,467] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:22:51,465] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:22:51,468] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:22:51,488] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run24
[2019-03-26 15:22:51,507] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run24
[2019-03-26 15:22:51,508] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run24
[2019-03-26 15:22:51,527] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run24
[2019-03-26 15:22:51,566] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run24
[2019-03-26 15:22:53,914] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.09247576], dtype=float32), 0.06698128]
[2019-03-26 15:22:53,916] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [23.6, 80.0, 1.0, 2.0, 0.3362444100452638, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 521523.916682339, 521523.9166823397, 168432.5051190772]
[2019-03-26 15:22:53,917] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:22:53,919] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.13864669e-12 1.00000000e+00 1.08850485e-14 6.58345135e-16
 3.08091796e-25], sampled 0.8261421257428362
[2019-03-26 15:23:09,572] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.09247576], dtype=float32), 0.06698128]
[2019-03-26 15:23:09,573] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.11666666666667, 71.16666666666667, 1.0, 2.0, 0.5864872376937534, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9792028089072652, 6.911199999999999, 6.9112, 168.9129181915668, 1639775.717601623, 1639775.717601624, 350293.3679863493]
[2019-03-26 15:23:09,574] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:23:09,578] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.7191844e-11 1.0000000e+00 6.9112093e-13 1.5075558e-12 4.9003686e-21], sampled 0.3271954852660034
[2019-03-26 15:23:21,558] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.09247576], dtype=float32), 0.06698128]
[2019-03-26 15:23:21,559] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [25.3, 90.0, 1.0, 2.0, 0.4860448323257275, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 679165.9036471585, 679165.9036471591, 181437.9391677412]
[2019-03-26 15:23:21,559] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 15:23:21,562] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.7205099e-13 1.0000000e+00 1.2572366e-15 1.1916674e-16 1.2219188e-26], sampled 0.6866067502019537
[2019-03-26 15:23:25,414] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.09247576], dtype=float32), 0.06698128]
[2019-03-26 15:23:25,414] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [33.13333333333334, 60.66666666666667, 1.0, 2.0, 0.8128096896562904, 1.0, 2.0, 0.8128096896562904, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2273202.059929941, 2273202.059929941, 426159.7411448776]
[2019-03-26 15:23:25,416] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:23:25,419] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [6.2529075e-09 9.9999762e-01 2.0881037e-09 2.3388363e-06 2.0365476e-14], sampled 0.33426146626620556
[2019-03-26 15:23:25,420] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2273202.059929941 W.
[2019-03-26 15:23:46,022] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.09247576], dtype=float32), 0.06698128]
[2019-03-26 15:23:46,023] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [36.65, 49.5, 1.0, 2.0, 0.6106835707394744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 853397.5400050007, 853397.5400050007, 202752.9780879872]
[2019-03-26 15:23:46,024] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:23:46,027] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [4.2163977e-13 1.0000000e+00 3.7281859e-15 4.5649925e-16 8.0240355e-26], sampled 0.9798595825299733
[2019-03-26 15:24:29,486] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.09247576], dtype=float32), 0.06698128]
[2019-03-26 15:24:29,487] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.98668179666667, 57.20845284666667, 1.0, 2.0, 0.3607031925111464, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 553378.435261431, 553378.4352614317, 170866.8260047713]
[2019-03-26 15:24:29,491] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 15:24:29,494] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.6228655e-12 1.0000000e+00 1.4738738e-14 1.1489619e-15 5.1623230e-25], sampled 0.4272374043131434
[2019-03-26 15:24:44,022] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.9164 3164002230.9074 1778.0000
[2019-03-26 15:24:44,317] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.9559 3007647868.8583 1766.0000
[2019-03-26 15:24:44,337] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.6296 2927288714.5388 1338.0000
[2019-03-26 15:24:44,460] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.4676 2779124528.0117 933.0000
[2019-03-26 15:24:44,626] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8495.3917 2842500259.9815 1131.0000
[2019-03-26 15:24:45,643] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 575000, evaluation results [575000.0, 7884.916440885027, 3164002230.907359, 1778.0, 8253.629619461894, 2927288714.5388227, 1338.0, 8661.467580702742, 2779124528.011676, 933.0, 7998.955910945021, 3007647868.858331, 1766.0, 8495.391660965437, 2842500259.9814672, 1131.0]
[2019-03-26 15:24:45,869] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1466818e-13 1.0000000e+00 3.5733135e-14 6.9653774e-16 2.6805696e-25], sum to 1.0000
[2019-03-26 15:24:45,878] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6004
[2019-03-26 15:24:45,883] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.93333333333334, 89.33333333333334, 1.0, 2.0, 0.4997674207621288, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 698347.215813829, 698347.215813829, 183559.6003165944], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5635200.0000, 
sim time next is 5635800.0000, 
raw observation next is [26.1, 88.5, 1.0, 2.0, 0.5009055488701574, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 699938.0967232737, 699938.0967232744, 183738.0839278941], 
processed observation next is [0.0, 0.21739130434782608, 0.4360189573459717, 0.885, 1.0, 1.0, 0.3986813841809125, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19442724908979828, 0.19442724908979844, 0.27423594616103597], 
reward next is 0.7258, 
noisyNet noise sample is [array([-2.3301349], dtype=float32), 0.5748594]. 
=============================================
[2019-03-26 15:24:47,819] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.4435705e-12 1.0000000e+00 4.5288673e-14 1.5624034e-13 1.7225608e-22], sum to 1.0000
[2019-03-26 15:24:47,830] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2940
[2019-03-26 15:24:47,834] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.15, 93.16666666666667, 1.0, 2.0, 0.9362284334903109, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129565104304, 1308609.343350536, 1308609.343350536, 280096.898005911], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5803800.0000, 
sim time next is 5804400.0000, 
raw observation next is [26.1, 93.33333333333334, 1.0, 2.0, 0.8847047730610226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1236550.425424683, 1236550.425424683, 265764.2286518241], 
processed observation next is [1.0, 0.17391304347826086, 0.4360189573459717, 0.9333333333333335, 1.0, 1.0, 0.8610900880253284, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3434862292846341, 0.3434862292846341, 0.39666302783854346], 
reward next is 0.6033, 
noisyNet noise sample is [array([-0.03747413], dtype=float32), -1.9504757]. 
=============================================
[2019-03-26 15:24:54,184] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.3951122e-13 1.0000000e+00 1.8391762e-15 1.0575006e-15 1.1892726e-26], sum to 1.0000
[2019-03-26 15:24:54,191] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5448
[2019-03-26 15:24:54,198] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.61666666666667, 75.0, 1.0, 2.0, 0.5538472464419999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 773942.8878947821, 773942.8878947821, 192462.6396366011], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5770200.0000, 
sim time next is 5770800.0000, 
raw observation next is [29.4, 76.0, 1.0, 2.0, 0.5523414727824326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 771837.9641421289, 771837.9641421289, 192203.0068118425], 
processed observation next is [0.0, 0.8260869565217391, 0.5924170616113744, 0.76, 1.0, 1.0, 0.46065237684630433, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2143994344839247, 0.2143994344839247, 0.28687015942066046], 
reward next is 0.7131, 
noisyNet noise sample is [array([0.36557022], dtype=float32), 2.1809676]. 
=============================================
[2019-03-26 15:24:54,838] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.0920909e-13 1.0000000e+00 6.2428425e-16 2.4828336e-16 5.9973778e-27], sum to 1.0000
[2019-03-26 15:24:54,847] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1508
[2019-03-26 15:24:54,851] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.56666666666667, 85.66666666666667, 1.0, 2.0, 0.5461227528156555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 763144.8483131959, 763144.8483131966, 191137.5523005457], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5781000.0000, 
sim time next is 5781600.0000, 
raw observation next is [27.5, 86.0, 1.0, 2.0, 0.5443056818944126, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 760604.7878911024, 760604.7878911024, 190828.5858248018], 
processed observation next is [0.0, 0.9565217391304348, 0.5023696682464456, 0.86, 1.0, 1.0, 0.45097070107760556, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21127910774752845, 0.21127910774752845, 0.284818784813137], 
reward next is 0.7152, 
noisyNet noise sample is [array([-0.95070887], dtype=float32), -0.6106106]. 
=============================================
[2019-03-26 15:24:57,033] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.9801273e-13 1.0000000e+00 7.0874686e-15 3.2058524e-15 2.8211346e-24], sum to 1.0000
[2019-03-26 15:24:57,041] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7073
[2019-03-26 15:24:57,045] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.73333333333333, 87.33333333333333, 1.0, 2.0, 0.9435376608628683, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1318832.130731554, 1318832.130731553, 282195.868357793], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6162600.0000, 
sim time next is 6163200.0000, 
raw observation next is [27.8, 87.0, 1.0, 2.0, 0.7811103214181025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1091682.194335292, 1091682.194335292, 239328.3936755353], 
processed observation next is [1.0, 0.34782608695652173, 0.5165876777251186, 0.87, 1.0, 1.0, 0.7362774956844609, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.30324505398202556, 0.30324505398202556, 0.3572065577246796], 
reward next is 0.6428, 
noisyNet noise sample is [array([-1.3640178], dtype=float32), -1.3071051]. 
=============================================
[2019-03-26 15:24:58,803] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.3653296e-06 7.8674012e-01 1.0184639e-06 2.1325743e-01 6.8611286e-08], sum to 1.0000
[2019-03-26 15:24:58,812] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8373
[2019-03-26 15:24:58,820] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.1, 64.33333333333333, 1.0, 2.0, 0.6979160705625299, 1.0, 2.0, 0.6695480747955276, 1.0, 2.0, 1.03, 7.005097567840654, 6.9112, 170.5573041426782, 2809411.053728039, 2742148.406374923, 520671.0137850718], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5848800.0000, 
sim time next is 5849400.0000, 
raw observation next is [32.05, 64.66666666666667, 1.0, 2.0, 0.9787090099863667, 1.0, 2.0, 0.9787090099863667, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2737684.484748906, 2737684.484748906, 516250.2578092753], 
processed observation next is [1.0, 0.6956521739130435, 0.7180094786729857, 0.6466666666666667, 1.0, 1.0, 0.9743482048028514, 1.0, 1.0, 0.9743482048028514, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7604679124302517, 0.7604679124302517, 0.7705227728496646], 
reward next is 0.2295, 
noisyNet noise sample is [array([-0.15502761], dtype=float32), 1.2610908]. 
=============================================
[2019-03-26 15:24:59,912] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.3136043e-13 1.0000000e+00 2.8446517e-15 2.0142767e-15 2.9961821e-24], sum to 1.0000
[2019-03-26 15:24:59,920] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7054
[2019-03-26 15:24:59,928] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.8, 95.0, 1.0, 2.0, 0.9620627942517301, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1344742.081665313, 1344742.081665313, 287578.9995235306], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5887800.0000, 
sim time next is 5888400.0000, 
raw observation next is [25.76666666666667, 95.0, 1.0, 2.0, 0.8652177586961459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1209297.945986567, 1209297.945986568, 260548.0217877897], 
processed observation next is [1.0, 0.13043478260869565, 0.42022116903633505, 0.95, 1.0, 1.0, 0.8376117574652361, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3359160961073797, 0.33591609610738, 0.3888776444593876], 
reward next is 0.6111, 
noisyNet noise sample is [array([-1.4709361], dtype=float32), 1.9312975]. 
=============================================
[2019-03-26 15:25:02,358] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.4933687e-13 1.0000000e+00 3.5492030e-16 1.4412255e-15 1.2755779e-25], sum to 1.0000
[2019-03-26 15:25:02,365] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3575
[2019-03-26 15:25:02,370] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.2, 88.0, 1.0, 2.0, 0.5409022988955433, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 755847.258253799, 755847.2582537985, 190252.5810709409], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6040800.0000, 
sim time next is 6041400.0000, 
raw observation next is [27.15, 88.33333333333334, 1.0, 2.0, 0.540081286645159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 754699.582762176, 754699.5827621754, 190114.1432237246], 
processed observation next is [1.0, 0.9565217391304348, 0.485781990521327, 0.8833333333333334, 1.0, 1.0, 0.44588106824717944, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20963877298949335, 0.20963877298949316, 0.28375245257272325], 
reward next is 0.7162, 
noisyNet noise sample is [array([-0.33167237], dtype=float32), 1.6289772]. 
=============================================
[2019-03-26 15:25:18,487] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.1257881e-08 9.9978596e-01 1.7801840e-08 2.1396462e-04 4.5424697e-12], sum to 1.0000
[2019-03-26 15:25:18,496] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8782
[2019-03-26 15:25:18,508] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2314842.957195647 W.
[2019-03-26 15:25:18,516] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.2, 71.0, 1.0, 2.0, 0.8276850973607577, 1.0, 2.0, 0.8276850973607577, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2314842.957195647, 2314842.957195647, 433572.4413875162], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6188400.0000, 
sim time next is 6189000.0000, 
raw observation next is [30.1, 71.33333333333334, 1.0, 2.0, 0.8046524410098511, 1.0, 2.0, 0.8046524410098511, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2250367.970427067, 2250367.970427067, 422140.8986878138], 
processed observation next is [1.0, 0.6521739130434783, 0.6255924170616115, 0.7133333333333334, 1.0, 1.0, 0.7646414951925917, 1.0, 1.0, 0.7646414951925917, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6251022140075186, 0.6251022140075186, 0.6300610428176325], 
reward next is 0.3699, 
noisyNet noise sample is [array([0.44633597], dtype=float32), -2.7597134]. 
=============================================
[2019-03-26 15:25:18,527] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[24.212723]
 [23.429403]
 [24.886772]
 [24.387434]
 [23.421377]], R is [[24.8172226 ]
 [24.9219265 ]
 [24.95868874]
 [24.70910263]
 [24.46201134]].
[2019-03-26 15:25:18,818] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.46481561e-08 9.99893665e-01 5.77397650e-08 1.06202475e-04
 4.62780031e-12], sum to 1.0000
[2019-03-26 15:25:18,825] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3329
[2019-03-26 15:25:18,833] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2307844.165386607 W.
[2019-03-26 15:25:18,840] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.0, 71.66666666666667, 1.0, 2.0, 0.8251849485772438, 1.0, 2.0, 0.8251849485772438, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2307844.165386607, 2307844.165386607, 432315.9534813511], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6189600.0000, 
sim time next is 6190200.0000, 
raw observation next is [29.9, 72.0, 1.0, 2.0, 0.8301687723786543, 1.0, 2.0, 0.8301687723786543, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2321795.671976353, 2321795.671976353, 434822.9274533091], 
processed observation next is [1.0, 0.6521739130434783, 0.6161137440758293, 0.72, 1.0, 1.0, 0.7953840631068124, 1.0, 1.0, 0.7953840631068124, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6449432422156536, 0.6449432422156536, 0.6489894439601629], 
reward next is 0.3510, 
noisyNet noise sample is [array([-0.36797333], dtype=float32), -1.6695188]. 
=============================================
[2019-03-26 15:25:25,283] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.8501886e-14 1.0000000e+00 1.2070864e-15 2.8806082e-17 1.4012843e-26], sum to 1.0000
[2019-03-26 15:25:25,295] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7787
[2019-03-26 15:25:25,300] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.3, 85.16666666666667, 1.0, 2.0, 0.5289172763333795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 739093.7742306674, 739093.7742306667, 188250.7419989714], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6307800.0000, 
sim time next is 6308400.0000, 
raw observation next is [27.3, 85.33333333333334, 1.0, 2.0, 0.5297373591888676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 740240.133698212, 740240.1336982113, 188386.3710716541], 
processed observation next is [0.0, 0.0, 0.4928909952606636, 0.8533333333333334, 1.0, 1.0, 0.43341850504682833, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20562225936061443, 0.20562225936061423, 0.28117368816664795], 
reward next is 0.7188, 
noisyNet noise sample is [array([0.59813154], dtype=float32), 0.82853484]. 
=============================================
[2019-03-26 15:25:25,658] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.3949953e-12 1.0000000e+00 1.1602505e-15 1.2075463e-16 6.9219814e-26], sum to 1.0000
[2019-03-26 15:25:25,672] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6306
[2019-03-26 15:25:25,680] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.05, 87.16666666666667, 1.0, 2.0, 0.5315417853551494, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 742762.4697981189, 742762.4697981195, 188685.4003177252], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6318600.0000, 
sim time next is 6319200.0000, 
raw observation next is [27.0, 87.33333333333334, 1.0, 2.0, 0.5312311069662969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 742328.1843169428, 742328.1843169421, 188633.784903191], 
processed observation next is [0.0, 0.13043478260869565, 0.4786729857819906, 0.8733333333333334, 1.0, 1.0, 0.43521820116421317, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.206202273421373, 0.20620227342137282, 0.2815429625420761], 
reward next is 0.7185, 
noisyNet noise sample is [array([-1.2728835], dtype=float32), -1.1212999]. 
=============================================
[2019-03-26 15:25:31,654] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.2149484e-11 1.0000000e+00 2.4788355e-12 4.0023340e-10 2.9575336e-20], sum to 1.0000
[2019-03-26 15:25:31,664] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4181
[2019-03-26 15:25:31,667] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.1, 71.0, 1.0, 2.0, 0.5080060797651659, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 709863.3065473617, 709863.3065473617, 184860.1133665696], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6459600.0000, 
sim time next is 6460200.0000, 
raw observation next is [29.0, 71.5, 1.0, 2.0, 0.5065285289715604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 707797.9601494962, 707797.9601494956, 184625.4918272529], 
processed observation next is [1.0, 0.782608695652174, 0.5734597156398105, 0.715, 1.0, 1.0, 0.40545605900188, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19661054448597118, 0.196610544485971, 0.27556043556306403], 
reward next is 0.7244, 
noisyNet noise sample is [array([0.5173405], dtype=float32), -0.7257373]. 
=============================================
[2019-03-26 15:25:40,816] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-26 15:25:40,817] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 15:25:40,818] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:25:40,818] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 15:25:40,819] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:25:40,820] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 15:25:40,821] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 15:25:40,821] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:25:40,821] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:25:40,823] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 15:25:40,824] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:25:40,848] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run25
[2019-03-26 15:25:40,849] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run25
[2019-03-26 15:25:40,849] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run25
[2019-03-26 15:25:40,867] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run25
[2019-03-26 15:25:40,884] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run25
[2019-03-26 15:26:02,521] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.09480758], dtype=float32), 0.0671788]
[2019-03-26 15:26:02,522] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.37325424, 94.55638492, 1.0, 2.0, 0.518676106750478, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 724778.1764992952, 724778.1764992945, 186573.0575793366]
[2019-03-26 15:26:02,524] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 15:26:02,526] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.1892623e-13 1.0000000e+00 8.1673993e-16 6.7101970e-17 7.0000728e-27], sampled 0.3382510759680206
[2019-03-26 15:26:09,783] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.09480758], dtype=float32), 0.0671788]
[2019-03-26 15:26:09,784] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [23.2, 93.66666666666667, 1.0, 2.0, 0.4157861890993451, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 616036.8703230956, 616036.8703230956, 175913.6515170794]
[2019-03-26 15:26:09,787] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 15:26:09,790] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.1660285e-13 1.0000000e+00 7.8460964e-16 7.0716895e-17 7.9750232e-27], sampled 0.2539696073660479
[2019-03-26 15:26:13,458] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.09480758], dtype=float32), 0.0671788]
[2019-03-26 15:26:13,459] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [23.2, 85.33333333333334, 1.0, 2.0, 0.3674077178350567, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 564743.4286414272, 564743.4286414278, 171864.2219266258]
[2019-03-26 15:26:13,461] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:26:13,465] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.3091308e-13 1.0000000e+00 1.6941541e-15 1.2544239e-16 2.3582590e-26], sampled 0.7912184099654035
[2019-03-26 15:26:21,262] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.09480758], dtype=float32), 0.0671788]
[2019-03-26 15:26:21,263] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [26.85, 88.5, 1.0, 2.0, 0.7097929063520719, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 991962.2017582664, 991962.2017582658, 222972.7859235226]
[2019-03-26 15:26:21,263] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:26:21,266] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.4761224e-13 1.0000000e+00 3.3500293e-15 3.9412787e-16 9.5841528e-26], sampled 0.426827593520403
[2019-03-26 15:26:28,557] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.09480758], dtype=float32), 0.0671788]
[2019-03-26 15:26:28,557] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [33.01246589, 79.96499754, 1.0, 2.0, 0.6901499997551589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 964498.0374235207, 964498.0374235207, 218745.8974872573]
[2019-03-26 15:26:28,558] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 15:26:28,560] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.3362342e-13 1.0000000e+00 1.8260197e-15 1.6610875e-16 2.6436750e-26], sampled 0.07495787052038905
[2019-03-26 15:26:31,553] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.09480758], dtype=float32), 0.0671788]
[2019-03-26 15:26:31,554] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.5, 79.0, 1.0, 2.0, 0.7904241305869535, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1104705.973821616, 1104705.973821616, 241571.4832407911]
[2019-03-26 15:26:31,554] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:26:31,557] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [4.3587952e-13 1.0000000e+00 4.4940324e-15 4.8756376e-16 1.4498922e-25], sampled 0.19654224222311756
[2019-03-26 15:27:17,589] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.09480758], dtype=float32), 0.0671788]
[2019-03-26 15:27:17,591] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [30.51666666666667, 57.83333333333333, 1.0, 2.0, 0.4832361731055028, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 676397.0275060844, 676397.027506085, 181159.9691284858]
[2019-03-26 15:27:17,591] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 15:27:17,593] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.4433561e-13 1.0000000e+00 4.0139748e-15 1.3175225e-15 3.1375263e-26], sampled 0.7810425253684988
[2019-03-26 15:27:28,983] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.09480758], dtype=float32), 0.0671788]
[2019-03-26 15:27:28,984] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.9, 70.0, 1.0, 2.0, 0.5684359389994967, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 794336.6638863148, 794336.6638863154, 195012.694734095]
[2019-03-26 15:27:28,984] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:27:28,986] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.6280982e-13 1.0000000e+00 1.2172221e-15 1.1926633e-16 1.4178995e-26], sampled 0.23553839514958153
[2019-03-26 15:27:33,771] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.4676 2779124528.0117 933.0000
[2019-03-26 15:27:33,945] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.1684 3164071917.9177 1778.0000
[2019-03-26 15:27:34,013] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7999.0502 3007584666.7691 1766.0000
[2019-03-26 15:27:34,036] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.4166 2842558242.3972 1131.0000
[2019-03-26 15:27:34,067] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.6481 2927351128.7738 1338.0000
[2019-03-26 15:27:35,082] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 600000, evaluation results [600000.0, 7884.168443086554, 3164071917.9176674, 1778.0, 8253.648088117536, 2927351128.7737722, 1338.0, 8661.467580702742, 2779124528.011676, 933.0, 7999.050242421542, 3007584666.769063, 1766.0, 8497.416582222564, 2842558242.397172, 1131.0]
[2019-03-26 15:27:39,048] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.6465263e-13 1.0000000e+00 5.7573226e-16 1.1387552e-16 1.8998433e-26], sum to 1.0000
[2019-03-26 15:27:39,060] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4483
[2019-03-26 15:27:39,064] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.65, 65.5, 1.0, 2.0, 0.4109523342994111, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 605500.8511653418, 605500.8511653412, 174826.5594496014], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6989400.0000, 
sim time next is 6990000.0000, 
raw observation next is [27.53333333333333, 66.66666666666667, 1.0, 2.0, 0.4144269176033511, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 608711.9609456295, 608711.9609456295, 175072.9004370057], 
processed observation next is [0.0, 0.9130434782608695, 0.5039494470774091, 0.6666666666666667, 1.0, 1.0, 0.2944902621727122, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16908665581823043, 0.16908665581823043, 0.26130283647314284], 
reward next is 0.7387, 
noisyNet noise sample is [array([0.85377055], dtype=float32), 0.21619162]. 
=============================================
[2019-03-26 15:27:39,071] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[73.53316 ]
 [73.49954 ]
 [73.47735 ]
 [73.438225]
 [73.42218 ]], R is [[73.5684967 ]
 [73.57187653]
 [73.57574463]
 [73.58074951]
 [73.58530426]].
[2019-03-26 15:27:43,315] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.8799930e-08 9.9992371e-01 1.9793180e-08 7.6147255e-05 1.2319582e-11], sum to 1.0000
[2019-03-26 15:27:43,325] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1808
[2019-03-26 15:27:43,330] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1904647.878598162 W.
[2019-03-26 15:27:43,335] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.4, 71.0, 1.0, 2.0, 0.681143180321183, 1.0, 1.0, 0.681143180321183, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 1904647.878598162, 1904647.878598162, 366145.8645622435], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7059600.0000, 
sim time next is 7060200.0000, 
raw observation next is [28.26666666666667, 71.83333333333334, 1.0, 2.0, 0.3186732830149777, 1.0, 2.0, 0.3186732830149777, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 890669.6686278308, 890669.6686278308, 253575.2761470499], 
processed observation next is [1.0, 0.7391304347826086, 0.53870458135861, 0.7183333333333334, 1.0, 1.0, 0.17912443736744302, 1.0, 1.0, 0.17912443736744302, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.24740824128550856, 0.24740824128550856, 0.3784705614135073], 
reward next is 0.6215, 
noisyNet noise sample is [array([1.1373187], dtype=float32), 0.053834755]. 
=============================================
[2019-03-26 15:28:00,224] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.3529323e-12 1.0000000e+00 4.5762234e-15 8.5481692e-16 2.9739418e-25], sum to 1.0000
[2019-03-26 15:28:00,233] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0391
[2019-03-26 15:28:00,239] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.7, 69.0, 1.0, 2.0, 0.7189436897528485, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1032662.526298912, 1032662.526298912, 228738.5850594525], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7027200.0000, 
sim time next is 7027800.0000, 
raw observation next is [27.86666666666667, 68.0, 1.0, 2.0, 0.657469769871141, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 944794.0736584287, 944794.0736584287, 215339.9679860453], 
processed observation next is [1.0, 0.34782608695652173, 0.519747235387046, 0.68, 1.0, 1.0, 0.5873129757483627, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2624427982384524, 0.2624427982384524, 0.3214029372926049], 
reward next is 0.6786, 
noisyNet noise sample is [array([-0.55204785], dtype=float32), -1.2881199]. 
=============================================
[2019-03-26 15:28:05,693] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.8319922e-13 1.0000000e+00 2.3644336e-15 3.1892011e-16 4.1787090e-26], sum to 1.0000
[2019-03-26 15:28:05,701] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4459
[2019-03-26 15:28:05,710] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.06666666666666, 90.33333333333334, 1.0, 2.0, 0.4734810867919897, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 663170.6182680926, 663170.6182680926, 179747.5908438063], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7087200.0000, 
sim time next is 7087800.0000, 
raw observation next is [25.03333333333333, 90.66666666666667, 1.0, 2.0, 0.4733658023761965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 662661.4765737271, 662661.4765737278, 179685.4985024148], 
processed observation next is [1.0, 0.0, 0.38546603475513425, 0.9066666666666667, 1.0, 1.0, 0.365500966718309, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18407263238159086, 0.18407263238159105, 0.268187311197634], 
reward next is 0.7318, 
noisyNet noise sample is [array([1.9900503], dtype=float32), -0.20582987]. 
=============================================
[2019-03-26 15:28:11,623] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.5194137e-13 1.0000000e+00 7.0954722e-16 2.2902357e-16 5.7505766e-26], sum to 1.0000
[2019-03-26 15:28:11,636] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1168
[2019-03-26 15:28:11,645] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333334, 89.66666666666666, 1.0, 2.0, 0.5690731935054382, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 795227.5014856862, 795227.5014856867, 195121.7565226524], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7191600.0000, 
sim time next is 7192200.0000, 
raw observation next is [26.46666666666667, 89.33333333333333, 1.0, 2.0, 0.5704420546150114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 797141.0768989144, 797141.0768989144, 195364.6506978352], 
processed observation next is [1.0, 0.21739130434782608, 0.45339652448657203, 0.8933333333333333, 1.0, 1.0, 0.48246030676507395, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22142807691636512, 0.22142807691636512, 0.2915890308922913], 
reward next is 0.7084, 
noisyNet noise sample is [array([-0.57931286], dtype=float32), 0.10828129]. 
=============================================
[2019-03-26 15:28:12,914] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.4744888e-08 9.9997246e-01 3.4100708e-08 2.7470198e-05 3.8276079e-12], sum to 1.0000
[2019-03-26 15:28:12,925] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3337
[2019-03-26 15:28:12,933] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1991404.250424934 W.
[2019-03-26 15:28:12,939] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.16666666666667, 82.5, 1.0, 2.0, 0.474760215298788, 1.0, 2.0, 0.474760215298788, 1.0, 2.0, 0.8222458053523732, 6.911200000000001, 6.9112, 170.5573041426782, 1991404.250424934, 1991404.250424934, 397747.3314395525], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7215000.0000, 
sim time next is 7215600.0000, 
raw observation next is [27.33333333333334, 86.0, 1.0, 2.0, 0.5574926052840761, 0.0, 1.0, 0.0, 1.0, 2.0, 0.953870777570428, 6.911199999999999, 6.9112, 168.9129565104273, 1558649.306574153, 1558649.306574154, 338131.4892671576], 
processed observation next is [1.0, 0.5217391304347826, 0.4944707740916275, 0.86, 1.0, 1.0, 0.46685856058322417, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 0.943744850695644, -8.881784197001253e-17, 0.0, 0.8294399451522846, 0.4329581407150425, 0.43295814071504274, 0.5046738645778472], 
reward next is 0.4953, 
noisyNet noise sample is [array([0.4419711], dtype=float32), -1.2024231]. 
=============================================
[2019-03-26 15:28:17,454] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.0286656e-13 1.0000000e+00 2.6039942e-15 2.9577766e-16 1.3840247e-25], sum to 1.0000
[2019-03-26 15:28:17,464] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8287
[2019-03-26 15:28:17,473] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.35, 75.0, 1.0, 2.0, 0.6882301421210009, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1067253.913742923, 1067253.913742923, 231366.6282060146], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7291800.0000, 
sim time next is 7292400.0000, 
raw observation next is [24.56666666666666, 74.0, 1.0, 2.0, 0.7306945428776342, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1131166.859759534, 1131166.859759534, 241497.8793449228], 
processed observation next is [1.0, 0.391304347826087, 0.3633491311216427, 0.74, 1.0, 1.0, 0.675535593828475, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.31421301659987055, 0.31421301659987055, 0.36044459603719825], 
reward next is 0.6396, 
noisyNet noise sample is [array([1.5422885], dtype=float32), 0.6287517]. 
=============================================
[2019-03-26 15:28:19,403] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.8759750e-13 1.0000000e+00 7.0049736e-16 9.5548830e-17 9.2701942e-27], sum to 1.0000
[2019-03-26 15:28:19,410] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9191
[2019-03-26 15:28:19,414] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 69.0, 1.0, 2.0, 0.3908386473102726, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 585495.8023767654, 585495.8023767654, 173276.329776291], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7324800.0000, 
sim time next is 7325400.0000, 
raw observation next is [26.4, 69.5, 1.0, 2.0, 0.3891532766210155, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 583257.8294127703, 583257.8294127703, 173082.2079879798], 
processed observation next is [1.0, 0.782608695652174, 0.45023696682464454, 0.695, 1.0, 1.0, 0.2640400923144765, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16201606372576954, 0.16201606372576954, 0.2583316537134027], 
reward next is 0.7417, 
noisyNet noise sample is [array([-0.08294727], dtype=float32), -2.4442704]. 
=============================================
[2019-03-26 15:28:28,585] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.501366e-14 1.000000e+00 6.731043e-16 1.417933e-17 7.305932e-28], sum to 1.0000
[2019-03-26 15:28:28,593] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1566
[2019-03-26 15:28:28,598] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.56666666666667, 83.0, 1.0, 2.0, 0.3911180894396441, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 581906.0985251336, 581906.0985251341, 172825.8553227844], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7476000.0000, 
sim time next is 7476600.0000, 
raw observation next is [24.68333333333333, 82.5, 1.0, 2.0, 0.3929669905831121, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 583741.7616279752, 583741.7616279759, 172963.5841207946], 
processed observation next is [0.0, 0.5217391304347826, 0.3688783570300157, 0.825, 1.0, 1.0, 0.26863492841338804, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1621504893411042, 0.1621504893411044, 0.2581546031653651], 
reward next is 0.7418, 
noisyNet noise sample is [array([1.537162], dtype=float32), -0.16385421]. 
=============================================
[2019-03-26 15:28:29,261] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.6040838e-14 1.0000000e+00 9.7661522e-16 8.9729310e-18 6.8596757e-28], sum to 1.0000
[2019-03-26 15:28:29,272] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6427
[2019-03-26 15:28:29,276] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.55, 79.5, 1.0, 2.0, 0.4140619188921128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 605155.6039935349, 605155.6039935349, 174647.3863554103], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7497000.0000, 
sim time next is 7497600.0000, 
raw observation next is [25.43333333333333, 80.0, 1.0, 2.0, 0.4123104407429036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 603519.7908392458, 603519.7908392464, 174521.6613810738], 
processed observation next is [0.0, 0.782608695652174, 0.40442338072669815, 0.8, 1.0, 1.0, 0.29194029005169103, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16764438634423492, 0.1676443863442351, 0.26048009161354296], 
reward next is 0.7395, 
noisyNet noise sample is [array([-0.7868363], dtype=float32), 0.11569352]. 
=============================================
[2019-03-26 15:28:29,668] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.8250293e-14 1.0000000e+00 7.0873841e-16 2.7571270e-18 3.5041560e-27], sum to 1.0000
[2019-03-26 15:28:29,677] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3197
[2019-03-26 15:28:29,682] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.55, 79.5, 1.0, 2.0, 0.4140619188921128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 605155.6039935349, 605155.6039935349, 174647.3863554103], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7497000.0000, 
sim time next is 7497600.0000, 
raw observation next is [25.43333333333333, 80.0, 1.0, 2.0, 0.4123104407429036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 603519.7908392458, 603519.7908392464, 174521.6613810738], 
processed observation next is [0.0, 0.782608695652174, 0.40442338072669815, 0.8, 1.0, 1.0, 0.29194029005169103, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16764438634423492, 0.1676443863442351, 0.26048009161354296], 
reward next is 0.7395, 
noisyNet noise sample is [array([0.5828341], dtype=float32), -0.36614335]. 
=============================================
[2019-03-26 15:28:30,035] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-26 15:28:30,038] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 15:28:30,039] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 15:28:30,040] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:28:30,040] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 15:28:30,043] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 15:28:30,043] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:28:30,044] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 15:28:30,045] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:28:30,048] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:28:30,052] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:28:30,066] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run26
[2019-03-26 15:28:30,083] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run26
[2019-03-26 15:28:30,084] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run26
[2019-03-26 15:28:30,129] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run26
[2019-03-26 15:28:30,148] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run26
[2019-03-26 15:29:25,924] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.09836774], dtype=float32), 0.06960653]
[2019-03-26 15:29:25,925] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [36.06666666666667, 50.33333333333334, 1.0, 2.0, 0.606832865299278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 848014.2374511915, 848014.2374511915, 202025.0342968824]
[2019-03-26 15:29:25,926] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:29:25,928] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [8.3270820e-14 1.0000000e+00 5.6049785e-16 1.1212196e-17 3.2121617e-27], sampled 0.27928008520942726
[2019-03-26 15:29:29,334] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.09836774], dtype=float32), 0.06960653]
[2019-03-26 15:29:29,336] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [33.77148755833333, 66.02112526333333, 1.0, 2.0, 0.6623439630745862, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005972915533027, 6.9112, 168.9123460194124, 1822435.980612384, 1755201.055504894, 376720.0619884254]
[2019-03-26 15:29:29,337] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 15:29:29,341] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [7.2885517e-12 1.0000000e+00 2.3798826e-13 1.3217978e-13 6.0511907e-22], sampled 0.7096200235166379
[2019-03-26 15:29:29,343] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1822435.980612384 W.
[2019-03-26 15:29:46,391] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.09836774], dtype=float32), 0.06960653]
[2019-03-26 15:29:46,391] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [33.2, 61.33333333333334, 1.0, 2.0, 0.7561205782686233, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005978787863307, 6.9112, 168.9123160230708, 1953664.255553818, 1886425.176368846, 397282.324886966]
[2019-03-26 15:29:46,393] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 15:29:46,397] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [6.9255206e-11 1.0000000e+00 3.5251788e-12 5.4856662e-12 6.1113260e-20], sampled 0.3033983698669446
[2019-03-26 15:29:46,400] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1953664.255553818 W.
[2019-03-26 15:30:19,086] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.09836774], dtype=float32), 0.06960653]
[2019-03-26 15:30:19,087] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.01666666666667, 76.5, 1.0, 2.0, 0.5736371814301668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 801607.6618839132, 801607.6618839132, 195937.4033563793]
[2019-03-26 15:30:19,089] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:30:19,091] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.7764041e-14 1.0000000e+00 1.0347503e-16 3.1923991e-18 2.9535303e-28], sampled 0.3174320417024955
[2019-03-26 15:30:22,780] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.5752 2842451949.6408 1131.0000
[2019-03-26 15:30:22,870] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.0653 2927317329.7462 1338.0000
[2019-03-26 15:30:22,907] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.5810 2779288737.8199 933.0000
[2019-03-26 15:30:22,960] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.5210 3007689212.2451 1766.0000
[2019-03-26 15:30:23,040] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.9164 3164002230.9074 1778.0000
[2019-03-26 15:30:24,057] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 625000, evaluation results [625000.0, 7884.916440885027, 3164002230.907359, 1778.0, 8255.065342017213, 2927317329.746172, 1338.0, 8660.581010407266, 2779288737.819882, 933.0, 7997.5209923145385, 3007689212.2451496, 1766.0, 8497.575228127671, 2842451949.640752, 1131.0]
[2019-03-26 15:30:30,900] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.4808390e-13 1.0000000e+00 1.7586737e-15 3.5823382e-16 1.6051048e-25], sum to 1.0000
[2019-03-26 15:30:30,909] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6016
[2019-03-26 15:30:30,915] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.36666666666667, 94.66666666666667, 1.0, 2.0, 0.4234716853187466, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 622088.4001608702, 622088.4001608702, 176350.7890637509], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7622400.0000, 
sim time next is 7623000.0000, 
raw observation next is [23.45, 94.5, 1.0, 2.0, 0.4154186491944362, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 608823.8065641823, 608823.8065641823, 175044.1358627848], 
processed observation next is [1.0, 0.21739130434782608, 0.3104265402843602, 0.945, 1.0, 1.0, 0.29568511951136894, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16911772404560618, 0.16911772404560618, 0.26125990427281315], 
reward next is 0.7387, 
noisyNet noise sample is [array([-0.73409826], dtype=float32), 0.049857896]. 
=============================================
[2019-03-26 15:30:30,943] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[70.551056]
 [70.51951 ]
 [70.43302 ]
 [70.42269 ]
 [70.43625 ]], R is [[70.61051178]
 [70.6411972 ]
 [70.67063904]
 [70.69496918]
 [70.71321106]].
[2019-03-26 15:30:31,122] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:30:31,123] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:30:31,156] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run4
[2019-03-26 15:30:31,271] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.4479510e-13 1.0000000e+00 5.4777532e-15 4.8482440e-16 2.3728893e-24], sum to 1.0000
[2019-03-26 15:30:31,280] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4201
[2019-03-26 15:30:31,284] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666666, 79.5, 1.0, 2.0, 0.5536865697355307, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9227835615332166, 6.911199999999999, 6.9112, 168.9126714804783, 1548000.556325949, 1548000.556325949, 330645.5170510426], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7636200.0000, 
sim time next is 7636800.0000, 
raw observation next is [26.93333333333333, 78.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.075475021640646, 6.9112, 168.9118416898277, 1570376.326284095, 1453834.741198473, 311346.3905318025], 
processed observation next is [1.0, 0.391304347826087, 0.4755134281200631, 0.78, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 0.016427502164064568, 0.0, 0.8294344708727733, 0.4362156461900264, 0.4038429836662425, 0.464696105271347], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.6706467], dtype=float32), -1.4511316]. 
=============================================
[2019-03-26 15:30:34,552] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.4743657e-13 1.0000000e+00 2.0405564e-15 1.7423261e-16 1.4886189e-25], sum to 1.0000
[2019-03-26 15:30:34,561] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2701
[2019-03-26 15:30:34,566] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.9, 92.0, 1.0, 2.0, 0.4764218507735118, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 665715.192146436, 665715.192146436, 179983.9668782419], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7693200.0000, 
sim time next is 7693800.0000, 
raw observation next is [24.85, 92.5, 1.0, 2.0, 0.475874665225491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 664950.3579151256, 664950.3579151256, 179902.1686926692], 
processed observation next is [1.0, 0.043478260869565216, 0.37677725118483424, 0.925, 1.0, 1.0, 0.3685236930427603, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18470843275420154, 0.18470843275420154, 0.2685106995412973], 
reward next is 0.7315, 
noisyNet noise sample is [array([0.55057746], dtype=float32), -0.86991227]. 
=============================================
[2019-03-26 15:30:36,812] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.6645105e-08 9.9999452e-01 1.8276982e-09 5.4706898e-06 3.3058362e-13], sum to 1.0000
[2019-03-26 15:30:36,824] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2670
[2019-03-26 15:30:36,832] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2348641.422216947 W.
[2019-03-26 15:30:36,835] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.01666666666667, 60.83333333333334, 1.0, 2.0, 0.8397585829309567, 1.0, 2.0, 0.8397585829309567, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2348641.422216947, 2348641.422216947, 439681.9140830796], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7746600.0000, 
sim time next is 7747200.0000, 
raw observation next is [30.9, 61.0, 1.0, 2.0, 0.8322573619015174, 1.0, 2.0, 0.8322573619015174, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2327642.427895094, 2327642.427895093, 435871.1081481157], 
processed observation next is [1.0, 0.6956521739130435, 0.6635071090047393, 0.61, 1.0, 1.0, 0.7979004360259246, 1.0, 1.0, 0.7979004360259246, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6465673410819704, 0.6465673410819702, 0.6505538927583816], 
reward next is 0.3494, 
noisyNet noise sample is [array([-1.7824858], dtype=float32), -0.82002056]. 
=============================================
[2019-03-26 15:30:37,525] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.8997854e-11 1.0000000e+00 6.9006419e-14 1.1054296e-13 3.9818363e-25], sum to 1.0000
[2019-03-26 15:30:37,531] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2588
[2019-03-26 15:30:37,538] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.86666666666667, 79.66666666666667, 1.0, 2.0, 0.5096494993358043, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 712160.5119462757, 712160.5119462751, 185122.2775402692], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7759200.0000, 
sim time next is 7759800.0000, 
raw observation next is [27.7, 81.0, 1.0, 2.0, 0.5111447883724254, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 714250.6617795123, 714250.6617795129, 185361.1814248074], 
processed observation next is [1.0, 0.8260869565217391, 0.5118483412322274, 0.81, 1.0, 1.0, 0.41101781731617515, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1984029616054201, 0.19840296160542026, 0.27665847973851854], 
reward next is 0.7233, 
noisyNet noise sample is [array([1.3846738], dtype=float32), 0.09775159]. 
=============================================
[2019-03-26 15:30:41,952] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.2854137e-13 1.0000000e+00 1.2002495e-15 8.6820831e-17 3.8426820e-26], sum to 1.0000
[2019-03-26 15:30:41,961] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6359
[2019-03-26 15:30:41,967] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 91.0, 1.0, 2.0, 0.5269769436579235, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 736381.4693973588, 736381.4693973588, 187930.8819400518], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7945200.0000, 
sim time next is 7945800.0000, 
raw observation next is [26.48333333333333, 91.33333333333334, 1.0, 2.0, 0.5273487139848947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 736901.1500824147, 736901.1500824147, 187992.1784649528], 
processed observation next is [1.0, 1.0, 0.4541864139020536, 0.9133333333333334, 1.0, 1.0, 0.43054061925890924, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20469476391178187, 0.20469476391178187, 0.28058534099246685], 
reward next is 0.7194, 
noisyNet noise sample is [array([1.092454], dtype=float32), 0.48124495]. 
=============================================
[2019-03-26 15:30:43,152] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:30:43,153] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:30:43,186] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run4
[2019-03-26 15:30:47,189] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:30:47,190] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:30:47,228] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run4
[2019-03-26 15:30:47,619] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.1056144e-07 9.9996185e-01 3.5378832e-08 3.8010046e-05 5.3953677e-12], sum to 1.0000
[2019-03-26 15:30:47,624] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2678
[2019-03-26 15:30:47,630] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2092841.415468393 W.
[2019-03-26 15:30:47,632] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.63333333333334, 63.66666666666667, 1.0, 2.0, 0.4989197173604267, 1.0, 1.0, 0.4989197173604267, 1.0, 2.0, 0.853810363662215, 6.9112, 6.9112, 170.5573041426782, 2092841.415468393, 2092841.415468393, 412103.6547551563], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7920600.0000, 
sim time next is 7921200.0000, 
raw observation next is [30.66666666666667, 63.33333333333334, 1.0, 2.0, 0.931763241735978, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.979873907538416, 6.9112, 168.9125477206875, 2199495.964758864, 2150776.44908502, 443939.6785489584], 
processed observation next is [1.0, 0.6956521739130435, 0.6524486571879939, 0.6333333333333334, 1.0, 1.0, 0.9177870382361181, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.00686739075384164, 0.0, 0.8294379378075174, 0.6109711013219067, 0.5974379025236166, 0.6625965351476991], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.34333828], dtype=float32), -1.0464958]. 
=============================================
[2019-03-26 15:30:48,513] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:30:48,513] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:30:48,559] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run4
[2019-03-26 15:30:48,985] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:30:48,986] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:30:49,001] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run4
[2019-03-26 15:30:49,401] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:30:49,401] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:30:49,416] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run4
[2019-03-26 15:30:49,449] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:30:49,449] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:30:49,458] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run4
[2019-03-26 15:30:49,556] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:30:49,556] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:30:49,557] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:30:49,558] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:30:49,569] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run4
[2019-03-26 15:30:49,589] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run4
[2019-03-26 15:30:49,665] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:30:49,666] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:30:49,678] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run4
[2019-03-26 15:30:49,698] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:30:49,699] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:30:49,706] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:30:49,707] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:30:49,709] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run4
[2019-03-26 15:30:49,723] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:30:49,724] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run4
[2019-03-26 15:30:49,725] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:30:49,749] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run4
[2019-03-26 15:30:49,839] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:30:49,840] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:30:49,841] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run4
[2019-03-26 15:30:49,858] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:30:49,858] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:30:49,860] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run4
[2019-03-26 15:30:49,898] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:30:49,898] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:30:49,900] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run4
[2019-03-26 15:30:52,539] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.168210e-13 1.000000e+00 4.077668e-15 2.224299e-16 2.260713e-25], sum to 1.0000
[2019-03-26 15:30:52,549] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2670
[2019-03-26 15:30:52,554] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 86.0, 1.0, 2.0, 0.3213215530535128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 512655.718011903, 512655.718011903, 168040.2722682601], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 21600.0000, 
sim time next is 22200.0000, 
raw observation next is [21.66666666666667, 85.66666666666667, 1.0, 2.0, 0.3690137845416782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 588413.6889443405, 588413.6889443405, 174182.9217423461], 
processed observation next is [1.0, 0.2608695652173913, 0.22590837282780438, 0.8566666666666667, 1.0, 1.0, 0.23977564402611834, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16344824692898346, 0.16344824692898346, 0.25997451006320316], 
reward next is 0.7400, 
noisyNet noise sample is [array([1.1736703], dtype=float32), -1.3901715]. 
=============================================
[2019-03-26 15:30:59,156] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.4864936e-14 1.0000000e+00 4.8292133e-16 7.6775060e-17 2.4905613e-26], sum to 1.0000
[2019-03-26 15:30:59,164] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0570
[2019-03-26 15:30:59,170] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.61666666666667, 96.0, 1.0, 2.0, 0.7387576761770659, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1107018.206574379, 1107018.206574378, 239246.3671416086], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 143400.0000, 
sim time next is 144000.0000, 
raw observation next is [22.6, 96.0, 1.0, 2.0, 0.7789358315697448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1167888.554337311, 1167888.554337311, 249431.4727295514], 
processed observation next is [1.0, 0.6956521739130435, 0.27014218009478685, 0.96, 1.0, 1.0, 0.7336576283972829, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.32441348731591974, 0.32441348731591974, 0.3722857801933603], 
reward next is 0.6277, 
noisyNet noise sample is [array([-0.7836351], dtype=float32), -0.54127425]. 
=============================================
[2019-03-26 15:30:59,189] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[72.15567 ]
 [72.16393 ]
 [72.11323 ]
 [72.03066 ]
 [71.954445]], R is [[72.08385468]
 [72.00592804]
 [71.93096924]
 [71.86248016]
 [71.79270935]].
[2019-03-26 15:31:04,628] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.1328481e-14 1.0000000e+00 5.1731690e-16 2.5755484e-18 4.1336148e-28], sum to 1.0000
[2019-03-26 15:31:04,636] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4587
[2019-03-26 15:31:04,646] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.7, 87.0, 1.0, 2.0, 0.3078086338347638, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 488466.0768189292, 488466.0768189292, 166205.6340837586], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 232200.0000, 
sim time next is 232800.0000, 
raw observation next is [21.66666666666667, 87.0, 1.0, 2.0, 0.3066397186984406, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 486969.8974030773, 486969.8974030766, 166102.9810175261], 
processed observation next is [0.0, 0.6956521739130435, 0.22590837282780438, 0.87, 1.0, 1.0, 0.16462616710655492, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13526941594529923, 0.13526941594529904, 0.24791489704108371], 
reward next is 0.7521, 
noisyNet noise sample is [array([-0.38275847], dtype=float32), 0.1943793]. 
=============================================
[2019-03-26 15:31:08,620] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.8744227e-13 1.0000000e+00 1.2365746e-15 1.1230560e-17 5.1247070e-26], sum to 1.0000
[2019-03-26 15:31:08,632] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3776
[2019-03-26 15:31:08,636] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.26666666666667, 77.0, 1.0, 2.0, 0.3076862754026411, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 486261.7797807696, 486261.7797807696, 166003.8724069634], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 300000.0000, 
sim time next is 300600.0000, 
raw observation next is [23.3, 77.0, 1.0, 2.0, 0.3084455235973469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 487097.8931467744, 487097.8931467751, 166056.6186274229], 
processed observation next is [0.0, 0.4782608695652174, 0.3033175355450238, 0.77, 1.0, 1.0, 0.16680183565945408, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13530497031854843, 0.13530497031854863, 0.24784569944391477], 
reward next is 0.7522, 
noisyNet noise sample is [array([-0.30898383], dtype=float32), 0.7498279]. 
=============================================
[2019-03-26 15:31:18,022] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-26 15:31:18,024] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 15:31:18,025] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 15:31:18,026] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 15:31:18,027] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:31:18,028] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:31:18,028] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 15:31:18,027] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:31:18,032] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:31:18,029] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 15:31:18,036] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:31:18,048] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run27
[2019-03-26 15:31:18,067] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run27
[2019-03-26 15:31:18,069] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run27
[2019-03-26 15:31:18,088] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run27
[2019-03-26 15:31:18,120] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run27
[2019-03-26 15:32:43,924] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10113538], dtype=float32), 0.071680665]
[2019-03-26 15:32:43,925] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.440231745, 82.168159715, 1.0, 2.0, 0.8925373113576296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1262667.02167368, 1262667.02167368, 270133.435256462]
[2019-03-26 15:32:43,925] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 15:32:43,930] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.4691562e-12 1.0000000e+00 9.1407493e-14 8.2372138e-14 1.9264179e-23], sampled 0.9536362143386875
[2019-03-26 15:33:00,993] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10113538], dtype=float32), 0.071680665]
[2019-03-26 15:33:00,995] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [22.64473701, 95.94471845, 1.0, 2.0, 0.4060461239559964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 608251.8699859389, 608251.8699859395, 175361.5511587296]
[2019-03-26 15:33:00,996] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 15:33:00,999] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.7994637e-14 1.0000000e+00 1.0315343e-16 1.2275067e-18 1.4280052e-28], sampled 0.537987097409584
[2019-03-26 15:33:09,696] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7999.0142 3007608811.4011 1766.0000
[2019-03-26 15:33:09,844] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.9689 2927381913.5140 1338.0000
[2019-03-26 15:33:10,028] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.1842 3164056715.8374 1778.0000
[2019-03-26 15:33:10,322] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.6796 2779156607.2113 933.0000
[2019-03-26 15:33:10,327] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.6119 2842427357.4275 1131.0000
[2019-03-26 15:33:11,343] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 650000, evaluation results [650000.0, 7884.184222210851, 3164056715.8373833, 1778.0, 8254.968948333817, 2927381913.5140486, 1338.0, 8660.679636567633, 2779156607.211253, 933.0, 7999.014205657292, 3007608811.4011106, 1766.0, 8497.61193292354, 2842427357.427519, 1131.0]
[2019-03-26 15:33:19,522] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.5103871e-13 1.0000000e+00 2.6174176e-16 1.9892286e-17 2.1415247e-27], sum to 1.0000
[2019-03-26 15:33:19,531] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3479
[2019-03-26 15:33:19,536] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666667, 89.0, 1.0, 2.0, 0.2960113747152114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 472572.1071909757, 472572.1071909757, 165111.9715307434], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 870000.0000, 
sim time next is 870600.0000, 
raw observation next is [21.13333333333334, 89.0, 1.0, 2.0, 0.2947343000337526, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 470860.63752339, 470860.63752339, 164996.0497487575], 
processed observation next is [0.0, 0.043478260869565216, 0.20063191153238583, 0.89, 1.0, 1.0, 0.1502822891972923, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.130794621534275, 0.130794621534275, 0.24626276081904105], 
reward next is 0.7537, 
noisyNet noise sample is [array([-0.7983185], dtype=float32), 0.20970295]. 
=============================================
[2019-03-26 15:33:21,102] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.8396833e-14 1.0000000e+00 9.0505280e-16 2.8269943e-17 8.2133131e-27], sum to 1.0000
[2019-03-26 15:33:21,110] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9181
[2019-03-26 15:33:21,115] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.48333333333333, 55.0, 1.0, 2.0, 0.3202940534713662, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 525968.4570514825, 525968.4570514825, 168698.9697377339], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 666600.0000, 
sim time next is 667200.0000, 
raw observation next is [24.26666666666667, 56.00000000000001, 1.0, 2.0, 0.2417796091616441, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 397264.0672467303, 397264.0672467309, 160112.5659771853], 
processed observation next is [1.0, 0.7391304347826086, 0.34913112164297017, 0.56, 1.0, 1.0, 0.08648145682125793, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11035112979075842, 0.11035112979075859, 0.2389739790704258], 
reward next is 0.7610, 
noisyNet noise sample is [array([2.1051073], dtype=float32), -0.6711391]. 
=============================================
[2019-03-26 15:33:31,995] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.8705690e-13 1.0000000e+00 2.3854155e-15 8.3916861e-18 7.6909509e-27], sum to 1.0000
[2019-03-26 15:33:32,006] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9480
[2019-03-26 15:33:32,009] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.1, 80.0, 1.0, 2.0, 0.2871132877756963, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 460869.582396531, 460869.5823965304, 164326.3750118936], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 806400.0000, 
sim time next is 807000.0000, 
raw observation next is [22.26666666666667, 78.83333333333334, 1.0, 2.0, 0.287628349372697, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 461493.1833494597, 461493.183349459, 164367.5519948861], 
processed observation next is [0.0, 0.34782608695652173, 0.2543443917851502, 0.7883333333333334, 1.0, 1.0, 0.14172090285867106, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1281925509304055, 0.1281925509304053, 0.24532470446997925], 
reward next is 0.7547, 
noisyNet noise sample is [array([-0.7535049], dtype=float32), 1.2409765]. 
=============================================
[2019-03-26 15:33:32,021] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[78.049835]
 [78.03879 ]
 [78.03441 ]
 [78.02204 ]
 [78.008446]], R is [[78.04734039]
 [78.02160645]
 [77.99630737]
 [77.97145844]
 [77.94707489]].
[2019-03-26 15:33:32,839] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.2020004e-14 1.0000000e+00 9.3312663e-17 3.1879938e-18 8.4687598e-28], sum to 1.0000
[2019-03-26 15:33:32,845] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7127
[2019-03-26 15:33:32,851] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.6, 63.0, 1.0, 2.0, 0.2842858543230357, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 456857.1522414534, 456857.1522414534, 164056.4707419873], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 828000.0000, 
sim time next is 828600.0000, 
raw observation next is [24.56666666666667, 63.66666666666666, 1.0, 2.0, 0.285631935401381, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 458666.5581729918, 458666.5581729918, 164177.2513483096], 
processed observation next is [0.0, 0.6086956521739131, 0.3633491311216432, 0.6366666666666666, 1.0, 1.0, 0.13931558482094095, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.12740737727027548, 0.12740737727027548, 0.24504067365419344], 
reward next is 0.7550, 
noisyNet noise sample is [array([-2.591542], dtype=float32), -1.2364619]. 
=============================================
[2019-03-26 15:33:37,314] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.8611848e-14 1.0000000e+00 2.3664989e-16 7.4706139e-18 7.7844851e-28], sum to 1.0000
[2019-03-26 15:33:37,323] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2945
[2019-03-26 15:33:37,330] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.45, 73.33333333333334, 1.0, 2.0, 0.2975666348156158, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 473890.9216368221, 473890.9216368227, 165187.7114412063], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 907800.0000, 
sim time next is 908400.0000, 
raw observation next is [23.6, 72.66666666666667, 1.0, 2.0, 0.2990771172722378, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 475818.0563652861, 475818.0563652861, 165316.3083429248], 
processed observation next is [0.0, 0.5217391304347826, 0.3175355450236968, 0.7266666666666667, 1.0, 1.0, 0.15551459912317805, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1321716823236906, 0.1321716823236906, 0.2467407587207833], 
reward next is 0.7533, 
noisyNet noise sample is [array([-0.33034047], dtype=float32), 1.542217]. 
=============================================
[2019-03-26 15:33:42,212] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.5276120e-13 1.0000000e+00 1.9665420e-16 1.9799168e-17 9.5419814e-26], sum to 1.0000
[2019-03-26 15:33:42,220] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3718
[2019-03-26 15:33:42,223] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.584112130816609, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 899525.1845637473, 899525.1845637478, 207878.2152914389], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 987600.0000, 
sim time next is 988200.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.6194185445970449, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 953925.4080664881, 953925.4080664881, 215179.2465219662], 
processed observation next is [1.0, 0.43478260869565216, 0.2417061611374408, 0.94, 1.0, 1.0, 0.5414681260205361, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.26497928001846893, 0.26497928001846893, 0.32116305451039734], 
reward next is 0.6788, 
noisyNet noise sample is [array([0.6681968], dtype=float32), -0.50118744]. 
=============================================
[2019-03-26 15:33:50,839] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.2751812e-14 1.0000000e+00 7.0805469e-16 3.3950794e-17 1.2638365e-26], sum to 1.0000
[2019-03-26 15:33:50,848] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7747
[2019-03-26 15:33:50,854] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.15, 93.16666666666667, 1.0, 2.0, 0.3193508661226476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 515050.079920298, 515050.0799202973, 168215.7292246842], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1134600.0000, 
sim time next is 1135200.0000, 
raw observation next is [20.1, 93.33333333333334, 1.0, 2.0, 0.2942293455128591, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 474785.2745179156, 474785.2745179156, 165290.5602383536], 
processed observation next is [1.0, 0.13043478260869565, 0.15165876777251197, 0.9333333333333335, 1.0, 1.0, 0.14967391025645677, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13188479847719878, 0.13188479847719878, 0.24670232871396058], 
reward next is 0.7533, 
noisyNet noise sample is [array([-0.3948052], dtype=float32), 0.30761868]. 
=============================================
[2019-03-26 15:33:51,245] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.7756690e-14 1.0000000e+00 5.0894128e-16 7.6120072e-17 1.2624247e-26], sum to 1.0000
[2019-03-26 15:33:51,257] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9969
[2019-03-26 15:33:51,262] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.6, 57.16666666666666, 1.0, 2.0, 0.8749218469490505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1349022.648056325, 1349022.648056325, 280355.8618688554], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1183800.0000, 
sim time next is 1184400.0000, 
raw observation next is [27.6, 57.0, 1.0, 2.0, 0.8641109400539346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1333435.593337787, 1333435.593337787, 277297.3716745664], 
processed observation next is [1.0, 0.7391304347826086, 0.5071090047393366, 0.57, 1.0, 1.0, 0.8362782410288369, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3703987759271631, 0.3703987759271631, 0.4138766741411439], 
reward next is 0.5861, 
noisyNet noise sample is [array([-1.1950226], dtype=float32), -0.8003048]. 
=============================================
[2019-03-26 15:33:58,751] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.7530846e-09 9.9999261e-01 3.6599954e-09 7.4312666e-06 2.8408005e-13], sum to 1.0000
[2019-03-26 15:33:58,761] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4975
[2019-03-26 15:33:58,770] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1949255.677557037 W.
[2019-03-26 15:33:58,779] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.93333333333333, 75.33333333333334, 1.0, 2.0, 0.4647209286653233, 1.0, 1.0, 0.4647209286653233, 1.0, 2.0, 0.788057792210206, 6.9112, 6.9112, 170.5573041426782, 1949255.677557037, 1949255.677557037, 388394.3017952204], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1268400.0000, 
sim time next is 1269000.0000, 
raw observation next is [27.9, 75.5, 1.0, 2.0, 0.4614229479569305, 1.0, 2.0, 0.4614229479569305, 1.0, 2.0, 0.7833520096085618, 6.911200000000001, 6.9112, 170.5573041426782, 1935409.918113329, 1935409.918113329, 386481.9997355926], 
processed observation next is [1.0, 0.6956521739130435, 0.5213270142180094, 0.755, 1.0, 1.0, 0.35111198549027767, 1.0, 1.0, 0.35111198549027767, 1.0, 1.0, 0.7357951336689778, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5376138661425914, 0.5376138661425914, 0.5768388055755113], 
reward next is 0.4232, 
noisyNet noise sample is [array([0.13175948], dtype=float32), -0.1247571]. 
=============================================
[2019-03-26 15:33:58,798] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[30.275303]
 [31.511446]
 [31.291033]
 [31.890017]
 [31.916866]], R is [[28.94576454]
 [29.07661438]
 [28.92769051]
 [28.63841438]
 [28.3520298 ]].
[2019-03-26 15:34:04,634] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.9007202e-14 1.0000000e+00 5.4665174e-17 1.6206458e-18 6.4102835e-28], sum to 1.0000
[2019-03-26 15:34:04,643] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8696
[2019-03-26 15:34:04,646] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.35, 89.5, 1.0, 2.0, 0.3446836717122636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 534035.2358530081, 534035.2358530075, 169418.3342282879], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1549800.0000, 
sim time next is 1550400.0000, 
raw observation next is [22.26666666666667, 90.0, 1.0, 2.0, 0.3444579342784178, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 533972.0111294887, 533972.0111294887, 169421.1715931408], 
processed observation next is [0.0, 0.9565217391304348, 0.2543443917851502, 0.9, 1.0, 1.0, 0.21019028226315398, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1483255586470802, 0.1483255586470802, 0.25286742028826986], 
reward next is 0.7471, 
noisyNet noise sample is [array([-0.06791162], dtype=float32), 0.94175416]. 
=============================================
[2019-03-26 15:34:06,357] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-26 15:34:06,357] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 15:34:06,358] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 15:34:06,358] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:34:06,359] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:34:06,360] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 15:34:06,359] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 15:34:06,362] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 15:34:06,364] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:34:06,364] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:34:06,366] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:34:06,386] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run28
[2019-03-26 15:34:06,404] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run28
[2019-03-26 15:34:06,405] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run28
[2019-03-26 15:34:06,440] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run28
[2019-03-26 15:34:06,461] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run28
[2019-03-26 15:34:48,945] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.100462], dtype=float32), 0.070724644]
[2019-03-26 15:34:48,947] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [27.93333333333333, 75.0, 1.0, 2.0, 0.6987073897062066, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 976462.654151441, 976462.654151441, 220563.7260622061]
[2019-03-26 15:34:48,948] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 15:34:48,951] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [5.9509723e-14 1.0000000e+00 3.4911135e-16 1.2525441e-17 4.2377816e-27], sampled 0.2893466238229143
[2019-03-26 15:34:57,369] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.100462], dtype=float32), 0.070724644]
[2019-03-26 15:34:57,370] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.3, 73.0, 1.0, 2.0, 0.5719105209504681, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 799193.89752599, 799193.89752599, 195628.9316185202]
[2019-03-26 15:34:57,372] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:34:57,374] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0702156e-14 1.0000000e+00 5.4499642e-17 1.5958182e-18 1.4188611e-28], sampled 0.38348866413132554
[2019-03-26 15:35:29,930] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.100462], dtype=float32), 0.070724644]
[2019-03-26 15:35:29,930] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [26.0, 95.0, 1.0, 2.0, 0.5389711611161302, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 753147.763964403, 753147.763964403, 189926.6508598806]
[2019-03-26 15:35:29,932] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:35:29,935] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.9433504e-14 1.0000000e+00 1.6851360e-16 5.1511482e-18 1.6925159e-27], sampled 0.5003304007201366
[2019-03-26 15:35:30,768] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.100462], dtype=float32), 0.070724644]
[2019-03-26 15:35:30,770] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [28.98333333333333, 75.66666666666667, 1.0, 2.0, 0.5504225320224396, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 769155.479389245, 769155.479389245, 191872.0228610883]
[2019-03-26 15:35:30,772] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:35:30,775] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.1975198e-14 1.0000000e+00 6.7761762e-17 2.2939844e-18 2.1197498e-28], sampled 0.31116268195306496
[2019-03-26 15:35:35,949] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.100462], dtype=float32), 0.070724644]
[2019-03-26 15:35:35,949] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.3, 86.0, 1.0, 2.0, 0.5333052148696199, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 745227.5040839148, 745227.5040839148, 188978.7343462476]
[2019-03-26 15:35:35,950] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:35:35,953] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.0863404e-14 1.0000000e+00 1.7412696e-16 3.4040517e-18 7.8961616e-28], sampled 0.15544016501356483
[2019-03-26 15:35:58,695] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.100462], dtype=float32), 0.070724644]
[2019-03-26 15:35:58,696] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.83396297, 72.96518188, 1.0, 2.0, 0.4500246778758654, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 651717.5633252616, 651717.563325261, 179059.9668650801]
[2019-03-26 15:35:58,698] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 15:35:58,701] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.4164464e-14 1.0000000e+00 1.2948214e-16 3.4131147e-18 5.5387993e-28], sampled 0.34516445253729644
[2019-03-26 15:35:59,518] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.8607 3007711637.9330 1766.0000
[2019-03-26 15:35:59,615] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7883.4154 3164069856.8990 1778.0000
[2019-03-26 15:35:59,772] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.0653 2927317329.7462 1338.0000
[2019-03-26 15:35:59,880] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.4676 2779124528.0117 933.0000
[2019-03-26 15:35:59,920] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.1106 2842514233.6127 1131.0000
[2019-03-26 15:36:00,939] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 675000, evaluation results [675000.0, 7883.415429794, 3164069856.898958, 1778.0, 8255.065342017213, 2927317329.746172, 1338.0, 8661.467580702742, 2779124528.011676, 933.0, 7998.86073322157, 3007711637.9330444, 1766.0, 8496.110621562273, 2842514233.6127224, 1131.0]
[2019-03-26 15:36:09,161] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.3614793e-13 1.0000000e+00 6.4574706e-16 3.0425967e-18 3.9207277e-27], sum to 1.0000
[2019-03-26 15:36:09,169] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5179
[2019-03-26 15:36:09,176] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.2, 78.5, 1.0, 2.0, 0.3560926938630097, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 546592.6715774988, 546592.6715774994, 170305.2003777306], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1539000.0000, 
sim time next is 1539600.0000, 
raw observation next is [24.0, 80.0, 1.0, 2.0, 0.3576428750531925, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 548685.4184535787, 548685.4184535787, 170471.7032823074], 
processed observation next is [0.0, 0.8260869565217391, 0.3364928909952607, 0.8, 1.0, 1.0, 0.2260757530761355, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1524126162371052, 0.1524126162371052, 0.25443537803329463], 
reward next is 0.7456, 
noisyNet noise sample is [array([1.6606716], dtype=float32), 1.1934276]. 
=============================================
[2019-03-26 15:36:09,605] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.4050785e-14 1.0000000e+00 1.2770785e-16 1.0523641e-18 2.5161129e-28], sum to 1.0000
[2019-03-26 15:36:09,614] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6038
[2019-03-26 15:36:09,620] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.13333333333333, 84.66666666666667, 1.0, 2.0, 0.5167793546206902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 722126.8266303921, 722126.8266303921, 186266.9261211203], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2035200.0000, 
sim time next is 2035800.0000, 
raw observation next is [27.25, 84.0, 1.0, 2.0, 0.5168110363721877, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 722171.1124931996, 722171.1124931996, 186272.0921017974], 
processed observation next is [0.0, 0.5652173913043478, 0.490521327014218, 0.84, 1.0, 1.0, 0.41784462213516593, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20060308680366656, 0.20060308680366656, 0.27801804791313045], 
reward next is 0.7220, 
noisyNet noise sample is [array([-0.66197425], dtype=float32), 1.1516768]. 
=============================================
[2019-03-26 15:36:15,339] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.6473840e-15 1.0000000e+00 1.3569042e-16 7.4292358e-18 2.1133641e-27], sum to 1.0000
[2019-03-26 15:36:15,346] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4243
[2019-03-26 15:36:15,354] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 98.0, 1.0, 2.0, 0.4208772223101874, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 614343.8698365949, 614343.8698365949, 175497.5859488033], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1639200.0000, 
sim time next is 1639800.0000, 
raw observation next is [23.1, 98.0, 1.0, 2.0, 0.4211568343095108, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 614751.3162887272, 614751.3162887272, 175536.5775794529], 
processed observation next is [1.0, 1.0, 0.2938388625592418, 0.98, 1.0, 1.0, 0.3025985955536274, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17076425452464644, 0.17076425452464644, 0.26199489190963116], 
reward next is 0.7380, 
noisyNet noise sample is [array([-2.3501658], dtype=float32), 0.9270541]. 
=============================================
[2019-03-26 15:36:21,086] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.5458805e-13 1.0000000e+00 1.1979486e-15 1.0231160e-17 5.3189415e-26], sum to 1.0000
[2019-03-26 15:36:21,097] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2827
[2019-03-26 15:36:21,102] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.05, 97.0, 1.0, 2.0, 0.4661282528298522, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 657108.7704664328, 657108.7704664321, 179205.3507496878], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2003400.0000, 
sim time next is 2004000.0000, 
raw observation next is [24.0, 97.33333333333333, 1.0, 2.0, 0.465416907545301, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 656347.9936221056, 656347.9936221063, 179131.2478526239], 
processed observation next is [0.0, 0.17391304347826086, 0.3364928909952607, 0.9733333333333333, 1.0, 1.0, 0.35592398499433864, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18231888711725155, 0.18231888711725175, 0.2673600714218267], 
reward next is 0.7326, 
noisyNet noise sample is [array([1.7824767], dtype=float32), 1.2652537]. 
=============================================
[2019-03-26 15:36:21,113] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[74.680786]
 [74.7663  ]
 [74.76357 ]
 [74.64564 ]
 [74.57281 ]], R is [[74.59416962]
 [74.58075714]
 [74.56755066]
 [74.55477142]
 [74.54229736]].
[2019-03-26 15:36:23,572] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.1392848e-13 1.0000000e+00 2.7475438e-16 5.6701153e-17 1.6469394e-26], sum to 1.0000
[2019-03-26 15:36:23,583] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6490
[2019-03-26 15:36:23,587] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.56666666666667, 89.66666666666667, 1.0, 2.0, 0.319945060754221, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 505384.0424212043, 505384.0424212049, 167419.6411399539], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1797600.0000, 
sim time next is 1798200.0000, 
raw observation next is [21.5, 90.0, 1.0, 2.0, 0.3193609982216318, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 504755.2680794219, 504755.2680794225, 167377.8087205701], 
processed observation next is [1.0, 0.8260869565217391, 0.21800947867298584, 0.9, 1.0, 1.0, 0.17995300990558044, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1402097966887283, 0.14020979668872846, 0.24981762495607476], 
reward next is 0.7502, 
noisyNet noise sample is [array([-1.1168107], dtype=float32), -1.1526217]. 
=============================================
[2019-03-26 15:36:24,724] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.7916254e-13 1.0000000e+00 7.4951987e-16 4.1826076e-15 8.5064646e-24], sum to 1.0000
[2019-03-26 15:36:24,730] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9849
[2019-03-26 15:36:24,737] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 83.33333333333334, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.152305130557446, 6.9112, 168.9115474263927, 1624918.922166852, 1453872.071248269, 311348.3894367213], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1864200.0000, 
sim time next is 1864800.0000, 
raw observation next is [27.1, 83.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.447655113339775, 6.9112, 168.9096263515161, 1834587.815335496, 1454015.597791453, 311348.5156116763], 
processed observation next is [1.0, 0.6086956521739131, 0.4834123222748816, 0.83, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.053645511333977505, 0.0, 0.8294235925474771, 0.5096077264820823, 0.4038932216087369, 0.4646992770323527], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.5225514], dtype=float32), -1.1173321]. 
=============================================
[2019-03-26 15:36:29,644] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.4518645e-14 1.0000000e+00 3.3156374e-16 3.1552682e-17 3.3015730e-26], sum to 1.0000
[2019-03-26 15:36:29,653] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8435
[2019-03-26 15:36:29,658] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.76666666666667, 89.66666666666666, 1.0, 2.0, 0.4555482627739102, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 648744.9343583201, 648744.9343583207, 178495.5949080214], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1893000.0000, 
sim time next is 1893600.0000, 
raw observation next is [24.7, 90.0, 1.0, 2.0, 0.453565014078821, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 646514.4292675435, 646514.4292675435, 178281.3387856896], 
processed observation next is [1.0, 0.9565217391304348, 0.3696682464454976, 0.9, 1.0, 1.0, 0.3416445952756879, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1795873414632065, 0.1795873414632065, 0.26609155042640237], 
reward next is 0.7339, 
noisyNet noise sample is [array([0.02810677], dtype=float32), 0.010318584]. 
=============================================
[2019-03-26 15:36:32,060] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.1910937e-13 1.0000000e+00 3.9976546e-15 7.5598978e-15 4.7417339e-25], sum to 1.0000
[2019-03-26 15:36:32,067] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2392
[2019-03-26 15:36:32,072] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.53333333333333, 92.0, 1.0, 2.0, 0.4073195822013206, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 601361.8269960075, 601361.8269960075, 174476.4283479775], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1968000.0000, 
sim time next is 1968600.0000, 
raw observation next is [23.41666666666667, 92.5, 1.0, 2.0, 0.4070167001426176, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 602061.6783329732, 602061.6783329732, 174575.397531686], 
processed observation next is [1.0, 0.782608695652174, 0.3088467614533968, 0.925, 1.0, 1.0, 0.28556228932845495, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16723935509249255, 0.16723935509249255, 0.2605602948234119], 
reward next is 0.7394, 
noisyNet noise sample is [array([0.14421022], dtype=float32), 0.54376745]. 
=============================================
[2019-03-26 15:36:43,063] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.0818809e-14 1.0000000e+00 8.3704659e-16 9.8873375e-17 1.3873489e-26], sum to 1.0000
[2019-03-26 15:36:43,070] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6854
[2019-03-26 15:36:43,075] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 75.5, 1.0, 2.0, 0.5597742409293968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 782228.2848523678, 782228.2848523678, 193491.8349713187], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2118600.0000, 
sim time next is 2119200.0000, 
raw observation next is [30.0, 75.66666666666667, 1.0, 2.0, 0.5612681575784264, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 784316.6540803378, 784316.6540803378, 193752.661080726], 
processed observation next is [0.0, 0.5217391304347826, 0.6208530805687204, 0.7566666666666667, 1.0, 1.0, 0.4714074187691884, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21786573724453828, 0.21786573724453828, 0.28918307623988954], 
reward next is 0.7108, 
noisyNet noise sample is [array([0.7868925], dtype=float32), 1.8770578]. 
=============================================
[2019-03-26 15:36:46,797] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.7579566e-12 1.0000000e+00 3.1384851e-14 1.4328862e-13 3.9131323e-22], sum to 1.0000
[2019-03-26 15:36:46,807] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1739
[2019-03-26 15:36:46,818] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1920742.655042127 W.
[2019-03-26 15:36:46,823] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.8, 79.5, 1.0, 2.0, 0.4579292432937556, 1.0, 2.0, 0.4579292432937556, 1.0, 1.0, 0.7938006106181599, 6.9112, 6.9112, 170.5573041426782, 1920742.655042127, 1920742.655042127, 387032.7696418947], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2191800.0000, 
sim time next is 2192400.0000, 
raw observation next is [28.9, 79.0, 1.0, 2.0, 0.6297671345184471, 1.0, 2.0, 0.6297671345184471, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1760869.469994661, 1760869.469994661, 345508.6918211386], 
processed observation next is [1.0, 0.391304347826087, 0.5687203791469194, 0.79, 1.0, 1.0, 0.5539363066487315, 1.0, 1.0, 0.5539363066487315, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.4891304083318503, 0.4891304083318503, 0.5156846146584159], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8127685], dtype=float32), -2.2853258]. 
=============================================
[2019-03-26 15:36:55,135] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.6495721e-13 1.0000000e+00 4.1932933e-16 1.3099394e-16 1.0191809e-26], sum to 1.0000
[2019-03-26 15:36:55,142] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6946
[2019-03-26 15:36:55,146] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.4, 81.0, 1.0, 2.0, 0.5466970916810645, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 763947.7106007746, 763947.7106007746, 191235.6963679117], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2331600.0000, 
sim time next is 2332200.0000, 
raw observation next is [28.35, 81.0, 1.0, 2.0, 0.5446453350928243, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 761079.5843328472, 761079.5843328472, 190886.468196256], 
processed observation next is [1.0, 1.0, 0.5426540284360191, 0.81, 1.0, 1.0, 0.4513799217985835, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2114109956480131, 0.2114109956480131, 0.2849051764123224], 
reward next is 0.7151, 
noisyNet noise sample is [array([0.48647904], dtype=float32), -0.33226386]. 
=============================================
[2019-03-26 15:36:56,077] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-26 15:36:56,078] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 15:36:56,079] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:36:56,079] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 15:36:56,080] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 15:36:56,080] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:36:56,082] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 15:36:56,083] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 15:36:56,084] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:36:56,080] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:36:56,086] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:36:56,099] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run29
[2019-03-26 15:36:56,100] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run29
[2019-03-26 15:36:56,101] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run29
[2019-03-26 15:36:56,118] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run29
[2019-03-26 15:36:56,177] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run29
[2019-03-26 15:37:03,693] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0967868], dtype=float32), 0.06641645]
[2019-03-26 15:37:03,695] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [19.51219133833333, 88.59133156666667, 1.0, 2.0, 0.2611011303428583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 428182.4964899888, 428182.4964899894, 162023.7368416949]
[2019-03-26 15:37:03,696] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 15:37:03,700] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.1574275e-12 1.0000000e+00 9.4295003e-15 2.2924820e-16 4.4731091e-25], sampled 0.7586080823244211
[2019-03-26 15:37:12,084] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0967868], dtype=float32), 0.06641645]
[2019-03-26 15:37:12,121] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [20.23168865333334, 94.44156445666667, 1.0, 2.0, 0.3048109673114828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 488676.4302223937, 488676.4302223931, 166278.4102208737]
[2019-03-26 15:37:12,122] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 15:37:12,125] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [5.8295095e-13 1.0000000e+00 4.1405389e-15 1.0734692e-16 1.5361188e-25], sampled 0.0506423383887723
[2019-03-26 15:37:23,536] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0967868], dtype=float32), 0.06641645]
[2019-03-26 15:37:23,538] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [25.42015090666667, 94.62618638500001, 1.0, 2.0, 0.7337295424714044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1025430.699140857, 1025430.699140857, 228292.2151864288]
[2019-03-26 15:37:23,539] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 15:37:23,541] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.5749992e-13 1.0000000e+00 3.0563746e-15 1.5005072e-16 1.1228243e-25], sampled 0.7518848126810065
[2019-03-26 15:37:36,925] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0967868], dtype=float32), 0.06641645]
[2019-03-26 15:37:36,926] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.26666666666667, 84.0, 1.0, 2.0, 0.6757635608304595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 944383.7702033484, 944383.7702033484, 215699.7630741714]
[2019-03-26 15:37:36,926] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:37:36,929] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.3014498e-13 1.0000000e+00 3.3455214e-15 2.3158625e-16 1.3449166e-25], sampled 0.05782356072417705
[2019-03-26 15:38:29,264] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0967868], dtype=float32), 0.06641645]
[2019-03-26 15:38:29,265] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [32.23333333333333, 59.0, 1.0, 2.0, 0.85049897918479, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1188714.279729904, 1188714.279729904, 256684.1026867624]
[2019-03-26 15:38:29,266] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:38:29,269] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.5206922e-13 1.0000000e+00 1.7356799e-15 3.6586138e-16 8.0066374e-26], sampled 0.06722611291959535
[2019-03-26 15:38:34,472] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0967868], dtype=float32), 0.06641645]
[2019-03-26 15:38:34,473] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.06666666666667, 72.66666666666666, 1.0, 2.0, 0.5327938368054266, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 744512.6666098931, 744512.6666098925, 188892.7262430181]
[2019-03-26 15:38:34,473] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:38:34,478] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [8.1295783e-14 1.0000000e+00 5.8793695e-16 3.3723747e-17 5.4919056e-27], sampled 0.5718565040131993
[2019-03-26 15:38:42,620] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0967868], dtype=float32), 0.06641645]
[2019-03-26 15:38:42,622] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.6, 86.66666666666667, 1.0, 2.0, 0.3723569981784813, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 562537.1515428284, 562537.1515428284, 171387.7869494212]
[2019-03-26 15:38:42,622] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:38:42,625] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.9636296e-13 1.0000000e+00 2.7966635e-15 6.2350572e-17 5.0734144e-26], sampled 0.42887695620475497
[2019-03-26 15:38:49,446] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.4676 2779124528.0117 933.0000
[2019-03-26 15:38:49,459] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7881.9893 3164123109.6779 1778.0000
[2019-03-26 15:38:49,517] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.0235 2842570284.2307 1131.0000
[2019-03-26 15:38:49,567] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.4425 3007811933.4359 1766.0000
[2019-03-26 15:38:49,588] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8252.8296 2927466318.6876 1338.0000
[2019-03-26 15:38:50,604] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 700000, evaluation results [700000.0, 7881.989326476217, 3164123109.67791, 1778.0, 8252.829617302405, 2927466318.6875734, 1338.0, 8661.467580702742, 2779124528.011676, 933.0, 7997.442523613624, 3007811933.4358845, 1766.0, 8496.023481210674, 2842570284.2307444, 1131.0]
[2019-03-26 15:38:58,628] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.1380310e-07 9.9994385e-01 4.2327862e-08 5.5973876e-05 1.1273910e-12], sum to 1.0000
[2019-03-26 15:38:58,643] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9988
[2019-03-26 15:38:58,651] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1905223.368966418 W.
[2019-03-26 15:38:58,655] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.2, 85.66666666666667, 1.0, 2.0, 0.4542325368464881, 1.0, 1.0, 0.4542325368464881, 1.0, 2.0, 0.779308100829759, 6.911200000000001, 6.9112, 170.5573041426782, 1905223.368966418, 1905223.368966417, 383386.0110892], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2473800.0000, 
sim time next is 2474400.0000, 
raw observation next is [27.3, 85.33333333333334, 1.0, 2.0, 0.8103281782157462, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.984948483720236, 6.9112, 168.9125177427152, 2029528.199198575, 1977208.622526026, 411170.8783056202], 
processed observation next is [1.0, 0.6521739130434783, 0.4928909952606636, 0.8533333333333334, 1.0, 1.0, 0.7714797327900557, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.007374848372023557, 0.0, 0.8294377906019494, 0.5637578331107153, 0.5492246173683406, 0.6136878780680899], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.168131], dtype=float32), 1.4072051]. 
=============================================
[2019-03-26 15:39:04,484] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.8499368e-13 1.0000000e+00 3.4282174e-15 1.5175874e-15 4.5548628e-26], sum to 1.0000
[2019-03-26 15:39:04,492] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0759
[2019-03-26 15:39:04,495] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.528905150777884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 789127.4283128334, 789127.4283128334, 194454.328277644], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3069600.0000, 
sim time next is 3070200.0000, 
raw observation next is [23.0, 94.0, 1.0, 2.0, 0.540977909640847, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 807130.6990653153, 807130.6990653153, 196616.662729004], 
processed observation next is [1.0, 0.5217391304347826, 0.28909952606635075, 0.94, 1.0, 1.0, 0.4469613369166831, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2242029719625876, 0.2242029719625876, 0.2934577055656776], 
reward next is 0.7065, 
noisyNet noise sample is [array([-0.6196491], dtype=float32), 1.3057569]. 
=============================================
[2019-03-26 15:39:06,747] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.4051904e-13 1.0000000e+00 3.5822442e-15 9.1156640e-17 5.7721587e-26], sum to 1.0000
[2019-03-26 15:39:06,757] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1793
[2019-03-26 15:39:06,762] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 86.5, 1.0, 2.0, 0.4660689571230514, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 655977.7309307858, 655977.7309307863, 179061.9022285829], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2619000.0000, 
sim time next is 2619600.0000, 
raw observation next is [25.66666666666666, 85.66666666666667, 1.0, 2.0, 0.4682794274503636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 657664.9178185721, 657664.9178185728, 179205.7604229623], 
processed observation next is [0.0, 0.30434782608695654, 0.4154818325434437, 0.8566666666666667, 1.0, 1.0, 0.35937280415706463, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18268469939404783, 0.18268469939404802, 0.26747128421337657], 
reward next is 0.7325, 
noisyNet noise sample is [array([1.4288595], dtype=float32), -0.6671437]. 
=============================================
[2019-03-26 15:39:21,421] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.1665453e-12 1.0000000e+00 2.9873510e-15 5.9590303e-16 2.2983997e-25], sum to 1.0000
[2019-03-26 15:39:21,429] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4558
[2019-03-26 15:39:21,435] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.3391349646522034, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 522432.1466490824, 522432.1466490824, 168393.0931199608], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2863800.0000, 
sim time next is 2864400.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.3456146005598426, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 532415.1094333327, 532415.109433332, 169196.7591309555], 
processed observation next is [1.0, 0.13043478260869565, 0.2417061611374408, 0.94, 1.0, 1.0, 0.2115838560961959, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1478930859537035, 0.14789308595370332, 0.252532476314859], 
reward next is 0.7475, 
noisyNet noise sample is [array([-0.7324093], dtype=float32), -1.3216826]. 
=============================================
[2019-03-26 15:39:22,151] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.2179825e-12 1.0000000e+00 4.2104144e-15 1.9695299e-16 2.0986326e-25], sum to 1.0000
[2019-03-26 15:39:22,162] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8967
[2019-03-26 15:39:22,165] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333334, 89.0, 1.0, 2.0, 0.6353656039245327, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 959454.6949367183, 959454.6949367183, 216482.4968872991], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3144000.0000, 
sim time next is 3144600.0000, 
raw observation next is [23.5, 89.0, 1.0, 2.0, 0.663191505572691, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 996052.9649350531, 996052.9649350538, 221913.1927502466], 
processed observation next is [1.0, 0.391304347826087, 0.31279620853080575, 0.89, 1.0, 1.0, 0.5942066332201097, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2766813791486259, 0.27668137914862606, 0.33121372052275616], 
reward next is 0.6688, 
noisyNet noise sample is [array([-0.92373395], dtype=float32), 0.18500271]. 
=============================================
[2019-03-26 15:39:29,642] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.4306525e-14 1.0000000e+00 6.6212555e-16 4.5697292e-17 3.9889626e-27], sum to 1.0000
[2019-03-26 15:39:29,651] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7876
[2019-03-26 15:39:29,658] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.3062731660905995, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 487720.7722757117, 487720.7722757111, 166178.537619431], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3007800.0000, 
sim time next is 3008400.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.3064534176698839, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 488008.0487519372, 488008.0487519379, 166199.4117093935], 
processed observation next is [1.0, 0.8260869565217391, 0.1469194312796209, 1.0, 1.0, 1.0, 0.16440170803600465, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13555779131998255, 0.13555779131998275, 0.24805882344685595], 
reward next is 0.7519, 
noisyNet noise sample is [array([-0.6132626], dtype=float32), 0.022222782]. 
=============================================
[2019-03-26 15:39:35,989] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.3582162e-13 1.0000000e+00 2.6807570e-15 1.7064191e-15 1.5858670e-24], sum to 1.0000
[2019-03-26 15:39:35,996] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5716
[2019-03-26 15:39:36,000] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 96.0, 1.0, 2.0, 0.4120562059347619, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 616328.7094646657, 616328.7094646663, 176091.7326102006], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3118800.0000, 
sim time next is 3119400.0000, 
raw observation next is [22.5, 97.0, 1.0, 2.0, 0.3926630830326238, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 588240.3927870096, 588240.3927870103, 173526.4117950871], 
processed observation next is [1.0, 0.08695652173913043, 0.2654028436018958, 0.97, 1.0, 1.0, 0.26826877473810096, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16340010910750266, 0.16340010910750286, 0.25899464447027926], 
reward next is 0.7410, 
noisyNet noise sample is [array([0.1598041], dtype=float32), 1.3912168]. 
=============================================
[2019-03-26 15:39:37,322] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.9694271e-10 1.0000000e+00 5.3774121e-11 1.5682016e-09 3.3600983e-17], sum to 1.0000
[2019-03-26 15:39:37,331] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6724
[2019-03-26 15:39:37,341] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2255322.752503868 W.
[2019-03-26 15:39:37,345] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.0, 75.0, 1.0, 2.0, 0.971650761477488, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.00310855013503, 6.9112, 168.9124097454391, 2255322.752503868, 2190119.874849895, 454805.4432651983], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3402000.0000, 
sim time next is 3402600.0000, 
raw observation next is [30.16666666666666, 74.16666666666667, 1.0, 2.0, 0.7933412510429029, 1.0, 1.0, 0.7933412510429029, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2218705.935324195, 2218705.935324196, 416644.9031909923], 
processed observation next is [1.0, 0.391304347826087, 0.6287519747235385, 0.7416666666666667, 1.0, 1.0, 0.7510135554733769, 1.0, 0.5, 0.7510135554733769, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6163072042567208, 0.616307204256721, 0.6218580644641676], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.67980415], dtype=float32), -1.3840672]. 
=============================================
[2019-03-26 15:39:41,319] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.7765553e-14 1.0000000e+00 1.8979552e-16 2.3905872e-17 1.8487464e-26], sum to 1.0000
[2019-03-26 15:39:41,329] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5384
[2019-03-26 15:39:41,333] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 92.66666666666666, 1.0, 2.0, 0.4810841055832136, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 672231.9291245964, 672231.9291245958, 180685.2682598107], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3202800.0000, 
sim time next is 3203400.0000, 
raw observation next is [25.0, 92.33333333333333, 1.0, 2.0, 0.4791888750308868, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 669582.8372130482, 669582.8372130488, 180399.4825859996], 
processed observation next is [0.0, 0.043478260869565216, 0.38388625592417064, 0.9233333333333333, 1.0, 1.0, 0.37251671690468285, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18599523255918007, 0.18599523255918024, 0.2692529590835815], 
reward next is 0.7307, 
noisyNet noise sample is [array([0.16888747], dtype=float32), 0.18858811]. 
=============================================
[2019-03-26 15:39:42,935] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.0652950e-08 9.9997997e-01 1.4144131e-08 1.9880270e-05 3.1197865e-12], sum to 1.0000
[2019-03-26 15:39:42,943] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2838
[2019-03-26 15:39:42,952] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2396239.355585715 W.
[2019-03-26 15:39:42,960] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.5, 70.5, 1.0, 2.0, 0.8567609599942118, 1.0, 2.0, 0.8567609599942118, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2396239.355585715, 2396239.355585715, 448455.7576246843], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3407400.0000, 
sim time next is 3408000.0000, 
raw observation next is [31.66666666666666, 70.66666666666666, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.632326972212486, 6.9112, 168.9090480820192, 2795730.162944199, 2284149.707168944, 474483.546144932], 
processed observation next is [1.0, 0.43478260869565216, 0.6998420221169034, 0.7066666666666666, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.07211269722124855, 0.0, 0.8294207529795146, 0.7765917119289442, 0.6344860297691511, 0.7081843972312417], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.5309787], dtype=float32), -0.037833303]. 
=============================================
[2019-03-26 15:39:42,977] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[27.914906]
 [28.137808]
 [29.013206]
 [32.251823]
 [33.535732]], R is [[27.22169304]
 [27.28013992]
 [27.33994102]
 [27.06654167]
 [26.79587746]].
[2019-03-26 15:39:44,824] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.1702995e-13 1.0000000e+00 3.2981658e-16 1.4400314e-17 3.3085543e-28], sum to 1.0000
[2019-03-26 15:39:44,833] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8801
[2019-03-26 15:39:44,838] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 80.66666666666667, 1.0, 2.0, 0.530733519724695, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 741632.6264427055, 741632.6264427049, 188551.2806606337], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3271200.0000, 
sim time next is 3271800.0000, 
raw observation next is [28.0, 79.83333333333334, 1.0, 2.0, 0.5266959904319644, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 735988.7379402305, 735988.7379402305, 187884.2469297457], 
processed observation next is [0.0, 0.8695652173913043, 0.5260663507109005, 0.7983333333333335, 1.0, 1.0, 0.4297542053397161, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20444131609450847, 0.20444131609450847, 0.2804242491488742], 
reward next is 0.7196, 
noisyNet noise sample is [array([-0.21018581], dtype=float32), 2.4015632]. 
=============================================
[2019-03-26 15:39:45,016] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.0074391e-14 1.0000000e+00 6.0812426e-17 2.2118598e-17 1.3147781e-27], sum to 1.0000
[2019-03-26 15:39:45,024] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3451
[2019-03-26 15:39:45,032] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 82.33333333333334, 1.0, 2.0, 0.5391602199958581, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 753412.044838922, 753412.0448389213, 189958.9602197447], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3270000.0000, 
sim time next is 3270600.0000, 
raw observation next is [28.0, 81.5, 1.0, 2.0, 0.5350485252847587, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 747664.420231969, 747664.4202319696, 189269.4674526293], 
processed observation next is [0.0, 0.8695652173913043, 0.5260663507109005, 0.815, 1.0, 1.0, 0.4398175003430827, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20768456117554693, 0.2076845611755471, 0.2824917424666109], 
reward next is 0.7175, 
noisyNet noise sample is [array([0.06256449], dtype=float32), 0.57310903]. 
=============================================
[2019-03-26 15:39:45,613] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-26 15:39:45,615] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 15:39:45,616] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 15:39:45,616] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:39:45,617] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:39:45,618] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 15:39:45,619] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 15:39:45,620] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:39:45,620] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:39:45,621] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 15:39:45,623] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:39:45,646] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run30
[2019-03-26 15:39:45,647] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run30
[2019-03-26 15:39:45,682] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run30
[2019-03-26 15:39:45,708] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run30
[2019-03-26 15:39:45,708] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run30
[2019-03-26 15:39:58,117] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10028186], dtype=float32), 0.06882559]
[2019-03-26 15:39:58,118] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [18.77382481833333, 87.53045080333334, 1.0, 2.0, 0.2358882917924365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 391112.9613240229, 391112.9613240229, 159367.2756995185]
[2019-03-26 15:39:58,119] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 15:39:58,122] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [4.0920311e-13 1.0000000e+00 2.3491588e-15 3.0513505e-17 3.0224672e-26], sampled 0.9259775564359918
[2019-03-26 15:40:07,613] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10028186], dtype=float32), 0.06882559]
[2019-03-26 15:40:07,614] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [22.15, 73.0, 1.0, 2.0, 0.277555081065828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 452330.8872630498, 452330.8872630498, 163689.3449639174]
[2019-03-26 15:40:07,614] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:40:07,616] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.00959687e-13 1.00000000e+00 4.97108020e-16 1.18465507e-17
 3.03501310e-27], sampled 0.7947455794314032
[2019-03-26 15:40:30,220] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10028186], dtype=float32), 0.06882559]
[2019-03-26 15:40:30,221] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [33.53333333333334, 59.66666666666667, 1.0, 2.0, 0.8194016601414389, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1145227.146580664, 1145227.146580664, 248732.5430182798]
[2019-03-26 15:40:30,223] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:40:30,226] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.1950789e-13 1.0000000e+00 9.7619806e-16 1.0906318e-16 2.4168188e-26], sampled 0.5820044729154623
[2019-03-26 15:40:53,229] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10028186], dtype=float32), 0.06882559]
[2019-03-26 15:40:53,230] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.5, 76.5, 1.0, 2.0, 0.5161334735872127, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 721223.9918837352, 721223.9918837352, 186162.8632412496]
[2019-03-26 15:40:53,230] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:40:53,232] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.5030903e-13 1.0000000e+00 2.3608195e-15 4.8279057e-16 6.9669329e-27], sampled 0.3414422656907735
[2019-03-26 15:41:10,004] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10028186], dtype=float32), 0.06882559]
[2019-03-26 15:41:10,005] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.43164844166667, 89.96458701666668, 1.0, 2.0, 0.8494504105649862, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1187247.910701903, 1187247.910701904, 256409.9761316337]
[2019-03-26 15:41:10,007] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 15:41:10,010] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [9.5399105e-14 1.0000000e+00 5.5442446e-16 4.4522222e-17 1.3656003e-26], sampled 0.04501211749785616
[2019-03-26 15:41:20,278] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10028186], dtype=float32), 0.06882559]
[2019-03-26 15:41:20,280] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.4, 93.0, 1.0, 2.0, 0.6252880155336923, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 873814.8638173329, 873814.8638173336, 205542.8369198811]
[2019-03-26 15:41:20,282] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:41:20,285] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.5672175e-13 1.0000000e+00 1.1084583e-15 4.2710895e-17 1.6944547e-26], sampled 0.79430742790316
[2019-03-26 15:41:38,196] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7999.0502 3007584666.7691 1766.0000
[2019-03-26 15:41:38,497] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.9164 3164002230.9074 1778.0000
[2019-03-26 15:41:38,614] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.5144 2842492707.2201 1131.0000
[2019-03-26 15:41:38,695] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8252.9283 2927297329.7882 1338.0000
[2019-03-26 15:41:38,846] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.2105 2779289845.7918 933.0000
[2019-03-26 15:41:39,863] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 725000, evaluation results [725000.0, 7884.916440885027, 3164002230.907359, 1778.0, 8252.928342499928, 2927297329.7881875, 1338.0, 8659.210468780357, 2779289845.791773, 933.0, 7999.050242421542, 3007584666.769063, 1766.0, 8497.514395919725, 2842492707.2200756, 1131.0]
[2019-03-26 15:41:40,448] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.7058061e-14 1.0000000e+00 2.6295672e-16 5.7441572e-17 6.2246605e-28], sum to 1.0000
[2019-03-26 15:41:40,456] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6451
[2019-03-26 15:41:40,462] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.4870881078076754, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 680624.172679582, 680624.172679582, 181597.4172454706], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3281400.0000, 
sim time next is 3282000.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.4867241055259631, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 680115.3775419996, 680115.3775420003, 181541.8185202424], 
processed observation next is [0.0, 1.0, 0.4786729857819906, 0.79, 1.0, 1.0, 0.38159530786260615, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.188920938206111, 0.1889209382061112, 0.27095793808991403], 
reward next is 0.7290, 
noisyNet noise sample is [array([1.6664667], dtype=float32), -2.2747364]. 
=============================================
[2019-03-26 15:41:40,478] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[77.43829]
 [77.4223 ]
 [77.41344]
 [77.38647]
 [77.37309]], R is [[77.40795135]
 [77.36283112]
 [77.31804657]
 [77.27353668]
 [77.2289505 ]].
[2019-03-26 15:41:48,738] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.2562074e-06 2.3225719e-01 1.4410781e-05 7.6772714e-01 3.3184328e-08], sum to 1.0000
[2019-03-26 15:41:48,746] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8089
[2019-03-26 15:41:48,751] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.33333333333334, 65.33333333333334, 1.0, 2.0, 0.5998033545393819, 1.0, 2.0, 0.5998033545393819, 1.0, 1.0, 1.03, 6.924307678487702, 6.9112, 170.5573041426782, 2516468.799298913, 2507079.236011901, 487907.1401968417], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3428400.0000, 
sim time next is 3429000.0000, 
raw observation next is [32.0, 66.5, 1.0, 2.0, 0.8860315012186144, 1.0, 2.0, 0.8860315012186144, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2478186.102417641, 2478186.102417642, 463930.6932537308], 
processed observation next is [1.0, 0.6956521739130435, 0.7156398104265403, 0.665, 1.0, 1.0, 0.8626885556850776, 1.0, 1.0, 0.8626885556850776, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6883850284493447, 0.6883850284493449, 0.6924338705279564], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.09301817], dtype=float32), 1.5026629]. 
=============================================
[2019-03-26 15:41:48,770] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[14.794853]
 [15.991507]
 [14.232912]
 [15.048453]
 [16.135849]], R is [[16.32147217]
 [16.15825844]
 [16.27820206]
 [16.11541939]
 [15.95426559]].
[2019-03-26 15:41:51,502] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.1075376e-13 1.0000000e+00 1.9180007e-15 5.8398085e-15 5.8719713e-24], sum to 1.0000
[2019-03-26 15:41:51,514] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2231
[2019-03-26 15:41:51,520] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.00000000000001, 1.0, 2.0, 0.7734705947839404, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1080999.454055136, 1080999.454055136, 237499.5673800751], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3640200.0000, 
sim time next is 3640800.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.759871013071652, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1061983.228120634, 1061983.228120635, 234295.6190430396], 
processed observation next is [1.0, 0.13043478260869565, 0.4786729857819906, 0.79, 1.0, 1.0, 0.7106879675562071, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.29499534114462056, 0.29499534114462084, 0.34969495379558146], 
reward next is 0.6503, 
noisyNet noise sample is [array([-0.11589441], dtype=float32), -1.6118011]. 
=============================================
[2019-03-26 15:41:54,915] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.9712590e-14 1.0000000e+00 1.4600900e-15 1.4904732e-15 4.0476589e-25], sum to 1.0000
[2019-03-26 15:41:54,923] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1413
[2019-03-26 15:41:54,926] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.16666666666667, 79.0, 1.0, 2.0, 0.5292705421878953, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 739587.5896174719, 739587.5896174725, 188308.8996478552], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3534600.0000, 
sim time next is 3535200.0000, 
raw observation next is [28.0, 79.0, 1.0, 2.0, 0.5231976593354678, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 731098.595647361, 731098.595647361, 187310.149921335], 
processed observation next is [1.0, 0.9565217391304348, 0.5260663507109005, 0.79, 1.0, 1.0, 0.42553934859694914, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20308294323537807, 0.20308294323537807, 0.279567387942291], 
reward next is 0.7204, 
noisyNet noise sample is [array([0.2697639], dtype=float32), -0.4530016]. 
=============================================
[2019-03-26 15:42:03,386] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0237206e-06 9.3558085e-01 1.9483487e-06 6.4416088e-02 4.6145454e-10], sum to 1.0000
[2019-03-26 15:42:03,392] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9435
[2019-03-26 15:42:03,398] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.0, 61.66666666666667, 1.0, 2.0, 0.9766686575033323, 1.0, 1.0, 0.9766686575033323, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2731970.887619716, 2731970.887619715, 515046.1716691136], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3676800.0000, 
sim time next is 3677400.0000, 
raw observation next is [33.0, 61.0, 1.0, 2.0, 0.985439325402686, 1.0, 2.0, 0.985439325402686, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2756531.565911396, 2756531.565911397, 520247.5392739587], 
processed observation next is [1.0, 0.5652173913043478, 0.7630331753554502, 0.61, 1.0, 1.0, 0.9824570185574529, 1.0, 1.0, 0.9824570185574529, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.7657032127531656, 0.7657032127531658, 0.776488864587998], 
reward next is 0.2235, 
noisyNet noise sample is [array([-0.4675656], dtype=float32), -0.80430794]. 
=============================================
[2019-03-26 15:42:03,456] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.4652027e-07 9.6629882e-01 1.7079616e-06 3.3699233e-02 3.5699232e-10], sum to 1.0000
[2019-03-26 15:42:03,461] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0745
[2019-03-26 15:42:03,472] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2426523.122108552 W.
[2019-03-26 15:42:03,477] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.0, 59.0, 1.0, 2.0, 0.8675782357856746, 1.0, 2.0, 0.8675782357856746, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2426523.122108552, 2426523.122108552, 454111.6362070195], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3679800.0000, 
sim time next is 3680400.0000, 
raw observation next is [33.0, 59.0, 1.0, 2.0, 0.6008927627179973, 1.0, 2.0, 0.6008927627179973, 1.0, 1.0, 1.03, 6.9264345346155, 6.9112, 170.5573041426782, 2521044.011025409, 2510130.89417908, 488301.7574307779], 
processed observation next is [1.0, 0.6086956521739131, 0.7630331753554502, 0.59, 1.0, 1.0, 0.5191479068891534, 1.0, 1.0, 0.5191479068891534, 1.0, 0.5, 1.0365853658536586, 0.001523453461549984, 0.0, 0.8375144448122397, 0.7002900030626137, 0.6972585817164112, 0.7288085931802655], 
reward next is 0.1950, 
noisyNet noise sample is [array([1.3455433], dtype=float32), 0.92770404]. 
=============================================
[2019-03-26 15:42:07,003] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.8803024e-13 1.0000000e+00 2.8743230e-14 2.3674764e-14 7.2227032e-24], sum to 1.0000
[2019-03-26 15:42:07,011] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1757
[2019-03-26 15:42:07,018] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.5, 72.0, 1.0, 2.0, 0.787689112228807, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1100881.498825694, 1100881.498825694, 240908.6796724935], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3742200.0000, 
sim time next is 3742800.0000, 
raw observation next is [28.66666666666666, 71.33333333333333, 1.0, 2.0, 0.7662399748439855, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1070888.872574917, 1070888.872574916, 235790.1693665746], 
processed observation next is [1.0, 0.30434782608695654, 0.5576619273301735, 0.7133333333333333, 1.0, 1.0, 0.7183614154746814, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2974691312708103, 0.29746913127081004, 0.3519256259202606], 
reward next is 0.6481, 
noisyNet noise sample is [array([0.7147285], dtype=float32), 0.6644007]. 
=============================================
[2019-03-26 15:42:15,849] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.1371505e-14 1.0000000e+00 9.4717785e-17 2.6595273e-17 4.5426794e-27], sum to 1.0000
[2019-03-26 15:42:15,860] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6204
[2019-03-26 15:42:15,864] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.16666666666667, 88.16666666666667, 1.0, 2.0, 0.5793226602816446, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 809555.6477844748, 809555.6477844748, 196956.585201882], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3891000.0000, 
sim time next is 3891600.0000, 
raw observation next is [28.0, 89.0, 1.0, 2.0, 0.5794535150899367, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 809738.5762904576, 809738.5762904576, 196980.0352166448], 
processed observation next is [0.0, 0.043478260869565216, 0.5260663507109005, 0.89, 1.0, 1.0, 0.4933174880601647, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2249273823029049, 0.2249273823029049, 0.29400005256215644], 
reward next is 0.7060, 
noisyNet noise sample is [array([0.39950833], dtype=float32), -1.8954232]. 
=============================================
[2019-03-26 15:42:18,702] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.7962848e-14 1.0000000e+00 1.3353987e-16 4.1433156e-17 1.4708592e-27], sum to 1.0000
[2019-03-26 15:42:18,713] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5276
[2019-03-26 15:42:18,724] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 73.66666666666667, 1.0, 2.0, 0.6309860994818122, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 881781.0125658162, 881781.0125658168, 206660.805679261], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3957600.0000, 
sim time next is 3958200.0000, 
raw observation next is [32.0, 73.0, 1.0, 2.0, 0.6216255229113851, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 868694.5845196096, 868694.5845196096, 204844.3145208912], 
processed observation next is [0.0, 0.8260869565217391, 0.7156398104265403, 0.73, 1.0, 1.0, 0.5441271360378133, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2413040512554471, 0.2413040512554471, 0.3057377828670018], 
reward next is 0.6943, 
noisyNet noise sample is [array([-0.94154096], dtype=float32), 1.4077024]. 
=============================================
[2019-03-26 15:42:19,135] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.5651034e-14 1.0000000e+00 6.1591058e-16 9.8944314e-17 7.9134135e-27], sum to 1.0000
[2019-03-26 15:42:19,145] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7739
[2019-03-26 15:42:19,151] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [34.16666666666667, 61.83333333333333, 1.0, 2.0, 0.6104027810238561, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 853004.9938681923, 853004.993868193, 202700.9115656583], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3948600.0000, 
sim time next is 3949200.0000, 
raw observation next is [34.0, 63.0, 1.0, 2.0, 0.6139418457987807, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 857952.643682573, 857952.643682573, 203372.9679471235], 
processed observation next is [0.0, 0.7391304347826086, 0.8104265402843602, 0.63, 1.0, 1.0, 0.5348696937334707, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2383201788007147, 0.2383201788007147, 0.303541743204662], 
reward next is 0.6965, 
noisyNet noise sample is [array([-0.3297313], dtype=float32), -0.058635242]. 
=============================================
[2019-03-26 15:42:20,000] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.3525801e-08 9.9925488e-01 2.5889541e-08 7.4505800e-04 4.5616263e-12], sum to 1.0000
[2019-03-26 15:42:20,012] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6875
[2019-03-26 15:42:20,025] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2538542.308115679 W.
[2019-03-26 15:42:20,033] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.66666666666667, 65.0, 1.0, 2.0, 0.907588894051685, 1.0, 2.0, 0.907588894051685, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2538542.308115679, 2538542.30811568, 475646.7166082464], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4015200.0000, 
sim time next is 4015800.0000, 
raw observation next is [32.0, 64.5, 1.0, 2.0, 0.6158980946846215, 1.0, 2.0, 0.6158980946846215, 1.0, 1.0, 1.03, 6.955730298387493, 6.9112, 170.5573041426782, 2584063.941617279, 2552165.077505591, 493814.6791091742], 
processed observation next is [1.0, 0.4782608695652174, 0.7156398104265403, 0.645, 1.0, 1.0, 0.5372266201019537, 1.0, 1.0, 0.5372266201019537, 1.0, 0.5, 1.0365853658536586, 0.004453029838749334, 0.0, 0.8375144448122397, 0.717795539338133, 0.708934743751553, 0.7370368344913047], 
reward next is 0.0403, 
noisyNet noise sample is [array([1.0897057], dtype=float32), -2.4075212]. 
=============================================
[2019-03-26 15:42:24,081] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.6553741e-07 4.2285153e-01 1.6157603e-06 5.7714665e-01 1.2963239e-10], sum to 1.0000
[2019-03-26 15:42:24,087] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3529
[2019-03-26 15:42:24,095] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 3253624.838364132 W.
[2019-03-26 15:42:24,099] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [34.0, 60.0, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 7.391271195969967, 6.9112, 170.5573041426782, 3253624.838364132, 2909730.312643138, 551064.4320043945], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4030200.0000, 
sim time next is 4030800.0000, 
raw observation next is [34.0, 60.0, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 7.534870999946562, 6.9112, 170.5573041426782, 3356611.051666856, 2909850.145090869, 550226.9422919562], 
processed observation next is [1.0, 0.6521739130434783, 0.8104265402843602, 0.6, 1.0, 1.0, 1.0481927710843375, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.2195121951219512, 0.06236709999465617, 0.0, 0.8375144448122397, 0.9323919587963488, 0.8082917069696859, 0.8212342422268002], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.7165318], dtype=float32), -0.10599414]. 
=============================================
[2019-03-26 15:42:26,162] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.12530536e-13 1.00000000e+00 2.75946552e-16 8.98256312e-16
 8.10281006e-26], sum to 1.0000
[2019-03-26 15:42:26,168] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5531
[2019-03-26 15:42:26,173] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.73333333333333, 85.33333333333334, 1.0, 2.0, 0.5405564260906415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 755363.7698949806, 755363.76989498, 190194.6108314481], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4065600.0000, 
sim time next is 4066200.0000, 
raw observation next is [27.7, 85.5, 1.0, 2.0, 0.5400614900624227, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 754671.9095572466, 754671.909557246, 190111.1631032673], 
processed observation next is [1.0, 0.043478260869565216, 0.5118483412322274, 0.855, 1.0, 1.0, 0.4458572169426779, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20963108598812405, 0.20963108598812388, 0.2837480046317422], 
reward next is 0.7163, 
noisyNet noise sample is [array([0.8588936], dtype=float32), 0.4267763]. 
=============================================
[2019-03-26 15:42:29,072] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.5330318e-10 1.0000000e+00 4.0091014e-11 8.4727636e-10 1.1874602e-17], sum to 1.0000
[2019-03-26 15:42:29,080] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8688
[2019-03-26 15:42:29,086] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1733507.998093469 W.
[2019-03-26 15:42:29,091] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.66666666666667, 87.33333333333334, 1.0, 2.0, 0.413326223137791, 1.0, 1.0, 0.413326223137791, 1.0, 1.0, 0.7178109605196199, 6.9112, 6.9112, 170.5573041426782, 1733507.998093469, 1733507.998093469, 360387.6671450328], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4591200.0000, 
sim time next is 4591800.0000, 
raw observation next is [27.5, 89.0, 1.0, 2.0, 0.5635448402456017, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9716892205757458, 6.911200000000001, 6.9112, 168.9129563369102, 1575582.828782418, 1575582.828782418, 343311.9770833107], 
processed observation next is [1.0, 0.13043478260869565, 0.5023696682464456, 0.89, 1.0, 1.0, 0.47415040993445984, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 0.9654746592387142, 8.881784197001253e-17, 0.0, 0.8294399443002362, 0.43766189688400503, 0.43766189688400503, 0.5124059359452399], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.0541167], dtype=float32), 0.7932069]. 
=============================================
[2019-03-26 15:42:30,944] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.6559527e-15 1.0000000e+00 1.0023139e-16 5.2587659e-16 3.8052639e-27], sum to 1.0000
[2019-03-26 15:42:30,951] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6552
[2019-03-26 15:42:30,961] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 84.0, 1.0, 2.0, 0.5833665816437785, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 815208.863036261, 815208.8630362618, 197687.9080803803], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4143000.0000, 
sim time next is 4143600.0000, 
raw observation next is [29.0, 84.0, 1.0, 2.0, 0.5832576327811173, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 815056.5571648519, 815056.5571648526, 197668.1565032419], 
processed observation next is [1.0, 1.0, 0.5734597156398105, 0.84, 1.0, 1.0, 0.4979007623868883, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22640459921245887, 0.22640459921245906, 0.29502709925856996], 
reward next is 0.7050, 
noisyNet noise sample is [array([-1.1406537], dtype=float32), -0.2851021]. 
=============================================
[2019-03-26 15:42:31,931] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.5775312e-13 1.0000000e+00 2.9254496e-15 2.7509445e-14 3.6257521e-25], sum to 1.0000
[2019-03-26 15:42:31,938] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4442
[2019-03-26 15:42:31,944] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 89.0, 1.0, 2.0, 0.9360712171787923, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.9129564826312, 1308389.459505324, 1308389.459505323, 280055.3816287004], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4167000.0000, 
sim time next is 4167600.0000, 
raw observation next is [28.0, 89.0, 1.0, 2.0, 0.9006624569647119, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510424, 1258867.677126204, 1258867.677126204, 270122.7089204718], 
processed observation next is [1.0, 0.21739130434782608, 0.5260663507109005, 0.89, 1.0, 1.0, 0.8803162132104962, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451522684, 0.34968546586838994, 0.34968546586838994, 0.4031682222693609], 
reward next is 0.5968, 
noisyNet noise sample is [array([-0.27528512], dtype=float32), -0.473952]. 
=============================================
[2019-03-26 15:42:35,044] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-26 15:42:35,048] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 15:42:35,048] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:42:35,051] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 15:42:35,052] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:42:35,053] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 15:42:35,053] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:42:35,054] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 15:42:35,056] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:42:35,057] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 15:42:35,059] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:42:35,073] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run31
[2019-03-26 15:42:35,073] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run31
[2019-03-26 15:42:35,107] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run31
[2019-03-26 15:42:35,124] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run31
[2019-03-26 15:42:35,141] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run31
[2019-03-26 15:42:39,288] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0984771], dtype=float32), 0.06649551]
[2019-03-26 15:42:39,289] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [23.4, 51.0, 1.0, 2.0, 0.216857213513092, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 361633.9675803445, 361633.9675803451, 157202.9185845502]
[2019-03-26 15:42:39,291] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:42:39,294] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.1999783e-13 1.0000000e+00 5.3319093e-16 4.0824732e-17 5.9424260e-27], sampled 0.035910569029985795
[2019-03-26 15:42:47,314] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0984771], dtype=float32), 0.06649551]
[2019-03-26 15:42:47,315] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.66666666666667, 70.16666666666667, 1.0, 2.0, 0.4124273617084923, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 609917.4691774137, 609917.4691774143, 175304.9959309288]
[2019-03-26 15:42:47,316] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 15:42:47,320] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.0042294e-14 1.0000000e+00 9.1439086e-17 1.8662425e-17 6.0899609e-28], sampled 0.027726156463869667
[2019-03-26 15:43:17,595] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0984771], dtype=float32), 0.06649551]
[2019-03-26 15:43:17,596] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [20.33333333333333, 98.0, 1.0, 2.0, 0.3084083045019793, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 489744.1291214715, 489744.1291214708, 166304.6750608207]
[2019-03-26 15:43:17,598] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:43:17,601] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.8057280e-14 1.0000000e+00 6.7369222e-17 7.8274935e-18 3.4589331e-28], sampled 0.41568643012866313
[2019-03-26 15:43:57,292] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0984771], dtype=float32), 0.06649551]
[2019-03-26 15:43:57,292] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.2, 87.0, 1.0, 2.0, 0.5377579331314782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 751451.8232215702, 751451.8232215696, 189723.1029902895]
[2019-03-26 15:43:57,293] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:43:57,295] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.8267342e-15 1.0000000e+00 4.1815826e-17 8.1508640e-18 1.5229127e-28], sampled 0.3757518053089025
[2019-03-26 15:44:00,168] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0984771], dtype=float32), 0.06649551]
[2019-03-26 15:44:00,170] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.10609994, 87.95750442, 1.0, 2.0, 0.5259737288357169, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 734979.1226887421, 734979.1226887415, 187763.8847453017]
[2019-03-26 15:44:00,172] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 15:44:00,176] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [4.0494965e-14 1.0000000e+00 1.7718848e-16 6.8895053e-17 4.9307308e-27], sampled 0.1431901977520278
[2019-03-26 15:44:07,378] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0984771], dtype=float32), 0.06649551]
[2019-03-26 15:44:07,381] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [32.06666666666667, 59.66666666666667, 1.0, 2.0, 0.5234154976627682, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 731403.100306471, 731403.1003064716, 187347.1055799989]
[2019-03-26 15:44:07,384] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:44:07,385] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.0113292e-14 1.0000000e+00 1.4982536e-16 1.1884306e-16 2.1782216e-27], sampled 0.18943535882758045
[2019-03-26 15:44:09,911] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0984771], dtype=float32), 0.06649551]
[2019-03-26 15:44:09,911] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [30.2, 60.0, 1.0, 2.0, 0.7287342550853784, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.959787690197473, 6.9112, 168.9126263619251, 1915338.948448555, 1880869.236136073, 392436.5375416873]
[2019-03-26 15:44:09,913] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:44:09,916] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.5531618e-10 9.9999988e-01 1.3825918e-10 6.3144448e-08 1.0126940e-17], sampled 0.2661930859484307
[2019-03-26 15:44:09,919] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1915338.948448555 W.
[2019-03-26 15:44:27,645] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.8717 2927447046.3306 1338.0000
[2019-03-26 15:44:27,781] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.5198 3007644995.7130 1766.0000
[2019-03-26 15:44:27,854] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7885.2965 3164072485.0147 1776.0000
[2019-03-26 15:44:28,162] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.5752 2842451949.6408 1131.0000
[2019-03-26 15:44:28,207] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.7167 2779156526.3284 933.0000
[2019-03-26 15:44:29,224] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 750000, evaluation results [750000.0, 7885.2964597360005, 3164072485.0147343, 1776.0, 8254.871735174753, 2927447046.3306217, 1338.0, 8660.716744232455, 2779156526.328446, 933.0, 7997.51984653401, 3007644995.7129836, 1766.0, 8497.575228127671, 2842451949.640752, 1131.0]
[2019-03-26 15:44:45,202] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.9413393e-15 1.0000000e+00 1.5497684e-17 1.3292272e-18 2.2004848e-29], sum to 1.0000
[2019-03-26 15:44:45,213] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2668
[2019-03-26 15:44:45,221] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666667, 85.66666666666667, 1.0, 2.0, 0.5162255930472541, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 721352.7595897908, 721352.7595897908, 186176.7387330674], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4490400.0000, 
sim time next is 4491000.0000, 
raw observation next is [26.5, 86.5, 1.0, 2.0, 0.5142657200147461, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 718613.1859502372, 718613.1859502365, 185860.829198575], 
processed observation next is [0.0, 1.0, 0.4549763033175356, 0.865, 1.0, 1.0, 0.4147779759213808, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1996147738750659, 0.1996147738750657, 0.2774042226844403], 
reward next is 0.7226, 
noisyNet noise sample is [array([0.12503733], dtype=float32), -0.38845417]. 
=============================================
[2019-03-26 15:44:45,229] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[75.02756]
 [74.99693]
 [74.95207]
 [74.92272]
 [74.90688]], R is [[75.03807831]
 [75.00981903]
 [74.9813385 ]
 [74.95243835]
 [74.92250824]].
[2019-03-26 15:44:47,956] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.3553162e-09 9.9999964e-01 7.2432804e-10 3.7119264e-07 1.2354001e-15], sum to 1.0000
[2019-03-26 15:44:47,966] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4689
[2019-03-26 15:44:47,977] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2099433.995732804 W.
[2019-03-26 15:44:47,981] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.0, 75.0, 1.0, 2.0, 0.5004898068405476, 1.0, 2.0, 0.5004898068405476, 1.0, 1.0, 0.8691852799736989, 6.9112, 6.9112, 170.5573041426782, 2099433.995732804, 2099433.995732804, 415484.7462396302], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4700400.0000, 
sim time next is 4701000.0000, 
raw observation next is [30.0, 75.0, 1.0, 2.0, 0.7339829562485886, 1.0, 2.0, 0.7339829562485886, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2052542.738032037, 2052542.738032037, 389015.0622835226], 
processed observation next is [1.0, 0.391304347826087, 0.6208530805687204, 0.75, 1.0, 1.0, 0.6794975376489019, 1.0, 1.0, 0.6794975376489019, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5701507605644547, 0.5701507605644547, 0.5806194959455562], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.34718546], dtype=float32), 0.021793308]. 
=============================================
[2019-03-26 15:44:47,993] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[33.756577]
 [37.6878  ]
 [39.688805]
 [44.491947]
 [47.401485]], R is [[32.1581192 ]
 [31.83653831]
 [31.51817322]
 [31.20299149]
 [30.8909626 ]].
[2019-03-26 15:44:49,890] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.4790206e-15 1.0000000e+00 3.0257804e-17 9.0504842e-18 6.2082742e-28], sum to 1.0000
[2019-03-26 15:44:49,902] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8106
[2019-03-26 15:44:49,907] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 79.0, 1.0, 2.0, 0.5224396684751482, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 730039.0410538552, 730039.0410538552, 187186.3100326881], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4566000.0000, 
sim time next is 4566600.0000, 
raw observation next is [28.0, 79.0, 1.0, 2.0, 0.5222476749156969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 729770.6637668267, 729770.6637668267, 187154.9695321051], 
processed observation next is [0.0, 0.8695652173913043, 0.5260663507109005, 0.79, 1.0, 1.0, 0.42439478905505645, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20271407326856297, 0.20271407326856297, 0.2793357754210524], 
reward next is 0.7207, 
noisyNet noise sample is [array([2.8483043], dtype=float32), 0.7563022]. 
=============================================
[2019-03-26 15:44:50,834] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.3860763e-13 1.0000000e+00 2.2595012e-14 9.5763588e-13 2.0306708e-23], sum to 1.0000
[2019-03-26 15:44:50,843] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7041
[2019-03-26 15:44:50,849] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 84.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.917175427952253, 6.9112, 168.9126476262729, 1457996.99829592, 1453757.831800237, 311356.4025560705], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4608000.0000, 
sim time next is 4608600.0000, 
raw observation next is [30.33333333333333, 82.5, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.876816102995563, 6.9112, 168.9075742834826, 2139243.665847994, 1454224.196534584, 311356.9084489496], 
processed observation next is [1.0, 0.34782608695652173, 0.6366508688783569, 0.825, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0965616102995563, 0.0, 0.8294135159539919, 0.5942343516244427, 0.4039511657040511, 0.46471180365514864], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.0900911], dtype=float32), -0.34001267]. 
=============================================
[2019-03-26 15:44:57,668] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.6091806e-13 1.0000000e+00 5.5497890e-16 2.3889762e-15 2.0731454e-26], sum to 1.0000
[2019-03-26 15:44:57,683] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9385
[2019-03-26 15:44:57,687] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 79.0, 1.0, 2.0, 0.6103805988004168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 852973.982958973, 852973.982958973, 202689.1448886647], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4951800.0000, 
sim time next is 4952400.0000, 
raw observation next is [28.33333333333334, 77.33333333333333, 1.0, 2.0, 0.6295088546874651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 879715.759654855, 879715.759654855, 206364.6282519365], 
processed observation next is [1.0, 0.30434782608695654, 0.5418641390205374, 0.7733333333333333, 1.0, 1.0, 0.553625126129476, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.24436548879301528, 0.24436548879301528, 0.30800690783871115], 
reward next is 0.6920, 
noisyNet noise sample is [array([1.1876556], dtype=float32), 1.0597522]. 
=============================================
[2019-03-26 15:44:58,386] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.339236e-11 1.000000e+00 6.740297e-11 2.611549e-08 4.438842e-17], sum to 1.0000
[2019-03-26 15:44:58,394] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3565
[2019-03-26 15:44:58,401] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2143611.435325603 W.
[2019-03-26 15:44:58,406] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.83333333333333, 70.66666666666667, 1.0, 2.0, 0.511010860309056, 1.0, 1.0, 0.511010860309056, 1.0, 2.0, 0.8803202817811124, 6.911199999999999, 6.9112, 170.5573041426782, 2143611.435325603, 2143611.435325603, 421520.5299161806], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4873800.0000, 
sim time next is 4874400.0000, 
raw observation next is [30.0, 70.0, 1.0, 2.0, 0.4864038041682957, 1.0, 2.0, 0.4864038041682957, 1.0, 2.0, 0.8391767498413027, 6.9112, 6.9112, 170.5573041426782, 2040290.343955241, 2040290.343955241, 404899.4354742479], 
processed observation next is [1.0, 0.43478260869565216, 0.6208530805687204, 0.7, 1.0, 1.0, 0.3812094026124045, 1.0, 1.0, 0.3812094026124045, 1.0, 1.0, 0.8038740851723204, 0.0, 0.0, 0.8375144448122397, 0.5667473177653447, 0.5667473177653447, 0.6043275156332059], 
reward next is 0.3957, 
noisyNet noise sample is [array([1.3512218], dtype=float32), 0.03428471]. 
=============================================
[2019-03-26 15:45:06,285] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.9641373e-14 1.0000000e+00 1.8333263e-16 1.6414535e-16 4.4842440e-27], sum to 1.0000
[2019-03-26 15:45:06,292] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9126
[2019-03-26 15:45:06,300] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.5091015903215216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 711394.6329976249, 711394.6329976243, 185034.4587508654], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5005800.0000, 
sim time next is 5006400.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.5104633257084197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 713298.0968898302, 713298.0968898295, 185251.679123224], 
processed observation next is [1.0, 0.9565217391304348, 0.4786729857819906, 0.84, 1.0, 1.0, 0.4101967779619514, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19813836024717504, 0.19813836024717485, 0.2764950434674985], 
reward next is 0.7235, 
noisyNet noise sample is [array([0.58830184], dtype=float32), -0.9972663]. 
=============================================
[2019-03-26 15:45:10,996] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.17851523e-08 9.99466479e-01 5.35684599e-08 5.33441314e-04
 1.06916795e-13], sum to 1.0000
[2019-03-26 15:45:11,003] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1193
[2019-03-26 15:45:11,014] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2262899.460506316 W.
[2019-03-26 15:45:11,020] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.7, 63.5, 1.0, 2.0, 0.9770640839490666, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.977740120153923, 6.9112, 168.9125052541869, 2262899.460506316, 2215693.735246839, 457318.0035821863], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4977000.0000, 
sim time next is 4977600.0000, 
raw observation next is [30.73333333333333, 63.33333333333334, 1.0, 2.0, 0.7818126766100302, 1.0, 1.0, 0.7818126766100302, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2186432.408168004, 2186432.408168004, 411107.485210269], 
processed observation next is [1.0, 0.6086956521739131, 0.6556082148499209, 0.6333333333333334, 1.0, 1.0, 0.7371237067590725, 1.0, 0.5, 0.7371237067590725, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6073423356022233, 0.6073423356022233, 0.6135932615078642], 
reward next is 0.3864, 
noisyNet noise sample is [array([-0.6031367], dtype=float32), -0.06750686]. 
=============================================
[2019-03-26 15:45:19,792] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.96321720e-08 1.02870455e-02 7.11853261e-07 9.89712119e-01
 1.94198158e-10], sum to 1.0000
[2019-03-26 15:45:19,804] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8024
[2019-03-26 15:45:19,811] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [35.91666666666666, 53.83333333333333, 1.0, 2.0, 0.8834571044284425, 1.0, 2.0, 0.7623185917284836, 1.0, 1.0, 1.03, 7.005112202039055, 6.9112, 170.5573041426782, 3199172.909867813, 3131899.779443101, 585538.6228071874], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5331000.0000, 
sim time next is 5331600.0000, 
raw observation next is [35.9, 54.0, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 7.579656572738628, 6.9112, 170.5573041426782, 3388730.154305009, 2909887.52017744, 549962.3328779438], 
processed observation next is [1.0, 0.7391304347826086, 0.9004739336492891, 0.54, 1.0, 1.0, 1.0481927710843375, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.2195121951219512, 0.0668456572738628, 0.0, 0.8375144448122397, 0.9413139317513914, 0.8083020889381777, 0.8208393028029012], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.60929066], dtype=float32), 1.8434658]. 
=============================================
[2019-03-26 15:45:24,178] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.5747074e-15 1.0000000e+00 7.4486780e-17 1.4800458e-18 1.4241536e-28], sum to 1.0000
[2019-03-26 15:45:24,181] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8406
[2019-03-26 15:45:24,184] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 63.0, 1.0, 2.0, 0.5508516237762893, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 769755.305596947, 769755.3055969476, 191947.3824051682], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5151600.0000, 
sim time next is 5152200.0000, 
raw observation next is [32.0, 63.0, 1.0, 2.0, 0.5736702554996205, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 801653.8974371125, 801653.8974371132, 195941.9700258927], 
processed observation next is [0.0, 0.6521739130434783, 0.7156398104265403, 0.63, 1.0, 1.0, 0.48634970542122946, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2226816381769757, 0.2226816381769759, 0.29245070153118313], 
reward next is 0.7075, 
noisyNet noise sample is [array([0.74785674], dtype=float32), 1.0151014]. 
=============================================
[2019-03-26 15:45:24,409] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-26 15:45:24,410] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 15:45:24,411] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 15:45:24,412] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:45:24,413] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 15:45:24,413] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 15:45:24,412] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 15:45:24,414] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:45:24,416] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:45:24,417] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:45:24,417] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:45:24,433] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run32
[2019-03-26 15:45:24,451] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run32
[2019-03-26 15:45:24,470] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run32
[2019-03-26 15:45:24,493] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run32
[2019-03-26 15:45:24,509] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run32
[2019-03-26 15:45:27,267] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10166019], dtype=float32), 0.06871469]
[2019-03-26 15:45:27,270] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [26.33333333333334, 41.33333333333334, 1.0, 2.0, 0.2879311767215511, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 477258.5563024807, 477258.5563024813, 164730.5228216081]
[2019-03-26 15:45:27,272] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:45:27,276] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [7.2319212e-14 1.0000000e+00 4.1385312e-16 3.5173655e-17 2.8524037e-27], sampled 0.2723321736488822
[2019-03-26 15:45:39,345] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10166019], dtype=float32), 0.06871469]
[2019-03-26 15:45:39,347] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [21.9, 93.0, 1.0, 2.0, 0.3282851924684677, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 508893.8120397911, 508893.8120397917, 167434.2684789953]
[2019-03-26 15:45:39,348] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:45:39,350] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [4.8849325e-14 1.0000000e+00 2.3785540e-16 1.2040408e-17 1.1480786e-27], sampled 0.6319137392081516
[2019-03-26 15:45:43,277] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10166019], dtype=float32), 0.06871469]
[2019-03-26 15:45:43,278] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.13697577, 80.03211142, 1.0, 2.0, 0.4381293724447656, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 627364.8952994545, 627364.8952994545, 176427.4073887476]
[2019-03-26 15:45:43,279] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 15:45:43,281] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.3739752e-14 1.0000000e+00 2.0840825e-16 2.3034560e-17 1.0674849e-27], sampled 0.6518159365470069
[2019-03-26 15:45:46,610] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10166019], dtype=float32), 0.06871469]
[2019-03-26 15:45:46,611] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [21.6, 79.33333333333334, 1.0, 2.0, 0.2807362103057556, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 455299.2992311864, 455299.2992311858, 163935.3402085471]
[2019-03-26 15:45:46,613] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 15:45:46,616] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.7713520e-14 1.0000000e+00 1.2664684e-16 8.7010434e-18 3.8593811e-28], sampled 0.7072321700610615
[2019-03-26 15:45:52,238] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10166019], dtype=float32), 0.06871469]
[2019-03-26 15:45:52,240] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [23.2935136, 83.22477437500001, 1.0, 2.0, 0.3586476218447434, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 558784.4555176859, 558784.4555176864, 171536.0503194871]
[2019-03-26 15:45:52,242] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 15:45:52,244] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.7376252e-14 1.0000000e+00 9.0271114e-17 9.5685565e-18 2.7024242e-28], sampled 0.5521365328445584
[2019-03-26 15:46:01,603] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10166019], dtype=float32), 0.06871469]
[2019-03-26 15:46:01,605] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [24.80705778166666, 90.19787155833333, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.051993786941397, 6.9112, 168.9124043514612, 1590593.484055426, 1490709.852361347, 317231.5085956364]
[2019-03-26 15:46:01,606] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 15:46:01,608] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.9678347e-14 1.0000000e+00 1.0315028e-16 2.1727886e-17 6.8387216e-28], sampled 0.002880923334724894
[2019-03-26 15:46:03,282] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10166019], dtype=float32), 0.06871469]
[2019-03-26 15:46:03,283] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.83549426666667, 90.44249731333333, 1.0, 2.0, 0.5134472456309, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 717469.0981902209, 717469.0981902202, 185729.0280810297]
[2019-03-26 15:46:03,283] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 15:46:03,287] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.0701241e-14 1.0000000e+00 1.4428971e-16 8.8028701e-18 4.8993982e-28], sampled 0.6157892971754557
[2019-03-26 15:46:05,031] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10166019], dtype=float32), 0.06871469]
[2019-03-26 15:46:05,032] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [18.74298609333333, 99.51770178000001, 1.0, 2.0, 0.2824795874598083, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 459903.1140531911, 459903.1140531917, 164206.3741460723]
[2019-03-26 15:46:05,032] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 15:46:05,034] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [6.8090391e-15 1.0000000e+00 2.4728884e-17 1.5904034e-18 2.5501154e-29], sampled 0.2192386833554848
[2019-03-26 15:46:47,327] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10166019], dtype=float32), 0.06871469]
[2019-03-26 15:46:47,328] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [34.43249249500001, 49.98437270166667, 1.0, 2.0, 0.5552340773073485, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 775881.5449879188, 775881.5449879181, 192701.4161057218]
[2019-03-26 15:46:47,329] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 15:46:47,332] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.3048163e-14 1.0000000e+00 6.9278507e-17 1.0211703e-17 1.4039902e-28], sampled 0.35697273396591434
[2019-03-26 15:47:17,342] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.1610 2927253227.7716 1338.0000
[2019-03-26 15:47:17,459] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7882.9807 3164206497.0946 1776.0000
[2019-03-26 15:47:17,538] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.0492 2779288638.4074 933.0000
[2019-03-26 15:47:17,588] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7995.9991 3007679856.8479 1766.0000
[2019-03-26 15:47:17,730] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.8347 2842452013.2942 1131.0000
[2019-03-26 15:47:18,745] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 775000, evaluation results [775000.0, 7882.980689958252, 3164206497.094631, 1776.0, 8255.161016606155, 2927253227.7715816, 1338.0, 8659.04921332747, 2779288638.407387, 933.0, 7995.999142500722, 3007679856.847881, 1766.0, 8496.834662578853, 2842452013.2941966, 1131.0]
[2019-03-26 15:47:29,508] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.5298306e-10 9.9994528e-01 1.1050741e-09 5.4716445e-05 1.9355120e-16], sum to 1.0000
[2019-03-26 15:47:29,515] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1455
[2019-03-26 15:47:29,519] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [34.65, 59.83333333333334, 1.0, 2.0, 0.5850136715225632, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 817511.4272214127, 817511.4272214132, 197989.9596358969], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5334600.0000, 
sim time next is 5335200.0000, 
raw observation next is [34.4, 61.0, 1.0, 2.0, 0.5935858059098574, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 829495.0005678909, 829495.0005678909, 199559.2392523383], 
processed observation next is [1.0, 0.782608695652174, 0.8293838862559241, 0.61, 1.0, 1.0, 0.5103443444697078, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23041527793552527, 0.23041527793552527, 0.29784961082438555], 
reward next is 0.7022, 
noisyNet noise sample is [array([0.6842252], dtype=float32), -1.2794359]. 
=============================================
[2019-03-26 15:47:29,557] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.1810670e-12 1.0000000e+00 3.0340524e-12 2.2317266e-09 1.9845698e-22], sum to 1.0000
[2019-03-26 15:47:29,566] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6669
[2019-03-26 15:47:29,572] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.46666666666667, 66.33333333333334, 1.0, 2.0, 0.612995612768629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 856629.7976872203, 856629.7976872203, 203193.3872224538], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5337600.0000, 
sim time next is 5338200.0000, 
raw observation next is [33.23333333333333, 67.66666666666666, 1.0, 2.0, 0.6155263378929764, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 860167.7877810613, 860167.7877810613, 203675.4658723222], 
processed observation next is [1.0, 0.782608695652174, 0.7740916271721956, 0.6766666666666665, 1.0, 1.0, 0.5367787203529836, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23893549660585034, 0.23893549660585034, 0.303993232645257], 
reward next is 0.6960, 
noisyNet noise sample is [array([-3.1309202], dtype=float32), 0.020294389]. 
=============================================
[2019-03-26 15:47:30,117] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.2216893e-14 1.0000000e+00 2.5417511e-16 5.3366099e-16 2.5838902e-28], sum to 1.0000
[2019-03-26 15:47:30,124] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9920
[2019-03-26 15:47:30,129] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.6, 80.33333333333334, 1.0, 2.0, 0.6182201795144697, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 863933.8300315007, 863933.8300315007, 204189.7184561313], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5348400.0000, 
sim time next is 5349000.0000, 
raw observation next is [30.5, 80.66666666666666, 1.0, 2.0, 0.6160710798660874, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 860929.3464296048, 860929.3464296055, 203778.4519992665], 
processed observation next is [1.0, 0.9130434782608695, 0.6445497630331753, 0.8066666666666665, 1.0, 1.0, 0.5374350359832378, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.23914704067489023, 0.23914704067489043, 0.3041469432824873], 
reward next is 0.6959, 
noisyNet noise sample is [array([0.2779693], dtype=float32), -0.76479]. 
=============================================
[2019-03-26 15:47:30,153] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[70.85518 ]
 [71.348   ]
 [71.7951  ]
 [72.21527 ]
 [72.425674]], R is [[70.72251892]
 [70.71053314]
 [70.69823456]
 [70.68548584]
 [70.67185211]].
[2019-03-26 15:47:34,934] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.8790870e-13 1.0000000e+00 3.0353575e-14 1.3119581e-11 1.8028454e-24], sum to 1.0000
[2019-03-26 15:47:34,941] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5092
[2019-03-26 15:47:34,947] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.81666666666667, 78.33333333333334, 1.0, 2.0, 0.5978075617003856, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 835396.9316206716, 835396.9316206716, 200339.4408282595], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5424600.0000, 
sim time next is 5425200.0000, 
raw observation next is [30.8, 79.0, 1.0, 2.0, 0.6051514834527427, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 845663.6670492422, 845663.6670492428, 201710.5977822977], 
processed observation next is [1.0, 0.8260869565217391, 0.6587677725118484, 0.79, 1.0, 1.0, 0.524278895726196, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.23490657418034505, 0.23490657418034522, 0.30106059370492194], 
reward next is 0.6989, 
noisyNet noise sample is [array([0.49019825], dtype=float32), -0.61197674]. 
=============================================
[2019-03-26 15:47:39,297] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.3824046e-14 1.0000000e+00 9.9088646e-16 3.4407685e-15 1.8352133e-26], sum to 1.0000
[2019-03-26 15:47:39,304] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4724
[2019-03-26 15:47:39,310] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.25, 84.0, 1.0, 2.0, 0.9526288836298518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1331547.379096038, 1331547.379096038, 284826.1462349914], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5556600.0000, 
sim time next is 5557200.0000, 
raw observation next is [28.43333333333333, 83.33333333333334, 1.0, 2.0, 0.8754328606615432, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1223583.621110263, 1223583.621110263, 263270.877240783], 
processed observation next is [1.0, 0.30434782608695654, 0.546603475513428, 0.8333333333333335, 1.0, 1.0, 0.849919109230775, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.33988433919729527, 0.33988433919729527, 0.3929416078220642], 
reward next is 0.6071, 
noisyNet noise sample is [array([1.997397], dtype=float32), -1.1497797]. 
=============================================
[2019-03-26 15:47:40,551] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.9492567e-10 1.0000000e+00 3.6849274e-11 1.6522845e-08 1.5775522e-17], sum to 1.0000
[2019-03-26 15:47:40,559] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3487
[2019-03-26 15:47:40,566] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2335723.129786717 W.
[2019-03-26 15:47:40,572] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.43333333333334, 72.66666666666667, 1.0, 2.0, 0.5567626332435127, 1.0, 2.0, 0.5567626332435127, 1.0, 1.0, 0.966912569727585, 6.9112, 6.9112, 170.5573041426782, 2335723.129786717, 2335723.129786717, 456617.6751291633], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5563200.0000, 
sim time next is 5563800.0000, 
raw observation next is [30.65, 71.5, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 7.559488032658834, 6.9112, 168.9095093399321, 2744683.319675039, 2284774.862944154, 474681.3887490145], 
processed observation next is [1.0, 0.391304347826087, 0.6516587677725119, 0.715, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.06482880326588339, 0.0, 0.8294230179670316, 0.7624120332430664, 0.6346596841511539, 0.7084796847000217], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.14189889], dtype=float32), -2.488372]. 
=============================================
[2019-03-26 15:47:52,525] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.8639402e-14 1.0000000e+00 1.9785049e-17 1.8879880e-18 1.2083407e-28], sum to 1.0000
[2019-03-26 15:47:52,534] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2608
[2019-03-26 15:47:52,540] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.3, 77.5, 1.0, 2.0, 0.5220835440044166, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 729541.2342042342, 729541.2342042349, 187128.3554926587], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5729400.0000, 
sim time next is 5730000.0000, 
raw observation next is [28.46666666666667, 76.66666666666667, 1.0, 2.0, 0.5231095193629334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 730975.3894732237, 730975.3894732231, 187295.9904514712], 
processed observation next is [0.0, 0.30434782608695654, 0.5481832543443919, 0.7666666666666667, 1.0, 1.0, 0.42543315585895586, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20304871929811769, 0.20304871929811755, 0.27954625440518094], 
reward next is 0.7205, 
noisyNet noise sample is [array([-1.9414173], dtype=float32), -0.49042767]. 
=============================================
[2019-03-26 15:47:52,557] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[73.22816]
 [73.23258]
 [73.24053]
 [73.22732]
 [73.22442]], R is [[73.21100616]
 [73.19960022]
 [73.18852997]
 [73.17778015]
 [73.1675415 ]].
[2019-03-26 15:47:52,752] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.70494466e-14 1.00000000e+00 9.03755170e-17 1.18142385e-17
 2.85736841e-28], sum to 1.0000
[2019-03-26 15:47:52,762] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1607
[2019-03-26 15:47:52,769] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.8, 91.0, 1.0, 2.0, 0.5106868069915107, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 713610.4843042409, 713610.4843042409, 185286.9209277059], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5718600.0000, 
sim time next is 5719200.0000, 
raw observation next is [25.76666666666667, 91.33333333333333, 1.0, 2.0, 0.5113428308367751, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 714527.4904560291, 714527.4904560298, 185391.8352907108], 
processed observation next is [0.0, 0.17391304347826086, 0.42022116903633505, 0.9133333333333333, 1.0, 1.0, 0.41125642269490975, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19847985846000807, 0.19847985846000826, 0.2767042317771803], 
reward next is 0.7233, 
noisyNet noise sample is [array([-1.2603539], dtype=float32), 0.1965702]. 
=============================================
[2019-03-26 15:47:53,378] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.6210624e-14 1.0000000e+00 7.7675060e-16 3.2280608e-17 4.5530190e-27], sum to 1.0000
[2019-03-26 15:47:53,386] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7226
[2019-03-26 15:47:53,395] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.85, 63.33333333333334, 1.0, 2.0, 0.520535416863393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 727377.194963408, 727377.1949634086, 186876.1747561599], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5739000.0000, 
sim time next is 5739600.0000, 
raw observation next is [31.0, 62.66666666666667, 1.0, 2.0, 0.5203874188900699, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 727170.3172103333, 727170.3172103326, 186852.1414968371], 
processed observation next is [0.0, 0.43478260869565216, 0.6682464454976303, 0.6266666666666667, 1.0, 1.0, 0.42215351673502394, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20199175478064815, 0.20199175478064796, 0.27888379327886137], 
reward next is 0.7211, 
noisyNet noise sample is [array([-1.0357236], dtype=float32), 0.4468564]. 
=============================================
[2019-03-26 15:47:56,362] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.2167883e-11 1.0000000e+00 7.0400005e-12 1.0403306e-09 1.6136256e-18], sum to 1.0000
[2019-03-26 15:47:56,372] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5039
[2019-03-26 15:47:56,379] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2535077.998673124 W.
[2019-03-26 15:47:56,385] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.25, 73.33333333333334, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 7.263088030185841, 6.9112, 168.9108821097352, 2535077.998673124, 2285439.584826425, 475397.8270846048], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5821800.0000, 
sim time next is 5822400.0000, 
raw observation next is [30.4, 72.66666666666667, 1.0, 2.0, 0.8396225423718646, 1.0, 1.0, 0.8396225423718646, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2348260.585752717, 2348260.585752717, 439623.0910102919], 
processed observation next is [1.0, 0.391304347826087, 0.6398104265402843, 0.7266666666666667, 1.0, 1.0, 0.8067741474359814, 1.0, 0.5, 0.8067741474359814, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6522946071535326, 0.6522946071535326, 0.6561538671795402], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.9726398], dtype=float32), -0.9339517]. 
=============================================
[2019-03-26 15:47:56,995] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.7076713e-12 1.0000000e+00 3.7114243e-13 4.0914403e-12 2.6990136e-21], sum to 1.0000
[2019-03-26 15:47:57,005] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4764
[2019-03-26 15:47:57,010] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.4, 91.66666666666667, 1.0, 2.0, 0.5554703578507313, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9452052099160082, 6.911200000000001, 6.9112, 168.9126837326494, 1552991.331213782, 1552991.331213781, 335848.4813815902], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5800800.0000, 
sim time next is 5801400.0000, 
raw observation next is [26.35, 92.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.117984384692422, 6.9112, 168.9116232741892, 1600554.197209832, 1453855.395647997, 311349.839479024], 
processed observation next is [1.0, 0.13043478260869565, 0.4478672985781992, 0.92, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 0.020678438469242177, 0.0, 0.8294333983519973, 0.4445983881138422, 0.4038487210133325, 0.4647012529537672], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.96010077], dtype=float32), -0.33106261]. 
=============================================
[2019-03-26 15:47:57,297] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.9453180e-12 1.0000000e+00 2.9773354e-14 1.7960973e-13 1.8560700e-23], sum to 1.0000
[2019-03-26 15:47:57,306] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3530
[2019-03-26 15:47:57,311] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.05, 93.5, 1.0, 2.0, 0.8699541005463699, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1215921.628945431, 1215921.628945431, 261805.6355599411], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5805000.0000, 
sim time next is 5805600.0000, 
raw observation next is [26.0, 93.66666666666667, 1.0, 2.0, 0.8595539333973279, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1201377.249518551, 1201377.24951855, 259053.2830891143], 
processed observation next is [1.0, 0.17391304347826086, 0.4312796208530806, 0.9366666666666668, 1.0, 1.0, 0.8307878715630457, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.33371590264404194, 0.33371590264404166, 0.38664669117778255], 
reward next is 0.6134, 
noisyNet noise sample is [array([0.11413293], dtype=float32), -0.7253225]. 
=============================================
[2019-03-26 15:48:09,145] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.5412882e-14 1.0000000e+00 1.2567613e-16 1.0163368e-15 1.8519228e-26], sum to 1.0000
[2019-03-26 15:48:09,153] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9933
[2019-03-26 15:48:09,159] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.15, 93.0, 1.0, 2.0, 0.6885700099204555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 962288.9705507327, 962288.9705507327, 218396.8103466938], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6060600.0000, 
sim time next is 6061200.0000, 
raw observation next is [26.13333333333333, 93.0, 1.0, 2.0, 0.6632363931908579, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 926869.336305587, 926869.3363055864, 213109.3370941949], 
processed observation next is [1.0, 0.13043478260869565, 0.43759873617693507, 0.93, 1.0, 1.0, 0.5942607146877806, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2574637045293297, 0.25746370452932954, 0.31807363745402223], 
reward next is 0.6819, 
noisyNet noise sample is [array([-0.04903263], dtype=float32), 0.79774976]. 
=============================================
[2019-03-26 15:48:14,015] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-26 15:48:14,017] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 15:48:14,017] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 15:48:14,019] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 15:48:14,018] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 15:48:14,021] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:48:14,020] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:48:14,019] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 15:48:14,021] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:48:14,023] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:48:14,025] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:48:14,045] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run33
[2019-03-26 15:48:14,046] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run33
[2019-03-26 15:48:14,063] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run33
[2019-03-26 15:48:14,082] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run33
[2019-03-26 15:48:14,123] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run33
[2019-03-26 15:48:46,496] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10043664], dtype=float32), 0.06714349]
[2019-03-26 15:48:46,497] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.6, 80.66666666666667, 1.0, 2.0, 0.6356834143183034, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 888348.0910900394, 888348.0910900394, 207571.4164844721]
[2019-03-26 15:48:46,497] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 15:48:46,502] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.7363762e-14 1.0000000e+00 5.4799630e-17 2.4718509e-17 9.1530013e-28], sampled 0.6254071287764759
[2019-03-26 15:49:15,230] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10043664], dtype=float32), 0.06714349]
[2019-03-26 15:49:15,232] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [31.8, 65.33333333333334, 1.0, 2.0, 0.8791050070829828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1228719.11273306, 1228719.112733061, 264256.876608537]
[2019-03-26 15:49:15,233] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 15:49:15,236] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.5908163e-14 1.0000000e+00 1.0678819e-16 2.4108458e-16 1.8939089e-27], sampled 0.11476521409037155
[2019-03-26 15:49:29,582] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10043664], dtype=float32), 0.06714349]
[2019-03-26 15:49:29,584] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [33.68333333333334, 61.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.708670124198843, 6.9112, 168.9089176603737, 2019881.682176302, 1454142.456887679, 311355.2969256254]
[2019-03-26 15:49:29,585] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:49:29,588] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.1052889e-12 1.0000000e+00 2.5533813e-14 9.9498827e-13 2.6167594e-23], sampled 0.5511328264044804
[2019-03-26 15:49:29,590] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2019881.682176302 W.
[2019-03-26 15:49:44,530] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10043664], dtype=float32), 0.06714349]
[2019-03-26 15:49:44,531] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.16666666666667, 89.83333333333333, 1.0, 2.0, 1.011782469448229, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1414285.022797933, 1414285.022797934, 302537.279576191]
[2019-03-26 15:49:44,532] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:49:44,535] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.5911569e-13 1.0000000e+00 2.5264208e-15 2.2583164e-14 2.2906445e-25], sampled 0.9362810883982792
[2019-03-26 15:49:49,690] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10043664], dtype=float32), 0.06714349]
[2019-03-26 15:49:49,692] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [34.78333333333333, 53.33333333333334, 1.0, 2.0, 0.5741291675810318, 0.0, 2.0, 0.0, 1.0, 1.0, 0.997072496671189, 6.911200000000001, 6.9112, 168.912619063904, 1605197.324579128, 1605197.324579127, 351296.9246659944]
[2019-03-26 15:49:49,694] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:49:49,697] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.2984267e-13 1.0000000e+00 3.2496982e-15 4.1177487e-14 1.3842947e-24], sampled 0.8883580249477545
[2019-03-26 15:49:53,016] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10043664], dtype=float32), 0.06714349]
[2019-03-26 15:49:53,019] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [30.46666666666667, 75.33333333333333, 1.0, 2.0, 0.590377995081501, 0.0, 2.0, 0.0, 1.0, 2.0, 1.025291336470137, 6.9112, 6.9112, 168.9128790703235, 1650662.452388208, 1650662.452388208, 361560.5332793769]
[2019-03-26 15:49:53,020] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 15:49:53,023] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.9918972e-10 1.0000000e+00 1.8016472e-11 6.2429009e-09 5.2075358e-18], sampled 0.8968510316007827
[2019-03-26 15:50:05,931] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7996.7979 3007697032.7242 1766.0000
[2019-03-26 15:50:06,188] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.0653 2927317329.7462 1338.0000
[2019-03-26 15:50:06,524] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.0345 2842634093.1756 1131.0000
[2019-03-26 15:50:06,635] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.9767 2779197554.3421 933.0000
[2019-03-26 15:50:06,675] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7885.0782 3164218686.7478 1776.0000
[2019-03-26 15:50:07,690] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 800000, evaluation results [800000.0, 7885.07824819414, 3164218686.747781, 1776.0, 8255.065342017213, 2927317329.746172, 1338.0, 8659.97666076793, 2779197554.342144, 933.0, 7996.797856796699, 3007697032.7241526, 1766.0, 8496.034480253436, 2842634093.17563, 1131.0]
[2019-03-26 15:50:08,199] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0623014e-08 9.9940288e-01 8.0575209e-09 5.9715234e-04 4.4418861e-15], sum to 1.0000
[2019-03-26 15:50:08,209] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5063
[2019-03-26 15:50:08,220] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2261185.677825712 W.
[2019-03-26 15:50:08,226] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.1, 65.0, 1.0, 2.0, 0.9758396418909645, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.989031197160295, 6.9112, 168.9124291210761, 2261185.677825712, 2205969.720215975, 456590.5716102494], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6097200.0000, 
sim time next is 6097800.0000, 
raw observation next is [31.1, 65.0, 1.0, 2.0, 0.8455397211658593, 1.0, 1.0, 0.8455397211658593, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2364825.440067209, 2364825.44006721, 442646.9117097447], 
processed observation next is [1.0, 0.5652173913043478, 0.6729857819905214, 0.65, 1.0, 1.0, 0.8139032785130835, 1.0, 0.5, 0.8139032785130835, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6568959555742246, 0.656895955574225, 0.660667032402604], 
reward next is 0.3393, 
noisyNet noise sample is [array([-1.3395413], dtype=float32), 2.287064]. 
=============================================
[2019-03-26 15:50:11,932] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.5924921e-14 1.0000000e+00 1.8470710e-16 5.8321474e-16 3.8803624e-26], sum to 1.0000
[2019-03-26 15:50:11,942] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9972
[2019-03-26 15:50:11,947] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.96666666666667, 86.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 10.80234669686688, 6.9112, 168.8853601891817, 4215511.649550125, 1455449.261463032, 303345.9558527796], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6164400.0000, 
sim time next is 6165000.0000, 
raw observation next is [28.05, 85.5, 1.0, 2.0, 0.7086805885022064, 1.0, 1.0, 0.6749303337653659, 1.0, 1.0, 1.03, 7.005098416622283, 6.9112, 170.5573041426782, 2832020.510185041, 2764757.254815118, 524083.7984907231], 
processed observation next is [1.0, 0.34782608695652173, 0.528436018957346, 0.855, 1.0, 1.0, 0.6490127572315739, 1.0, 0.5, 0.6083497997173083, 1.0, 0.5, 1.0365853658536586, 0.009389841662228272, 0.0, 0.8375144448122397, 0.7866723639402892, 0.7679881263375328, 0.7822146246130195], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9374723], dtype=float32), -0.59490955]. 
=============================================
[2019-03-26 15:50:11,963] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[63.965664]
 [65.246956]
 [65.60516 ]
 [65.53255 ]
 [65.77128 ]], R is [[55.89951706]
 [55.34052277]
 [54.787117  ]
 [54.88203812]
 [54.91202927]].
[2019-03-26 15:50:25,054] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.1378814e-16 1.0000000e+00 1.7554671e-18 1.0726535e-18 2.6683914e-30], sum to 1.0000
[2019-03-26 15:50:25,063] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0585
[2019-03-26 15:50:25,068] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.15, 82.5, 1.0, 2.0, 0.512316550059083, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 715888.5804238338, 715888.5804238344, 185548.0190812189], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6391800.0000, 
sim time next is 6392400.0000, 
raw observation next is [27.13333333333333, 82.66666666666666, 1.0, 2.0, 0.5122698657261385, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 715823.3238133806, 715823.3238133806, 185540.5564482097], 
processed observation next is [0.0, 1.0, 0.484992101105845, 0.8266666666666665, 1.0, 1.0, 0.41237333220016686, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1988398121703835, 0.1988398121703835, 0.27692620365404436], 
reward next is 0.7231, 
noisyNet noise sample is [array([-1.0834045], dtype=float32), 2.4541621]. 
=============================================
[2019-03-26 15:50:25,429] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.4625415e-14 1.0000000e+00 4.8770304e-17 5.2305906e-18 3.8339076e-28], sum to 1.0000
[2019-03-26 15:50:25,436] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5255
[2019-03-26 15:50:25,441] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.81666666666666, 45.16666666666667, 1.0, 2.0, 0.3151149670062715, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 499939.8225847081, 499939.8225847087, 167050.0548113685], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6868200.0000, 
sim time next is 6868800.0000, 
raw observation next is [28.9, 44.0, 1.0, 2.0, 0.3082228783828225, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 490716.1005350184, 490716.1005350178, 166395.1013074031], 
processed observation next is [0.0, 0.5217391304347826, 0.5687203791469194, 0.44, 1.0, 1.0, 0.1665335884130391, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13631002792639402, 0.13631002792639382, 0.24835089747373595], 
reward next is 0.7516, 
noisyNet noise sample is [array([-0.5547711], dtype=float32), 0.15911624]. 
=============================================
[2019-03-26 15:50:27,313] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.2364892e-14 1.0000000e+00 1.2403535e-16 1.3339839e-15 1.7727276e-26], sum to 1.0000
[2019-03-26 15:50:27,321] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6194
[2019-03-26 15:50:27,328] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.63333333333333, 82.0, 1.0, 2.0, 0.7601599449829616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1062387.236601977, 1062387.236601977, 234365.63250699], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6420000.0000, 
sim time next is 6420600.0000, 
raw observation next is [27.7, 81.5, 1.0, 2.0, 0.7733937611344698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1080892.016997347, 1080892.016997347, 237483.7981963268], 
processed observation next is [1.0, 0.30434782608695654, 0.5118483412322274, 0.815, 1.0, 1.0, 0.7269804351017708, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.30024778249926304, 0.30024778249926304, 0.35445343014377134], 
reward next is 0.6455, 
noisyNet noise sample is [array([0.5730095], dtype=float32), 0.37948924]. 
=============================================
[2019-03-26 15:50:34,429] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.1816528e-11 1.0000000e+00 9.8987745e-13 1.6145728e-08 1.1822110e-20], sum to 1.0000
[2019-03-26 15:50:34,439] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6453
[2019-03-26 15:50:34,445] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.3, 67.0, 1.0, 2.0, 0.4775000144673006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 667222.2081572149, 667222.2081572142, 180146.5940536082], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6544800.0000, 
sim time next is 6545400.0000, 
raw observation next is [29.18333333333333, 67.5, 1.0, 2.0, 0.4822364814289826, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 673842.6860054275, 673842.6860054282, 180860.1301193106], 
processed observation next is [1.0, 0.782608695652174, 0.5821484992101105, 0.675, 1.0, 1.0, 0.3761885318421478, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18717852389039652, 0.18717852389039671, 0.26994049271538895], 
reward next is 0.7301, 
noisyNet noise sample is [array([0.44387335], dtype=float32), 0.9696091]. 
=============================================
[2019-03-26 15:50:48,094] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.9189813e-15 1.0000000e+00 4.2865307e-17 5.4052243e-16 1.7164562e-27], sum to 1.0000
[2019-03-26 15:50:48,106] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8381
[2019-03-26 15:50:48,115] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.25, 54.5, 1.0, 2.0, 0.322858277554824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 508053.5868684333, 508053.5868684333, 167581.9541114929], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6808200.0000, 
sim time next is 6808800.0000, 
raw observation next is [27.1, 55.00000000000001, 1.0, 2.0, 0.3225041806554598, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 508029.8917311263, 508029.8917311269, 167591.8918616561], 
processed observation next is [1.0, 0.8260869565217391, 0.4834123222748816, 0.55, 1.0, 1.0, 0.1837399766933251, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1411194143697573, 0.14111941436975747, 0.25013715203232256], 
reward next is 0.7499, 
noisyNet noise sample is [array([-0.07550799], dtype=float32), 0.14562385]. 
=============================================
[2019-03-26 15:50:51,363] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.6925253e-15 1.0000000e+00 6.7142939e-17 1.9732685e-15 6.0795884e-27], sum to 1.0000
[2019-03-26 15:50:51,368] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7976
[2019-03-26 15:50:51,375] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.15, 65.5, 1.0, 2.0, 0.3666095040643219, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 548563.7826171903, 548563.7826171903, 169998.3087747669], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7320600.0000, 
sim time next is 7321200.0000, 
raw observation next is [27.06666666666666, 66.0, 1.0, 2.0, 0.3735589569850205, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 558884.8204358664, 558884.8204358664, 170885.9874909668], 
processed observation next is [1.0, 0.7391304347826086, 0.4818325434439175, 0.66, 1.0, 1.0, 0.24525175540363917, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15524578345440732, 0.15524578345440732, 0.2550537126730848], 
reward next is 0.7449, 
noisyNet noise sample is [array([0.15853554], dtype=float32), -1.637161]. 
=============================================
[2019-03-26 15:50:51,560] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.6138678e-15 1.0000000e+00 4.3635776e-17 5.9274882e-18 5.7065786e-29], sum to 1.0000
[2019-03-26 15:50:51,567] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7999
[2019-03-26 15:50:51,575] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.6, 79.0, 1.0, 2.0, 0.3749525497400966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 567696.0458414528, 567696.0458414521, 171876.2560999354], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6852600.0000, 
sim time next is 6853200.0000, 
raw observation next is [24.7, 78.66666666666667, 1.0, 2.0, 0.3776137079235777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 570824.3978629658, 570824.3978629658, 172123.2898209765], 
processed observation next is [0.0, 0.30434782608695654, 0.3696682464454976, 0.7866666666666667, 1.0, 1.0, 0.2501369974982864, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15856233273971274, 0.15856233273971274, 0.25690043256862166], 
reward next is 0.7431, 
noisyNet noise sample is [array([0.6750345], dtype=float32), 0.49007118]. 
=============================================
[2019-03-26 15:50:57,135] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.8201925e-14 1.0000000e+00 5.2112916e-18 1.3570012e-18 1.2673976e-29], sum to 1.0000
[2019-03-26 15:50:57,143] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0732
[2019-03-26 15:50:57,146] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.01666666666667, 82.83333333333333, 1.0, 2.0, 0.4190303621525407, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 613990.9822505518, 613990.9822505518, 175531.1922872106], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6934200.0000, 
sim time next is 6934800.0000, 
raw observation next is [25.23333333333333, 81.66666666666667, 1.0, 2.0, 0.4206809444509638, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 615312.0034052789, 615312.0034052783, 175626.2067373386], 
processed observation next is [0.0, 0.2608695652173913, 0.39494470774091617, 0.8166666666666668, 1.0, 1.0, 0.3020252342782696, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1709200009459108, 0.17092000094591064, 0.26212866677214713], 
reward next is 0.7379, 
noisyNet noise sample is [array([1.9020944], dtype=float32), 0.21015418]. 
=============================================
[2019-03-26 15:51:00,599] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.4069866e-14 1.0000000e+00 1.7258604e-17 3.4530181e-18 2.1899097e-28], sum to 1.0000
[2019-03-26 15:51:00,614] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4289
[2019-03-26 15:51:00,619] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.13333333333334, 79.66666666666667, 1.0, 2.0, 0.4528319381208636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 646801.0828001656, 646801.0828001656, 178343.8153820888], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7001400.0000, 
sim time next is 7002000.0000, 
raw observation next is [26.1, 80.0, 1.0, 2.0, 0.4536449394158682, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 647514.3464406335, 647514.3464406335, 178405.7921409908], 
processed observation next is [1.0, 0.043478260869565216, 0.4360189573459717, 0.8, 1.0, 1.0, 0.3417408908624918, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17986509623350933, 0.17986509623350933, 0.2662773017029713], 
reward next is 0.7337, 
noisyNet noise sample is [array([0.14964803], dtype=float32), -0.8732291]. 
=============================================
[2019-03-26 15:51:00,638] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[73.96361 ]
 [74.687874]
 [75.4622  ]
 [76.270515]
 [77.292305]], R is [[73.71554565]
 [73.71221161]
 [73.70888519]
 [73.70545197]
 [73.70201111]].
[2019-03-26 15:51:02,610] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-26 15:51:02,611] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 15:51:02,612] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 15:51:02,613] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 15:51:02,614] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:51:02,616] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:51:02,617] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:51:02,616] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 15:51:02,619] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 15:51:02,619] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:51:02,620] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:51:02,648] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run34
[2019-03-26 15:51:02,649] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run34
[2019-03-26 15:51:02,685] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run34
[2019-03-26 15:51:02,687] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run34
[2019-03-26 15:51:02,738] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run34
[2019-03-26 15:51:40,256] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10438892], dtype=float32), 0.06999905]
[2019-03-26 15:51:40,257] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [31.5, 57.33333333333334, 1.0, 2.0, 0.8346763561140503, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.9129565104158, 1166587.374307126, 1166587.374307126, 252598.2604428879]
[2019-03-26 15:51:40,257] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 15:51:40,260] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [5.3076945e-14 1.0000000e+00 6.0533564e-16 3.0589756e-15 6.4423059e-26], sampled 0.8041536864394467
[2019-03-26 15:52:07,258] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10438892], dtype=float32), 0.06999905]
[2019-03-26 15:52:07,261] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [34.0, 57.0, 1.0, 2.0, 0.6092305873403321, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 851366.2598389222, 851366.2598389222, 202476.2208295905]
[2019-03-26 15:52:07,264] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:52:07,267] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.2734402e-15 1.0000000e+00 3.1922285e-18 3.2675812e-18 5.8288808e-30], sampled 0.3169009038084386
[2019-03-26 15:52:16,324] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10438892], dtype=float32), 0.06999905]
[2019-03-26 15:52:16,326] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.5, 84.0, 1.0, 2.0, 0.599199923842057, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 837343.4335335614, 837343.4335335614, 200597.0733920147]
[2019-03-26 15:52:16,327] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:52:16,329] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [4.7116822e-15 1.0000000e+00 1.1548885e-17 4.1916898e-18 5.1594772e-29], sampled 0.2587800714842785
[2019-03-26 15:52:55,085] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.4351 2779146317.7726 933.0000
[2019-03-26 15:52:55,464] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7883.6602 3164302654.9282 1776.0000
[2019-03-26 15:52:55,605] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.9559 3007647868.8583 1766.0000
[2019-03-26 15:52:55,715] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.7732 2842493075.8620 1131.0000
[2019-03-26 15:52:55,715] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.6481 2927341976.6106 1338.0000
[2019-03-26 15:52:56,732] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 825000, evaluation results [825000.0, 7883.660209816038, 3164302654.9282207, 1776.0, 8253.648086340168, 2927341976.6106434, 1338.0, 8661.435058671452, 2779146317.7726398, 933.0, 7998.955910945021, 3007647868.858331, 1766.0, 8496.773184478096, 2842493075.8619537, 1131.0]
[2019-03-26 15:53:08,175] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.2784481e-15 1.0000000e+00 1.3926735e-17 2.8295946e-17 1.0053640e-27], sum to 1.0000
[2019-03-26 15:53:08,183] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3060
[2019-03-26 15:53:08,187] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.73333333333333, 87.0, 1.0, 2.0, 0.6034012002840791, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 843216.7781832678, 843216.7781832678, 201374.9563591422], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7716000.0000, 
sim time next is 7716600.0000, 
raw observation next is [26.9, 86.5, 1.0, 2.0, 0.6148752916851967, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 859257.6147002022, 859257.6147002022, 203543.1267455017], 
processed observation next is [1.0, 0.30434782608695654, 0.4739336492890995, 0.865, 1.0, 1.0, 0.5359943273315623, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23868267075005617, 0.23868267075005617, 0.3037957115604503], 
reward next is 0.6962, 
noisyNet noise sample is [array([-0.5697868], dtype=float32), 1.2755823]. 
=============================================
[2019-03-26 15:53:10,131] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.4978600e-15 1.0000000e+00 1.0229242e-18 9.5673885e-18 3.0769418e-29], sum to 1.0000
[2019-03-26 15:53:10,138] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6671
[2019-03-26 15:53:10,142] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.43333333333333, 91.33333333333334, 1.0, 2.0, 0.3594736064731612, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 551913.1091430961, 551913.1091430968, 170755.0267024983], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7249200.0000, 
sim time next is 7249800.0000, 
raw observation next is [22.41666666666667, 91.16666666666667, 1.0, 2.0, 0.3577087760983002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 549808.5951016503, 549808.5951016503, 170595.6592206569], 
processed observation next is [1.0, 0.9130434782608695, 0.26145339652448685, 0.9116666666666667, 1.0, 1.0, 0.2261551519256629, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15272460975045843, 0.15272460975045843, 0.25462038689650285], 
reward next is 0.7454, 
noisyNet noise sample is [array([-0.80245507], dtype=float32), 0.34132943]. 
=============================================
[2019-03-26 15:53:10,554] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.4597120e-14 1.0000000e+00 2.5694066e-17 2.3443326e-16 3.4466065e-27], sum to 1.0000
[2019-03-26 15:53:10,560] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5765
[2019-03-26 15:53:10,568] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 57.0, 1.0, 2.0, 0.8869069489788981, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1355159.041262277, 1355159.041262277, 282422.3412690971], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7308000.0000, 
sim time next is 7308600.0000, 
raw observation next is [27.96666666666667, 57.5, 1.0, 2.0, 1.000270505240883, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1526743.240083183, 1526743.240083183, 318064.6699848701], 
processed observation next is [1.0, 0.6086956521739131, 0.524486571879937, 0.575, 1.0, 1.0, 1.0003259099287747, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.4240953444675508, 0.4240953444675508, 0.4747233880371196], 
reward next is 0.5253, 
noisyNet noise sample is [array([-0.67391014], dtype=float32), 0.6654127]. 
=============================================
[2019-03-26 15:53:11,832] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.9604873e-15 1.0000000e+00 4.1520652e-17 2.5354274e-16 1.3425062e-27], sum to 1.0000
[2019-03-26 15:53:11,838] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6649
[2019-03-26 15:53:11,848] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.56666666666667, 65.66666666666667, 1.0, 2.0, 0.7915253984119822, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1203102.992149177, 1203102.992149176, 254728.7923880796], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7298400.0000, 
sim time next is 7299000.0000, 
raw observation next is [26.65, 65.0, 1.0, 2.0, 0.7596995043752693, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1155855.917024349, 1155855.917024349, 246575.1284569858], 
processed observation next is [1.0, 0.4782608695652174, 0.462085308056872, 0.65, 1.0, 1.0, 0.7104813305726136, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3210710880623192, 0.3210710880623192, 0.368022579786546], 
reward next is 0.6320, 
noisyNet noise sample is [array([-0.807057], dtype=float32), -0.6821833]. 
=============================================
[2019-03-26 15:53:11,865] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[68.534195]
 [68.416725]
 [68.35197 ]
 [68.46486 ]
 [68.577965]], R is [[68.60845184]
 [68.54217529]
 [68.46026611]
 [68.33061981]
 [68.21118164]].
[2019-03-26 15:53:12,905] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.1187381e-14 1.0000000e+00 2.1221575e-16 3.2484571e-16 1.5113627e-26], sum to 1.0000
[2019-03-26 15:53:12,918] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7008
[2019-03-26 15:53:12,921] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.73333333333333, 64.33333333333334, 1.0, 2.0, 0.7743874539833375, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1179373.118487598, 1179373.118487598, 250502.7218039786], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7299600.0000, 
sim time next is 7300200.0000, 
raw observation next is [26.81666666666667, 63.66666666666666, 1.0, 2.0, 0.7866281003577029, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1199196.73302138, 1199196.733021379, 253857.3074249674], 
processed observation next is [1.0, 0.4782608695652174, 0.46998420221169057, 0.6366666666666666, 1.0, 1.0, 0.7429254221177144, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.33311020361704996, 0.33311020361704974, 0.37889150361935436], 
reward next is 0.6211, 
noisyNet noise sample is [array([0.48548776], dtype=float32), 1.3533167]. 
=============================================
[2019-03-26 15:53:14,073] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.8445049e-16 1.0000000e+00 1.5413022e-17 6.2558558e-17 2.1475366e-28], sum to 1.0000
[2019-03-26 15:53:14,083] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6230
[2019-03-26 15:53:14,090] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.98333333333333, 66.5, 1.0, 2.0, 0.3762490660728819, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 562824.6120057555, 562824.6120057555, 171227.0679055988], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7321800.0000, 
sim time next is 7322400.0000, 
raw observation next is [26.9, 67.0, 1.0, 2.0, 0.3800291821125275, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 568403.7290773244, 568403.729077325, 171715.604130279], 
processed observation next is [1.0, 0.782608695652174, 0.4739336492890995, 0.67, 1.0, 1.0, 0.253047207364491, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15788992474370123, 0.1578899247437014, 0.256291946463103], 
reward next is 0.7437, 
noisyNet noise sample is [array([0.10486067], dtype=float32), -0.9543984]. 
=============================================
[2019-03-26 15:53:15,054] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.5523963e-15 1.0000000e+00 2.1661844e-17 2.2492040e-17 3.9589753e-28], sum to 1.0000
[2019-03-26 15:53:15,067] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5934
[2019-03-26 15:53:15,070] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.26666666666667, 93.0, 1.0, 2.0, 0.6418571287601026, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1010958.854033334, 1010958.854033334, 222285.5119544567], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7384800.0000, 
sim time next is 7385400.0000, 
raw observation next is [21.25, 93.0, 1.0, 2.0, 0.605954555514079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 954801.4699806212, 954801.4699806207, 214489.5681947949], 
processed observation next is [1.0, 0.4782608695652174, 0.20616113744075834, 0.93, 1.0, 1.0, 0.5252464524266012, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2652226305501726, 0.2652226305501724, 0.3201336838728282], 
reward next is 0.6799, 
noisyNet noise sample is [array([0.3610581], dtype=float32), 0.7829035]. 
=============================================
[2019-03-26 15:53:16,847] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.8238083e-14 1.0000000e+00 3.6884745e-17 1.6521761e-17 1.5291715e-27], sum to 1.0000
[2019-03-26 15:53:16,853] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0121
[2019-03-26 15:53:16,865] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.8, 89.66666666666667, 1.0, 2.0, 0.4051620648402793, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 618301.9594440827, 618301.9594440827, 176551.4574145646], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7364400.0000, 
sim time next is 7365000.0000, 
raw observation next is [22.6, 89.83333333333333, 1.0, 2.0, 0.3908969466713055, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 599718.7713122347, 599718.7713122341, 174926.9392147202], 
processed observation next is [1.0, 0.21739130434782608, 0.27014218009478685, 0.8983333333333333, 1.0, 1.0, 0.2661408996039825, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16658854758673186, 0.1665885475867317, 0.26108498390256746], 
reward next is 0.7389, 
noisyNet noise sample is [array([0.64583397], dtype=float32), -0.36254787]. 
=============================================
[2019-03-26 15:53:16,879] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[71.280914]
 [71.14186 ]
 [71.09967 ]
 [71.018456]
 [70.9656  ]], R is [[71.34944916]
 [71.37244415]
 [71.39299774]
 [71.41537476]
 [71.4223938 ]].
[2019-03-26 15:53:16,971] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.00033244e-14 1.00000000e+00 6.10947064e-17 5.03376361e-17
 1.38860753e-28], sum to 1.0000
[2019-03-26 15:53:16,983] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0122
[2019-03-26 15:53:16,990] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.56666666666667, 92.16666666666667, 1.0, 2.0, 0.5690211435355871, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 912923.0050732447, 912923.0050732447, 208190.4419254536], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7377000.0000, 
sim time next is 7377600.0000, 
raw observation next is [20.63333333333333, 92.33333333333334, 1.0, 2.0, 0.5817624780692395, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 931735.4583651241, 931735.4583651234, 210682.2938787546], 
processed observation next is [1.0, 0.391304347826087, 0.17693522906793036, 0.9233333333333335, 1.0, 1.0, 0.49609937116775843, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.25881540510142337, 0.25881540510142315, 0.3144511848936636], 
reward next is 0.6855, 
noisyNet noise sample is [array([1.0006943], dtype=float32), 1.1322861]. 
=============================================
[2019-03-26 15:53:18,215] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.0919770e-15 1.0000000e+00 1.2114115e-18 3.5020190e-19 9.0679846e-30], sum to 1.0000
[2019-03-26 15:53:18,224] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2440
[2019-03-26 15:53:18,230] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.35, 91.5, 1.0, 2.0, 0.3133050122001033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 494907.9830848176, 494907.983084817, 166635.0146898113], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7439400.0000, 
sim time next is 7440000.0000, 
raw observation next is [21.33333333333333, 91.66666666666666, 1.0, 2.0, 0.3135819889640823, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 495301.1078864357, 495301.1078864357, 166663.2430660371], 
processed observation next is [0.0, 0.08695652173913043, 0.21011058451816728, 0.9166666666666665, 1.0, 1.0, 0.17299034814949674, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13758364107956547, 0.13758364107956547, 0.24875110905378672], 
reward next is 0.7512, 
noisyNet noise sample is [array([0.32737786], dtype=float32), -0.21320689]. 
=============================================
[2019-03-26 15:53:18,243] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[75.52293 ]
 [75.350296]
 [74.9437  ]
 [74.78949 ]
 [74.39183 ]], R is [[75.76673889]
 [75.76036072]
 [75.75406647]
 [75.74782562]
 [75.7416153 ]].
[2019-03-26 15:53:20,232] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.5872843e-15 1.0000000e+00 4.3850201e-17 1.6241735e-18 6.6024244e-28], sum to 1.0000
[2019-03-26 15:53:20,242] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3213
[2019-03-26 15:53:20,249] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.35, 91.5, 1.0, 2.0, 0.3145421837505583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 496828.6231944223, 496828.6231944217, 166777.0656819067], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7435800.0000, 
sim time next is 7436400.0000, 
raw observation next is [21.36666666666667, 91.33333333333334, 1.0, 2.0, 0.3141037069787677, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 496181.5054580989, 496181.5054580989, 166729.8703255484], 
processed observation next is [0.0, 0.043478260869565216, 0.21169036334913136, 0.9133333333333334, 1.0, 1.0, 0.17361892407080448, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13782819596058302, 0.13782819596058302, 0.2488505527246991], 
reward next is 0.7511, 
noisyNet noise sample is [array([0.29380402], dtype=float32), 1.2281038]. 
=============================================
[2019-03-26 15:53:22,347] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.1062943e-15 1.0000000e+00 2.9496496e-18 1.4462728e-19 3.3643472e-30], sum to 1.0000
[2019-03-26 15:53:22,358] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3555
[2019-03-26 15:53:22,365] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.01666666666667, 77.5, 1.0, 2.0, 0.4200347975032969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 610208.4788215889, 610208.4788215889, 175016.526801844], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7494600.0000, 
sim time next is 7495200.0000, 
raw observation next is [25.9, 78.0, 1.0, 2.0, 0.4192212272567798, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 609932.050515837, 609932.050515837, 175017.344579115], 
processed observation next is [0.0, 0.782608695652174, 0.42654028436018954, 0.78, 1.0, 1.0, 0.3002665388635901, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1694255695877325, 0.1694255695877325, 0.2612199172822612], 
reward next is 0.7388, 
noisyNet noise sample is [array([-0.7278767], dtype=float32), 0.46259603]. 
=============================================
[2019-03-26 15:53:24,004] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:53:24,005] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:53:24,039] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run5
[2019-03-26 15:53:26,413] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.2031182e-15 1.0000000e+00 3.6075557e-17 2.6168359e-18 1.7883948e-29], sum to 1.0000
[2019-03-26 15:53:26,422] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1688
[2019-03-26 15:53:26,426] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.15, 90.0, 1.0, 2.0, 0.3728689970565986, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 563456.4493623809, 563456.4493623809, 171472.3764390005], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7536600.0000, 
sim time next is 7537200.0000, 
raw observation next is [23.2, 90.0, 1.0, 2.0, 0.374328916147929, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 564747.1899638186, 564747.1899638181, 171555.5652551689], 
processed observation next is [0.0, 0.21739130434782608, 0.29857819905213273, 0.9, 1.0, 1.0, 0.2461794170456976, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15687421943439406, 0.15687421943439392, 0.25605308247040137], 
reward next is 0.7439, 
noisyNet noise sample is [array([-0.35159814], dtype=float32), -0.40437123]. 
=============================================
[2019-03-26 15:53:28,191] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.7462036e-16 1.0000000e+00 2.0745392e-17 3.6744289e-18 2.0477783e-29], sum to 1.0000
[2019-03-26 15:53:28,204] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0824
[2019-03-26 15:53:28,209] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 60.33333333333333, 1.0, 2.0, 0.4255031755308653, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 617378.1013947607, 617378.10139476, 175682.6651552374], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7566000.0000, 
sim time next is 7566600.0000, 
raw observation next is [29.0, 59.66666666666667, 1.0, 2.0, 0.4198261349064711, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 611936.4929325556, 611936.492932555, 175241.8906953333], 
processed observation next is [0.0, 0.5652173913043478, 0.5734597156398105, 0.5966666666666667, 1.0, 1.0, 0.3009953432608085, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1699823591479321, 0.16998235914793194, 0.26155506073930346], 
reward next is 0.7384, 
noisyNet noise sample is [array([0.64088076], dtype=float32), -0.43580535]. 
=============================================
[2019-03-26 15:53:31,192] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.8434161e-14 1.0000000e+00 1.5111340e-16 7.5646210e-17 1.7657887e-27], sum to 1.0000
[2019-03-26 15:53:31,208] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6698
[2019-03-26 15:53:31,220] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.7, 94.0, 1.0, 2.0, 0.424038380884282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 616986.5242341505, 616986.52423415, 175694.964490759], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7624800.0000, 
sim time next is 7625400.0000, 
raw observation next is [23.8, 93.66666666666667, 1.0, 2.0, 0.4700282567033772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 682312.3596196418, 682312.3596196418, 182274.0844446681], 
processed observation next is [1.0, 0.2608695652173913, 0.3270142180094788, 0.9366666666666668, 1.0, 1.0, 0.3614798273534665, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18953121100545606, 0.18953121100545606, 0.27205087230547476], 
reward next is 0.7279, 
noisyNet noise sample is [array([1.4847043], dtype=float32), -1.2831905]. 
=============================================
[2019-03-26 15:53:32,355] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.8666935e-11 1.0000000e+00 5.5791569e-12 1.2824562e-08 1.3230454e-18], sum to 1.0000
[2019-03-26 15:53:32,368] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6868
[2019-03-26 15:53:32,373] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.36666666666667, 60.66666666666667, 1.0, 2.0, 0.995461080155038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.9129565104282, 1391455.782989629, 1391455.782989629, 297542.7774216346], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7648800.0000, 
sim time next is 7649400.0000, 
raw observation next is [30.43333333333333, 60.33333333333333, 1.0, 2.0, 1.008520122390701, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1409721.836249652, 1409721.836249652, 301529.4237665405], 
processed observation next is [1.0, 0.5217391304347826, 0.6413902053712479, 0.6033333333333333, 1.0, 1.0, 1.0102652076996397, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3915893989582367, 0.3915893989582367, 0.4500439160694634], 
reward next is 0.5500, 
noisyNet noise sample is [array([0.49621156], dtype=float32), -0.8775649]. 
=============================================
[2019-03-26 15:53:36,395] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:53:36,395] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:53:36,419] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run5
[2019-03-26 15:53:39,014] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.1129271e-15 1.0000000e+00 2.1764064e-16 7.2240004e-16 1.3506369e-28], sum to 1.0000
[2019-03-26 15:53:39,019] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2586
[2019-03-26 15:53:39,023] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.05, 86.0, 1.0, 2.0, 0.5204531958061286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 727262.2629279441, 727262.2629279447, 186862.8848569513], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7763400.0000, 
sim time next is 7764000.0000, 
raw observation next is [27.0, 86.33333333333334, 1.0, 2.0, 0.5206336275893874, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 727514.4780434177, 727514.4780434177, 186892.2380089225], 
processed observation next is [1.0, 0.8695652173913043, 0.4786729857819906, 0.8633333333333334, 1.0, 1.0, 0.42245015372215344, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20208735501206046, 0.20208735501206046, 0.2789436388192873], 
reward next is 0.7211, 
noisyNet noise sample is [array([0.6390868], dtype=float32), 1.21577]. 
=============================================
[2019-03-26 15:53:39,032] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[73.459465]
 [73.378876]
 [73.24433 ]
 [73.01094 ]
 [72.78394 ]], R is [[73.25197601]
 [73.24055481]
 [73.22945404]
 [73.21885681]
 [73.20871735]].
[2019-03-26 15:53:41,764] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:53:41,764] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:53:41,787] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run5
[2019-03-26 15:53:41,972] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.4866986e-07 9.3873316e-01 4.0121648e-07 6.1266232e-02 5.2858516e-12], sum to 1.0000
[2019-03-26 15:53:41,977] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0546
[2019-03-26 15:53:41,985] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1780989.727885334 W.
[2019-03-26 15:53:41,990] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.0, 70.0, 1.0, 2.0, 0.6369519297040807, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.996494145885501, 6.9112, 168.9124366878455, 1780989.727885334, 1720479.311415074, 371625.4301064675], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7820400.0000, 
sim time next is 7821000.0000, 
raw observation next is [31.0, 70.0, 1.0, 2.0, 0.3868929670530946, 1.0, 1.0, 0.3868929670530946, 1.0, 2.0, 0.671905136311869, 6.911199999999999, 6.9112, 170.5573041426782, 1622561.85448675, 1622561.854486751, 345751.6992009609], 
processed observation next is [1.0, 0.5217391304347826, 0.6682464454976303, 0.7, 1.0, 1.0, 0.2613168277748128, 1.0, 0.5, 0.2613168277748128, 1.0, 1.0, 0.5998843125754499, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.45071162624631944, 0.4507116262463197, 0.5160473122402401], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0810289], dtype=float32), 2.4199438]. 
=============================================
[2019-03-26 15:53:42,000] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[27.057096]
 [26.208244]
 [25.89094 ]
 [25.475126]
 [24.77962 ]], R is [[26.12505341]
 [25.86380386]
 [25.96649933]
 [25.70683479]
 [25.44976616]].
[2019-03-26 15:53:48,130] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:53:48,130] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:53:48,163] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run5
[2019-03-26 15:53:48,352] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:53:48,353] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:53:48,378] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run5
[2019-03-26 15:53:48,874] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:53:48,874] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:53:48,895] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run5
[2019-03-26 15:53:49,572] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:53:49,573] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:53:49,598] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run5
[2019-03-26 15:53:49,777] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:53:49,777] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:53:49,791] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:53:49,791] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:53:49,800] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run5
[2019-03-26 15:53:49,826] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run5
[2019-03-26 15:53:49,934] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:53:49,935] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:53:49,954] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run5
[2019-03-26 15:53:49,990] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:53:49,991] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:53:50,007] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run5
[2019-03-26 15:53:50,027] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:53:50,027] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:53:50,050] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run5
[2019-03-26 15:53:50,084] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:53:50,084] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:53:50,093] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run5
[2019-03-26 15:53:50,149] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:53:50,149] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:53:50,151] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:53:50,151] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:53:50,154] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run5
[2019-03-26 15:53:50,175] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run5
[2019-03-26 15:53:50,257] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:53:50,257] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:53:50,259] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run5
[2019-03-26 15:53:50,703] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-26 15:53:50,710] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 15:53:50,710] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:53:50,711] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run35
[2019-03-26 15:53:50,728] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 15:53:50,729] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:53:50,730] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run35
[2019-03-26 15:53:50,754] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 15:53:50,755] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:53:50,756] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run35
[2019-03-26 15:53:50,788] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 15:53:50,791] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:53:50,805] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run35
[2019-03-26 15:53:50,858] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 15:53:50,858] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:53:50,860] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run35
[2019-03-26 15:54:24,430] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10522749], dtype=float32), 0.07051063]
[2019-03-26 15:54:24,431] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.95, 63.5, 1.0, 2.0, 0.6156048977468884, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.948551847149451, 6.9112, 168.912695823423, 1721252.600329691, 1694753.955306499, 367758.5025258613]
[2019-03-26 15:54:24,434] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:54:24,436] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [4.3645980e-09 9.9998569e-01 4.3702211e-09 1.4308178e-05 8.9780844e-16], sampled 0.09127098766584607
[2019-03-26 15:54:24,438] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1721252.600329691 W.
[2019-03-26 15:54:26,762] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10522749], dtype=float32), 0.07051063]
[2019-03-26 15:54:26,763] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.8, 87.33333333333334, 1.0, 2.0, 0.7595408546378654, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.979259693861562, 6.9112, 168.912494647736, 1958450.795948318, 1910167.038712824, 399038.0596486974]
[2019-03-26 15:54:26,765] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:54:26,768] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [4.8735556e-12 1.0000000e+00 2.7987904e-13 7.5522132e-12 1.2230597e-21], sampled 0.030373409926841344
[2019-03-26 15:54:26,770] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1958450.795948318 W.
[2019-03-26 15:54:28,162] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10522749], dtype=float32), 0.07051063]
[2019-03-26 15:54:28,164] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.1, 76.0, 1.0, 2.0, 0.83626938358531, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.988313745695198, 6.9112, 168.9124352866891, 2065835.032402885, 2011128.055969177, 417651.9510475583]
[2019-03-26 15:54:28,165] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:54:28,170] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.0850282e-09 9.9999619e-01 1.2878212e-09 3.8405524e-06 2.1987038e-16], sampled 0.8446914367931344
[2019-03-26 15:54:28,171] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2065835.032402885 W.
[2019-03-26 15:54:28,927] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10522749], dtype=float32), 0.07051063]
[2019-03-26 15:54:28,929] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [24.16666666666667, 92.0, 1.0, 2.0, 0.4417324161473611, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 636596.4127780722, 636596.4127780729, 177456.4061942771]
[2019-03-26 15:54:28,930] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:54:28,933] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [6.3138327e-15 1.0000000e+00 1.7732296e-17 5.7239430e-18 1.2648337e-28], sampled 0.5201241092093342
[2019-03-26 15:55:23,774] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10522749], dtype=float32), 0.07051063]
[2019-03-26 15:55:23,775] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.36666666666667, 85.0, 1.0, 2.0, 0.4994401387150711, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 697889.7398451762, 697889.7398451768, 183510.3536381895]
[2019-03-26 15:55:23,775] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:55:23,777] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.4346570e-11 1.0000000e+00 3.2080900e-12 4.1742760e-09 5.3561956e-21], sampled 0.19996321769153058
[2019-03-26 15:55:29,055] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10522749], dtype=float32), 0.07051063]
[2019-03-26 15:55:29,057] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.04643728666667, 67.47573772333334, 1.0, 2.0, 0.6985053442689078, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1039961.803188813, 1039961.803188813, 228818.2697459188]
[2019-03-26 15:55:29,059] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 15:55:29,063] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.2954032e-14 1.0000000e+00 5.6847339e-17 2.5669868e-17 6.6048930e-28], sampled 0.048725832953291026
[2019-03-26 15:55:36,545] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10522749], dtype=float32), 0.07051063]
[2019-03-26 15:55:36,547] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.0, 64.0, 1.0, 2.0, 0.471308193381048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 666265.6706217547, 666265.6706217547, 180213.7942265318]
[2019-03-26 15:55:36,548] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 15:55:36,552] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [7.2110634e-15 1.0000000e+00 2.0589528e-17 4.2385285e-18 1.0637324e-28], sampled 0.6306071015490419
[2019-03-26 15:55:41,836] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.1801 3164313792.8744 1776.0000
[2019-03-26 15:55:42,155] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.6119 2842427357.4275 1131.0000
[2019-03-26 15:55:42,295] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.1725 2779322230.8975 933.0000
[2019-03-26 15:55:42,453] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8252.9167 2927409372.7140 1338.0000
[2019-03-26 15:55:42,551] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7996.8346 3007664847.7666 1766.0000
[2019-03-26 15:55:43,569] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 850000, evaluation results [850000.0, 7884.180077883168, 3164313792.874403, 1776.0, 8252.91667573031, 2927409372.713999, 1338.0, 8661.172501768742, 2779322230.897455, 933.0, 7996.834631788349, 3007664847.766646, 1766.0, 8497.61193292354, 2842427357.427519, 1131.0]
[2019-03-26 15:55:45,418] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.21275392e-14 1.00000000e+00 1.08146765e-16 4.84391573e-17
 2.28469063e-27], sum to 1.0000
[2019-03-26 15:55:45,428] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3170
[2019-03-26 15:55:45,434] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.38333333333333, 79.0, 1.0, 2.0, 0.679146518094398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1063261.778769645, 1063261.778769644, 230258.9121231225], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 31800.0000, 
sim time next is 32400.0000, 
raw observation next is [23.6, 78.0, 1.0, 2.0, 0.6790472624039123, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1061161.792628991, 1061161.792628991, 230043.0018780414], 
processed observation next is [1.0, 0.391304347826087, 0.3175355450236968, 0.78, 1.0, 1.0, 0.6133099547035088, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.29476716461916413, 0.29476716461916413, 0.3433477639970767], 
reward next is 0.6567, 
noisyNet noise sample is [array([-0.7289489], dtype=float32), -0.8005167]. 
=============================================
[2019-03-26 15:55:55,382] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.1474786e-15 1.0000000e+00 1.6856495e-17 2.9169969e-19 2.0080021e-29], sum to 1.0000
[2019-03-26 15:55:55,393] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8995
[2019-03-26 15:55:55,405] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.26666666666667, 93.66666666666667, 1.0, 2.0, 0.2903122729880573, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 466795.059711286, 466795.0597112866, 164737.5517270314], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 199200.0000, 
sim time next is 199800.0000, 
raw observation next is [20.3, 93.5, 1.0, 2.0, 0.2908045899499951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 467461.3572708468, 467461.3572708468, 164783.221668899], 
processed observation next is [0.0, 0.30434782608695654, 0.16113744075829392, 0.935, 1.0, 1.0, 0.14554769873493384, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.12985037701967966, 0.12985037701967966, 0.24594510696850597], 
reward next is 0.7541, 
noisyNet noise sample is [array([-0.05128536], dtype=float32), 0.50969166]. 
=============================================
[2019-03-26 15:55:56,303] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1547487e-15 1.0000000e+00 2.5549690e-18 8.4873578e-20 2.5392907e-30], sum to 1.0000
[2019-03-26 15:55:56,313] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6091
[2019-03-26 15:55:56,318] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.96666666666667, 91.33333333333334, 1.0, 2.0, 0.3037413313631027, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 484300.2789703728, 484300.2789703728, 165939.3758367369], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 213600.0000, 
sim time next is 214200.0000, 
raw observation next is [21.05, 91.0, 1.0, 2.0, 0.3044481571744767, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 484982.0902380803, 484982.0902380803, 165982.5573559715], 
processed observation next is [0.0, 0.4782608695652174, 0.1966824644549764, 0.91, 1.0, 1.0, 0.1619857315355141, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13471724728835563, 0.13471724728835563, 0.2477351602327933], 
reward next is 0.7523, 
noisyNet noise sample is [array([0.54206544], dtype=float32), -0.41761205]. 
=============================================
[2019-03-26 15:55:58,642] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.7240118e-15 1.0000000e+00 2.4603819e-18 2.5174495e-19 1.4242282e-30], sum to 1.0000
[2019-03-26 15:55:58,653] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1438
[2019-03-26 15:55:58,660] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 91.66666666666666, 1.0, 2.0, 0.2846809848806243, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 457797.0968169583, 457797.0968169583, 164121.7406051502], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 258000.0000, 
sim time next is 258600.0000, 
raw observation next is [20.5, 91.83333333333333, 1.0, 2.0, 0.285225199115697, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 458494.5264729814, 458494.5264729809, 164168.3022195481], 
processed observation next is [0.0, 1.0, 0.1706161137440759, 0.9183333333333333, 1.0, 1.0, 0.13882554110324938, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12735959068693928, 0.12735959068693914, 0.24502731674559416], 
reward next is 0.7550, 
noisyNet noise sample is [array([-0.75854594], dtype=float32), -1.1129658]. 
=============================================
[2019-03-26 15:56:04,491] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.0075799e-15 1.0000000e+00 4.2327302e-17 2.3755965e-17 1.9294209e-28], sum to 1.0000
[2019-03-26 15:56:04,501] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1737
[2019-03-26 15:56:04,507] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.45, 71.5, 1.0, 2.0, 0.2478202630018402, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 408548.6347422035, 408548.634742204, 160668.6997043289], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 588600.0000, 
sim time next is 589200.0000, 
raw observation next is [21.3, 72.0, 1.0, 2.0, 0.244931129363862, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 404123.4828991839, 404123.4828991832, 160374.5148678368], 
processed observation next is [1.0, 0.8260869565217391, 0.2085308056872039, 0.72, 1.0, 1.0, 0.09027846911308673, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11225652302755107, 0.11225652302755088, 0.23936494756393553], 
reward next is 0.7606, 
noisyNet noise sample is [array([0.3648718], dtype=float32), 0.33536988]. 
=============================================
[2019-03-26 15:56:05,254] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.6979166e-15 1.0000000e+00 2.9742051e-16 1.0652576e-16 1.3203376e-26], sum to 1.0000
[2019-03-26 15:56:05,265] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5954
[2019-03-26 15:56:05,271] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.3, 87.0, 1.0, 2.0, 0.2569084511794936, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 418598.7393006994, 418598.7393006994, 161538.0374686603], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 367200.0000, 
sim time next is 367800.0000, 
raw observation next is [20.36666666666667, 86.5, 1.0, 2.0, 0.2609633783394137, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 425208.3495388778, 425208.3495388784, 161948.2201520966], 
processed observation next is [1.0, 0.2608695652173913, 0.1642969984202214, 0.865, 1.0, 1.0, 0.10959443173423335, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11811343042746605, 0.11811343042746623, 0.24171376142103967], 
reward next is 0.7583, 
noisyNet noise sample is [array([-1.4199584], dtype=float32), 2.3272429]. 
=============================================
[2019-03-26 15:56:17,740] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.7673154e-15 1.0000000e+00 3.3246136e-18 1.1944144e-19 3.1801900e-29], sum to 1.0000
[2019-03-26 15:56:17,750] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7549
[2019-03-26 15:56:17,755] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.53333333333333, 65.0, 1.0, 2.0, 0.291832647351383, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 466766.9952571982, 466766.9952571976, 164717.0981647818], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 814800.0000, 
sim time next is 815400.0000, 
raw observation next is [24.7, 64.0, 1.0, 2.0, 0.2917469936813316, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 466636.1393664615, 466636.1393664609, 164708.0811510054], 
processed observation next is [0.0, 0.43478260869565216, 0.3696682464454976, 0.64, 1.0, 1.0, 0.14668312491726698, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12962114982401707, 0.12962114982401693, 0.2458329569417991], 
reward next is 0.7542, 
noisyNet noise sample is [array([-1.9236133], dtype=float32), 0.018341731]. 
=============================================
[2019-03-26 15:56:26,269] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.8398570e-15 1.0000000e+00 1.4558672e-17 4.8220504e-17 5.8837088e-28], sum to 1.0000
[2019-03-26 15:56:26,277] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0566
[2019-03-26 15:56:26,284] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.88333333333333, 62.16666666666666, 1.0, 2.0, 0.5791120084840637, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 943359.6611344671, 943359.6611344671, 211027.4510708565], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 727800.0000, 
sim time next is 728400.0000, 
raw observation next is [24.06666666666667, 61.33333333333334, 1.0, 2.0, 0.5228121604416931, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 851124.0959881367, 851124.095988136, 199873.8175829679], 
processed observation next is [1.0, 0.43478260869565216, 0.3396524486571882, 0.6133333333333334, 1.0, 1.0, 0.4250748920984254, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.23642335999670464, 0.23642335999670444, 0.2983191307208476], 
reward next is 0.7017, 
noisyNet noise sample is [array([-0.2949046], dtype=float32), -2.029262]. 
=============================================
[2019-03-26 15:56:28,270] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.7309985e-15 1.0000000e+00 7.1060527e-19 2.2295795e-19 8.4871851e-30], sum to 1.0000
[2019-03-26 15:56:28,282] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1213
[2019-03-26 15:56:28,287] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.8, 63.0, 1.0, 2.0, 0.2904307138657254, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 465128.1484360214, 465128.1484360207, 164610.1315868421], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 824400.0000, 
sim time next is 825000.0000, 
raw observation next is [24.76666666666667, 63.0, 1.0, 2.0, 0.2898091305429463, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 464338.8374976719, 464338.8374976725, 164557.6143666503], 
processed observation next is [0.0, 0.5652173913043478, 0.3728278041074251, 0.63, 1.0, 1.0, 0.14434835005174254, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12898301041601998, 0.12898301041602014, 0.24560837965171686], 
reward next is 0.7544, 
noisyNet noise sample is [array([-1.8730086], dtype=float32), -0.45730424]. 
=============================================
[2019-03-26 15:56:28,300] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[80.02662 ]
 [79.974815]
 [79.93797 ]
 [79.89285 ]
 [79.8465  ]], R is [[80.04512787]
 [79.99898529]
 [79.95349121]
 [79.90858459]
 [79.86412048]].
[2019-03-26 15:56:36,782] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.4840063e-14 1.0000000e+00 1.5148501e-17 1.8229822e-18 5.5759354e-30], sum to 1.0000
[2019-03-26 15:56:36,790] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2902
[2019-03-26 15:56:36,795] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.03333333333333, 75.66666666666666, 1.0, 2.0, 0.2966799430323602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 473057.4905222168, 473057.4905222162, 165137.9243036443], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 906000.0000, 
sim time next is 906600.0000, 
raw observation next is [23.16666666666667, 74.83333333333334, 1.0, 2.0, 0.296635130069516, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 472871.0608527992, 472871.0608527992, 165123.0257339152], 
processed observation next is [0.0, 0.4782608695652174, 0.2969984202211693, 0.7483333333333334, 1.0, 1.0, 0.1525724458668867, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1313530724591109, 0.1313530724591109, 0.2464522772147988], 
reward next is 0.7535, 
noisyNet noise sample is [array([-0.14596987], dtype=float32), 0.07406884]. 
=============================================
[2019-03-26 15:56:38,475] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-26 15:56:38,479] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 15:56:38,480] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:56:38,480] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 15:56:38,481] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:56:38,483] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 15:56:38,484] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 15:56:38,485] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:56:38,485] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:56:38,485] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 15:56:38,486] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:56:38,512] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run36
[2019-03-26 15:56:38,531] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run36
[2019-03-26 15:56:38,532] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run36
[2019-03-26 15:56:38,568] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run36
[2019-03-26 15:56:38,570] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run36
[2019-03-26 15:56:39,582] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10810269], dtype=float32), 0.07326425]
[2019-03-26 15:56:39,583] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.28333333333333, 73.66666666666667, 1.0, 2.0, 0.3826539349713504, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 581310.4094313494, 581310.4094313494, 173134.6629697775]
[2019-03-26 15:56:39,583] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:56:39,584] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.1274536e-04 9.9986267e-01 1.2610797e-05 1.1916603e-05 1.2524566e-08], sampled 0.01936660986625105
[2019-03-26 15:56:47,531] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10810269], dtype=float32), 0.07326425]
[2019-03-26 15:56:47,533] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.61007829333334, 49.42363283333334, 1.0, 2.0, 0.3290045434895869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 533496.5815225496, 533496.581522549, 169573.7632979112]
[2019-03-26 15:56:47,535] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 15:56:47,538] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [5.5779991e-15 1.0000000e+00 1.2196891e-17 1.0358708e-18 5.2291851e-29], sampled 0.786465229961681
[2019-03-26 15:57:01,844] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10810269], dtype=float32), 0.07326425]
[2019-03-26 15:57:01,846] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [22.28256612333334, 86.73427183333334, 1.0, 2.0, 0.344387393407694, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 538075.8351289459, 538075.8351289459, 169858.6927778916]
[2019-03-26 15:57:01,847] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 15:57:01,850] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [6.8915591e-16 1.0000000e+00 1.2176987e-18 1.4205410e-19 9.8492462e-31], sampled 0.6756601286842868
[2019-03-26 15:57:10,874] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10810269], dtype=float32), 0.07326425]
[2019-03-26 15:57:10,877] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [23.16666666666667, 92.0, 1.0, 2.0, 0.3964991605396932, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 593159.1450721821, 593159.1450721821, 173952.8596217512]
[2019-03-26 15:57:10,879] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 15:57:10,882] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.4473886e-16 1.0000000e+00 5.5133594e-19 7.0165932e-20 3.0596395e-31], sampled 0.8801245907229411
[2019-03-26 15:57:25,673] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10810269], dtype=float32), 0.07326425]
[2019-03-26 15:57:25,674] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.14701001333334, 93.07675472666668, 1.0, 2.0, 0.4968921433700517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 694328.1499444381, 694328.1499444387, 183110.0482130884]
[2019-03-26 15:57:25,676] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 15:57:25,680] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.574688e-15 1.000000e+00 4.946522e-18 2.899247e-19 9.618562e-30], sampled 0.5462084381638997
[2019-03-26 15:57:59,851] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10810269], dtype=float32), 0.07326425]
[2019-03-26 15:57:59,854] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [32.43333333333334, 60.00000000000001, 1.0, 2.0, 0.5469084769276154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 764243.2039768497, 764243.2039768504, 191272.2893454655]
[2019-03-26 15:57:59,857] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:57:59,858] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.6479922e-16 1.0000000e+00 2.1675637e-18 4.0164326e-19 2.6238369e-30], sampled 0.7623589871175797
[2019-03-26 15:58:12,778] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10810269], dtype=float32), 0.07326425]
[2019-03-26 15:58:12,780] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [27.5, 86.5, 1.0, 2.0, 0.8040128704824469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1123707.80406183, 1123707.80406183, 244898.6415222323]
[2019-03-26 15:58:12,783] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 15:58:12,786] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.8171669e-15 1.0000000e+00 5.5215919e-18 2.3904674e-18 2.1331573e-29], sampled 0.25125368619840915
[2019-03-26 15:58:16,813] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10810269], dtype=float32), 0.07326425]
[2019-03-26 15:58:16,814] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.17607676166667, 27.6620823, 1.0, 2.0, 0.2356926146188715, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 394264.3077488017, 394264.3077488023, 144809.3230579038]
[2019-03-26 15:58:16,815] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 15:58:16,818] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.7224875e-15 1.0000000e+00 7.6740176e-18 5.9454434e-19 1.8718494e-29], sampled 0.636928908932217
[2019-03-26 15:58:30,815] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10810269], dtype=float32), 0.07326425]
[2019-03-26 15:58:30,816] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.8, 76.0, 1.0, 2.0, 0.8606766654771171, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.983318024289176, 6.9112, 168.9124699179618, 2099996.147765886, 2048833.286611075, 424203.9860918047]
[2019-03-26 15:58:30,816] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:58:30,817] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.0495302e-11 1.0000000e+00 5.3653713e-12 3.1976774e-10 1.1686879e-19], sampled 0.4550632908582485
[2019-03-26 15:58:30,818] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2099996.147765886 W.
[2019-03-26 15:58:31,186] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.9689 2927381913.5140 1338.0000
[2019-03-26 15:58:31,383] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.6119 2842427357.4275 1131.0000
[2019-03-26 15:58:31,430] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.3303 3164283735.2533 1776.0000
[2019-03-26 15:58:31,490] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.2362 2779163560.2392 933.0000
[2019-03-26 15:58:31,541] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.8607 3007711637.9330 1766.0000
[2019-03-26 15:58:32,560] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 875000, evaluation results [875000.0, 7884.330262989354, 3164283735.253313, 1776.0, 8254.968948333817, 2927381913.5140486, 1338.0, 8659.23621074804, 2779163560.2392178, 933.0, 7998.86073322157, 3007711637.9330444, 1766.0, 8497.61193292354, 2842427357.427519, 1131.0]
[2019-03-26 15:58:46,212] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.4808783e-15 1.0000000e+00 1.0626068e-17 3.4092517e-17 5.2144445e-29], sum to 1.0000
[2019-03-26 15:58:46,221] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4098
[2019-03-26 15:58:46,227] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.4, 61.66666666666667, 1.0, 2.0, 0.8490237964735008, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1287123.343506175, 1287123.343506175, 270109.6205624607], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1172400.0000, 
sim time next is 1173000.0000, 
raw observation next is [27.5, 61.33333333333334, 1.0, 2.0, 0.8638685322429966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1308217.633318777, 1308217.633318777, 274173.3348086234], 
processed observation next is [1.0, 0.5652173913043478, 0.5023696682464456, 0.6133333333333334, 1.0, 1.0, 0.8359861834252972, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3633937870329936, 0.3633937870329936, 0.40921393255018423], 
reward next is 0.5908, 
noisyNet noise sample is [array([-0.12473562], dtype=float32), 0.77651525]. 
=============================================
[2019-03-26 15:58:46,246] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[71.42865]
 [71.55325]
 [71.74072]
 [71.90195]
 [71.7265 ]], R is [[71.19251251]
 [71.07743835]
 [70.96195984]
 [70.8743515 ]
 [70.85821533]].
[2019-03-26 15:58:48,100] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.5971549e-16 1.0000000e+00 5.2095628e-18 1.8246103e-18 1.1380571e-29], sum to 1.0000
[2019-03-26 15:58:48,109] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8761
[2019-03-26 15:58:48,120] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.85, 80.0, 1.0, 2.0, 0.355786980345851, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 547949.502035673, 547949.502035673, 170471.4634428558], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1200600.0000, 
sim time next is 1201200.0000, 
raw observation next is [23.73333333333333, 80.66666666666667, 1.0, 2.0, 0.3559500502563797, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 548524.3494125624, 548524.3494125631, 170528.4996202623], 
processed observation next is [1.0, 0.9130434782608695, 0.3238546603475513, 0.8066666666666668, 1.0, 1.0, 0.22403620512816833, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1523678748368229, 0.1523678748368231, 0.25452014868695866], 
reward next is 0.7455, 
noisyNet noise sample is [array([2.2455716], dtype=float32), 0.5849908]. 
=============================================
[2019-03-26 15:58:58,591] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.2526140e-16 1.0000000e+00 2.2397847e-18 3.4706083e-18 1.6582780e-29], sum to 1.0000
[2019-03-26 15:58:58,599] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6132
[2019-03-26 15:58:58,607] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 97.0, 1.0, 2.0, 0.3111750875570063, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 493698.8909508252, 493698.8909508258, 166587.574781193], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1382400.0000, 
sim time next is 1383000.0000, 
raw observation next is [20.48333333333333, 97.0, 1.0, 2.0, 0.3109299914006426, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 493489.0386009165, 493489.0386009165, 166575.1628752845], 
processed observation next is [0.0, 0.0, 0.16982622432859393, 0.97, 1.0, 1.0, 0.16979517036221997, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13708028850025458, 0.13708028850025458, 0.2486196460825142], 
reward next is 0.7514, 
noisyNet noise sample is [array([0.39736292], dtype=float32), -2.922942]. 
=============================================
[2019-03-26 15:58:58,619] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[75.366936]
 [75.990486]
 [75.95592 ]
 [75.91405 ]
 [75.87218 ]], R is [[74.99471283]
 [74.99612427]
 [74.99737549]
 [74.99836731]
 [74.9990387 ]].
[2019-03-26 15:58:58,652] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.507825e-17 1.000000e+00 4.633125e-19 5.355708e-20 9.270741e-31], sum to 1.0000
[2019-03-26 15:58:58,658] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7983
[2019-03-26 15:58:58,662] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.15, 95.5, 1.0, 2.0, 0.3652517941314636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 556892.7480991762, 556892.7480991769, 171062.7908768603], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1463400.0000, 
sim time next is 1464000.0000, 
raw observation next is [22.1, 95.66666666666667, 1.0, 2.0, 0.3639018098302271, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 555346.3876218017, 555346.3876218017, 170946.5490673208], 
processed observation next is [0.0, 0.9565217391304348, 0.24644549763033188, 0.9566666666666667, 1.0, 1.0, 0.23361663834967117, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15426288545050046, 0.15426288545050046, 0.2551441030855534], 
reward next is 0.7449, 
noisyNet noise sample is [array([1.3250769], dtype=float32), -0.37316957]. 
=============================================
[2019-03-26 15:58:58,676] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[80.97569]
 [80.95058]
 [80.93006]
 [80.88722]
 [80.85349]], R is [[80.93481445]
 [80.87014771]
 [80.80594635]
 [80.74220276]
 [80.67889404]].
[2019-03-26 15:59:00,267] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.6128597e-16 1.0000000e+00 2.5800423e-18 3.6099217e-18 1.0430784e-28], sum to 1.0000
[2019-03-26 15:59:00,288] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9750
[2019-03-26 15:59:00,294] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666667, 94.0, 1.0, 2.0, 0.4768157272293644, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 666265.7373571822, 666265.7373571828, 180042.9938791809], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1734600.0000, 
sim time next is 1735200.0000, 
raw observation next is [24.6, 94.0, 1.0, 2.0, 0.4742197296898489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 662885.1596225568, 662885.1596225568, 179687.1728541443], 
processed observation next is [1.0, 0.08695652173913043, 0.36492890995260674, 0.94, 1.0, 1.0, 0.3665297948070469, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18413476656182132, 0.18413476656182132, 0.2681898102300661], 
reward next is 0.7318, 
noisyNet noise sample is [array([-1.0594677], dtype=float32), -1.5767858]. 
=============================================
[2019-03-26 15:59:07,214] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.4092622e-15 1.0000000e+00 2.3550873e-17 2.6656913e-18 1.9944450e-28], sum to 1.0000
[2019-03-26 15:59:07,224] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4031
[2019-03-26 15:59:07,232] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.7, 91.00000000000001, 1.0, 2.0, 0.3264188989787366, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 511970.4120501378, 511970.4120501378, 167843.0780645584], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1559400.0000, 
sim time next is 1560000.0000, 
raw observation next is [21.7, 91.0, 1.0, 2.0, 0.3260876342298332, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 511458.9051673762, 511458.9051673768, 167803.87279087], 
processed observation next is [1.0, 0.043478260869565216, 0.2274881516587678, 0.91, 1.0, 1.0, 0.18805739063835328, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14207191810204894, 0.1420719181020491, 0.2504535414789104], 
reward next is 0.7495, 
noisyNet noise sample is [array([-0.43322244], dtype=float32), -0.10288918]. 
=============================================
[2019-03-26 15:59:07,243] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[73.94542 ]
 [74.383286]
 [74.62364 ]
 [75.359   ]
 [76.15025 ]], R is [[73.60655975]
 [73.61998749]
 [73.63317108]
 [73.64602661]
 [73.65859222]].
[2019-03-26 15:59:12,367] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.5029385e-15 1.0000000e+00 1.2752077e-18 4.6189367e-19 6.4141908e-30], sum to 1.0000
[2019-03-26 15:59:12,381] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4817
[2019-03-26 15:59:12,389] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.73333333333333, 93.33333333333334, 1.0, 2.0, 0.512815282090766, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 716585.7216602801, 716585.7216602807, 185628.2625937236], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2161200.0000, 
sim time next is 2161800.0000, 
raw observation next is [25.7, 93.5, 1.0, 2.0, 0.512143694793553, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 715646.9587259385, 715646.958725939, 185520.5706594243], 
processed observation next is [1.0, 0.0, 0.4170616113744076, 0.935, 1.0, 1.0, 0.4122213190283771, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19879082186831623, 0.1987908218683164, 0.27689637411854373], 
reward next is 0.7231, 
noisyNet noise sample is [array([0.27862364], dtype=float32), 2.1378348]. 
=============================================
[2019-03-26 15:59:27,445] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.7578459e-10 9.9999988e-01 2.0386862e-10 1.2744647e-07 1.2723226e-16], sum to 1.0000
[2019-03-26 15:59:27,455] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4794
[2019-03-26 15:59:27,465] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2110599.374937617 W.
[2019-03-26 15:59:27,473] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.7, 75.5, 1.0, 2.0, 0.7547233987004422, 1.0, 2.0, 0.7547233987004422, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2110599.374937617, 2110599.374937617, 398432.4651189265], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2196600.0000, 
sim time next is 2197200.0000, 
raw observation next is [29.8, 75.0, 1.0, 2.0, 0.7554405106944625, 1.0, 2.0, 0.7554405106944625, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2112606.770776487, 2112606.770776487, 398762.7983373152], 
processed observation next is [1.0, 0.43478260869565216, 0.6113744075829385, 0.75, 1.0, 1.0, 0.7053500128848945, 1.0, 1.0, 0.7053500128848945, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5868352141045797, 0.5868352141045797, 0.5951683557273362], 
reward next is 0.4048, 
noisyNet noise sample is [array([0.89791876], dtype=float32), -0.38497573]. 
=============================================
[2019-03-26 15:59:27,543] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-26 15:59:27,545] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 15:59:27,545] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:59:27,545] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 15:59:27,546] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 15:59:27,546] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 15:59:27,547] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:59:27,547] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 15:59:27,548] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:59:27,551] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:59:27,548] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:59:27,569] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run37
[2019-03-26 15:59:27,570] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run37
[2019-03-26 15:59:27,606] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run37
[2019-03-26 15:59:27,606] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run37
[2019-03-26 15:59:27,636] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run37
[2019-03-26 15:59:36,665] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10694078], dtype=float32), 0.07146424]
[2019-03-26 15:59:36,668] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [21.75, 85.0, 1.0, 2.0, 0.3154352471887549, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 502854.734285067, 502854.734285067, 167299.1474475567]
[2019-03-26 15:59:36,669] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:59:36,672] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0955946e-15 1.0000000e+00 2.5218144e-18 2.3940708e-19 4.7152246e-30], sampled 0.5511455359978245
[2019-03-26 15:59:51,101] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10694078], dtype=float32), 0.07146424]
[2019-03-26 15:59:51,102] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [23.8, 92.5, 1.0, 2.0, 0.4557743111401972, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 665175.1766153434, 665175.1766153434, 180549.1846655403]
[2019-03-26 15:59:51,103] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:59:51,107] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.5737851e-15 1.0000000e+00 4.3668726e-18 5.0732776e-19 1.2313033e-29], sampled 0.06435418789476788
[2019-03-26 16:00:08,134] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10694078], dtype=float32), 0.07146424]
[2019-03-26 16:00:08,136] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [22.88729982166667, 88.69186432666667, 1.0, 2.0, 0.3709971398018772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 565717.8123358947, 565717.812335894, 171823.7682689182]
[2019-03-26 16:00:08,137] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 16:00:08,139] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [9.5634943e-16 1.0000000e+00 2.0672625e-18 1.4860419e-19 2.9765560e-30], sampled 0.31299409724898175
[2019-03-26 16:00:09,630] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10694078], dtype=float32), 0.07146424]
[2019-03-26 16:00:09,631] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [30.86666666666667, 60.66666666666667, 1.0, 2.0, 0.7456884112295046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1042152.130844593, 1042152.130844592, 231013.9868910038]
[2019-03-26 16:00:09,631] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:00:09,634] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.3358106e-15 1.0000000e+00 1.5276575e-17 4.4921917e-18 9.3021375e-29], sampled 0.05914662720827457
[2019-03-26 16:00:32,264] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10694078], dtype=float32), 0.07146424]
[2019-03-26 16:00:32,265] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.43333333333333, 78.0, 1.0, 2.0, 0.5624060620103928, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 785907.3510694405, 785907.3510694398, 193951.2717523441]
[2019-03-26 16:00:32,266] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 16:00:32,272] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.1101479e-15 1.0000000e+00 8.9583950e-18 8.8582792e-19 3.6289275e-29], sampled 0.26383651218320014
[2019-03-26 16:00:44,857] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10694078], dtype=float32), 0.07146424]
[2019-03-26 16:00:44,858] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [35.8, 51.66666666666667, 1.0, 2.0, 1.002777864187599, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005993509437348, 6.9112, 168.9123159263004, 2298890.162599381, 2231640.639501236, 464157.4993758462]
[2019-03-26 16:00:44,859] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:00:44,862] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [5.8662286e-10 9.9999857e-01 5.6999788e-10 1.4801248e-06 1.2929975e-17], sampled 0.3607890952813637
[2019-03-26 16:00:44,863] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2298890.162599381 W.
[2019-03-26 16:01:00,752] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10694078], dtype=float32), 0.07146424]
[2019-03-26 16:01:00,755] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.93333333333334, 60.33333333333333, 1.0, 2.0, 0.5832445492680339, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 815038.266972072, 815038.266972072, 197662.452777993]
[2019-03-26 16:01:00,756] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 16:01:00,761] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [9.78132683e-16 1.00000000e+00 4.70325301e-18 2.72354014e-18
 1.12298056e-29], sampled 0.6981215080617057
[2019-03-26 16:01:14,696] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10694078], dtype=float32), 0.07146424]
[2019-03-26 16:01:14,697] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.7, 67.0, 1.0, 2.0, 0.5710421030939586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 797979.9052473458, 797979.9052473458, 195475.2896976702]
[2019-03-26 16:01:14,699] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 16:01:14,702] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.9946180e-15 1.0000000e+00 5.8916220e-18 6.9571349e-19 1.5410575e-29], sampled 0.16714422938152285
[2019-03-26 16:01:19,889] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.8607 3007711637.9330 1766.0000
[2019-03-26 16:01:20,132] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8252.1880 2927338418.5362 1338.0000
[2019-03-26 16:01:20,214] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7883.5806 3164351363.5028 1776.0000
[2019-03-26 16:01:20,359] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.3694 2779190338.1949 933.0000
[2019-03-26 16:01:20,437] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.3184 2842623991.1978 1131.0000
[2019-03-26 16:01:21,454] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 900000, evaluation results [900000.0, 7883.580621162545, 3164351363.5028076, 1776.0, 8252.187984735712, 2927338418.5362086, 1338.0, 8661.369356548688, 2779190338.194891, 933.0, 7998.86073322157, 3007711637.9330444, 1766.0, 8497.318449684271, 2842623991.1978283, 1131.0]
[2019-03-26 16:01:21,718] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.6209822e-15 1.0000000e+00 8.7119373e-18 2.7737405e-19 1.2344826e-29], sum to 1.0000
[2019-03-26 16:01:21,724] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3455
[2019-03-26 16:01:21,731] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.71666666666667, 83.16666666666667, 1.0, 2.0, 0.5222250281006039, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 729739.0070281659, 729739.0070281659, 187152.2280137217], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2106600.0000, 
sim time next is 2107200.0000, 
raw observation next is [27.93333333333334, 82.33333333333334, 1.0, 2.0, 0.5247232997634513, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 733231.209425492, 733231.209425492, 187561.110487983], 
processed observation next is [0.0, 0.391304347826087, 0.5229067930489735, 0.8233333333333335, 1.0, 1.0, 0.42737746959451967, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20367533595152554, 0.20367533595152554, 0.27994195595221344], 
reward next is 0.7201, 
noisyNet noise sample is [array([1.2763995], dtype=float32), 0.73200005]. 
=============================================
[2019-03-26 16:01:22,311] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.2782781e-15 1.0000000e+00 2.6115903e-18 2.4075625e-18 1.1313393e-29], sum to 1.0000
[2019-03-26 16:01:22,320] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7516
[2019-03-26 16:01:22,327] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 91.33333333333333, 1.0, 2.0, 0.4519204511806106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 644920.737521176, 644920.7375211767, 178137.1501138371], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1896000.0000, 
sim time next is 1896600.0000, 
raw observation next is [24.45, 91.66666666666667, 1.0, 2.0, 0.4515776399186808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 644592.5742515107, 644592.5742515113, 178107.702219366], 
processed observation next is [1.0, 0.9565217391304348, 0.3578199052132702, 0.9166666666666667, 1.0, 1.0, 0.33925016857672385, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17905349284764185, 0.17905349284764202, 0.26583239137218806], 
reward next is 0.7342, 
noisyNet noise sample is [array([0.84686136], dtype=float32), 0.40977317]. 
=============================================
[2019-03-26 16:01:23,010] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.14172127e-13 1.00000000e+00 8.15248936e-16 4.62675213e-14
 1.25347995e-26], sum to 1.0000
[2019-03-26 16:01:23,013] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4915
[2019-03-26 16:01:23,020] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.88333333333333, 90.5, 1.0, 2.0, 0.4203797816618292, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 617110.0769192945, 617110.0769192945, 175860.9917961153], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1966200.0000, 
sim time next is 1966800.0000, 
raw observation next is [23.76666666666667, 91.0, 1.0, 2.0, 0.4171357845435575, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 613512.9860393727, 613512.9860393734, 175550.7873324743], 
processed observation next is [1.0, 0.782608695652174, 0.32543443917851517, 0.91, 1.0, 1.0, 0.2977539572813946, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17042027389982575, 0.17042027389982595, 0.2620161004962303], 
reward next is 0.7380, 
noisyNet noise sample is [array([-1.4076086], dtype=float32), 0.8998892]. 
=============================================
[2019-03-26 16:01:27,495] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.3571637e-15 1.0000000e+00 6.2807208e-18 6.0619232e-18 4.7726106e-29], sum to 1.0000
[2019-03-26 16:01:27,503] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5515
[2019-03-26 16:01:27,508] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 96.5, 1.0, 2.0, 0.4148082964729517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 610197.1089894206, 610197.1089894206, 175239.8477476627], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1978200.0000, 
sim time next is 1978800.0000, 
raw observation next is [23.13333333333333, 96.66666666666666, 1.0, 2.0, 0.4178358495282614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 613399.0595182208, 613399.0595182214, 175507.790073486], 
processed observation next is [1.0, 0.9130434782608695, 0.29541864139020524, 0.9666666666666666, 1.0, 1.0, 0.2985974090701945, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17038862764395024, 0.17038862764395038, 0.26195192548281493], 
reward next is 0.7380, 
noisyNet noise sample is [array([0.28533518], dtype=float32), -0.60274446]. 
=============================================
[2019-03-26 16:01:29,907] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0345698e-14 1.0000000e+00 7.0466160e-18 4.1421260e-19 5.5213505e-29], sum to 1.0000
[2019-03-26 16:01:29,919] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1510
[2019-03-26 16:01:29,923] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.56666666666667, 94.0, 1.0, 2.0, 0.505891989172379, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 706908.1948985324, 706908.194898533, 184524.5759677409], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2020800.0000, 
sim time next is 2021400.0000, 
raw observation next is [25.55, 94.0, 1.0, 2.0, 0.5061863276668502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 707319.625740364, 707319.6257403634, 184571.1629275885], 
processed observation next is [0.0, 0.391304347826087, 0.40995260663507116, 0.94, 1.0, 1.0, 0.4050437682733135, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19647767381676776, 0.19647767381676762, 0.27547934765311716], 
reward next is 0.7245, 
noisyNet noise sample is [array([-0.3246656], dtype=float32), 0.56075037]. 
=============================================
[2019-03-26 16:01:36,365] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.9741117e-15 1.0000000e+00 5.9925571e-18 2.2314186e-18 3.0882777e-29], sum to 1.0000
[2019-03-26 16:01:36,375] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5570
[2019-03-26 16:01:36,382] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.06666666666666, 75.66666666666666, 1.0, 2.0, 0.5661459106881557, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 791135.3693099535, 791135.3693099535, 194608.8102520434], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2137200.0000, 
sim time next is 2137800.0000, 
raw observation next is [29.88333333333333, 76.33333333333334, 1.0, 2.0, 0.5653684545235572, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 790048.5438035389, 790048.5438035389, 194471.7247832766], 
processed observation next is [0.0, 0.7391304347826086, 0.6153238546603473, 0.7633333333333334, 1.0, 1.0, 0.4763475355705508, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21945792883431636, 0.21945792883431636, 0.2902563056466815], 
reward next is 0.7097, 
noisyNet noise sample is [array([-1.0480064], dtype=float32), -0.06404259]. 
=============================================
[2019-03-26 16:01:37,680] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.8341251e-14 1.0000000e+00 1.0145545e-16 1.1937740e-16 7.8022973e-27], sum to 1.0000
[2019-03-26 16:01:37,688] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7339
[2019-03-26 16:01:37,694] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.6, 88.66666666666667, 1.0, 2.0, 0.6527409758815224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 912195.7474786133, 912195.7474786133, 210974.1382841424], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2184000.0000, 
sim time next is 2184600.0000, 
raw observation next is [26.8, 87.83333333333333, 1.0, 2.0, 0.6433061124819769, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 899005.0866422273, 899005.0866422273, 209083.0829255941], 
processed observation next is [1.0, 0.2608695652173913, 0.4691943127962086, 0.8783333333333333, 1.0, 1.0, 0.5702483282915384, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.24972363517839646, 0.24972363517839646, 0.31206430287402104], 
reward next is 0.6879, 
noisyNet noise sample is [array([-0.83736587], dtype=float32), 1.9653591]. 
=============================================
[2019-03-26 16:01:57,702] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.2604691e-14 1.0000000e+00 7.0962263e-17 8.6727529e-16 9.4611087e-28], sum to 1.0000
[2019-03-26 16:01:57,711] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7895
[2019-03-26 16:01:57,719] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.98333333333333, 93.0, 1.0, 2.0, 0.5552882462485712, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 775957.2680658587, 775957.2680658587, 192711.916653557], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2491800.0000, 
sim time next is 2492400.0000, 
raw observation next is [26.96666666666667, 93.0, 1.0, 2.0, 0.5563324514544964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 777416.9696505311, 777416.9696505311, 192892.673262696], 
processed observation next is [1.0, 0.8695652173913043, 0.47709320695102697, 0.93, 1.0, 1.0, 0.46546078488493536, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21594915823625863, 0.21594915823625863, 0.2878995123323821], 
reward next is 0.7121, 
noisyNet noise sample is [array([-1.219938], dtype=float32), -0.43331528]. 
=============================================
[2019-03-26 16:01:59,867] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.8365201e-14 1.0000000e+00 2.8359159e-17 3.5452772e-17 2.0144950e-27], sum to 1.0000
[2019-03-26 16:01:59,877] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5163
[2019-03-26 16:01:59,886] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.4581022426458296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 683473.5253452257, 683473.5253452263, 182696.7856311444], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3070800.0000, 
sim time next is 3071400.0000, 
raw observation next is [23.0, 95.0, 1.0, 2.0, 0.5296480638879271, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 787887.8744350799, 787887.8744350792, 194310.1199839892], 
processed observation next is [1.0, 0.5652173913043478, 0.28909952606635075, 0.95, 1.0, 1.0, 0.43331092034690005, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2188577428986333, 0.2188577428986331, 0.2900151044537152], 
reward next is 0.7100, 
noisyNet noise sample is [array([-0.4471541], dtype=float32), 0.2031266]. 
=============================================
[2019-03-26 16:02:00,151] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.1574370e-15 1.0000000e+00 3.7295316e-18 2.1728207e-18 2.6998366e-29], sum to 1.0000
[2019-03-26 16:02:00,161] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8992
[2019-03-26 16:02:00,167] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.3466114755863642, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 533945.5494993416, 533945.5494993416, 169321.0441365112], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2763000.0000, 
sim time next is 2763600.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.34953729368586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 538453.7168682074, 538453.7168682081, 169689.5798246755], 
processed observation next is [0.0, 1.0, 0.2417061611374408, 0.94, 1.0, 1.0, 0.2163099923926024, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1495704769078354, 0.1495704769078356, 0.2532680295890679], 
reward next is 0.7467, 
noisyNet noise sample is [array([0.820852], dtype=float32), 0.42705384]. 
=============================================
[2019-03-26 16:02:02,012] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.7625966e-14 1.0000000e+00 6.7786584e-17 4.9950316e-16 2.1502356e-26], sum to 1.0000
[2019-03-26 16:02:02,019] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6718
[2019-03-26 16:02:02,027] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 90.0, 1.0, 2.0, 0.632583246504928, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 968802.9882136934, 968802.9882136927, 217419.3970134303], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2890800.0000, 
sim time next is 2891400.0000, 
raw observation next is [22.75, 89.83333333333333, 1.0, 2.0, 0.7239476025630669, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1107836.51087096, 1107836.51087096, 238384.3031321589], 
processed observation next is [1.0, 0.4782608695652174, 0.27725118483412325, 0.8983333333333333, 1.0, 1.0, 0.6674067500759842, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3077323641308222, 0.3077323641308222, 0.3557974673614312], 
reward next is 0.6442, 
noisyNet noise sample is [array([-0.98082536], dtype=float32), -0.9664885]. 
=============================================
[2019-03-26 16:02:02,939] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.8630733e-14 1.0000000e+00 7.9957429e-18 6.1360473e-18 6.0431878e-29], sum to 1.0000
[2019-03-26 16:02:02,951] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7989
[2019-03-26 16:02:02,958] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666667, 82.33333333333334, 1.0, 2.0, 0.4869201134928406, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 680389.353542873, 680389.3535428736, 181572.1421513857], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2647200.0000, 
sim time next is 2647800.0000, 
raw observation next is [26.5, 84.0, 1.0, 2.0, 0.4886596575628824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 682820.8564156874, 682820.856415688, 181838.4814686216], 
processed observation next is [0.0, 0.6521739130434783, 0.4549763033175356, 0.84, 1.0, 1.0, 0.383927298268533, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1896724601154687, 0.18967246011546887, 0.271400718609883], 
reward next is 0.7286, 
noisyNet noise sample is [array([0.28001744], dtype=float32), 1.0539056]. 
=============================================
[2019-03-26 16:02:02,998] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.7392568e-15 1.0000000e+00 6.4434167e-17 4.1416425e-16 1.4456389e-26], sum to 1.0000
[2019-03-26 16:02:03,005] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3299
[2019-03-26 16:02:03,014] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 91.5, 1.0, 2.0, 0.691377519829407, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1058189.701077414, 1058189.701077414, 230590.0933971494], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2907000.0000, 
sim time next is 2907600.0000, 
raw observation next is [22.33333333333334, 92.33333333333334, 1.0, 2.0, 0.6938240014645728, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1063880.020833004, 1063880.020833004, 231383.7439126078], 
processed observation next is [1.0, 0.6521739130434783, 0.2575039494470777, 0.9233333333333335, 1.0, 1.0, 0.6311132547765937, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2955222280091678, 0.2955222280091678, 0.34534887151135496], 
reward next is 0.6547, 
noisyNet noise sample is [array([0.14647579], dtype=float32), 0.3539356]. 
=============================================
[2019-03-26 16:02:06,486] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.6233348e-15 1.0000000e+00 3.5200216e-18 1.5843360e-18 2.6673037e-29], sum to 1.0000
[2019-03-26 16:02:06,495] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7749
[2019-03-26 16:02:06,501] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 82.33333333333334, 1.0, 2.0, 0.495270425329538, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 692061.3174084985, 692061.3174084985, 182858.6997948849], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2637600.0000, 
sim time next is 2638200.0000, 
raw observation next is [27.0, 83.16666666666666, 1.0, 2.0, 0.499595863403963, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 698107.4123252076, 698107.4123252076, 183533.1453478362], 
processed observation next is [0.0, 0.5217391304347826, 0.4786729857819906, 0.8316666666666666, 1.0, 1.0, 0.39710344988429275, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.193918725645891, 0.193918725645891, 0.2739300676833376], 
reward next is 0.7261, 
noisyNet noise sample is [array([-2.0122879], dtype=float32), -0.35950664]. 
=============================================
[2019-03-26 16:02:07,564] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2709118e-15 1.0000000e+00 6.2255443e-19 1.1080507e-18 4.0406909e-30], sum to 1.0000
[2019-03-26 16:02:07,572] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1621
[2019-03-26 16:02:07,576] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.3930336420206463, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 586467.0610255925, 586467.0610255925, 173294.4695076119], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2733600.0000, 
sim time next is 2734200.0000, 
raw observation next is [23.0, 94.0, 1.0, 2.0, 0.393498388311652, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 587159.3775001465, 587159.3775001465, 173357.6295001984], 
processed observation next is [0.0, 0.6521739130434783, 0.28909952606635075, 0.94, 1.0, 1.0, 0.26927516664054457, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16309982708337403, 0.16309982708337403, 0.25874273059731107], 
reward next is 0.7413, 
noisyNet noise sample is [array([1.6475209], dtype=float32), 0.653666]. 
=============================================
[2019-03-26 16:02:09,230] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.4638702e-15 1.0000000e+00 1.4892270e-17 1.0901238e-17 5.9771159e-28], sum to 1.0000
[2019-03-26 16:02:09,238] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6986
[2019-03-26 16:02:09,242] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.3045042132623334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 484905.0750497521, 484905.0750497521, 165974.590092472], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3014400.0000, 
sim time next is 3015000.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.3045115160978191, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 484916.7636848349, 484916.7636848342, 165975.4354292633], 
processed observation next is [1.0, 0.9130434782608695, 0.1469194312796209, 1.0, 1.0, 1.0, 0.16206206758773387, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13469910102356525, 0.13469910102356505, 0.24772453049143778], 
reward next is 0.7523, 
noisyNet noise sample is [array([0.4090034], dtype=float32), -1.0937773]. 
=============================================
[2019-03-26 16:02:09,251] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[72.759285]
 [72.73528 ]
 [72.66948 ]
 [72.64988 ]
 [72.63247 ]], R is [[72.81236267]
 [72.8365097 ]
 [72.86039734]
 [72.88404083]
 [72.90745544]].
[2019-03-26 16:02:14,581] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.1387965e-14 1.0000000e+00 1.0816657e-16 4.0838436e-17 3.1619862e-28], sum to 1.0000
[2019-03-26 16:02:14,587] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9422
[2019-03-26 16:02:14,596] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 96.0, 1.0, 2.0, 0.337116271885331, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 520451.6342583667, 520451.6342583673, 168272.3744305947], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2776800.0000, 
sim time next is 2777400.0000, 
raw observation next is [21.5, 97.0, 1.0, 2.0, 0.3334609077491934, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 515505.4628424659, 515505.4628424659, 167904.5039443714], 
processed observation next is [1.0, 0.13043478260869565, 0.21800947867298584, 0.97, 1.0, 1.0, 0.19694085270987158, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14319596190068498, 0.14319596190068498, 0.2506037372304051], 
reward next is 0.7494, 
noisyNet noise sample is [array([1.0992424], dtype=float32), -0.25783825]. 
=============================================
[2019-03-26 16:02:16,560] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-26 16:02:16,562] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 16:02:16,562] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 16:02:16,564] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:02:16,563] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 16:02:16,565] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:02:16,566] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 16:02:16,567] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:02:16,567] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 16:02:16,569] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:02:16,569] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:02:16,594] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run38
[2019-03-26 16:02:16,595] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run38
[2019-03-26 16:02:16,612] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run38
[2019-03-26 16:02:16,612] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run38
[2019-03-26 16:02:16,633] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run38
[2019-03-26 16:02:55,822] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10442044], dtype=float32), 0.071420215]
[2019-03-26 16:02:55,825] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.87384351, 81.86086679, 1.0, 2.0, 0.513023291354748, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 716876.4828179842, 716876.4828179842, 185660.5215928023]
[2019-03-26 16:02:55,827] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 16:02:55,829] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.7068880e-15 1.0000000e+00 4.2440458e-18 8.3403649e-19 1.4006995e-29], sampled 0.4170623781210391
[2019-03-26 16:03:26,499] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10442044], dtype=float32), 0.071420215]
[2019-03-26 16:03:26,500] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.39013835, 70.450271145, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.242265872417785, 6.9112, 168.9110546021311, 1688782.664236546, 1453915.784494524, 311349.0666904444]
[2019-03-26 16:03:26,500] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 16:03:26,502] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [5.8748784e-11 1.0000000e+00 9.6958466e-12 2.9812242e-09 2.3409687e-19], sampled 0.6881132908716673
[2019-03-26 16:03:26,503] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1688782.664236546 W.
[2019-03-26 16:03:26,715] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10442044], dtype=float32), 0.071420215]
[2019-03-26 16:03:26,715] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.06666666666667, 79.16666666666667, 1.0, 2.0, 0.6367036580665152, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 889774.4476904591, 889774.4476904591, 207782.9923298054]
[2019-03-26 16:03:26,716] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 16:03:26,718] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [5.2427020e-16 1.0000000e+00 3.0054063e-18 6.1107496e-18 3.4574257e-30], sampled 0.604188388355621
[2019-03-26 16:03:42,149] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10442044], dtype=float32), 0.071420215]
[2019-03-26 16:03:42,152] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [27.18333333333333, 93.5, 1.0, 2.0, 0.7051616802285355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 985486.8865286118, 985486.8865286123, 221965.6773864901]
[2019-03-26 16:03:42,153] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:03:42,156] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.8386465e-15 1.0000000e+00 1.1626595e-17 4.8497744e-18 8.6656514e-29], sampled 0.8414470553078143
[2019-03-26 16:03:42,470] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10442044], dtype=float32), 0.071420215]
[2019-03-26 16:03:42,472] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.45479182666667, 82.23546844666666, 1.0, 2.0, 0.5640487568935214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 788203.7078744586, 788203.7078744586, 194238.5275721911]
[2019-03-26 16:03:42,475] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 16:03:42,478] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [5.7124971e-16 1.0000000e+00 2.4042402e-18 2.8117745e-18 3.3057248e-30], sampled 0.33567272747663435
[2019-03-26 16:03:45,543] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10442044], dtype=float32), 0.071420215]
[2019-03-26 16:03:45,545] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.14765042666667, 94.16658976, 1.0, 2.0, 0.5958094808033222, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 832603.6499779972, 832603.6499779979, 199960.614739412]
[2019-03-26 16:03:45,546] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 16:03:45,549] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.6709180e-15 1.0000000e+00 1.1618260e-17 3.6138760e-18 1.0999298e-28], sampled 0.10408950184180776
[2019-03-26 16:03:59,397] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10442044], dtype=float32), 0.071420215]
[2019-03-26 16:03:59,400] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.8, 89.0, 1.0, 2.0, 0.5763088049091502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 805342.4367698091, 805342.4367698084, 196409.3213774699]
[2019-03-26 16:03:59,402] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:03:59,404] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.1723034e-15 1.0000000e+00 1.8326541e-17 7.2899891e-18 2.4123491e-28], sampled 0.953441648578837
[2019-03-26 16:04:07,421] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10442044], dtype=float32), 0.071420215]
[2019-03-26 16:04:07,423] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.4, 85.33333333333334, 1.0, 2.0, 0.4953321174589059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 692147.5503904558, 692147.5503904558, 182867.9319834963]
[2019-03-26 16:04:07,426] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:04:07,428] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.6408225e-15 1.0000000e+00 1.1349253e-17 5.9275333e-18 1.5160499e-28], sampled 0.3091073183840234
[2019-03-26 16:04:09,724] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.3273 2927391892.5307 1338.0000
[2019-03-26 16:04:09,814] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7883.0863 3164481195.8555 1773.0000
[2019-03-26 16:04:10,021] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.4308 2779149198.4617 933.0000
[2019-03-26 16:04:10,051] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.6640 2842632297.7926 1131.0000
[2019-03-26 16:04:10,114] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.5735 3007648438.5815 1766.0000
[2019-03-26 16:04:11,130] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 925000, evaluation results [925000.0, 7883.0862798145445, 3164481195.855466, 1773.0, 8254.327253941756, 2927391892.530706, 1338.0, 8661.430759135581, 2779149198.4616733, 933.0, 7997.573465804901, 3007648438.5815053, 1766.0, 8496.663997866628, 2842632297.792627, 1131.0]
[2019-03-26 16:04:14,844] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.2421682e-14 1.0000000e+00 5.2976432e-17 4.4340865e-17 1.1856211e-27], sum to 1.0000
[2019-03-26 16:04:14,853] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6159
[2019-03-26 16:04:14,858] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.3445782197527655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 530816.2143129116, 530816.2143129123, 169067.0264720253], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2874000.0000, 
sim time next is 2874600.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.3496208299396052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 538583.736769365, 538583.7367693643, 169700.2904138055], 
processed observation next is [1.0, 0.2608695652173913, 0.2417061611374408, 0.94, 1.0, 1.0, 0.21641063848145203, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14960659354704584, 0.14960659354704564, 0.2532840155429933], 
reward next is 0.7467, 
noisyNet noise sample is [array([1.0750515], dtype=float32), 0.78444356]. 
=============================================
[2019-03-26 16:04:15,803] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.3248879e-11 9.9999988e-01 1.4064331e-11 6.7679402e-08 1.1680454e-20], sum to 1.0000
[2019-03-26 16:04:15,811] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9994
[2019-03-26 16:04:15,815] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 70.0, 1.0, 2.0, 0.5342107793664643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 746493.362137565, 746493.3621375657, 189132.3836544046], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3433800.0000, 
sim time next is 3434400.0000, 
raw observation next is [31.0, 70.0, 1.0, 2.0, 0.5394196110894326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 753774.6415356724, 753774.641535673, 190004.9813101066], 
processed observation next is [1.0, 0.782608695652174, 0.6682464454976303, 0.7, 1.0, 1.0, 0.4450838687824489, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2093818448710201, 0.2093818448710203, 0.2835895243434427], 
reward next is 0.7164, 
noisyNet noise sample is [array([0.6741833], dtype=float32), -1.0960385]. 
=============================================
[2019-03-26 16:04:24,228] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.10123075e-14 1.00000000e+00 6.16777827e-17 2.54571699e-18
 1.18256697e-28], sum to 1.0000
[2019-03-26 16:04:24,237] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9530
[2019-03-26 16:04:24,242] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.0, 1.0, 2.0, 0.3072393866141007, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 486032.5584057404, 486032.558405741, 165997.7728645652], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3038400.0000, 
sim time next is 3039000.0000, 
raw observation next is [21.0, 95.0, 1.0, 2.0, 0.3072213973422602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 484896.8313961297, 484896.8313961304, 165889.6080298697], 
processed observation next is [1.0, 0.17391304347826086, 0.19431279620853087, 0.95, 1.0, 1.0, 0.1653269847497111, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13469356427670268, 0.13469356427670287, 0.24759642989532793], 
reward next is 0.7524, 
noisyNet noise sample is [array([-2.1134133], dtype=float32), 0.2650946]. 
=============================================
[2019-03-26 16:04:24,263] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[71.89162]
 [71.93834]
 [72.03166]
 [72.09048]
 [72.07446]], R is [[71.8647995 ]
 [71.89839172]
 [71.93175507]
 [71.96490479]
 [71.99775696]].
[2019-03-26 16:04:29,890] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.0865820e-15 1.0000000e+00 7.7958510e-17 3.6018526e-15 5.8422490e-26], sum to 1.0000
[2019-03-26 16:04:29,898] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3007
[2019-03-26 16:04:29,909] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1700050.750542538 W.
[2019-03-26 16:04:29,914] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.16666666666667, 84.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.258139185992692, 6.9112, 168.9106585972182, 1700050.750542538, 1453923.499665863, 311346.7066446944], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3165000.0000, 
sim time next is 3165600.0000, 
raw observation next is [26.33333333333334, 84.0, 1.0, 2.0, 0.3670756045091874, 1.0, 1.0, 0.3670756045091874, 1.0, 1.0, 0.6189928215993247, 6.911199999999999, 6.9112, 170.5573041426782, 1539391.59241472, 1539391.59241472, 333021.0021144766], 
processed observation next is [1.0, 0.6521739130434783, 0.44707740916271754, 0.84, 1.0, 1.0, 0.23744048736046677, 1.0, 0.5, 0.23744048736046677, 1.0, 0.5, 0.5353570995113716, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.42760877567075556, 0.42760877567075556, 0.4970462718126516], 
reward next is 0.5030, 
noisyNet noise sample is [array([0.9055639], dtype=float32), -0.7413474]. 
=============================================
[2019-03-26 16:04:33,525] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.1486824e-15 1.0000000e+00 9.6179599e-18 1.1747867e-16 1.9597152e-28], sum to 1.0000
[2019-03-26 16:04:33,534] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2143
[2019-03-26 16:04:33,539] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.4862856898744213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 679502.5692020772, 679502.5692020766, 181475.2182603159], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3199800.0000, 
sim time next is 3200400.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.4859197774397443, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 678991.1046314024, 678991.1046314024, 181419.4148364319], 
processed observation next is [0.0, 0.043478260869565216, 0.38388625592417064, 0.94, 1.0, 1.0, 0.38062623787921, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18860864017538956, 0.18860864017538956, 0.27077524602452524], 
reward next is 0.7292, 
noisyNet noise sample is [array([-0.06706323], dtype=float32), 0.8213957]. 
=============================================
[2019-03-26 16:04:35,336] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.1751920e-16 1.0000000e+00 2.9626179e-18 1.5862401e-19 8.3849152e-30], sum to 1.0000
[2019-03-26 16:04:35,346] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5176
[2019-03-26 16:04:35,352] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.5, 76.5, 1.0, 2.0, 0.4813187504993471, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 672559.9086517622, 672559.9086517622, 180721.0391912017], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3227400.0000, 
sim time next is 3228000.0000, 
raw observation next is [27.66666666666666, 75.66666666666666, 1.0, 2.0, 0.4819381726124791, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 673425.7185285833, 673425.7185285833, 180814.7536619801], 
processed observation next is [0.0, 0.34782608695652173, 0.5102685624012636, 0.7566666666666666, 1.0, 1.0, 0.37582912362949294, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18706269959127314, 0.18706269959127314, 0.2698727666596718], 
reward next is 0.7301, 
noisyNet noise sample is [array([0.06679974], dtype=float32), 0.7925319]. 
=============================================
[2019-03-26 16:04:35,363] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[75.09787 ]
 [75.10075 ]
 [75.1091  ]
 [75.096214]
 [75.09151 ]], R is [[75.07441711]
 [75.05394745]
 [75.03392792]
 [75.01451874]
 [74.99565887]].
[2019-03-26 16:04:37,502] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.8315438e-16 1.0000000e+00 1.4793403e-18 8.8723856e-18 7.4893435e-30], sum to 1.0000
[2019-03-26 16:04:37,512] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3154
[2019-03-26 16:04:37,518] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.33333333333333, 82.33333333333334, 1.0, 2.0, 0.5482050241216667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 766055.6364621427, 766055.6364621427, 191493.4416566957], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3267600.0000, 
sim time next is 3268200.0000, 
raw observation next is [28.16666666666667, 83.16666666666666, 1.0, 2.0, 0.5466986700205162, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 763949.9169458079, 763949.9169458079, 191236.2476275458], 
processed observation next is [0.0, 0.8260869565217391, 0.5339652448657191, 0.8316666666666666, 1.0, 1.0, 0.4538538193018267, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2122083102627244, 0.2122083102627244, 0.2854272352649937], 
reward next is 0.7146, 
noisyNet noise sample is [array([-0.92452675], dtype=float32), -2.9840806]. 
=============================================
[2019-03-26 16:04:39,960] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.9826198e-15 1.0000000e+00 2.2123998e-17 1.4147932e-18 1.5106348e-28], sum to 1.0000
[2019-03-26 16:04:39,973] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5980
[2019-03-26 16:04:39,980] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 83.0, 1.0, 2.0, 0.4210350578213153, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 616474.9472071078, 616474.9472071084, 175755.7255499691], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3303600.0000, 
sim time next is 3304200.0000, 
raw observation next is [25.0, 83.0, 1.0, 2.0, 0.4209428935094727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 616340.1499663205, 616340.1499663205, 175742.8214674003], 
processed observation next is [0.0, 0.21739130434782608, 0.38388625592417064, 0.83, 1.0, 1.0, 0.30234083555358165, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1712055972128668, 0.1712055972128668, 0.26230271860806015], 
reward next is 0.7377, 
noisyNet noise sample is [array([1.6766059], dtype=float32), 1.3097694]. 
=============================================
[2019-03-26 16:04:45,885] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.0281767e-09 9.9992168e-01 2.9688876e-09 7.8339966e-05 3.4198396e-14], sum to 1.0000
[2019-03-26 16:04:45,893] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6746
[2019-03-26 16:04:45,900] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2110811.602567621 W.
[2019-03-26 16:04:45,908] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.83333333333334, 70.83333333333333, 1.0, 2.0, 0.7547992138951912, 1.0, 2.0, 0.7547992138951912, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2110811.602567621, 2110811.602567621, 398469.4905254321], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3405000.0000, 
sim time next is 3405600.0000, 
raw observation next is [31.0, 70.0, 1.0, 2.0, 0.5482075014778531, 1.0, 2.0, 0.5482075014778531, 1.0, 1.0, 0.9520551350759422, 6.911199999999999, 6.9112, 170.5573041426782, 2299799.731538553, 2299799.731538554, 450083.3001272223], 
processed observation next is [1.0, 0.43478260869565216, 0.6682464454976303, 0.7, 1.0, 1.0, 0.45567168852753387, 1.0, 1.0, 0.45567168852753387, 1.0, 0.5, 0.9415306525316367, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6388332587607091, 0.6388332587607095, 0.6717661195928691], 
reward next is 0.3282, 
noisyNet noise sample is [array([-0.84067154], dtype=float32), -1.0622381]. 
=============================================
[2019-03-26 16:04:49,252] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.4459539e-14 1.0000000e+00 2.0364019e-17 1.8475714e-16 7.2153671e-27], sum to 1.0000
[2019-03-26 16:04:49,258] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5403
[2019-03-26 16:04:49,263] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.5016900063401247, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 701034.6165113848, 701034.6165113841, 183861.1716263127], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3463200.0000, 
sim time next is 3463800.0000, 
raw observation next is [26.16666666666667, 87.33333333333334, 1.0, 2.0, 0.9440242841929092, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1319512.732405236, 1319512.732405236, 282332.0423234189], 
processed observation next is [1.0, 0.08695652173913043, 0.4391785150078992, 0.8733333333333334, 1.0, 1.0, 0.9325593785456737, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.36653131455701, 0.36653131455701, 0.42139110794540136], 
reward next is 0.5786, 
noisyNet noise sample is [array([0.12086292], dtype=float32), 0.0021134932]. 
=============================================
[2019-03-26 16:04:50,354] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.5900397e-14 1.0000000e+00 5.2378016e-17 3.0199012e-16 1.7219398e-26], sum to 1.0000
[2019-03-26 16:04:50,368] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1960
[2019-03-26 16:04:50,375] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 75.66666666666666, 1.0, 2.0, 0.8415241081692422, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1176163.451920618, 1176163.451920618, 254356.2268265564], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3483600.0000, 
sim time next is 3484200.0000, 
raw observation next is [28.0, 74.83333333333334, 1.0, 2.0, 0.8107814939858168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1133172.843484096, 1133172.843484096, 246571.6962283344], 
processed observation next is [1.0, 0.30434782608695654, 0.5260663507109005, 0.7483333333333334, 1.0, 1.0, 0.772025896368454, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.31477023430113776, 0.31477023430113776, 0.3680174570572155], 
reward next is 0.6320, 
noisyNet noise sample is [array([-0.18191189], dtype=float32), -0.7109847]. 
=============================================
[2019-03-26 16:04:55,858] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.03297296e-07 9.79879141e-01 1.05232033e-07 2.01206598e-02
 2.86352175e-11], sum to 1.0000
[2019-03-26 16:04:55,865] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2773
[2019-03-26 16:04:55,873] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2201724.93044996 W.
[2019-03-26 16:04:55,879] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.0, 68.0, 1.0, 2.0, 0.5248501864967065, 1.0, 2.0, 0.5248501864967065, 1.0, 1.0, 0.9114912033357903, 6.9112, 6.9112, 170.5573041426782, 2201724.93044996, 2201724.93044996, 432755.548664294], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3580200.0000, 
sim time next is 3580800.0000, 
raw observation next is [31.0, 68.66666666666667, 1.0, 2.0, 0.9797479492612532, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 7.001171948330664, 6.9112, 168.9124212267372, 2266655.927205641, 2202826.93273856, 457314.2457067004], 
processed observation next is [1.0, 0.43478260869565216, 0.6682464454976303, 0.6866666666666668, 1.0, 1.0, 0.9755999388689798, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.008997194833066402, 0.0, 0.8294373166643122, 0.6296266464460113, 0.6118963702051555, 0.6825585756816425], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.44074535], dtype=float32), -1.6655214]. 
=============================================
[2019-03-26 16:04:59,771] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.3278163e-15 1.0000000e+00 1.9603467e-17 3.4935400e-15 3.1533614e-28], sum to 1.0000
[2019-03-26 16:04:59,782] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6216
[2019-03-26 16:04:59,789] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.83333333333334, 74.83333333333334, 1.0, 2.0, 0.5250013921539649, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 733619.94084384, 733619.9408438393, 187605.9176718834], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3701400.0000, 
sim time next is 3702000.0000, 
raw observation next is [28.66666666666667, 75.66666666666667, 1.0, 2.0, 0.5240767536253047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 732327.4355252552, 732327.4355252557, 187454.3107003784], 
processed observation next is [1.0, 0.8695652173913043, 0.5576619273301741, 0.7566666666666667, 1.0, 1.0, 0.4265984983437406, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2034242876459042, 0.20342428764590437, 0.27978255328414686], 
reward next is 0.7202, 
noisyNet noise sample is [array([-0.12325531], dtype=float32), 1.596267]. 
=============================================
[2019-03-26 16:04:59,812] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[74.635086]
 [75.15212 ]
 [75.17757 ]
 [74.777336]
 [74.089806]], R is [[74.25222778]
 [74.22969818]
 [74.20716095]
 [74.18365479]
 [74.15909576]].
[2019-03-26 16:05:00,821] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.26368515e-14 1.00000000e+00 2.64236626e-17 1.69782884e-15
 1.59284375e-26], sum to 1.0000
[2019-03-26 16:05:00,829] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7856
[2019-03-26 16:05:00,833] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 70.66666666666667, 1.0, 2.0, 0.8983964366072466, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1255698.557909694, 1255698.557909695, 269494.8043879569], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3658200.0000, 
sim time next is 3658800.0000, 
raw observation next is [29.0, 71.33333333333334, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 9.506414680963704, 6.9112, 168.8981974579482, 3295882.319507225, 1454908.576656296, 307864.9356635855], 
processed observation next is [1.0, 0.34782608695652173, 0.5734597156398105, 0.7133333333333334, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.25952146809637044, 0.0, 0.8293674714478887, 0.9155228665297848, 0.40414127129341554, 0.4594999039755007], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8554696], dtype=float32), 0.39738646]. 
=============================================
[2019-03-26 16:05:00,851] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.4303151e-12 1.0000000e+00 2.3440321e-13 1.1564400e-10 3.1346765e-20], sum to 1.0000
[2019-03-26 16:05:00,861] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7140
[2019-03-26 16:05:00,875] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1982211.426894278 W.
[2019-03-26 16:05:00,882] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 73.33333333333334, 1.0, 2.0, 0.77651904643552, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.980249473969214, 6.9112, 168.9125453743722, 1982211.426894278, 1933225.472793692, 403036.6017715411], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3660600.0000, 
sim time next is 3661200.0000, 
raw observation next is [29.0, 74.0, 1.0, 2.0, 0.7833369860059791, 1.0, 1.0, 0.7833369860059791, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2190699.680539191, 2190699.680539191, 411835.2144553283], 
processed observation next is [1.0, 0.391304347826087, 0.5734597156398105, 0.74, 1.0, 1.0, 0.7389602241035893, 1.0, 0.5, 0.7389602241035893, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.608527689038664, 0.608527689038664, 0.6146794245601915], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2120775], dtype=float32), 2.3926692]. 
=============================================
[2019-03-26 16:05:03,910] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.2163317e-15 1.0000000e+00 1.3738937e-17 6.0228373e-16 5.1830561e-27], sum to 1.0000
[2019-03-26 16:05:03,918] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8521
[2019-03-26 16:05:03,926] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 74.0, 1.0, 2.0, 0.4975647508796914, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 695268.3200912824, 695268.320091283, 183214.8986190758], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3708000.0000, 
sim time next is 3708600.0000, 
raw observation next is [28.0, 74.0, 1.0, 2.0, 0.4953545255053409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 692178.8722590733, 692178.872259074, 182871.0488825453], 
processed observation next is [1.0, 0.9565217391304348, 0.5260663507109005, 0.74, 1.0, 1.0, 0.39199340422330237, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1922719089608537, 0.1922719089608539, 0.27294186400379894], 
reward next is 0.7271, 
noisyNet noise sample is [array([-0.32677624], dtype=float32), 0.17868996]. 
=============================================
[2019-03-26 16:05:06,327] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-26 16:05:06,328] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 16:05:06,329] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:05:06,330] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 16:05:06,333] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 16:05:06,336] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 16:05:06,335] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:05:06,336] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 16:05:06,339] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:05:06,338] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:05:06,340] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:05:06,357] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run39
[2019-03-26 16:05:06,377] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run39
[2019-03-26 16:05:06,378] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run39
[2019-03-26 16:05:06,378] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run39
[2019-03-26 16:05:06,414] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run39
[2019-03-26 16:05:09,254] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10834838], dtype=float32), 0.068246655]
[2019-03-26 16:05:09,256] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [21.02874222, 96.08524239, 1.0, 2.0, 0.4659796561806878, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 735029.5324833832, 735029.5324833826, 188130.384268754]
[2019-03-26 16:05:09,259] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 16:05:09,260] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [4.0367007e-15 1.0000000e+00 5.3420829e-18 1.1165630e-17 5.2009781e-28], sampled 0.6694008412897878
[2019-03-26 16:05:13,287] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10834838], dtype=float32), 0.068246655]
[2019-03-26 16:05:13,288] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [19.23675515666667, 82.21862211666667, 1.0, 2.0, 0.235052483418482, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 391013.9039824528, 391013.9039824534, 159090.1851209414]
[2019-03-26 16:05:13,289] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 16:05:13,293] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.2564616e-15 1.0000000e+00 3.2605834e-18 4.3229671e-18 2.0703456e-28], sampled 0.27408546540833845
[2019-03-26 16:05:13,880] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10834838], dtype=float32), 0.068246655]
[2019-03-26 16:05:13,882] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [18.80483681666666, 87.67804460833334, 1.0, 2.0, 0.2402321914087857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 397780.7693922079, 397780.7693922073, 159831.2497286808]
[2019-03-26 16:05:13,884] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 16:05:13,886] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [9.2350960e-15 1.0000000e+00 1.0267442e-17 6.5036430e-18 1.0920328e-27], sampled 0.9699193076180579
[2019-03-26 16:05:18,541] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10834838], dtype=float32), 0.068246655]
[2019-03-26 16:05:18,541] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [19.29063416, 92.22211262, 1.0, 2.0, 0.273829660517161, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 447917.3109639993, 447917.3109639993, 163337.7096743411]
[2019-03-26 16:05:18,542] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 16:05:18,544] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.6356038e-15 1.0000000e+00 1.5822221e-18 2.9578750e-18 7.1674891e-29], sampled 0.6131531616339321
[2019-03-26 16:05:19,733] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10834838], dtype=float32), 0.068246655]
[2019-03-26 16:05:19,735] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [22.18333333333333, 95.16666666666667, 1.0, 2.0, 0.3782464466167446, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 577008.8621369342, 577008.8621369342, 172818.0809859047]
[2019-03-26 16:05:19,735] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 16:05:19,737] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.5244456e-15 1.0000000e+00 1.4855155e-18 2.2554233e-18 4.7816128e-29], sampled 0.5509595658962017
[2019-03-26 16:05:30,715] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10834838], dtype=float32), 0.068246655]
[2019-03-26 16:05:30,717] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.55, 83.0, 1.0, 2.0, 0.4026209198342081, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 599043.5112038342, 599043.5112038335, 174398.9916814665]
[2019-03-26 16:05:30,718] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 16:05:30,722] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [5.3546594e-15 1.0000000e+00 6.6312332e-18 9.3782950e-18 6.0065330e-28], sampled 0.8008104902612848
[2019-03-26 16:05:45,197] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10834838], dtype=float32), 0.068246655]
[2019-03-26 16:05:45,197] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.0, 80.66666666666667, 1.0, 2.0, 0.4938176322457861, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 690030.6117701499, 690030.6117701493, 182632.9445954108]
[2019-03-26 16:05:45,198] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:05:45,201] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.1949254e-15 1.0000000e+00 2.4821963e-18 5.0005550e-18 1.2012813e-28], sampled 0.7501988974187429
[2019-03-26 16:05:47,519] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10834838], dtype=float32), 0.068246655]
[2019-03-26 16:05:47,520] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.33333333333334, 86.33333333333334, 1.0, 2.0, 0.5305773171708572, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 831678.084157785, 831678.0841577856, 199045.1700357139]
[2019-03-26 16:05:47,522] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:05:47,525] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.2976282e-15 1.0000000e+00 7.8713002e-18 1.7380037e-17 9.3985535e-28], sampled 0.9196472767638363
[2019-03-26 16:06:13,212] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10834838], dtype=float32), 0.068246655]
[2019-03-26 16:06:13,214] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.0, 94.00000000000001, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.102677248842616, 6.9112, 168.9114987242614, 1589687.337456006, 1453847.959346866, 311352.299979346]
[2019-03-26 16:06:13,215] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:06:13,218] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.2583020e-11 1.0000000e+00 6.9860643e-13 2.4608238e-10 5.6534544e-20], sampled 0.569547904687952
[2019-03-26 16:06:32,843] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10834838], dtype=float32), 0.068246655]
[2019-03-26 16:06:32,844] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.52718254666667, 88.75560845000001, 1.0, 2.0, 0.5457267083849024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 762591.222302881, 762591.222302881, 191068.5544342211]
[2019-03-26 16:06:32,846] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 16:06:32,849] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.4257595e-15 1.0000000e+00 5.5075187e-18 5.2521671e-17 1.1144594e-27], sampled 0.07876534361533338
[2019-03-26 16:06:41,107] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10834838], dtype=float32), 0.068246655]
[2019-03-26 16:06:41,108] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.17996839333333, 72.64962504333333, 1.0, 2.0, 0.5095974812803824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 712087.799971189, 712087.7999711897, 185112.1277266003]
[2019-03-26 16:06:41,110] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 16:06:41,112] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.2513084e-15 1.0000000e+00 1.5715869e-18 8.2664716e-18 7.2090043e-29], sampled 0.897902950466674
[2019-03-26 16:06:50,011] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10834838], dtype=float32), 0.068246655]
[2019-03-26 16:06:50,012] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.44749925, 96.24846971, 1.0, 2.0, 0.5179023335639074, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 723696.567088977, 723696.5670889764, 186448.3652774666]
[2019-03-26 16:06:50,013] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 16:06:50,018] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [5.1957971e-15 1.0000000e+00 7.5722396e-18 1.7529385e-17 8.3376550e-28], sampled 0.2786280580770346
[2019-03-26 16:06:59,600] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7883.8590 3164265328.5615 1770.0000
[2019-03-26 16:06:59,809] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.6630 3007693089.1811 1764.0000
[2019-03-26 16:06:59,941] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.1610 2927253227.7716 1338.0000
[2019-03-26 16:06:59,982] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8498.6209 2842345808.4554 1128.0000
[2019-03-26 16:06:59,989] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.4676 2779124528.0117 933.0000
[2019-03-26 16:07:01,007] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 950000, evaluation results [950000.0, 7883.858978945934, 3164265328.5614576, 1770.0, 8255.161016606155, 2927253227.7715816, 1338.0, 8661.467580702742, 2779124528.011676, 933.0, 7997.663011243735, 3007693089.181078, 1764.0, 8498.6209430905, 2842345808.4554043, 1128.0]
[2019-03-26 16:07:04,239] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0775108e-15 1.0000000e+00 5.6279802e-19 3.8719204e-18 7.5069055e-30], sum to 1.0000
[2019-03-26 16:07:04,246] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2157
[2019-03-26 16:07:04,252] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.33333333333334, 63.33333333333333, 1.0, 2.0, 0.5572060011874463, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 778638.1123257191, 778638.1123257191, 193045.2620676647], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3868800.0000, 
sim time next is 3869400.0000, 
raw observation next is [32.16666666666666, 65.16666666666667, 1.0, 2.0, 0.5640217650058872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 788165.9753220618, 788165.9753220612, 194235.5952034292], 
processed observation next is [0.0, 0.782608695652174, 0.7235387045813582, 0.6516666666666667, 1.0, 1.0, 0.4747250180793821, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21893499314501716, 0.218934993145017, 0.28990387343795404], 
reward next is 0.7101, 
noisyNet noise sample is [array([0.99752593], dtype=float32), 0.2542186]. 
=============================================
[2019-03-26 16:07:07,572] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.8132864e-16 1.0000000e+00 4.4322390e-19 1.9312792e-18 1.6742012e-28], sum to 1.0000
[2019-03-26 16:07:07,581] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5956
[2019-03-26 16:07:07,588] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333334, 92.33333333333334, 1.0, 2.0, 0.5711563119389853, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 798139.5617838425, 798139.5617838431, 195494.9711987829], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3900000.0000, 
sim time next is 3900600.0000, 
raw observation next is [27.5, 91.5, 1.0, 2.0, 0.5719451471865765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 799242.3028045539, 799242.3028045546, 195635.3687388565], 
processed observation next is [0.0, 0.13043478260869565, 0.5023696682464456, 0.915, 1.0, 1.0, 0.4842712616705741, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22201175077904275, 0.22201175077904295, 0.29199308766993504], 
reward next is 0.7080, 
noisyNet noise sample is [array([-0.93231404], dtype=float32), -0.4826138]. 
=============================================
[2019-03-26 16:07:15,217] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.6741313e-13 1.0000000e+00 3.9108629e-15 1.2536132e-12 8.2864592e-25], sum to 1.0000
[2019-03-26 16:07:15,227] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2289
[2019-03-26 16:07:15,234] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.66666666666667, 84.0, 1.0, 2.0, 0.9275756485046667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129565104115, 1296507.56478544, 1296507.56478544, 277638.1815150605], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4003800.0000, 
sim time next is 4004400.0000, 
raw observation next is [28.33333333333334, 84.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.944485458845475, 6.9112, 168.907504178448, 2187281.697413325, 1454257.091991945, 311352.3076946266], 
processed observation next is [1.0, 0.34782608695652173, 0.5418641390205374, 0.84, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.10332854588454747, 0.0, 0.8294131717061778, 0.6075782492814791, 0.40396030333109584, 0.4647049368576517], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.13804616], dtype=float32), -1.4425459]. 
=============================================
[2019-03-26 16:07:15,314] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.0003265e-12 1.0000000e+00 6.5004848e-13 6.8135551e-09 6.3658584e-21], sum to 1.0000
[2019-03-26 16:07:15,322] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3154
[2019-03-26 16:07:15,326] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 84.0, 1.0, 2.0, 0.8993734095448372, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1257064.892096279, 1257064.89209628, 269768.7844800379], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3996000.0000, 
sim time next is 3996600.0000, 
raw observation next is [29.16666666666667, 84.0, 1.0, 2.0, 0.9836277700152309, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1374904.467449562, 1374904.467449563, 293981.0077860346], 
processed observation next is [1.0, 0.2608695652173913, 0.581358609794629, 0.84, 1.0, 1.0, 0.9802744217050975, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3819179076248783, 0.38191790762487865, 0.43877762356124567], 
reward next is 0.5612, 
noisyNet noise sample is [array([1.2910479], dtype=float32), 0.84788084]. 
=============================================
[2019-03-26 16:07:17,252] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.7648748e-14 1.0000000e+00 1.7585914e-17 7.1485589e-16 8.5217169e-27], sum to 1.0000
[2019-03-26 16:07:17,263] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2869
[2019-03-26 16:07:17,269] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.8, 85.0, 1.0, 2.0, 0.5417378231236277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 757015.2210022269, 757015.2210022275, 190394.0819614282], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4064400.0000, 
sim time next is 4065000.0000, 
raw observation next is [27.76666666666667, 85.16666666666667, 1.0, 2.0, 0.5412760465771025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 756369.7125669847, 756369.7125669853, 190316.0600203178], 
processed observation next is [1.0, 0.043478260869565216, 0.515007898894155, 0.8516666666666667, 1.0, 1.0, 0.4473205380447018, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21010269793527353, 0.2101026979352737, 0.28405382092584747], 
reward next is 0.7159, 
noisyNet noise sample is [array([-0.9692987], dtype=float32), 0.2230389]. 
=============================================
[2019-03-26 16:07:17,293] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[65.39548]
 [65.45934]
 [65.85224]
 [66.2696 ]
 [66.80745]], R is [[65.2963562 ]
 [65.35922241]
 [65.42147064]
 [65.48306274]
 [65.54390717]].
[2019-03-26 16:07:20,871] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.7627087e-13 1.0000000e+00 1.1756211e-15 8.7180767e-13 8.9899654e-24], sum to 1.0000
[2019-03-26 16:07:20,882] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0228
[2019-03-26 16:07:20,890] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2138145.069752628 W.
[2019-03-26 16:07:20,894] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.33333333333334, 80.66666666666667, 1.0, 2.0, 0.7645635668852933, 1.0, 2.0, 0.7645635668852933, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2138145.069752628, 2138145.069752628, 402992.868038636], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4092000.0000, 
sim time next is 4092600.0000, 
raw observation next is [29.66666666666666, 79.83333333333334, 1.0, 2.0, 0.9506082917187195, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.005990672409787, 6.9112, 168.9123931444886, 2225871.285584567, 2158623.744421615, 448466.6218703049], 
processed observation next is [1.0, 0.34782608695652173, 0.6050552922590835, 0.7983333333333335, 1.0, 1.0, 0.940491917733397, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.009479067240978712, 0.0, 0.8294371787676154, 0.6182975793290464, 0.5996177067837819, 0.6693531669706043], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.125715], dtype=float32), 0.46531618]. 
=============================================
[2019-03-26 16:07:24,638] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.4399961e-16 1.0000000e+00 1.8270133e-18 9.9435825e-17 1.8281551e-27], sum to 1.0000
[2019-03-26 16:07:24,647] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9996
[2019-03-26 16:07:24,654] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.33333333333334, 87.33333333333334, 1.0, 2.0, 0.5729372617275736, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 800629.2168491923, 800629.2168491923, 195812.6602071171], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4152000.0000, 
sim time next is 4152600.0000, 
raw observation next is [28.5, 86.5, 1.0, 2.0, 0.5745347565422327, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 802862.4184390918, 802862.4184390925, 196097.8567500488], 
processed observation next is [1.0, 0.043478260869565216, 0.5497630331753555, 0.865, 1.0, 1.0, 0.48739127294244905, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22301733845530328, 0.22301733845530347, 0.29268336828365493], 
reward next is 0.7073, 
noisyNet noise sample is [array([-0.1232404], dtype=float32), 0.58379465]. 
=============================================
[2019-03-26 16:07:26,953] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.5636698e-11 4.4794258e-05 3.4418457e-09 9.9995518e-01 1.9884465e-12], sum to 1.0000
[2019-03-26 16:07:26,962] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0854
[2019-03-26 16:07:26,967] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [37.0, 50.0, 1.0, 2.0, 0.9338116243504668, 1.0, 2.0, 0.7874958516894959, 1.0, 1.0, 1.03, 7.005116175231901, 6.9112, 170.5573041426782, 3304972.500396786, 3237696.52381242, 605358.1613205218], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4201200.0000, 
sim time next is 4201800.0000, 
raw observation next is [36.83333333333334, 50.5, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 7.792376839223762, 6.9112, 170.5573041426782, 3541287.869532783, 2910065.055614704, 548647.5286639831], 
processed observation next is [1.0, 0.6521739130434783, 0.9447077409162722, 0.505, 1.0, 1.0, 1.0481927710843375, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.2195121951219512, 0.08811768392237615, 0.0, 0.8375144448122397, 0.9836910748702176, 0.8083514043374177, 0.8188769084537061], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3777406], dtype=float32), -1.1430916]. 
=============================================
[2019-03-26 16:07:27,861] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.71092987e-10 1.82602112e-03 9.13640608e-10 9.98173952e-01
 1.03102985e-13], sum to 1.0000
[2019-03-26 16:07:27,871] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7972
[2019-03-26 16:07:27,875] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [36.0, 50.5, 1.0, 2.0, 0.9611326346644532, 1.0, 2.0, 0.9611326346644532, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2688466.234534354, 2688466.234534354, 505944.2836187745], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4207800.0000, 
sim time next is 4208400.0000, 
raw observation next is [36.0, 50.0, 1.0, 2.0, 0.9836026564267747, 1.0, 2.0, 0.9836026564267747, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2751388.264747094, 2751388.264747094, 519156.880436341], 
processed observation next is [1.0, 0.7391304347826086, 0.9052132701421801, 0.5, 1.0, 1.0, 0.980244164369608, 1.0, 1.0, 0.980244164369608, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7642745179853039, 0.7642745179853039, 0.7748610155766283], 
reward next is 0.2251, 
noisyNet noise sample is [array([1.5263082], dtype=float32), 1.0419909]. 
=============================================
[2019-03-26 16:07:29,058] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.6136442e-16 1.0000000e+00 1.9577835e-17 1.2822724e-16 5.7932223e-27], sum to 1.0000
[2019-03-26 16:07:29,069] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8046
[2019-03-26 16:07:29,074] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.83333333333334, 75.66666666666667, 1.0, 2.0, 0.598659206729781, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 836587.5184940917, 836587.5184940911, 200496.4403018882], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4237800.0000, 
sim time next is 4238400.0000, 
raw observation next is [30.66666666666667, 76.33333333333334, 1.0, 2.0, 0.5952278981837773, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 831790.6091750228, 831790.6091750228, 199860.3863433832], 
processed observation next is [1.0, 0.043478260869565216, 0.6524486571879939, 0.7633333333333334, 1.0, 1.0, 0.5123227688961172, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2310529469930619, 0.2310529469930619, 0.2982990840946018], 
reward next is 0.7017, 
noisyNet noise sample is [array([-0.73368007], dtype=float32), -0.69978976]. 
=============================================
[2019-03-26 16:07:35,648] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.3521651e-16 1.0000000e+00 4.8001136e-19 8.5638596e-18 5.6026542e-29], sum to 1.0000
[2019-03-26 16:07:35,655] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8792
[2019-03-26 16:07:35,660] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 84.0, 1.0, 2.0, 0.6172839849490032, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 862625.0105602542, 862625.0105602542, 204010.4118206888], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4411800.0000, 
sim time next is 4412400.0000, 
raw observation next is [30.0, 84.0, 1.0, 2.0, 0.6169288354558088, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 862128.5046051946, 862128.5046051946, 203942.4717339644], 
processed observation next is [0.0, 0.043478260869565216, 0.6208530805687204, 0.84, 1.0, 1.0, 0.5384684764527816, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2394801401681096, 0.2394801401681096, 0.30439174885666326], 
reward next is 0.6956, 
noisyNet noise sample is [array([-1.3181404], dtype=float32), 0.5733338]. 
=============================================
[2019-03-26 16:07:39,282] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.2592759e-08 9.4996434e-01 1.7956287e-08 5.0035618e-02 7.2834147e-14], sum to 1.0000
[2019-03-26 16:07:39,291] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1822
[2019-03-26 16:07:39,299] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2378625.203708421 W.
[2019-03-26 16:07:39,306] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.0, 66.0, 1.0, 2.0, 0.8504691141555165, 1.0, 2.0, 0.8504691141555165, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2378625.203708421, 2378625.203708421, 445185.9780067751], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4716000.0000, 
sim time next is 4716600.0000, 
raw observation next is [30.83333333333334, 67.5, 1.0, 2.0, 0.5163748367809559, 1.0, 2.0, 0.5163748367809559, 1.0, 1.0, 0.8954418048694337, 6.9112, 6.9112, 170.5573041426782, 2166135.237266724, 2166135.237266724, 426405.6340039021], 
processed observation next is [1.0, 0.6086956521739131, 0.6603475513428123, 0.675, 1.0, 1.0, 0.4173190804589829, 1.0, 1.0, 0.4173190804589829, 1.0, 0.5, 0.8724900059383338, 0.0, 0.0, 0.8375144448122397, 0.60170423257409, 0.60170423257409, 0.6364263194088091], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.41395456], dtype=float32), 0.29492232]. 
=============================================
[2019-03-26 16:07:51,178] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.9120365e-13 1.0000000e+00 7.6683815e-15 1.3769989e-11 9.7357647e-23], sum to 1.0000
[2019-03-26 16:07:51,188] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9825
[2019-03-26 16:07:51,196] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2643041.613352013 W.
[2019-03-26 16:07:51,201] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.66666666666667, 81.0, 1.0, 2.0, 0.6299402608691385, 1.0, 1.0, 0.6299402608691385, 1.0, 1.0, 1.03, 6.983146955924678, 6.9112, 170.5573041426782, 2643041.613352013, 2591503.082208116, 499091.0785842719], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4609200.0000, 
sim time next is 4609800.0000, 
raw observation next is [31.0, 79.5, 1.0, 2.0, 0.6892029043130249, 1.0, 2.0, 0.6651914916707752, 1.0, 2.0, 1.03, 7.005096880830477, 6.9112, 170.5573041426782, 2791110.491799228, 2723848.336579448, 517941.4536789292], 
processed observation next is [1.0, 0.34782608695652173, 0.6682464454976303, 0.795, 1.0, 1.0, 0.6255456678470179, 1.0, 1.0, 0.5966162550250304, 1.0, 1.0, 1.0365853658536586, 0.009389688083047697, 0.0, 0.8375144448122397, 0.77530846994423, 0.7566245379387356, 0.7730469457894465], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2787287], dtype=float32), 0.034743857]. 
=============================================
[2019-03-26 16:07:54,444] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.3878374e-17 1.0000000e+00 2.0117845e-19 6.9631386e-18 7.5608782e-30], sum to 1.0000
[2019-03-26 16:07:54,452] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2179
[2019-03-26 16:07:54,461] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.58333333333334, 94.00000000000001, 1.0, 2.0, 0.4767004995338715, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 668384.50316243, 668384.50316243, 180320.1372688563], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4659000.0000, 
sim time next is 4659600.0000, 
raw observation next is [24.66666666666667, 94.0, 1.0, 2.0, 0.4810413142265207, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 672172.116678605, 672172.1166786043, 180678.4378513148], 
processed observation next is [1.0, 0.9565217391304348, 0.36808846761453423, 0.94, 1.0, 1.0, 0.37474857135725387, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18671447685516804, 0.18671447685516784, 0.269669310225843], 
reward next is 0.7303, 
noisyNet noise sample is [array([1.4842911], dtype=float32), -1.6444111]. 
=============================================
[2019-03-26 16:07:56,427] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-26 16:07:56,429] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 16:07:56,431] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:07:56,431] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 16:07:56,432] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:07:56,433] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 16:07:56,436] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 16:07:56,434] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 16:07:56,437] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:07:56,439] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:07:56,439] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:07:56,460] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run40
[2019-03-26 16:07:56,460] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run40
[2019-03-26 16:07:56,503] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run40
[2019-03-26 16:07:56,522] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run40
[2019-03-26 16:07:56,545] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run40
[2019-03-26 16:08:22,727] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10808968], dtype=float32), 0.06945923]
[2019-03-26 16:08:22,729] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.8, 86.0, 1.0, 2.0, 0.7142684420788515, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 998219.8703792222, 998219.8703792222, 223951.429905212]
[2019-03-26 16:08:22,730] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 16:08:22,733] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [6.9832562e-16 1.0000000e+00 7.6167049e-19 1.6767598e-18 2.9804774e-29], sampled 0.5724818334021053
[2019-03-26 16:08:43,600] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10808968], dtype=float32), 0.06945923]
[2019-03-26 16:08:43,600] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.0, 93.0, 1.0, 2.0, 0.482662126705178, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 674437.641003603, 674437.641003603, 180924.049788991]
[2019-03-26 16:08:43,602] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:08:43,605] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.8922469e-16 1.0000000e+00 1.0263482e-18 1.8541570e-18 5.5909114e-29], sampled 0.18478393432032125
[2019-03-26 16:08:59,118] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10808968], dtype=float32), 0.06945923]
[2019-03-26 16:08:59,121] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [36.66666666666666, 58.0, 1.0, 2.0, 0.8206934176284542, 1.0, 2.0, 0.7309367483284898, 1.0, 1.0, 1.03, 7.005107250650194, 6.9112, 170.5573041426782, 3067313.03809717, 3000043.454553709, 562162.0801740482]
[2019-03-26 16:08:59,122] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:08:59,126] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [6.3074497e-09 1.2929194e-02 5.9801543e-08 9.8707062e-01 1.8785507e-12], sampled 0.9430619123727534
[2019-03-26 16:09:45,945] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10808968], dtype=float32), 0.06945923]
[2019-03-26 16:09:45,946] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.28333333333333, 94.83333333333334, 1.0, 2.0, 0.4266384581965208, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 628160.9977933567, 628160.9977933567, 176974.5281979145]
[2019-03-26 16:09:45,947] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:09:45,950] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.3292799e-15 1.0000000e+00 1.2611976e-18 8.9436743e-19 5.6342027e-29], sampled 0.3279478005652574
[2019-03-26 16:09:49,958] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.1610 2927253227.7716 1338.0000
[2019-03-26 16:09:50,291] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7883.5006 3164337656.5808 1776.0000
[2019-03-26 16:09:50,393] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.0346 2842628843.6434 1131.0000
[2019-03-26 16:09:50,471] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7996.8346 3007720350.8920 1766.0000
[2019-03-26 16:09:50,529] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.4676 2779124528.0117 933.0000
[2019-03-26 16:09:51,544] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 975000, evaluation results [975000.0, 7883.500604504034, 3164337656.580765, 1776.0, 8255.161016606155, 2927253227.7715816, 1338.0, 8661.467580702742, 2779124528.011676, 933.0, 7996.834632877974, 3007720350.891978, 1766.0, 8496.034569384168, 2842628843.643416, 1131.0]
[2019-03-26 16:09:55,906] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.6297256e-15 1.0000000e+00 1.0839535e-17 2.6772096e-16 5.2115464e-27], sum to 1.0000
[2019-03-26 16:09:55,917] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4727
[2019-03-26 16:09:55,921] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.00000000000001, 1.0, 2.0, 0.658356801585593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 920047.1792237106, 920047.1792237106, 212110.0031102683], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4767000.0000, 
sim time next is 4767600.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.6178432015270224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 863406.806771601, 863406.806771601, 204107.879601269], 
processed observation next is [1.0, 0.17391304347826086, 0.4786729857819906, 0.79, 1.0, 1.0, 0.5395701223217138, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2398352241032225, 0.2398352241032225, 0.30463862627055077], 
reward next is 0.6954, 
noisyNet noise sample is [array([0.6790271], dtype=float32), -0.4046752]. 
=============================================
[2019-03-26 16:09:56,986] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.2086831e-08 9.3974978e-01 2.5849856e-08 6.0250100e-02 4.7981595e-13], sum to 1.0000
[2019-03-26 16:09:56,995] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6824
[2019-03-26 16:09:57,001] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2292774.223554749 W.
[2019-03-26 16:09:57,008] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 66.0, 1.0, 2.0, 0.8198015294901458, 1.0, 1.0, 0.8198015294901458, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2292774.223554749, 2292774.223554749, 429623.942067946], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4794600.0000, 
sim time next is 4795200.0000, 
raw observation next is [31.0, 66.0, 1.0, 2.0, 0.8399811430586676, 1.0, 2.0, 0.8399811430586676, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2349264.464688442, 2349264.464688442, 439801.7249908058], 
processed observation next is [1.0, 0.5217391304347826, 0.6682464454976303, 0.66, 1.0, 1.0, 0.8072061964562259, 1.0, 1.0, 0.8072061964562259, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6525734624134562, 0.6525734624134562, 0.6564204850609041], 
reward next is 0.3436, 
noisyNet noise sample is [array([0.33553413], dtype=float32), -0.12089998]. 
=============================================
[2019-03-26 16:09:57,233] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.7079448e-15 1.0000000e+00 3.6817829e-17 1.2328066e-15 1.4881582e-26], sum to 1.0000
[2019-03-26 16:09:57,244] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9001
[2019-03-26 16:09:57,249] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.83333333333334, 1.0, 2.0, 0.6573587196675788, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 918651.7662806674, 918651.7662806674, 211907.3129420844], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4849800.0000, 
sim time next is 4850400.0000, 
raw observation next is [27.0, 80.66666666666667, 1.0, 2.0, 0.6177226191331104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 863238.2300704888, 863238.2300704888, 204085.358952211], 
processed observation next is [1.0, 0.13043478260869565, 0.4786729857819906, 0.8066666666666668, 1.0, 1.0, 0.5394248423290487, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23978839724180243, 0.23978839724180243, 0.30460501336150897], 
reward next is 0.6954, 
noisyNet noise sample is [array([-0.3539999], dtype=float32), -0.95800215]. 
=============================================
[2019-03-26 16:09:58,963] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.3840964e-15 1.0000000e+00 5.3252771e-18 1.8694551e-18 4.8495648e-28], sum to 1.0000
[2019-03-26 16:09:58,973] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4124
[2019-03-26 16:09:58,978] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 66.0, 1.0, 2.0, 0.5152981199419538, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 720056.3069346979, 720056.3069346979, 186027.3340077684], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5130000.0000, 
sim time next is 5130600.0000, 
raw observation next is [30.0, 66.0, 1.0, 2.0, 0.5230494490516497, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 730891.4203920225, 730891.4203920232, 187285.3622219982], 
processed observation next is [0.0, 0.391304347826087, 0.6208530805687204, 0.66, 1.0, 1.0, 0.42536078198993943, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20302539455333957, 0.20302539455333976, 0.2795303913761167], 
reward next is 0.7205, 
noisyNet noise sample is [array([-0.82708746], dtype=float32), 0.30872986]. 
=============================================
[2019-03-26 16:10:00,261] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.0432587e-17 1.0000000e+00 1.4135462e-19 1.8833422e-17 7.2464462e-29], sum to 1.0000
[2019-03-26 16:10:00,269] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2069
[2019-03-26 16:10:00,280] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.58333333333334, 76.5, 1.0, 2.0, 0.4925415304471977, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 688246.8873747757, 688246.887374775, 182435.5013616573], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4834200.0000, 
sim time next is 4834800.0000, 
raw observation next is [27.5, 77.0, 1.0, 2.0, 0.4933954913837593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 689440.5464808679, 689440.5464808679, 182567.4639977381], 
processed observation next is [1.0, 1.0, 0.5023696682464456, 0.77, 1.0, 1.0, 0.38963312214910767, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1915112629113522, 0.1915112629113522, 0.27248875223542995], 
reward next is 0.7275, 
noisyNet noise sample is [array([0.77367], dtype=float32), -1.5295323]. 
=============================================
[2019-03-26 16:10:03,041] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.2132310e-08 7.2374684e-01 4.4159147e-08 2.7625307e-01 4.1428224e-13], sum to 1.0000
[2019-03-26 16:10:03,049] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2124
[2019-03-26 16:10:03,064] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2167266.973009735 W.
[2019-03-26 16:10:03,069] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.75, 64.0, 1.0, 2.0, 0.7749665299614132, 1.0, 2.0, 0.7749665299614132, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2167266.973009735, 2167266.973009735, 407868.7236830475], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4890600.0000, 
sim time next is 4891200.0000, 
raw observation next is [31.66666666666667, 64.33333333333333, 1.0, 2.0, 1.015914060061749, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.997612123778127, 6.9112, 168.9124427008759, 2317276.849497447, 2255973.301290845, 468558.2523371694], 
processed observation next is [1.0, 0.6086956521739131, 0.6998420221169038, 0.6433333333333333, 1.0, 1.0, 1.0191735663394565, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.008641212377812657, 0.0, 0.8294374221121642, 0.6436880137492907, 0.6266592503585681, 0.6993406751301037], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.18163721], dtype=float32), -1.6270105]. 
=============================================
[2019-03-26 16:10:05,710] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.4911398e-16 1.0000000e+00 8.6610029e-19 1.7390979e-17 4.3716148e-29], sum to 1.0000
[2019-03-26 16:10:05,718] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7992
[2019-03-26 16:10:05,724] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.5093660140353766, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 711764.250056138, 711764.2500561386, 185076.5959637272], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4924200.0000, 
sim time next is 4924800.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.5096187058562838, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 712117.4681467947, 712117.4681467941, 185116.8829735978], 
processed observation next is [1.0, 0.0, 0.4786729857819906, 0.84, 1.0, 1.0, 0.4091791636822696, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19781040781855408, 0.1978104078185539, 0.2762938551844743], 
reward next is 0.7237, 
noisyNet noise sample is [array([-0.35217324], dtype=float32), 1.8441406]. 
=============================================
[2019-03-26 16:10:06,376] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4233437e-14 1.0000000e+00 4.3528523e-18 2.1245145e-16 1.9226039e-27], sum to 1.0000
[2019-03-26 16:10:06,384] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2190
[2019-03-26 16:10:06,390] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.6243657399675033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 872525.4913893507, 872525.4913893507, 205364.4257652663], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4944000.0000, 
sim time next is 4944600.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.6599435366153074, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 922265.5886796128, 922265.5886796123, 212434.3622953894], 
processed observation next is [1.0, 0.21739130434782608, 0.4312796208530806, 0.89, 1.0, 1.0, 0.590293417608804, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2561848857443369, 0.25618488574433673, 0.3170662123811782], 
reward next is 0.6829, 
noisyNet noise sample is [array([-1.5567906], dtype=float32), -1.412682]. 
=============================================
[2019-03-26 16:10:07,254] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.3449764e-08 9.9468082e-01 1.1647551e-08 5.3192191e-03 8.7505090e-13], sum to 1.0000
[2019-03-26 16:10:07,262] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9301
[2019-03-26 16:10:07,268] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1915189.738935048 W.
[2019-03-26 16:10:07,272] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.0, 66.66666666666666, 1.0, 2.0, 0.4566065403550504, 1.0, 1.0, 0.4566065403550504, 1.0, 2.0, 0.7802193323614028, 6.9112, 6.9112, 170.5573041426782, 1915189.738935048, 1915189.738935048, 384338.4439601882], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4963800.0000, 
sim time next is 4964400.0000, 
raw observation next is [30.0, 66.0, 1.0, 2.0, 0.739380729299282, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.977172616889521, 6.9112, 168.9125633305385, 1930237.80396426, 1883434.667884843, 394424.9360013743], 
processed observation next is [1.0, 0.4782608695652174, 0.6208530805687204, 0.66, 1.0, 1.0, 0.6860008786738337, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.006597261688952116, 0.0, 0.8294380144590319, 0.53617716776785, 0.5231762966346786, 0.5886939343304094], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8163476], dtype=float32), 0.05663299]. 
=============================================
[2019-03-26 16:10:13,257] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.9744627e-16 1.0000000e+00 1.4042651e-18 6.9936156e-19 8.9896640e-30], sum to 1.0000
[2019-03-26 16:10:13,266] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8822
[2019-03-26 16:10:13,270] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 59.0, 1.0, 2.0, 0.5230332995882274, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 730868.8459204002, 730868.8459204008, 187284.1077407033], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5065200.0000, 
sim time next is 5065800.0000, 
raw observation next is [31.83333333333334, 59.66666666666667, 1.0, 2.0, 0.5228005374421864, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 730543.4802124075, 730543.4802124068, 187246.0124310103], 
processed observation next is [0.0, 0.6521739130434783, 0.7077409162717223, 0.5966666666666667, 1.0, 1.0, 0.42506088848456186, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20292874450344653, 0.20292874450344633, 0.27947166034479154], 
reward next is 0.7205, 
noisyNet noise sample is [array([-1.8700925], dtype=float32), 0.70562756]. 
=============================================
[2019-03-26 16:10:15,471] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.5316321e-16 1.0000000e+00 1.9410718e-19 7.5796917e-19 4.0602214e-30], sum to 1.0000
[2019-03-26 16:10:15,479] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7215
[2019-03-26 16:10:15,488] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.5170087466958854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 722447.478955866, 722447.478955866, 186303.4505701619], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5095200.0000, 
sim time next is 5095800.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.5164354593231327, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 721646.1178474353, 721646.1178474353, 186210.8231642146], 
processed observation next is [0.0, 1.0, 0.4786729857819906, 0.84, 1.0, 1.0, 0.4173921196664249, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20045725495762093, 0.20045725495762093, 0.2779266017376337], 
reward next is 0.7221, 
noisyNet noise sample is [array([1.832431], dtype=float32), -0.61360615]. 
=============================================
[2019-03-26 16:10:16,911] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.1445611e-15 1.0000000e+00 1.3730652e-18 1.7283434e-18 9.0426300e-30], sum to 1.0000
[2019-03-26 16:10:16,922] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9557
[2019-03-26 16:10:16,929] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.33333333333334, 65.0, 1.0, 2.0, 0.5125044579218224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 716151.2431057073, 716151.2431057073, 185578.5904867777], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5134800.0000, 
sim time next is 5135400.0000, 
raw observation next is [30.5, 64.5, 1.0, 2.0, 0.5153740946603607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 720162.5068553776, 720162.506855377, 186040.0357613687], 
processed observation next is [0.0, 0.43478260869565216, 0.6445497630331753, 0.645, 1.0, 1.0, 0.4161133670606755, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20004514079316044, 0.20004514079316027, 0.2776716951662219], 
reward next is 0.7223, 
noisyNet noise sample is [array([0.1041975], dtype=float32), -2.508003]. 
=============================================
[2019-03-26 16:10:21,417] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.7415409e-15 1.0000000e+00 2.7621167e-18 5.7850808e-17 3.0679789e-27], sum to 1.0000
[2019-03-26 16:10:21,428] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8335
[2019-03-26 16:10:21,437] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1786011.749639883 W.
[2019-03-26 16:10:21,445] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.83333333333333, 84.83333333333333, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.379225645507997, 6.9112, 168.9108766384548, 1786011.749639883, 1453982.336937338, 311348.6666362893], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5191800.0000, 
sim time next is 5192400.0000, 
raw observation next is [26.66666666666667, 85.66666666666667, 1.0, 2.0, 0.6080866883023059, 0.0, 2.0, 0.0, 1.0, 1.0, 1.026274944316548, 6.911199999999999, 6.9112, 168.9125754234714, 1700214.588686799, 1700214.588686799, 366233.7023834737], 
processed observation next is [1.0, 0.08695652173913043, 0.4628751974723541, 0.8566666666666667, 1.0, 1.0, 0.527815287111212, 0.0, 1.0, -0.20481927710843376, 1.0, 0.5, 1.0320426150201805, -8.881784197001253e-17, 0.0, 0.8294380738408687, 0.47228183019077746, 0.47228183019077746, 0.5466174662439905], 
reward next is 0.4534, 
noisyNet noise sample is [array([-1.4872059], dtype=float32), -0.5428848]. 
=============================================
[2019-03-26 16:10:22,909] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.5725313e-08 9.8695719e-01 3.0829835e-08 1.3042790e-02 1.7746749e-12], sum to 1.0000
[2019-03-26 16:10:22,918] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4832
[2019-03-26 16:10:22,928] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2467289.412561914 W.
[2019-03-26 16:10:22,934] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.0, 67.33333333333334, 1.0, 2.0, 0.5880929503464287, 1.0, 1.0, 0.5880929503464287, 1.0, 2.0, 1.021322969441157, 6.911199999999999, 6.9112, 170.5573041426782, 2467289.412561914, 2467289.412561914, 481407.009568937], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5221200.0000, 
sim time next is 5221800.0000, 
raw observation next is [31.0, 68.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 7.504434154044782, 6.9112, 168.9096104974354, 2709484.344570382, 2288631.955017767, 475018.1094212808], 
processed observation next is [1.0, 0.43478260869565216, 0.6682464454976303, 0.68, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.059323415404478205, 0.0, 0.829423514696683, 0.7526345401584394, 0.6357310986160464, 0.7089822528675833], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.70081466], dtype=float32), 1.0201247]. 
=============================================
[2019-03-26 16:10:23,836] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.5807532e-09 5.5826795e-01 9.7511110e-09 4.4173205e-01 8.4506792e-15], sum to 1.0000
[2019-03-26 16:10:23,844] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0707
[2019-03-26 16:10:23,853] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2782523.4675411 W.
[2019-03-26 16:10:23,856] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.66666666666667, 68.0, 1.0, 2.0, 0.9947208982549747, 1.0, 2.0, 0.9947208982549747, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2782523.4675411, 2782523.4675411, 525802.5257678672], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5242800.0000, 
sim time next is 5243400.0000, 
raw observation next is [31.5, 68.5, 1.0, 2.0, 0.9973744416946864, 1.0, 2.0, 0.9973744416946864, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2789954.488533048, 2789954.488533048, 527399.4053829213], 
processed observation next is [1.0, 0.6956521739130435, 0.6919431279620853, 0.685, 1.0, 1.0, 0.996836676740586, 1.0, 1.0, 0.996836676740586, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7749873579258466, 0.7749873579258466, 0.7871632916163005], 
reward next is 0.2128, 
noisyNet noise sample is [array([0.49961773], dtype=float32), 0.8397106]. 
=============================================
[2019-03-26 16:10:32,890] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.0771791e-09 2.7348532e-04 1.6761401e-08 9.9972647e-01 1.2933648e-11], sum to 1.0000
[2019-03-26 16:10:32,896] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7004
[2019-03-26 16:10:32,906] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 3 has been changed to 4 for the demand 3408883.846304848 W.
[2019-03-26 16:10:32,913] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [34.83333333333334, 61.33333333333334, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 7.607758062007343, 6.9112, 170.5573041426782, 3408883.846304848, 2909910.9723186, 549796.650801731], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5395200.0000, 
sim time next is 5395800.0000, 
raw observation next is [35.01666666666667, 60.66666666666666, 1.0, 2.0, 1.000380443823284, 1.0, 2.0, 0.8207802614259048, 1.0, 1.0, 1.03, 7.005121428837076, 6.9112, 170.5573041426782, 3444853.62196088, 3377573.882005423, 633015.150325358], 
processed observation next is [1.0, 0.43478260869565216, 0.8586097946287523, 0.6066666666666666, 1.0, 1.0, 1.0004583660521493, 1.0, 1.0, 0.784072604127596, 1.0, 0.5, 1.0365853658536586, 0.0093921428837076, 0.0, 0.8375144448122397, 0.9569037838780221, 0.9382149672237285, 0.9447987318288926], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5769465], dtype=float32), -0.756281]. 
=============================================
[2019-03-26 16:10:36,315] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.7586995e-16 1.0000000e+00 1.0754683e-18 3.1697919e-18 5.7433554e-29], sum to 1.0000
[2019-03-26 16:10:36,324] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0762
[2019-03-26 16:10:36,329] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.93333333333334, 64.0, 1.0, 2.0, 0.5579368814429562, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 779659.8171915929, 779659.8171915929, 193171.5707137766], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5660400.0000, 
sim time next is 5661000.0000, 
raw observation next is [32.0, 63.5, 1.0, 2.0, 0.5563401364978955, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 777427.7126325896, 777427.7126325902, 192894.3859055719], 
processed observation next is [0.0, 0.5217391304347826, 0.7156398104265403, 0.635, 1.0, 1.0, 0.46547004397336805, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21595214239794155, 0.21595214239794172, 0.28790206851577893], 
reward next is 0.7121, 
noisyNet noise sample is [array([-0.77092904], dtype=float32), -0.4444744]. 
=============================================
[2019-03-26 16:10:36,347] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[71.90709 ]
 [71.86545 ]
 [71.80575 ]
 [71.753716]
 [71.71687 ]], R is [[71.9465332 ]
 [71.93875122]
 [71.93054962]
 [71.92282867]
 [71.9152832 ]].
[2019-03-26 16:10:41,264] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0012907e-14 1.0000000e+00 2.3976378e-17 2.0109140e-15 2.7062736e-27], sum to 1.0000
[2019-03-26 16:10:41,276] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7605
[2019-03-26 16:10:41,281] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666667, 95.0, 1.0, 2.0, 0.6727435266841869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 940161.3856267879, 940161.3856267885, 215070.7680563582], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5546400.0000, 
sim time next is 5547000.0000, 
raw observation next is [25.63333333333333, 95.0, 1.0, 2.0, 0.6666946170284421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 931704.3056290358, 931704.3056290364, 213819.2751754902], 
processed observation next is [1.0, 0.17391304347826086, 0.4139020537124801, 0.95, 1.0, 1.0, 0.598427249431858, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.25880675156362104, 0.2588067515636212, 0.3191332465305824], 
reward next is 0.6809, 
noisyNet noise sample is [array([-1.4910253], dtype=float32), -1.0516223]. 
=============================================
[2019-03-26 16:10:41,296] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[63.838165]
 [63.07775 ]
 [62.38675 ]
 [61.44141 ]
 [60.85901 ]], R is [[64.71392059]
 [64.74578094]
 [64.77489471]
 [64.79756165]
 [64.80175018]].
[2019-03-26 16:10:44,945] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.3090572e-13 1.0000000e+00 2.0107539e-14 5.7916261e-10 2.5488979e-23], sum to 1.0000
[2019-03-26 16:10:44,950] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7717
[2019-03-26 16:10:44,955] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.11666666666667, 66.66666666666667, 1.0, 2.0, 0.5294437350616796, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 739829.6886895798, 739829.6886895798, 188339.5782874853], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5595000.0000, 
sim time next is 5595600.0000, 
raw observation next is [30.83333333333333, 68.33333333333334, 1.0, 2.0, 0.5362148964518305, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 749294.8551498201, 749294.8551498195, 189465.9900256268], 
processed observation next is [1.0, 0.782608695652174, 0.6603475513428118, 0.6833333333333335, 1.0, 1.0, 0.44122276680943434, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2081374597638389, 0.20813745976383877, 0.2827850597397415], 
reward next is 0.7172, 
noisyNet noise sample is [array([-0.75005853], dtype=float32), -1.45055]. 
=============================================
[2019-03-26 16:10:45,469] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.5908420e-16 1.0000000e+00 2.4624557e-19 1.3223239e-18 8.2580062e-30], sum to 1.0000
[2019-03-26 16:10:45,482] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8689
[2019-03-26 16:10:45,493] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.26666666666667, 60.0, 1.0, 2.0, 0.5599378463623756, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 782456.9912215542, 782456.9912215542, 193518.6832922029], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5670600.0000, 
sim time next is 5671200.0000, 
raw observation next is [32.23333333333333, 60.00000000000001, 1.0, 2.0, 0.5412211549960072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 756292.9807215903, 756292.980721591, 190306.8403208943], 
processed observation next is [0.0, 0.6521739130434783, 0.7266982622432857, 0.6000000000000001, 1.0, 1.0, 0.4472544036096472, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2100813835337751, 0.21008138353377528, 0.28404006018043926], 
reward next is 0.7160, 
noisyNet noise sample is [array([-1.6647502], dtype=float32), 0.94422305]. 
=============================================
[2019-03-26 16:10:46,948] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-26 16:10:46,950] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 16:10:46,952] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:10:46,953] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 16:10:46,955] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:10:46,955] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 16:10:46,956] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 16:10:46,958] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 16:10:46,961] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:10:46,958] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:10:46,963] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:10:47,313] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run41
[2019-03-26 16:10:47,345] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run41
[2019-03-26 16:10:47,490] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run41
[2019-03-26 16:10:47,551] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run41
[2019-03-26 16:10:47,562] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run41
[2019-03-26 16:11:07,422] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10679514], dtype=float32), 0.070615046]
[2019-03-26 16:11:07,423] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.79357961, 76.26595044333334, 1.0, 2.0, 0.5209332035111732, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.9129564261771, 727933.2379660174, 727933.2379660174, 186941.5961984999]
[2019-03-26 16:11:07,424] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 16:11:07,428] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.3327296e-12 1.0000000e+00 1.6087673e-14 2.4498452e-11 1.0398680e-21], sampled 0.6861808491822475
[2019-03-26 16:11:42,358] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10679514], dtype=float32), 0.070615046]
[2019-03-26 16:11:42,360] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.7, 70.66666666666667, 1.0, 2.0, 0.5679287518978273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 793627.6520306073, 793627.6520306073, 194922.8084241151]
[2019-03-26 16:11:42,364] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 16:11:42,367] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.7269414e-16 1.0000000e+00 1.2249661e-19 1.4598093e-18 2.6363581e-30], sampled 0.9157458483243243
[2019-03-26 16:11:49,677] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10679514], dtype=float32), 0.070615046]
[2019-03-26 16:11:49,678] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [31.6, 69.0, 1.0, 2.0, 0.8323692456965263, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1163361.069520896, 1163361.069520896, 252014.8952105388]
[2019-03-26 16:11:49,680] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:11:49,683] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0311139e-15 1.0000000e+00 1.2341363e-18 1.1937551e-17 9.4443723e-29], sampled 0.3104370679958538
[2019-03-26 16:12:06,307] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10679514], dtype=float32), 0.070615046]
[2019-03-26 16:12:06,308] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.55, 75.5, 1.0, 2.0, 0.5611152367749177, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 784102.8835313723, 784102.8835313717, 193724.7057330963]
[2019-03-26 16:12:06,309] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:12:06,311] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [5.9194045e-16 1.0000000e+00 6.3129287e-19 6.2289442e-18 2.7781741e-29], sampled 0.5954755820519944
[2019-03-26 16:12:06,613] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10679514], dtype=float32), 0.070615046]
[2019-03-26 16:12:06,614] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.1, 71.0, 1.0, 2.0, 0.5886085296542373, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 822536.9089788558, 822536.9089788558, 198642.1597831575]
[2019-03-26 16:12:06,615] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 16:12:06,617] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.2591475e-14 1.0000000e+00 6.4276069e-17 6.4594109e-14 9.2221199e-27], sampled 0.450819867240714
[2019-03-26 16:12:41,856] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7886.4688 3163889899.2346 1777.0000
[2019-03-26 16:12:42,273] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8498.2182 2842346753.3935 1130.0000
[2019-03-26 16:12:42,550] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7996.4615 3007580961.1409 1765.0000
[2019-03-26 16:12:42,674] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.2476 2779224191.2983 933.0000
[2019-03-26 16:12:42,683] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.3741 2927600600.1826 1338.0000
[2019-03-26 16:12:43,698] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 1000000, evaluation results [1000000.0, 7886.46884515784, 3163889899.2345724, 1777.0, 8253.374096424963, 2927600600.1825533, 1338.0, 8659.247559062687, 2779224191.2983274, 933.0, 7996.461496105773, 3007580961.1408653, 1765.0, 8498.218214586843, 2842346753.3934665, 1130.0]
[2019-03-26 16:12:55,170] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.4082658e-09 6.8991578e-01 5.9017125e-09 3.1008425e-01 1.1258690e-14], sum to 1.0000
[2019-03-26 16:12:55,178] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0461
[2019-03-26 16:12:55,181] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.8, 66.0, 1.0, 2.0, 0.4191698084349512, 1.0, 2.0, 0.4191698084349512, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1171703.931433832, 1171703.931433832, 277071.1041871152], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5850600.0000, 
sim time next is 5851200.0000, 
raw observation next is [31.6, 67.0, 1.0, 2.0, 0.5242925147824838, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 732629.0369667722, 732629.0369667716, 187493.1678875674], 
processed observation next is [1.0, 0.7391304347826086, 0.6966824644549764, 0.67, 1.0, 1.0, 0.4268584515451612, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20350806582410338, 0.20350806582410322, 0.2798405490859215], 
reward next is 0.7202, 
noisyNet noise sample is [array([0.5462462], dtype=float32), -0.16325419]. 
=============================================
[2019-03-26 16:13:00,042] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.4679756e-09 5.9876317e-01 6.1009526e-09 4.0123683e-01 8.4734472e-14], sum to 1.0000
[2019-03-26 16:13:00,048] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7858
[2019-03-26 16:13:00,054] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.63333333333333, 72.83333333333333, 1.0, 2.0, 0.5016807319944437, 1.0, 1.0, 0.5016807319944437, 1.0, 2.0, 0.8712535231210499, 6.9112, 6.9112, 170.5573041426782, 2104434.546497775, 2104434.546497775, 416310.3877457615], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5921400.0000, 
sim time next is 5922000.0000, 
raw observation next is [30.5, 73.0, 1.0, 2.0, 0.6815819518961639, 1.0, 2.0, 0.6815819518961639, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1905875.885675804, 1905875.885675804, 366344.7941436301], 
processed observation next is [1.0, 0.5652173913043478, 0.6445497630331753, 0.73, 1.0, 1.0, 0.6163637974652577, 1.0, 1.0, 0.6163637974652577, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5294099682432789, 0.5294099682432789, 0.5467832748412389], 
reward next is 0.4532, 
noisyNet noise sample is [array([-0.47380024], dtype=float32), 0.13839914]. 
=============================================
[2019-03-26 16:13:00,069] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[36.341045]
 [38.054592]
 [36.84804 ]
 [36.114574]
 [34.291325]], R is [[37.63658142]
 [37.6388588 ]
 [37.26247025]
 [36.8898468 ]
 [36.89875031]].
[2019-03-26 16:13:03,033] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.2774697e-16 1.0000000e+00 3.4404745e-18 3.8875681e-16 2.2290686e-27], sum to 1.0000
[2019-03-26 16:13:03,041] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5563
[2019-03-26 16:13:03,047] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.2, 92.0, 1.0, 2.0, 0.7353930691574068, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1027756.701699502, 1027756.701699502, 228669.3756156479], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5972400.0000, 
sim time next is 5973000.0000, 
raw observation next is [26.18333333333333, 92.16666666666667, 1.0, 2.0, 0.7914261599237846, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1106107.151097853, 1106107.151097853, 241816.2047291317], 
processed observation next is [1.0, 0.13043478260869565, 0.4399684044233806, 0.9216666666666667, 1.0, 1.0, 0.7487062167756441, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.30725198641607027, 0.30725198641607027, 0.36091970855094285], 
reward next is 0.6391, 
noisyNet noise sample is [array([-1.9927248], dtype=float32), 0.9263899]. 
=============================================
[2019-03-26 16:13:03,072] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[65.355644]
 [65.299095]
 [65.18769 ]
 [65.225296]
 [65.41384 ]], R is [[65.25817108]
 [65.26428986]
 [65.264534  ]
 [65.25521088]
 [65.20919037]].
[2019-03-26 16:13:06,599] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.6738860e-16 1.0000000e+00 1.5988955e-18 1.8991222e-15 2.4116578e-29], sum to 1.0000
[2019-03-26 16:13:06,610] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0492
[2019-03-26 16:13:06,617] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.75, 85.0, 1.0, 2.0, 0.5381012223055038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 751931.6982087173, 751931.6982087173, 189781.4013220653], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6035400.0000, 
sim time next is 6036000.0000, 
raw observation next is [27.7, 85.33333333333333, 1.0, 2.0, 0.5379872024702902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 751772.3128294167, 751772.3128294161, 189762.2583688775], 
processed observation next is [1.0, 0.8695652173913043, 0.5118483412322274, 0.8533333333333333, 1.0, 1.0, 0.4433580752654098, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20882564245261576, 0.2088256424526156, 0.28322725129683207], 
reward next is 0.7168, 
noisyNet noise sample is [array([-1.1373999], dtype=float32), 0.2668753]. 
=============================================
[2019-03-26 16:13:06,629] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[71.93978 ]
 [72.371864]
 [72.94069 ]
 [73.25513 ]
 [73.66653 ]], R is [[71.12915802]
 [71.13461304]
 [71.13996124]
 [71.14519501]
 [71.15036011]].
[2019-03-26 16:13:13,435] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.1059404e-16 1.0000000e+00 7.8461442e-19 8.6952081e-17 1.6553274e-28], sum to 1.0000
[2019-03-26 16:13:13,446] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3391
[2019-03-26 16:13:13,451] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.71666666666667, 88.83333333333334, 1.0, 2.0, 0.5217213575510007, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 729034.9538810509, 729034.9538810509, 187069.6210340689], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6220200.0000, 
sim time next is 6220800.0000, 
raw observation next is [26.7, 89.0, 1.0, 2.0, 0.5218301179650611, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 729186.9839966983, 729186.9839966976, 187087.3749641027], 
processed observation next is [0.0, 0.0, 0.46445497630331756, 0.89, 1.0, 1.0, 0.4238917083916398, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20255193999908286, 0.20255193999908266, 0.27923488800612345], 
reward next is 0.7208, 
noisyNet noise sample is [array([1.5878056], dtype=float32), 0.36577934]. 
=============================================
[2019-03-26 16:13:16,880] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.3092665e-13 1.0000000e+00 5.2373275e-15 1.7612941e-09 2.7105448e-24], sum to 1.0000
[2019-03-26 16:13:16,888] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7117
[2019-03-26 16:13:16,893] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.41666666666666, 79.50000000000001, 1.0, 2.0, 0.5292441657337011, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 739550.7190805513, 739550.7190805506, 188305.4077222904], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6199800.0000, 
sim time next is 6200400.0000, 
raw observation next is [28.33333333333334, 80.0, 1.0, 2.0, 0.5292859431617035, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 739609.1179921674, 739609.1179921674, 188312.3025866869], 
processed observation next is [1.0, 0.782608695652174, 0.5418641390205374, 0.8, 1.0, 1.0, 0.43287463031530543, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20544697722004648, 0.20544697722004648, 0.28106313818908496], 
reward next is 0.7189, 
noisyNet noise sample is [array([0.0999293], dtype=float32), -0.49180353]. 
=============================================
[2019-03-26 16:13:28,518] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.3534313e-08 1.2605381e-01 2.0046377e-08 8.7394613e-01 1.7336057e-12], sum to 1.0000
[2019-03-26 16:13:28,523] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8443
[2019-03-26 16:13:28,528] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.9, 69.0, 1.0, 2.0, 0.8543066685128599, 1.0, 2.0, 0.8543066685128599, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2389368.486552693, 2389368.486552693, 447168.8114289066], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6436800.0000, 
sim time next is 6437400.0000, 
raw observation next is [29.9, 69.0, 1.0, 2.0, 0.8338306452952545, 1.0, 2.0, 0.8338306452952545, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2332046.66416119, 2332046.66416119, 436670.8702920698], 
processed observation next is [1.0, 0.5217391304347826, 0.6161137440758293, 0.69, 1.0, 1.0, 0.7997959581870536, 1.0, 1.0, 0.7997959581870536, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.647790740044775, 0.647790740044775, 0.6517475676001042], 
reward next is 0.3483, 
noisyNet noise sample is [array([1.9001207], dtype=float32), -0.58292395]. 
=============================================
[2019-03-26 16:13:29,203] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0847617e-14 1.0000000e+00 4.0688227e-17 4.6172376e-15 4.8874189e-26], sum to 1.0000
[2019-03-26 16:13:29,214] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3484
[2019-03-26 16:13:29,220] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.65, 86.5, 1.0, 2.0, 0.8092786043371636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1131071.240538237, 1131071.240538237, 246199.3353515615], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6409800.0000, 
sim time next is 6410400.0000, 
raw observation next is [26.63333333333333, 86.66666666666667, 1.0, 2.0, 0.8158653122606526, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1140281.957457591, 1140281.957457591, 247840.6586379914], 
processed observation next is [1.0, 0.17391304347826086, 0.46129541864139006, 0.8666666666666667, 1.0, 1.0, 0.7781509786272923, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.31674498818266417, 0.31674498818266417, 0.36991143080297223], 
reward next is 0.6301, 
noisyNet noise sample is [array([-0.5076821], dtype=float32), 0.8586922]. 
=============================================
[2019-03-26 16:13:31,152] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.0560060e-09 6.7287433e-01 1.7571740e-08 3.2712564e-01 1.5165025e-14], sum to 1.0000
[2019-03-26 16:13:31,155] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5733
[2019-03-26 16:13:31,162] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1658259.330270431 W.
[2019-03-26 16:13:31,167] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.91666666666667, 68.83333333333333, 1.0, 2.0, 0.3953982978142323, 1.0, 2.0, 0.3953982978142323, 1.0, 1.0, 0.6777733182140108, 6.9112, 6.9112, 170.5573041426782, 1658259.330270431, 1658259.330270431, 349121.3945702133], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6441000.0000, 
sim time next is 6441600.0000, 
raw observation next is [29.93333333333333, 68.66666666666667, 1.0, 2.0, 0.8944139326635794, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.983203582479412, 6.9112, 168.9125293341912, 2147217.582908822, 2096135.892510396, 433331.1606426059], 
processed observation next is [1.0, 0.5652173913043478, 0.6176935229067929, 0.6866666666666668, 1.0, 1.0, 0.8727878706790113, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.007200358247941185, 0.0, 0.829437847521403, 0.5964493285857839, 0.5822599701417767, 0.6467629263322476], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0279659], dtype=float32), -0.30586725]. 
=============================================
[2019-03-26 16:13:37,978] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.5341894e-15 1.0000000e+00 1.4340133e-16 1.6664022e-13 5.7027568e-26], sum to 1.0000
[2019-03-26 16:13:37,989] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4207
[2019-03-26 16:13:37,994] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.16666666666667, 85.00000000000001, 1.0, 2.0, 0.5183179903372933, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 724277.5877025435, 724277.587702544, 186516.119772264], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6635400.0000, 
sim time next is 6636000.0000, 
raw observation next is [27.13333333333334, 85.0, 1.0, 2.0, 0.517155402362409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 722652.4794647552, 722652.4794647545, 186327.840041978], 
processed observation next is [1.0, 0.8260869565217391, 0.4849921011058455, 0.85, 1.0, 1.0, 0.418259520918565, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20073679985132087, 0.20073679985132067, 0.278101253793997], 
reward next is 0.7219, 
noisyNet noise sample is [array([0.94627726], dtype=float32), 0.54352313]. 
=============================================
[2019-03-26 16:13:38,009] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[73.878784]
 [72.714005]
 [71.43667 ]
 [70.243195]
 [68.21728 ]], R is [[74.68991852]
 [74.66464233]
 [74.63929749]
 [74.61370087]
 [74.58835602]].
[2019-03-26 16:13:38,390] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-26 16:13:38,391] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 16:13:38,392] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:13:38,392] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 16:13:38,394] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:13:38,395] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 16:13:38,396] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:13:38,397] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 16:13:38,397] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:13:38,398] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 16:13:38,399] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:13:38,425] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run42
[2019-03-26 16:13:38,446] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run42
[2019-03-26 16:13:38,448] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run42
[2019-03-26 16:13:38,466] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run42
[2019-03-26 16:13:38,512] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run42
[2019-03-26 16:13:49,093] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.1051744], dtype=float32), 0.07216765]
[2019-03-26 16:13:49,095] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [24.6, 60.33333333333334, 1.0, 2.0, 0.2877822486020971, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 465858.9072375446, 465858.9072375452, 164660.8032607686]
[2019-03-26 16:13:49,097] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:13:49,099] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0692928e-15 1.0000000e+00 8.7270005e-19 6.2279462e-18 3.5717939e-29], sampled 0.9752896661831332
[2019-03-26 16:13:55,481] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.1051744], dtype=float32), 0.07216765]
[2019-03-26 16:13:55,482] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [20.75, 91.5, 1.0, 2.0, 0.3013804495338689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 482240.2122836426, 482240.2122836426, 165809.8527482715]
[2019-03-26 16:13:55,482] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:13:55,484] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [5.6951118e-16 1.0000000e+00 3.3462036e-19 1.7608864e-18 1.2575059e-29], sampled 0.11091654264297879
[2019-03-26 16:14:03,019] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.1051744], dtype=float32), 0.07216765]
[2019-03-26 16:14:03,021] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [23.55, 93.0, 1.0, 2.0, 0.4199998989951648, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 617232.8827177004, 617232.8827177004, 175891.569525208]
[2019-03-26 16:14:03,022] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 16:14:03,024] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.3591273e-15 1.0000000e+00 9.6755461e-19 3.0371001e-18 6.1928729e-29], sampled 0.9608904935974472
[2019-03-26 16:14:06,474] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.1051744], dtype=float32), 0.07216765]
[2019-03-26 16:14:06,475] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [23.0, 92.0, 1.0, 2.0, 0.3945100619543737, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 593712.2902885507, 593712.2902885507, 174104.0259056078]
[2019-03-26 16:14:06,476] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:14:06,481] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [5.1994821e-16 1.0000000e+00 3.8081255e-19 3.3898366e-18 1.3701850e-29], sampled 0.858319999925491
[2019-03-26 16:14:35,005] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.1051744], dtype=float32), 0.07216765]
[2019-03-26 16:14:35,006] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.3, 70.5, 1.0, 2.0, 0.5533244342764245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 773212.0473396234, 773212.0473396234, 192372.1895989347]
[2019-03-26 16:14:35,007] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 16:14:35,010] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.7436162e-16 1.0000000e+00 2.0286617e-19 3.1998973e-18 4.3433049e-30], sampled 0.04012486662919368
[2019-03-26 16:14:42,578] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.1051744], dtype=float32), 0.07216765]
[2019-03-26 16:14:42,579] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.57927218, 92.36423922, 1.0, 2.0, 0.6062537347940316, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 847204.6129064778, 847204.6129064785, 201917.316780881]
[2019-03-26 16:14:42,580] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 16:14:42,583] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [7.9240308e-16 1.0000000e+00 1.1094465e-18 3.7891900e-17 6.4769174e-29], sampled 0.22209922016070083
[2019-03-26 16:14:44,963] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.1051744], dtype=float32), 0.07216765]
[2019-03-26 16:14:44,964] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [36.36666666666667, 50.33333333333334, 1.0, 2.0, 0.6127537713687046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 856291.7005514625, 856291.7005514619, 203145.5588916994]
[2019-03-26 16:14:44,965] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:14:44,969] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0206767e-15 1.0000000e+00 8.7273004e-19 6.9575096e-18 4.3144911e-29], sampled 0.6719747868700253
[2019-03-26 16:14:45,064] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.1051744], dtype=float32), 0.07216765]
[2019-03-26 16:14:45,065] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [37.3, 44.0, 1.0, 2.0, 0.5859099865252722, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 818764.440979066, 818764.440979066, 198149.7678407352]
[2019-03-26 16:14:45,066] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:14:45,069] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [8.5381313e-16 1.0000000e+00 7.2126169e-19 6.9481476e-18 2.9780453e-29], sampled 0.2510750084786013
[2019-03-26 16:14:46,512] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.1051744], dtype=float32), 0.07216765]
[2019-03-26 16:14:46,513] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.52284843166667, 85.62115848666667, 1.0, 2.0, 0.6637995663015422, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005973023235249, 6.9112, 168.9123160594943, 1824472.785820048, 1757237.796230618, 376986.381946835]
[2019-03-26 16:14:46,514] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 16:14:46,517] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [9.4189756e-10 9.9997175e-01 2.7602173e-10 2.8232082e-05 8.9698751e-17], sampled 0.6758934163171384
[2019-03-26 16:14:46,518] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1824472.785820048 W.
[2019-03-26 16:14:50,551] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.1051744], dtype=float32), 0.07216765]
[2019-03-26 16:14:50,552] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.0, 84.0, 1.0, 2.0, 0.5097186140793517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 712257.1220534906, 712257.1220534906, 185132.8167083495]
[2019-03-26 16:14:50,553] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:14:50,556] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.3734699e-16 1.0000000e+00 2.5933027e-19 4.4115101e-18 8.7226586e-30], sampled 0.9345792767395086
[2019-03-26 16:14:55,115] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.1051744], dtype=float32), 0.07216765]
[2019-03-26 16:14:55,116] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.81666666666667, 75.5, 1.0, 2.0, 0.5517074822705876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 770951.708893965, 770951.7088939657, 192094.7839103541]
[2019-03-26 16:14:55,116] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:14:55,118] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [8.4033637e-14 1.0000000e+00 2.3442175e-15 2.3031084e-10 3.7603183e-25], sampled 0.4431411087743644
[2019-03-26 16:15:31,591] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8252.9283 2927297329.7882 1338.0000
[2019-03-26 16:15:32,669] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8500.3235 2842098119.8744 1122.0000
[2019-03-26 16:15:32,691] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7894.5720 3164002357.7143 1754.0000
[2019-03-26 16:15:32,726] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7999.1675 3007664743.0219 1765.0000
[2019-03-26 16:15:32,854] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.5921 2779214994.0068 933.0000
[2019-03-26 16:15:33,871] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1025000, evaluation results [1025000.0, 7894.572020806667, 3164002357.7142725, 1754.0, 8252.928342499928, 2927297329.7881875, 1338.0, 8660.592086161303, 2779214994.0067887, 933.0, 7999.16747876032, 3007664743.0218863, 1765.0, 8500.32354164238, 2842098119.874411, 1122.0]
[2019-03-26 16:15:36,525] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.7904153e-10 9.9960190e-01 7.9203866e-10 3.9817745e-04 1.2313854e-15], sum to 1.0000
[2019-03-26 16:15:36,531] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4615
[2019-03-26 16:15:36,539] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.55, 73.5, 1.0, 2.0, 0.9750771210918537, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.912956503881, 1364335.127677527, 1364335.127677527, 291636.338107019], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7129800.0000, 
sim time next is 7130400.0000, 
raw observation next is [27.43333333333333, 74.33333333333333, 1.0, 2.0, 0.969141203040183, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.9129565104294, 1357649.184749751, 1357649.184749752, 290126.6360330723], 
processed observation next is [1.0, 0.5217391304347826, 0.49921011058451803, 0.7433333333333333, 1.0, 1.0, 0.9628207265544374, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451522949, 0.37712477354159746, 0.3771247735415978, 0.43302482990010793], 
reward next is 0.5670, 
noisyNet noise sample is [array([0.07898914], dtype=float32), 0.076576136]. 
=============================================
[2019-03-26 16:15:41,601] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.6724586e-09 9.9923539e-01 2.0092483e-09 7.6463330e-04 9.3583810e-16], sum to 1.0000
[2019-03-26 16:15:41,606] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4430
[2019-03-26 16:15:41,614] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2067403.825068521 W.
[2019-03-26 16:15:41,618] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.05, 62.0, 1.0, 2.0, 0.8373902587076376, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 6.963014436593392, 6.9112, 168.911720186025, 2067403.825068521, 2030645.149483591, 418651.5665015894], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6701400.0000, 
sim time next is 6702000.0000, 
raw observation next is [30.1, 61.33333333333334, 1.0, 2.0, 0.7498430008406768, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.96228244268428, 6.9112, 168.9126095746411, 1944879.085844175, 1908639.51731573, 397211.6105255572], 
processed observation next is [1.0, 0.5652173913043478, 0.6255924170616115, 0.6133333333333334, 1.0, 1.0, 0.6986060251092491, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.005108244268428042, 0.0, 0.8294382415387463, 0.5402441905122708, 0.5301776436988139, 0.5928531500381451], 
reward next is 0.1517, 
noisyNet noise sample is [array([0.04135343], dtype=float32), -1.1497947]. 
=============================================
[2019-03-26 16:15:41,630] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[42.968754]
 [43.537888]
 [40.01113 ]
 [41.040485]
 [36.644997]], R is [[42.69551086]
 [42.26855469]
 [41.84587097]
 [41.42741394]
 [41.01314163]].
[2019-03-26 16:15:43,760] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.75782535e-15 1.00000000e+00 4.58019790e-18 6.83427792e-16
 1.20275904e-26], sum to 1.0000
[2019-03-26 16:15:43,771] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5750
[2019-03-26 16:15:43,775] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.2, 83.66666666666667, 1.0, 2.0, 0.3422726798846468, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 542331.6899244603, 542331.6899244603, 170328.2951468949], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6748800.0000, 
sim time next is 6749400.0000, 
raw observation next is [22.15, 83.83333333333333, 1.0, 2.0, 0.3336939028776395, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 529080.5901565697, 529080.5901565697, 169277.7967602219], 
processed observation next is [1.0, 0.08695652173913043, 0.24881516587677724, 0.8383333333333333, 1.0, 1.0, 0.19722156973209579, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14696683059904714, 0.14696683059904714, 0.2526534280003312], 
reward next is 0.7473, 
noisyNet noise sample is [array([1.2670718], dtype=float32), 1.3890269]. 
=============================================
[2019-03-26 16:15:47,511] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.0095294e-15 1.0000000e+00 2.1534880e-17 2.0799457e-15 1.1672219e-27], sum to 1.0000
[2019-03-26 16:15:47,517] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9316
[2019-03-26 16:15:47,521] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.06666666666667, 52.33333333333334, 1.0, 2.0, 0.327127050225511, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 510597.1251775273, 510597.125177528, 167672.0984467441], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6804600.0000, 
sim time next is 6805200.0000, 
raw observation next is [27.93333333333333, 52.66666666666667, 1.0, 2.0, 0.3291272454004744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 514442.2397993554, 514442.2397993554, 167989.4457651611], 
processed observation next is [1.0, 0.782608695652174, 0.522906793048973, 0.5266666666666667, 1.0, 1.0, 0.19171957277165588, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1429006221664876, 0.1429006221664876, 0.25073051606740465], 
reward next is 0.7493, 
noisyNet noise sample is [array([-2.8747993], dtype=float32), 1.0789943]. 
=============================================
[2019-03-26 16:15:51,430] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.3073355e-16 1.0000000e+00 1.0228418e-19 1.0834439e-19 4.1624093e-30], sum to 1.0000
[2019-03-26 16:15:51,439] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0067
[2019-03-26 16:15:51,445] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.56666666666667, 34.66666666666667, 1.0, 2.0, 0.2648799904228961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 432452.1975484979, 432452.1975484979, 162377.8519226228], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6873600.0000, 
sim time next is 6874200.0000, 
raw observation next is [29.65, 33.5, 1.0, 2.0, 0.2608519516318573, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 427038.6891723659, 427038.6891723666, 161990.3035745148], 
processed observation next is [0.0, 0.5652173913043478, 0.6042654028436019, 0.335, 1.0, 1.0, 0.1094601826889847, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11862185810343497, 0.11862185810343516, 0.24177657249927584], 
reward next is 0.7582, 
noisyNet noise sample is [array([0.91254663], dtype=float32), -0.6680238]. 
=============================================
[2019-03-26 16:15:51,540] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.5980068e-16 1.0000000e+00 1.9367598e-19 9.0744673e-20 4.4217437e-30], sum to 1.0000
[2019-03-26 16:15:51,549] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5394
[2019-03-26 16:15:51,559] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.46666666666667, 59.83333333333334, 1.0, 2.0, 0.3651673809196034, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 557958.4867546587, 557958.4867546587, 171189.7000053049], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6894600.0000, 
sim time next is 6895200.0000, 
raw observation next is [27.33333333333334, 60.66666666666667, 1.0, 2.0, 0.3659445231085839, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 558768.4986753551, 558768.4986753558, 171247.8002511893], 
processed observation next is [0.0, 0.8260869565217391, 0.4944707740916275, 0.6066666666666667, 1.0, 1.0, 0.2360777386850408, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15521347185426532, 0.1552134718542655, 0.255593731718193], 
reward next is 0.7444, 
noisyNet noise sample is [array([1.0095866], dtype=float32), 1.827541]. 
=============================================
[2019-03-26 16:15:58,862] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.6035210e-16 1.0000000e+00 2.2735713e-19 1.8523188e-18 3.4845425e-30], sum to 1.0000
[2019-03-26 16:15:58,872] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5441
[2019-03-26 16:15:58,876] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.23333333333333, 78.66666666666667, 1.0, 2.0, 0.4525873872756873, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 647814.4362222591, 647814.4362222597, 178481.043968464], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6999600.0000, 
sim time next is 7000200.0000, 
raw observation next is [26.2, 79.0, 1.0, 2.0, 0.4527797744168931, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 647631.4518774964, 647631.451877497, 178451.0905255409], 
processed observation next is [1.0, 0.0, 0.44075829383886256, 0.79, 1.0, 1.0, 0.3406985233938471, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1798976255215268, 0.17989762552152694, 0.2663449112321506], 
reward next is 0.7337, 
noisyNet noise sample is [array([0.49959084], dtype=float32), -0.6933009]. 
=============================================
[2019-03-26 16:15:59,658] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.0628758e-15 1.0000000e+00 2.6085637e-18 1.0878852e-16 4.9942222e-27], sum to 1.0000
[2019-03-26 16:15:59,667] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3745
[2019-03-26 16:15:59,673] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.25, 86.33333333333334, 1.0, 2.0, 0.6385519128081782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 908463.525086581, 908463.5250865803, 210248.3359778945], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7013400.0000, 
sim time next is 7014000.0000, 
raw observation next is [25.2, 86.66666666666667, 1.0, 2.0, 0.6158495117229907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 876285.895155288, 876285.895155288, 205765.4420471193], 
processed observation next is [1.0, 0.17391304347826086, 0.3933649289099526, 0.8666666666666667, 1.0, 1.0, 0.5371680864132419, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.24341274865424667, 0.24341274865424667, 0.3071126000703273], 
reward next is 0.6929, 
noisyNet noise sample is [array([0.10496228], dtype=float32), 1.0440452]. 
=============================================
[2019-03-26 16:15:59,682] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[68.03761]
 [68.12489]
 [68.08543]
 [68.03822]
 [67.93423]], R is [[68.21609497]
 [68.22013092]
 [68.21909332]
 [68.21473694]
 [68.20641327]].
[2019-03-26 16:16:01,776] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.9134611e-10 9.9870861e-01 4.9523241e-10 1.2914238e-03 4.2164114e-16], sum to 1.0000
[2019-03-26 16:16:01,785] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8266
[2019-03-26 16:16:01,792] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1899637.03305244 W.
[2019-03-26 16:16:01,797] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.95, 45.5, 1.0, 2.0, 0.6619977813665969, 1.0, 1.0, 0.6619977813665969, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1899637.03305244, 1899637.03305244, 364235.5141072707], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7047000.0000, 
sim time next is 7047600.0000, 
raw observation next is [32.03333333333334, 45.0, 1.0, 2.0, 0.4292111241674913, 1.0, 2.0, 0.4292111241674913, 1.0, 1.0, 0.7209735845006816, 6.911199999999999, 6.9112, 170.5573041426782, 1824590.731562486, 1824590.731562486, 367898.0019632477], 
processed observation next is [1.0, 0.5652173913043478, 0.7172195892575042, 0.45, 1.0, 1.0, 0.3123025592379413, 1.0, 1.0, 0.3123025592379413, 1.0, 0.5, 0.6597238835374165, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5068307587673572, 0.5068307587673572, 0.549101495467534], 
reward next is 0.4509, 
noisyNet noise sample is [array([-0.13437448], dtype=float32), -1.353187]. 
=============================================
[2019-03-26 16:16:05,016] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.6641704e-15 1.0000000e+00 1.9320602e-18 3.0972395e-17 4.3312643e-28], sum to 1.0000
[2019-03-26 16:16:05,025] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8168
[2019-03-26 16:16:05,033] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333334, 85.66666666666667, 1.0, 2.0, 0.5065954625839889, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 721175.2415038793, 721175.2415038793, 186333.5788862473], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7107600.0000, 
sim time next is 7108200.0000, 
raw observation next is [25.5, 84.5, 1.0, 2.0, 0.5052259938965823, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 719182.4200182089, 719182.4200182089, 186106.7225950922], 
processed observation next is [1.0, 0.2608695652173913, 0.40758293838862564, 0.845, 1.0, 1.0, 0.40388673963443644, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19977289444950247, 0.19977289444950247, 0.277771227753869], 
reward next is 0.7222, 
noisyNet noise sample is [array([0.40923223], dtype=float32), 1.1843837]. 
=============================================
[2019-03-26 16:16:08,933] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.5935729e-13 1.0000000e+00 5.2632438e-15 5.8541592e-12 1.7949419e-22], sum to 1.0000
[2019-03-26 16:16:08,940] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7111
[2019-03-26 16:16:08,951] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1940659.961939648 W.
[2019-03-26 16:16:08,957] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.86666666666667, 84.0, 1.0, 2.0, 0.7468281401299011, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 7.005978164216662, 6.9112, 168.9123932189331, 1940659.961939648, 1873421.294460168, 395119.1179958739], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7203000.0000, 
sim time next is 7203600.0000, 
raw observation next is [29.0, 84.0, 1.0, 2.0, 0.6902267699671631, 1.0, 1.0, 0.6902267699671631, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1930070.761397745, 1930070.761397745, 369976.0600438436], 
processed observation next is [1.0, 0.391304347826087, 0.5734597156398105, 0.84, 1.0, 1.0, 0.6267792409242929, 1.0, 0.5, 0.6267792409242929, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5361307670549291, 0.5361307670549291, 0.5522030746923039], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.616977], dtype=float32), -0.19862089]. 
=============================================
[2019-03-26 16:16:10,385] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.9829792e-16 1.0000000e+00 7.1351168e-19 4.5460483e-17 1.7466143e-28], sum to 1.0000
[2019-03-26 16:16:10,397] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7056
[2019-03-26 16:16:10,401] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.13333333333333, 87.0, 1.0, 2.0, 0.6174904446249414, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 862913.6453420465, 862913.6453420465, 204043.490274068], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7195200.0000, 
sim time next is 7195800.0000, 
raw observation next is [27.26666666666667, 86.5, 1.0, 2.0, 0.6424714448815768, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 897838.1653691144, 897838.1653691144, 208917.7598972099], 
processed observation next is [1.0, 0.2608695652173913, 0.4913112164297, 0.865, 1.0, 1.0, 0.5692427046765985, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.24939949038030954, 0.24939949038030954, 0.3118175520853879], 
reward next is 0.6882, 
noisyNet noise sample is [array([-0.7498111], dtype=float32), -1.1589154]. 
=============================================
[2019-03-26 16:16:10,481] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.10638885e-14 1.00000000e+00 6.38206156e-18 7.79971761e-17
 9.24148432e-28], sum to 1.0000
[2019-03-26 16:16:10,487] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9815
[2019-03-26 16:16:10,493] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.06666666666667, 84.33333333333333, 1.0, 2.0, 0.7052206546148992, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 985569.34343799, 985569.34343799, 221977.3092704298], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7199400.0000, 
sim time next is 7200000.0000, 
raw observation next is [28.2, 84.0, 1.0, 2.0, 0.6548218342147747, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 915104.9686728433, 915104.9686728439, 211397.2321037971], 
processed observation next is [1.0, 0.34782608695652173, 0.5355450236966824, 0.84, 1.0, 1.0, 0.5841226918250297, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2541958246313454, 0.25419582463134555, 0.315518256871339], 
reward next is 0.6845, 
noisyNet noise sample is [array([1.3578434], dtype=float32), -0.42013857]. 
=============================================
[2019-03-26 16:16:10,509] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[69.26953 ]
 [69.34916 ]
 [69.423096]
 [69.41934 ]
 [69.36601 ]], R is [[69.28800201]
 [69.26381683]
 [69.24764252]
 [69.24822235]
 [69.24976349]].
[2019-03-26 16:16:13,305] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.5042045e-15 1.0000000e+00 8.8766127e-19 6.1852139e-17 7.3408524e-28], sum to 1.0000
[2019-03-26 16:16:13,316] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2385
[2019-03-26 16:16:13,323] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.51666666666667, 92.0, 1.0, 2.0, 0.3657264946643853, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 558837.8636058999, 558837.8636058999, 171265.5716764953], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7246200.0000, 
sim time next is 7246800.0000, 
raw observation next is [22.5, 92.0, 1.0, 2.0, 0.3657914902121746, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 559219.1450910879, 559219.1450910879, 171306.429318115], 
processed observation next is [1.0, 0.9130434782608695, 0.2654028436018958, 0.92, 1.0, 1.0, 0.2358933617014152, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1553386514141911, 0.1553386514141911, 0.2556812377882313], 
reward next is 0.7443, 
noisyNet noise sample is [array([0.3394396], dtype=float32), 0.944006]. 
=============================================
[2019-03-26 16:16:13,947] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.5163972e-16 1.0000000e+00 3.6059010e-19 1.5005979e-17 2.8169765e-29], sum to 1.0000
[2019-03-26 16:16:13,957] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7206
[2019-03-26 16:16:13,961] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.31666666666667, 91.0, 1.0, 2.0, 0.3532704015992723, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 544990.5873430512, 544990.5873430519, 170251.2897799421], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7253400.0000, 
sim time next is 7254000.0000, 
raw observation next is [22.3, 91.0, 1.0, 2.0, 0.3529199585290324, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 544707.1351822099, 544707.1351822099, 170234.988984636], 
processed observation next is [1.0, 1.0, 0.25592417061611383, 0.91, 1.0, 1.0, 0.2203854922036535, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15130753755061385, 0.15130753755061385, 0.254082073111397], 
reward next is 0.7459, 
noisyNet noise sample is [array([-0.5167822], dtype=float32), 1.1870174]. 
=============================================
[2019-03-26 16:16:13,975] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[73.41275 ]
 [73.40418 ]
 [73.38809 ]
 [73.36979 ]
 [73.355194]], R is [[73.44995117]
 [73.46134949]
 [73.4726181 ]
 [73.48375702]
 [73.49475098]].
[2019-03-26 16:16:17,773] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.6992585e-15 1.0000000e+00 3.4513720e-18 1.8000694e-16 8.9756925e-28], sum to 1.0000
[2019-03-26 16:16:17,781] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4568
[2019-03-26 16:16:17,784] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.83333333333334, 92.83333333333333, 1.0, 2.0, 0.5834743065123338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 929380.7455296658, 929380.7455296658, 210651.7969317116], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7379400.0000, 
sim time next is 7380000.0000, 
raw observation next is [20.9, 93.0, 1.0, 2.0, 0.5517688611380813, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 877217.9051937595, 877217.9051937595, 204146.8271148559], 
processed observation next is [1.0, 0.43478260869565216, 0.1895734597156398, 0.93, 1.0, 1.0, 0.4599624832988931, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.24367164033159985, 0.24367164033159985, 0.30469675688784464], 
reward next is 0.6953, 
noisyNet noise sample is [array([1.6663384], dtype=float32), 0.6584304]. 
=============================================
[2019-03-26 16:16:17,795] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[69.784424]
 [69.87723 ]
 [70.0213  ]
 [70.193184]
 [70.34901 ]], R is [[69.80369568]
 [69.79125214]
 [69.77896881]
 [69.76142883]
 [69.74935913]].
[2019-03-26 16:16:18,027] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.0572488e-16 1.0000000e+00 1.3256870e-19 2.4058902e-19 3.7088803e-30], sum to 1.0000
[2019-03-26 16:16:18,036] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5183
[2019-03-26 16:16:18,041] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 90.0, 1.0, 2.0, 0.3711948784039869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 561825.6157539217, 561825.6157539217, 171359.5274785451], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7536000.0000, 
sim time next is 7536600.0000, 
raw observation next is [23.15, 90.0, 1.0, 2.0, 0.3728689970565986, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 563456.4493623809, 563456.4493623809, 171472.3764390005], 
processed observation next is [0.0, 0.21739130434782608, 0.2962085308056872, 0.9, 1.0, 1.0, 0.2444204783814441, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15651568037843913, 0.15651568037843913, 0.2559289200582097], 
reward next is 0.7441, 
noisyNet noise sample is [array([1.1559813], dtype=float32), -0.15884909]. 
=============================================
[2019-03-26 16:16:25,528] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:16:25,529] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:16:25,604] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run6
[2019-03-26 16:16:28,439] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-26 16:16:28,440] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 16:16:28,441] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 16:16:28,442] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:16:28,442] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 16:16:28,443] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 16:16:28,443] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:16:28,444] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 16:16:28,448] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:16:28,450] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:16:28,449] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:16:28,469] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run43
[2019-03-26 16:16:28,492] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run43
[2019-03-26 16:16:28,512] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run43
[2019-03-26 16:16:28,540] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run43
[2019-03-26 16:16:28,558] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run43
[2019-03-26 16:16:52,502] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10166839], dtype=float32), 0.07537187]
[2019-03-26 16:16:52,503] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.875553675, 87.79611431000001, 1.0, 2.0, 0.4014193256827775, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 593826.1498402796, 593826.1498402802, 173814.424822691]
[2019-03-26 16:16:52,505] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 16:16:52,507] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [6.2578402e-16 1.0000000e+00 4.5874873e-19 5.3230199e-19 1.0868783e-29], sampled 0.6341751348685493
[2019-03-26 16:16:56,305] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10166839], dtype=float32), 0.07537187]
[2019-03-26 16:16:56,307] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [22.98710485, 91.518497225, 1.0, 2.0, 0.3829329580309134, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 577166.9221455816, 577166.9221455816, 172633.8851655557]
[2019-03-26 16:16:56,310] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 16:16:56,314] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [5.5496619e-16 1.0000000e+00 3.5926103e-19 3.3173021e-19 8.3507600e-30], sampled 0.07058308846255801
[2019-03-26 16:17:14,802] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10166839], dtype=float32), 0.07537187]
[2019-03-26 16:17:14,804] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [22.70184927, 89.14912767, 1.0, 2.0, 0.3768997116479578, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 575484.7850836472, 575484.7850836465, 172697.5036508899]
[2019-03-26 16:17:14,805] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 16:17:14,808] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [5.6845630e-16 1.0000000e+00 5.9671424e-19 2.7613793e-18 2.2332795e-29], sampled 0.8534304866989464
[2019-03-26 16:17:22,907] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10166839], dtype=float32), 0.07537187]
[2019-03-26 16:17:22,909] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [32.13333333333334, 62.33333333333334, 1.0, 2.0, 0.5610334981850477, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 783988.6198070841, 783988.6198070834, 193710.7564236449]
[2019-03-26 16:17:22,911] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:17:22,915] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [9.1610868e-17 1.0000000e+00 8.2468408e-20 1.0476377e-18 7.3951149e-31], sampled 0.36548195957419116
[2019-03-26 16:17:35,135] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10166839], dtype=float32), 0.07537187]
[2019-03-26 16:17:35,136] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.92295205, 86.939876365, 1.0, 2.0, 0.5826877038145744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 814259.8210907832, 814259.8210907832, 197563.2072899876]
[2019-03-26 16:17:35,137] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 16:17:35,138] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.7454611e-16 1.0000000e+00 2.7889764e-19 4.9029730e-19 5.4209413e-30], sampled 0.9426410073612332
[2019-03-26 16:18:03,117] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10166839], dtype=float32), 0.07537187]
[2019-03-26 16:18:03,120] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [32.1, 55.0, 1.0, 2.0, 0.9607770885701378, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.971738302380464, 6.9112, 168.9125476587598, 2240103.650381869, 2197155.799060583, 452626.6163885034]
[2019-03-26 16:18:03,121] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:18:03,123] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.1766528e-10 9.9993801e-01 1.5188206e-10 6.2016312e-05 8.3990770e-18], sampled 0.6247882395456804
[2019-03-26 16:18:03,125] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2240103.650381869 W.
[2019-03-26 16:18:06,295] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10166839], dtype=float32), 0.07537187]
[2019-03-26 16:18:06,296] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.62335445, 78.656712175, 1.0, 2.0, 0.4757863976650271, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 667853.9853113119, 667853.9853113119, 180279.5204759951]
[2019-03-26 16:18:06,297] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 16:18:06,303] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.4764214e-16 1.0000000e+00 1.1251216e-19 5.0892690e-19 1.0961756e-30], sampled 0.9252059151325901
[2019-03-26 16:18:10,835] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10166839], dtype=float32), 0.07537187]
[2019-03-26 16:18:10,835] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.78416138333333, 74.25370101000001, 1.0, 2.0, 0.5361210951609481, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 749163.7330745775, 749163.7330745775, 189447.7643634465]
[2019-03-26 16:18:10,838] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 16:18:10,843] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.1784228e-15 1.0000000e+00 3.9083068e-18 7.4011828e-16 3.6312816e-29], sampled 0.6157878118535421
[2019-03-26 16:18:15,201] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10166839], dtype=float32), 0.07537187]
[2019-03-26 16:18:15,206] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.2, 85.0, 1.0, 2.0, 0.5325703633966957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 744200.2811147927, 744200.2811147921, 188855.825532543]
[2019-03-26 16:18:15,207] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 16:18:15,209] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [9.6601037e-17 1.0000000e+00 8.5068715e-20 7.2615642e-19 7.8172368e-31], sampled 0.9581321265724146
[2019-03-26 16:18:19,395] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10166839], dtype=float32), 0.07537187]
[2019-03-26 16:18:19,395] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.23601841333333, 89.18803216166667, 1.0, 2.0, 0.5892543154545186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 823439.6967097147, 823439.6967097147, 198760.584239656]
[2019-03-26 16:18:19,398] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 16:18:19,402] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.07388697e-16 1.00000000e+00 9.37127650e-20 8.34485238e-19
 1.01033749e-30], sampled 0.7972695270644915
[2019-03-26 16:18:22,466] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.8935 2927432489.3116 1338.0000
[2019-03-26 16:18:22,707] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7995.9509 3007731619.9915 1766.0000
[2019-03-26 16:18:22,877] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.5817 3164433649.1198 1765.0000
[2019-03-26 16:18:22,891] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.5293 2779256595.0998 933.0000
[2019-03-26 16:18:22,900] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8498.9056 2842332500.8407 1126.0000
[2019-03-26 16:18:23,915] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1050000, evaluation results [1050000.0, 7884.5817232134505, 3164433649.1198254, 1765.0, 8254.89346206886, 2927432489.31157, 1338.0, 8660.529287309864, 2779256595.0998096, 933.0, 7995.950884061574, 3007731619.9915137, 1766.0, 8498.90556320189, 2842332500.8407016, 1126.0]
[2019-03-26 16:18:29,019] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.8834010e-16 1.0000000e+00 1.6441527e-18 1.1537706e-16 3.9544169e-28], sum to 1.0000
[2019-03-26 16:18:29,029] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7456
[2019-03-26 16:18:29,036] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.8, 81.50000000000001, 1.0, 2.0, 0.7127881500550555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 996150.1304022573, 996150.1304022567, 223629.0965376089], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7805400.0000, 
sim time next is 7806000.0000, 
raw observation next is [27.9, 81.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.033352266784503, 6.9112, 168.9124136582439, 1540473.016786713, 1453814.27307785, 311349.7422177122], 
processed observation next is [1.0, 0.34782608695652173, 0.5213270142180094, 0.81, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.012215226678450274, 0.0, 0.8294372794995453, 0.42790917132964246, 0.40383729807718055, 0.4647011077876302], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.16879416], dtype=float32), -0.64456964]. 
=============================================
[2019-03-26 16:18:29,057] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[69.43223]
 [69.38992]
 [69.47234]
 [69.59422]
 [69.70265]], R is [[68.23042297]
 [68.21434021]
 [68.1771698 ]
 [68.13887024]
 [68.10623932]].
[2019-03-26 16:18:31,015] A3C_AGENT_WORKER-Thread-10 INFO:Local step 66500, global step 1053305: loss 0.0194
[2019-03-26 16:18:31,018] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 66500, global step 1053305: learning rate 0.0000
[2019-03-26 16:18:32,535] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:18:32,535] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:18:32,589] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run6
[2019-03-26 16:18:37,678] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:18:37,679] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:18:37,743] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run6
[2019-03-26 16:18:40,531] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.4777676e-08 7.5336051e-01 3.5616729e-08 2.4663948e-01 4.8877558e-13], sum to 1.0000
[2019-03-26 16:18:40,536] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0595
[2019-03-26 16:18:40,544] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2387025.240955017 W.
[2019-03-26 16:18:40,548] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.0, 70.0, 1.0, 2.0, 0.853469652280413, 1.0, 2.0, 0.853469652280413, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2387025.240955017, 2387025.240955017, 446743.1781761128], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7819200.0000, 
sim time next is 7819800.0000, 
raw observation next is [31.0, 70.0, 1.0, 2.0, 0.5285350634459048, 1.0, 2.0, 0.5285350634459048, 1.0, 1.0, 0.9178906159891194, 6.9112, 6.9112, 170.5573041426782, 2217198.161613202, 2217198.161613202, 435439.6475086499], 
processed observation next is [1.0, 0.5217391304347826, 0.6682464454976303, 0.7, 1.0, 1.0, 0.43196995595892146, 1.0, 1.0, 0.43196995595892146, 1.0, 0.5, 0.8998666048647798, 0.0, 0.0, 0.8375144448122397, 0.6158883782258895, 0.6158883782258895, 0.6499099216547014], 
reward next is 0.3501, 
noisyNet noise sample is [array([1.2303258], dtype=float32), -0.8084552]. 
=============================================
[2019-03-26 16:18:41,931] A3C_AGENT_WORKER-Thread-9 INFO:Local step 66500, global step 1058731: loss 0.0273
[2019-03-26 16:18:41,935] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 66500, global step 1058733: learning rate 0.0000
[2019-03-26 16:18:45,311] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:18:45,312] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:18:45,368] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run6
[2019-03-26 16:18:46,015] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:18:46,015] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:18:46,070] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run6
[2019-03-26 16:18:46,351] A3C_AGENT_WORKER-Thread-10 INFO:Local step 67000, global step 1060655: loss 0.1487
[2019-03-26 16:18:46,353] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 67000, global step 1060655: learning rate 0.0000
[2019-03-26 16:18:46,677] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.5228696e-09 3.5420117e-01 6.0641256e-09 6.4579886e-01 5.9922922e-15], sum to 1.0000
[2019-03-26 16:18:46,682] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1336
[2019-03-26 16:18:46,687] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2091022.406313971 W.
[2019-03-26 16:18:46,694] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.8, 62.0, 1.0, 2.0, 0.7477297504254227, 1.0, 2.0, 0.7477297504254227, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2091022.406313971, 2091022.40631397, 395219.3459977715], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7923600.0000, 
sim time next is 7924200.0000, 
raw observation next is [30.63333333333333, 63.0, 1.0, 2.0, 0.2285589165500565, 1.0, 2.0, 0.2285589165500565, 1.0, 1.0, 0.3891282141859561, 6.9112, 6.9112, 170.5573041426782, 958239.5952707824, 958239.5952707824, 277786.5847824165], 
processed observation next is [1.0, 0.7391304347826086, 0.6508688783570299, 0.63, 1.0, 1.0, 0.07055291150609216, 1.0, 1.0, 0.07055291150609216, 1.0, 0.5, 0.25503440754384893, 0.0, 0.0, 0.8375144448122397, 0.2661776653529951, 0.2661776653529951, 0.41460684295883066], 
reward next is 0.5854, 
noisyNet noise sample is [array([1.1482264], dtype=float32), -0.21355334]. 
=============================================
[2019-03-26 16:18:47,089] A3C_AGENT_WORKER-Thread-13 INFO:Local step 66500, global step 1061110: loss 0.0232
[2019-03-26 16:18:47,093] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 66500, global step 1061111: learning rate 0.0000
[2019-03-26 16:18:47,419] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:18:47,420] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:18:47,511] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run6
[2019-03-26 16:18:47,821] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:18:47,822] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:18:47,883] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run6
[2019-03-26 16:18:48,384] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:18:48,386] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:18:48,438] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run6
[2019-03-26 16:18:48,539] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:18:48,540] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:18:48,592] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run6
[2019-03-26 16:18:48,621] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:18:48,622] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:18:48,668] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run6
[2019-03-26 16:18:48,683] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:18:48,685] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:18:48,717] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:18:48,717] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:18:48,731] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run6
[2019-03-26 16:18:48,747] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:18:48,748] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:18:48,766] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run6
[2019-03-26 16:18:48,799] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run6
[2019-03-26 16:18:48,829] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:18:48,830] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:18:48,843] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run6
[2019-03-26 16:18:48,929] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:18:48,929] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:18:48,933] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run6
[2019-03-26 16:18:49,084] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:18:49,084] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:18:49,098] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run6
[2019-03-26 16:18:50,216] A3C_AGENT_WORKER-Thread-14 INFO:Local step 66500, global step 1062764: loss 0.0075
[2019-03-26 16:18:50,218] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 66500, global step 1062764: learning rate 0.0000
[2019-03-26 16:18:51,077] A3C_AGENT_WORKER-Thread-2 INFO:Local step 66500, global step 1063207: loss 0.0033
[2019-03-26 16:18:51,084] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 66500, global step 1063207: learning rate 0.0000
[2019-03-26 16:18:54,078] A3C_AGENT_WORKER-Thread-9 INFO:Local step 67000, global step 1064571: loss 0.0794
[2019-03-26 16:18:54,084] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 67000, global step 1064572: learning rate 0.0000
[2019-03-26 16:18:55,377] A3C_AGENT_WORKER-Thread-15 INFO:Local step 66500, global step 1065165: loss 0.0007
[2019-03-26 16:18:55,380] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 66500, global step 1065165: learning rate 0.0000
[2019-03-26 16:18:56,017] A3C_AGENT_WORKER-Thread-3 INFO:Local step 66500, global step 1065454: loss 0.0011
[2019-03-26 16:18:56,023] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 66500, global step 1065455: learning rate 0.0000
[2019-03-26 16:18:56,218] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.5309448e-15 1.0000000e+00 9.6963114e-19 7.9691639e-17 2.3040056e-28], sum to 1.0000
[2019-03-26 16:18:56,226] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9284
[2019-03-26 16:18:56,233] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.9, 93.0, 1.0, 2.0, 0.7745131948637836, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1164801.432218528, 1164801.432218527, 248736.2027919169], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 120600.0000, 
sim time next is 121200.0000, 
raw observation next is [22.9, 93.33333333333334, 1.0, 2.0, 0.6944983242685399, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1042988.007843672, 1042988.007843671, 228991.4354119874], 
processed observation next is [1.0, 0.391304347826087, 0.2843601895734597, 0.9333333333333335, 1.0, 1.0, 0.6319256918898071, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.28971889106768667, 0.2897188910676864, 0.3417782618089364], 
reward next is 0.6582, 
noisyNet noise sample is [array([0.70399165], dtype=float32), 1.1891984]. 
=============================================
[2019-03-26 16:18:57,960] A3C_AGENT_WORKER-Thread-22 INFO:Local step 66500, global step 1066297: loss 0.0017
[2019-03-26 16:18:57,962] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 66500, global step 1066297: learning rate 0.0000
[2019-03-26 16:18:58,327] A3C_AGENT_WORKER-Thread-21 INFO:Local step 66500, global step 1066464: loss 0.0010
[2019-03-26 16:18:58,331] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 66500, global step 1066464: learning rate 0.0000
[2019-03-26 16:18:58,430] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.3120658e-17 1.0000000e+00 2.5921356e-19 2.0180431e-17 2.3450504e-29], sum to 1.0000
[2019-03-26 16:18:58,439] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4233
[2019-03-26 16:18:58,443] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.76666666666667, 96.0, 1.0, 2.0, 0.9044035746117289, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1348117.53132895, 1348117.53132895, 283243.743922193], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 138000.0000, 
sim time next is 138600.0000, 
raw observation next is [22.75, 96.0, 1.0, 2.0, 0.9123297797886507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1360691.385182906, 1360691.385182906, 285705.5645954492], 
processed observation next is [1.0, 0.6086956521739131, 0.27725118483412325, 0.96, 1.0, 1.0, 0.894373228661025, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.37796982921747385, 0.37796982921747385, 0.4264262158141033], 
reward next is 0.5736, 
noisyNet noise sample is [array([-0.27539805], dtype=float32), -0.18155797]. 
=============================================
[2019-03-26 16:18:58,778] A3C_AGENT_WORKER-Thread-10 INFO:Local step 67500, global step 1066662: loss 1.2338
[2019-03-26 16:18:58,780] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 67500, global step 1066663: learning rate 0.0000
[2019-03-26 16:18:58,878] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0290745e-15 1.0000000e+00 3.2757665e-19 3.6514136e-19 3.4481678e-29], sum to 1.0000
[2019-03-26 16:18:58,880] A3C_AGENT_WORKER-Thread-18 INFO:Local step 66500, global step 1066706: loss 0.0007
[2019-03-26 16:18:58,880] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4400
[2019-03-26 16:18:58,885] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 66500, global step 1066708: learning rate 0.0000
[2019-03-26 16:18:58,887] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.03333333333333, 83.33333333333334, 1.0, 2.0, 0.2963295790978868, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 471918.240543293, 471918.2405432923, 165048.3676505503], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 289200.0000, 
sim time next is 289800.0000, 
raw observation next is [22.1, 83.0, 1.0, 2.0, 0.2966076757588989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 472137.6107390649, 472137.6107390655, 165060.0192987906], 
processed observation next is [0.0, 0.34782608695652173, 0.24644549763033188, 0.83, 1.0, 1.0, 0.15253936838421553, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13114933631640693, 0.13114933631640707, 0.24635823775938898], 
reward next is 0.7536, 
noisyNet noise sample is [array([0.14249937], dtype=float32), 0.23794894]. 
=============================================
[2019-03-26 16:18:59,198] A3C_AGENT_WORKER-Thread-16 INFO:Local step 66500, global step 1066852: loss 0.0015
[2019-03-26 16:18:59,205] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 66500, global step 1066854: learning rate 0.0000
[2019-03-26 16:18:59,292] A3C_AGENT_WORKER-Thread-11 INFO:Local step 66500, global step 1066899: loss 0.0015
[2019-03-26 16:18:59,294] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 66500, global step 1066899: learning rate 0.0000
[2019-03-26 16:18:59,345] A3C_AGENT_WORKER-Thread-19 INFO:Local step 66500, global step 1066922: loss 0.0017
[2019-03-26 16:18:59,347] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 66500, global step 1066923: learning rate 0.0000
[2019-03-26 16:18:59,359] A3C_AGENT_WORKER-Thread-17 INFO:Local step 66500, global step 1066926: loss 0.0020
[2019-03-26 16:18:59,362] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 66500, global step 1066927: learning rate 0.0000
[2019-03-26 16:18:59,423] A3C_AGENT_WORKER-Thread-20 INFO:Local step 66500, global step 1066953: loss 0.0023
[2019-03-26 16:18:59,426] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 66500, global step 1066954: learning rate 0.0000
[2019-03-26 16:18:59,521] A3C_AGENT_WORKER-Thread-13 INFO:Local step 67000, global step 1066998: loss 0.0589
[2019-03-26 16:18:59,525] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 67000, global step 1066999: learning rate 0.0000
[2019-03-26 16:18:59,592] A3C_AGENT_WORKER-Thread-12 INFO:Local step 66500, global step 1067028: loss 0.0025
[2019-03-26 16:18:59,595] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 66500, global step 1067030: learning rate 0.0000
[2019-03-26 16:18:59,827] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.5280643e-16 1.0000000e+00 7.8321157e-20 1.8241222e-19 2.6668649e-30], sum to 1.0000
[2019-03-26 16:18:59,835] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5803
[2019-03-26 16:18:59,840] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.86666666666667, 86.66666666666667, 1.0, 2.0, 0.3131247584795168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 495602.7717489544, 495602.7717489544, 166706.5928255732], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 229200.0000, 
sim time next is 229800.0000, 
raw observation next is [21.83333333333334, 86.83333333333333, 1.0, 2.0, 0.3124297950515363, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 494635.7626226757, 494635.7626226764, 166637.5361426853], 
processed observation next is [0.0, 0.6521739130434783, 0.23380726698262277, 0.8683333333333333, 1.0, 1.0, 0.17160216271269432, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13739882295074324, 0.13739882295074343, 0.2487127405114706], 
reward next is 0.7513, 
noisyNet noise sample is [array([0.07697064], dtype=float32), 0.53787243]. 
=============================================
[2019-03-26 16:19:00,301] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.4780210e-17 1.0000000e+00 1.6853134e-19 1.6252218e-17 3.8675566e-30], sum to 1.0000
[2019-03-26 16:19:00,309] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5048
[2019-03-26 16:19:00,317] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.4, 96.0, 1.0, 2.0, 0.3043500634891076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 485130.2792367901, 485130.2792367901, 165997.3618849702], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 172800.0000, 
sim time next is 173400.0000, 
raw observation next is [20.36666666666667, 96.0, 1.0, 2.0, 0.3031448632281573, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 483559.4951141838, 483559.4951141845, 165888.6869817479], 
processed observation next is [0.0, 0.0, 0.1642969984202214, 0.96, 1.0, 1.0, 0.16041549786524978, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13432208197616216, 0.13432208197616236, 0.24759505519663863], 
reward next is 0.7524, 
noisyNet noise sample is [array([0.05548222], dtype=float32), 0.77851886]. 
=============================================
[2019-03-26 16:19:05,956] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.6503919e-17 1.0000000e+00 5.9025007e-21 4.5468066e-19 6.0607732e-31], sum to 1.0000
[2019-03-26 16:19:05,966] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1451
[2019-03-26 16:19:05,971] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.76666666666667, 86.0, 1.0, 2.0, 0.2702746393103583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 437882.283578461, 437882.283578461, 162795.8371069399], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 340800.0000, 
sim time next is 341400.0000, 
raw observation next is [20.73333333333333, 86.0, 1.0, 2.0, 0.2699359480484261, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 437581.6072774009, 437581.6072774003, 162773.8817263108], 
processed observation next is [0.0, 0.9565217391304348, 0.18167456556082143, 0.86, 1.0, 1.0, 0.12040475668485069, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12155044646594469, 0.12155044646594454, 0.24294609212882207], 
reward next is 0.7571, 
noisyNet noise sample is [array([-0.23332886], dtype=float32), -0.33516628]. 
=============================================
[2019-03-26 16:19:07,382] A3C_AGENT_WORKER-Thread-14 INFO:Local step 67000, global step 1070764: loss 0.0672
[2019-03-26 16:19:07,388] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 67000, global step 1070767: learning rate 0.0000
[2019-03-26 16:19:08,185] A3C_AGENT_WORKER-Thread-2 INFO:Local step 67000, global step 1071129: loss 0.0569
[2019-03-26 16:19:08,187] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 67000, global step 1071129: learning rate 0.0000
[2019-03-26 16:19:11,394] A3C_AGENT_WORKER-Thread-9 INFO:Local step 67500, global step 1072576: loss 1.2281
[2019-03-26 16:19:11,396] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 67500, global step 1072576: learning rate 0.0000
[2019-03-26 16:19:11,886] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.4154762e-16 1.0000000e+00 2.2646644e-19 9.6831946e-18 1.3782534e-28], sum to 1.0000
[2019-03-26 16:19:11,898] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9238
[2019-03-26 16:19:11,907] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.7, 86.0, 1.0, 2.0, 0.2442807504006924, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 402025.3453116264, 402025.3453116264, 160343.6647814425], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 432000.0000, 
sim time next is 432600.0000, 
raw observation next is [19.68333333333333, 85.83333333333334, 1.0, 2.0, 0.2435470947532007, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 400939.6576215969, 400939.6576215975, 160270.3409328334], 
processed observation next is [1.0, 0.0, 0.13191153238546593, 0.8583333333333334, 1.0, 1.0, 0.08861095753397673, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11137212711711024, 0.11137212711711042, 0.23920946407885582], 
reward next is 0.7608, 
noisyNet noise sample is [array([0.2732566], dtype=float32), -1.2571214]. 
=============================================
[2019-03-26 16:19:12,775] A3C_AGENT_WORKER-Thread-15 INFO:Local step 67000, global step 1073201: loss 0.0560
[2019-03-26 16:19:12,777] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 67000, global step 1073202: learning rate 0.0000
[2019-03-26 16:19:13,304] A3C_AGENT_WORKER-Thread-3 INFO:Local step 67000, global step 1073441: loss 0.0520
[2019-03-26 16:19:13,306] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 67000, global step 1073441: learning rate 0.0000
[2019-03-26 16:19:15,156] A3C_AGENT_WORKER-Thread-22 INFO:Local step 67000, global step 1074279: loss 0.0478
[2019-03-26 16:19:15,158] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 67000, global step 1074280: learning rate 0.0000
[2019-03-26 16:19:15,367] A3C_AGENT_WORKER-Thread-21 INFO:Local step 67000, global step 1074378: loss 0.0488
[2019-03-26 16:19:15,368] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 67000, global step 1074378: learning rate 0.0000
[2019-03-26 16:19:15,969] A3C_AGENT_WORKER-Thread-10 INFO:Local step 68000, global step 1074650: loss 0.0110
[2019-03-26 16:19:15,972] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 68000, global step 1074651: learning rate 0.0000
[2019-03-26 16:19:16,001] A3C_AGENT_WORKER-Thread-18 INFO:Local step 67000, global step 1074661: loss 0.0382
[2019-03-26 16:19:16,003] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 67000, global step 1074661: learning rate 0.0000
[2019-03-26 16:19:16,470] A3C_AGENT_WORKER-Thread-11 INFO:Local step 67000, global step 1074876: loss 0.0390
[2019-03-26 16:19:16,472] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 67000, global step 1074876: learning rate 0.0000
[2019-03-26 16:19:16,507] A3C_AGENT_WORKER-Thread-16 INFO:Local step 67000, global step 1074893: loss 0.0391
[2019-03-26 16:19:16,508] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 67000, global step 1074893: learning rate 0.0000
[2019-03-26 16:19:16,587] A3C_AGENT_WORKER-Thread-19 INFO:Local step 67000, global step 1074928: loss 0.0388
[2019-03-26 16:19:16,590] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 67000, global step 1074928: learning rate 0.0000
[2019-03-26 16:19:16,606] A3C_AGENT_WORKER-Thread-17 INFO:Local step 67000, global step 1074937: loss 0.0371
[2019-03-26 16:19:16,607] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 67000, global step 1074937: learning rate 0.0000
[2019-03-26 16:19:16,653] A3C_AGENT_WORKER-Thread-20 INFO:Local step 67000, global step 1074959: loss 0.0378
[2019-03-26 16:19:16,654] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 67000, global step 1074959: learning rate 0.0000
[2019-03-26 16:19:16,749] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-26 16:19:16,750] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 16:19:16,751] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:19:16,751] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 16:19:16,753] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 16:19:16,755] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:19:16,757] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:19:16,754] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 16:19:16,758] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 16:19:16,760] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:19:16,764] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:19:16,783] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run44
[2019-03-26 16:19:16,783] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run44
[2019-03-26 16:19:16,784] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run44
[2019-03-26 16:19:16,849] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run44
[2019-03-26 16:19:16,849] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run44
[2019-03-26 16:19:17,933] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.09941707], dtype=float32), 0.077811524]
[2019-03-26 16:19:17,934] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.38333333333333, 74.16666666666667, 1.0, 2.0, 0.3922140317846211, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 591677.4914211158, 591677.4914211164, 173957.0962910506]
[2019-03-26 16:19:17,936] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 16:19:17,941] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.7772804e-03 9.9603844e-01 4.5451493e-04 1.7225624e-03 7.2579278e-06], sampled 0.08286594928901725
[2019-03-26 16:19:25,726] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.09941707], dtype=float32), 0.077811524]
[2019-03-26 16:19:25,727] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [22.23333333333333, 64.66666666666667, 1.0, 2.0, 0.2385552146288322, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 394441.1915664291, 394441.1915664297, 159717.1914089242]
[2019-03-26 16:19:25,729] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:19:25,731] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [5.2832362e-16 1.0000000e+00 1.9037604e-19 1.5397962e-19 6.7380344e-30], sampled 0.02504251079448616
[2019-03-26 16:20:02,751] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.09941707], dtype=float32), 0.077811524]
[2019-03-26 16:20:02,752] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.85, 77.5, 1.0, 2.0, 0.5791991462417341, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 809382.9813360535, 809382.9813360535, 196934.3835084231]
[2019-03-26 16:20:02,753] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:20:02,757] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.58320482e-17 1.00000000e+00 1.18345635e-20 2.43039959e-19
 1.02999295e-31], sampled 0.6012296909674131
[2019-03-26 16:20:03,318] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.09941707], dtype=float32), 0.077811524]
[2019-03-26 16:20:03,320] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [22.67915911, 93.77669709999999, 1.0, 2.0, 0.4445477960308391, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 673168.2263800786, 673168.2263800792, 181775.760767309]
[2019-03-26 16:20:03,321] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 16:20:03,324] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.8924029e-16 1.0000000e+00 6.8082432e-20 1.0817053e-19 1.5392766e-30], sampled 0.9882392816915853
[2019-03-26 16:20:18,051] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.09941707], dtype=float32), 0.077811524]
[2019-03-26 16:20:18,052] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.89683439, 84.34444691000002, 1.0, 2.0, 0.55567841166581, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 776502.6827309888, 776502.6827309881, 192778.5395478387]
[2019-03-26 16:20:18,053] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 16:20:18,055] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.7610018e-17 1.0000000e+00 2.8607502e-20 7.6180419e-19 4.7823375e-31], sampled 0.28120877062086247
[2019-03-26 16:20:18,573] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.09941707], dtype=float32), 0.077811524]
[2019-03-26 16:20:18,576] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [34.99945136333334, 61.10427307333333, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.344094113635181, 6.9112, 168.9103645917758, 1761070.539054317, 1453965.268286558, 311358.3899755856]
[2019-03-26 16:20:18,578] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 16:20:18,581] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.1153602e-16 1.0000000e+00 5.4735647e-19 2.1261280e-16 6.9351827e-30], sampled 0.5794742017626155
[2019-03-26 16:20:18,582] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1761070.539054317 W.
[2019-03-26 16:20:28,002] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.09941707], dtype=float32), 0.077811524]
[2019-03-26 16:20:28,004] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [37.3, 45.0, 1.0, 2.0, 0.7720176959383167, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005979780637919, 6.9112, 168.9123160185017, 1975911.829780361, 1908672.0462914, 401037.0437321805]
[2019-03-26 16:20:28,005] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:20:28,008] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.7901827e-10 9.9979943e-01 1.3081328e-10 2.0055695e-04 1.5680810e-17], sampled 0.8881759916579975
[2019-03-26 16:20:28,009] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1975911.829780361 W.
[2019-03-26 16:20:53,546] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.09941707], dtype=float32), 0.077811524]
[2019-03-26 16:20:53,549] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [33.2, 57.0, 1.0, 2.0, 0.7031873694607353, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 982726.4449843674, 982726.4449843674, 221536.2452594312]
[2019-03-26 16:20:53,551] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 16:20:53,555] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.1294839e-16 1.0000000e+00 7.3030083e-20 1.2226978e-18 1.9408758e-30], sampled 0.049391734967026535
[2019-03-26 16:21:08,872] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7886.7822 3164629572.3519 1773.0000
[2019-03-26 16:21:09,012] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.2879 3007616961.0997 1765.0000
[2019-03-26 16:21:09,104] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.8802 2842580288.0339 1129.0000
[2019-03-26 16:21:09,202] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.2711 2779256177.9474 933.0000
[2019-03-26 16:21:09,251] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.8717 2927447046.3306 1338.0000
[2019-03-26 16:21:10,270] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1075000, evaluation results [1075000.0, 7886.782244218958, 3164629572.3518534, 1773.0, 8254.871735174753, 2927447046.3306217, 1338.0, 8661.271088261434, 2779256177.947352, 933.0, 7997.287865507279, 3007616961.099672, 1765.0, 8496.8801560243, 2842580288.0338655, 1129.0]
[2019-03-26 16:21:10,356] A3C_AGENT_WORKER-Thread-13 INFO:Local step 67500, global step 1075045: loss 1.0581
[2019-03-26 16:21:10,359] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 67500, global step 1075046: learning rate 0.0000
[2019-03-26 16:21:10,365] A3C_AGENT_WORKER-Thread-12 INFO:Local step 67000, global step 1075050: loss 0.0338
[2019-03-26 16:21:10,368] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 67000, global step 1075051: learning rate 0.0000
[2019-03-26 16:21:18,271] A3C_AGENT_WORKER-Thread-14 INFO:Local step 67500, global step 1078739: loss 0.9820
[2019-03-26 16:21:18,273] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 67500, global step 1078740: learning rate 0.0000
[2019-03-26 16:21:18,858] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.2967012e-16 1.0000000e+00 2.2900214e-20 1.1975304e-19 5.4952475e-31], sum to 1.0000
[2019-03-26 16:21:18,866] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9829
[2019-03-26 16:21:18,869] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 79.0, 1.0, 2.0, 0.2944205443343038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 469975.2778719852, 469975.2778719852, 164928.8755524824], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 903600.0000, 
sim time next is 904200.0000, 
raw observation next is [22.63333333333333, 78.16666666666667, 1.0, 2.0, 0.2951472756626367, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 471027.3742975031, 471027.3742975031, 165001.1317824985], 
processed observation next is [0.0, 0.4782608695652174, 0.27172195892575024, 0.7816666666666667, 1.0, 1.0, 0.15077985019594783, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13084093730486196, 0.13084093730486196, 0.2462703459440276], 
reward next is 0.7537, 
noisyNet noise sample is [array([-0.03834886], dtype=float32), 0.8838558]. 
=============================================
[2019-03-26 16:21:19,170] A3C_AGENT_WORKER-Thread-2 INFO:Local step 67500, global step 1079159: loss 0.9653
[2019-03-26 16:21:19,171] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 67500, global step 1079159: learning rate 0.0000
[2019-03-26 16:21:21,854] A3C_AGENT_WORKER-Thread-9 INFO:Local step 68000, global step 1080606: loss 0.0058
[2019-03-26 16:21:21,860] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 68000, global step 1080606: learning rate 0.0000
[2019-03-26 16:21:23,205] A3C_AGENT_WORKER-Thread-15 INFO:Local step 67500, global step 1081154: loss 0.9805
[2019-03-26 16:21:23,209] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 67500, global step 1081154: learning rate 0.0000
[2019-03-26 16:21:23,850] A3C_AGENT_WORKER-Thread-3 INFO:Local step 67500, global step 1081449: loss 0.9877
[2019-03-26 16:21:23,854] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 67500, global step 1081451: learning rate 0.0000
[2019-03-26 16:21:25,743] A3C_AGENT_WORKER-Thread-22 INFO:Local step 67500, global step 1082304: loss 0.9872
[2019-03-26 16:21:25,746] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 67500, global step 1082304: learning rate 0.0000
[2019-03-26 16:21:25,880] A3C_AGENT_WORKER-Thread-21 INFO:Local step 67500, global step 1082366: loss 0.9756
[2019-03-26 16:21:25,883] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 67500, global step 1082367: learning rate 0.0000
[2019-03-26 16:21:26,569] A3C_AGENT_WORKER-Thread-18 INFO:Local step 67500, global step 1082678: loss 0.9817
[2019-03-26 16:21:26,572] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 67500, global step 1082680: learning rate 0.0000
[2019-03-26 16:21:26,771] A3C_AGENT_WORKER-Thread-10 INFO:Local step 68500, global step 1082766: loss 0.0249
[2019-03-26 16:21:26,777] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 68500, global step 1082767: learning rate 0.0000
[2019-03-26 16:21:26,918] A3C_AGENT_WORKER-Thread-16 INFO:Local step 67500, global step 1082833: loss 0.9747
[2019-03-26 16:21:26,922] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 67500, global step 1082834: learning rate 0.0000
[2019-03-26 16:21:26,989] A3C_AGENT_WORKER-Thread-11 INFO:Local step 67500, global step 1082863: loss 0.9754
[2019-03-26 16:21:26,992] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 67500, global step 1082864: learning rate 0.0000
[2019-03-26 16:21:27,087] A3C_AGENT_WORKER-Thread-17 INFO:Local step 67500, global step 1082910: loss 0.9666
[2019-03-26 16:21:27,088] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 67500, global step 1082910: learning rate 0.0000
[2019-03-26 16:21:27,105] A3C_AGENT_WORKER-Thread-19 INFO:Local step 67500, global step 1082917: loss 0.9698
[2019-03-26 16:21:27,110] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 67500, global step 1082917: learning rate 0.0000
[2019-03-26 16:21:27,179] A3C_AGENT_WORKER-Thread-20 INFO:Local step 67500, global step 1082948: loss 0.9629
[2019-03-26 16:21:27,182] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 67500, global step 1082949: learning rate 0.0000
[2019-03-26 16:21:27,394] A3C_AGENT_WORKER-Thread-13 INFO:Local step 68000, global step 1083046: loss 0.0031
[2019-03-26 16:21:27,398] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 68000, global step 1083048: learning rate 0.0000
[2019-03-26 16:21:27,484] A3C_AGENT_WORKER-Thread-12 INFO:Local step 67500, global step 1083087: loss 0.9502
[2019-03-26 16:21:27,487] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 67500, global step 1083088: learning rate 0.0000
[2019-03-26 16:21:28,599] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2333657e-16 1.0000000e+00 2.2595472e-19 1.3005376e-18 9.0913989e-30], sum to 1.0000
[2019-03-26 16:21:28,604] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3081
[2019-03-26 16:21:28,609] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.5, 91.0, 1.0, 2.0, 0.2593282128459597, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 424640.0631925294, 424640.0631925301, 161836.7362211405], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 781200.0000, 
sim time next is 781800.0000, 
raw observation next is [19.48333333333333, 91.16666666666667, 1.0, 2.0, 0.2598342173364092, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 425380.873992416, 425380.873992416, 161886.837825513], 
processed observation next is [0.0, 0.043478260869565216, 0.12243285939968399, 0.9116666666666667, 1.0, 1.0, 0.10823399679085446, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.11816135388678223, 0.11816135388678223, 0.24162214600822837], 
reward next is 0.7584, 
noisyNet noise sample is [array([0.14605412], dtype=float32), -0.34769842]. 
=============================================
[2019-03-26 16:21:31,832] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.7995992e-16 1.0000000e+00 6.9838278e-20 4.7919151e-20 3.6247059e-30], sum to 1.0000
[2019-03-26 16:21:31,842] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4606
[2019-03-26 16:21:31,853] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.06666666666667, 70.5, 1.0, 2.0, 0.3044113315652733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 482975.088490818, 482975.0884908187, 165805.0815643549], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 835800.0000, 
sim time next is 836400.0000, 
raw observation next is [24.03333333333333, 71.0, 1.0, 2.0, 0.3059152853668513, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 484905.6064027717, 484905.6064027717, 165935.9978862028], 
processed observation next is [0.0, 0.6956521739130435, 0.3380726698262243, 0.71, 1.0, 1.0, 0.16375335586367626, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1346960017785477, 0.1346960017785477, 0.24766566848686983], 
reward next is 0.7523, 
noisyNet noise sample is [array([1.2375379], dtype=float32), -0.40190572]. 
=============================================
[2019-03-26 16:21:35,529] A3C_AGENT_WORKER-Thread-14 INFO:Local step 68000, global step 1086725: loss 0.0195
[2019-03-26 16:21:35,533] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 68000, global step 1086725: learning rate 0.0000
[2019-03-26 16:21:36,460] A3C_AGENT_WORKER-Thread-2 INFO:Local step 68000, global step 1087145: loss 0.0168
[2019-03-26 16:21:36,464] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 68000, global step 1087145: learning rate 0.0000
[2019-03-26 16:21:39,956] A3C_AGENT_WORKER-Thread-9 INFO:Local step 68500, global step 1088708: loss 0.0077
[2019-03-26 16:21:39,960] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 68500, global step 1088708: learning rate 0.0000
[2019-03-26 16:21:40,828] A3C_AGENT_WORKER-Thread-15 INFO:Local step 68000, global step 1089104: loss 0.0199
[2019-03-26 16:21:40,832] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 68000, global step 1089104: learning rate 0.0000
[2019-03-26 16:21:41,475] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.8327320e-16 1.0000000e+00 1.0278444e-19 3.3456710e-17 1.0703790e-29], sum to 1.0000
[2019-03-26 16:21:41,485] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0525
[2019-03-26 16:21:41,488] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 95.33333333333334, 1.0, 2.0, 0.4818392120468271, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 745854.2547514256, 745854.2547514256, 189439.2363740163], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 998400.0000, 
sim time next is 999000.0000, 
raw observation next is [21.65, 95.5, 1.0, 2.0, 0.5313514610631803, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 822365.051914735, 822365.0519147357, 198156.9302293351], 
processed observation next is [1.0, 0.5652173913043478, 0.22511848341232227, 0.955, 1.0, 1.0, 0.4353632061002172, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22843473664298194, 0.22843473664298214, 0.2957566122825897], 
reward next is 0.7042, 
noisyNet noise sample is [array([1.9533527], dtype=float32), -0.032128144]. 
=============================================
[2019-03-26 16:21:41,512] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[73.69838]
 [73.70985]
 [73.51791]
 [73.4051 ]
 [73.31154]], R is [[73.58136749]
 [73.56281281]
 [73.56616974]
 [73.56448364]
 [73.55090332]].
[2019-03-26 16:21:41,645] A3C_AGENT_WORKER-Thread-3 INFO:Local step 68000, global step 1089465: loss 0.0204
[2019-03-26 16:21:41,647] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 68000, global step 1089465: learning rate 0.0000
[2019-03-26 16:21:43,488] A3C_AGENT_WORKER-Thread-22 INFO:Local step 68000, global step 1090304: loss 0.0220
[2019-03-26 16:21:43,490] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 68000, global step 1090304: learning rate 0.0000
[2019-03-26 16:21:43,651] A3C_AGENT_WORKER-Thread-21 INFO:Local step 68000, global step 1090381: loss 0.0217
[2019-03-26 16:21:43,652] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 68000, global step 1090381: learning rate 0.0000
[2019-03-26 16:21:44,204] A3C_AGENT_WORKER-Thread-18 INFO:Local step 68000, global step 1090628: loss 0.0213
[2019-03-26 16:21:44,206] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 68000, global step 1090628: learning rate 0.0000
[2019-03-26 16:21:44,563] A3C_AGENT_WORKER-Thread-10 INFO:Local step 69000, global step 1090790: loss 0.0069
[2019-03-26 16:21:44,565] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 69000, global step 1090790: learning rate 0.0000
[2019-03-26 16:21:44,623] A3C_AGENT_WORKER-Thread-16 INFO:Local step 68000, global step 1090818: loss 0.0191
[2019-03-26 16:21:44,626] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 68000, global step 1090819: learning rate 0.0000
[2019-03-26 16:21:44,698] A3C_AGENT_WORKER-Thread-17 INFO:Local step 68000, global step 1090854: loss 0.0199
[2019-03-26 16:21:44,702] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 68000, global step 1090855: learning rate 0.0000
[2019-03-26 16:21:44,817] A3C_AGENT_WORKER-Thread-11 INFO:Local step 68000, global step 1090905: loss 0.0190
[2019-03-26 16:21:44,818] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 68000, global step 1090905: learning rate 0.0000
[2019-03-26 16:21:44,857] A3C_AGENT_WORKER-Thread-20 INFO:Local step 68000, global step 1090925: loss 0.0192
[2019-03-26 16:21:44,859] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 68000, global step 1090926: learning rate 0.0000
[2019-03-26 16:21:44,865] A3C_AGENT_WORKER-Thread-19 INFO:Local step 68000, global step 1090928: loss 0.0196
[2019-03-26 16:21:44,867] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 68000, global step 1090929: learning rate 0.0000
[2019-03-26 16:21:45,261] A3C_AGENT_WORKER-Thread-12 INFO:Local step 68000, global step 1091104: loss 0.0214
[2019-03-26 16:21:45,268] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 68000, global step 1091104: learning rate 0.0000
[2019-03-26 16:21:45,302] A3C_AGENT_WORKER-Thread-13 INFO:Local step 68500, global step 1091117: loss 0.0079
[2019-03-26 16:21:45,308] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 68500, global step 1091120: learning rate 0.0000
[2019-03-26 16:21:46,596] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.7909052e-16 1.0000000e+00 4.5676159e-19 5.7741864e-18 3.5094768e-29], sum to 1.0000
[2019-03-26 16:21:46,606] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6080
[2019-03-26 16:21:46,610] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.53333333333333, 76.33333333333334, 1.0, 2.0, 0.3235873671865032, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 509134.3369792977, 509134.3369792977, 167663.0093492231], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1108200.0000, 
sim time next is 1108800.0000, 
raw observation next is [23.4, 77.0, 1.0, 2.0, 0.3214824784130845, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 506240.8193310649, 506240.8193310655, 167451.8144013427], 
processed observation next is [1.0, 0.8695652173913043, 0.30805687203791465, 0.77, 1.0, 1.0, 0.1825090101362464, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14062244981418467, 0.14062244981418487, 0.24992808119603388], 
reward next is 0.7501, 
noisyNet noise sample is [array([-1.7928364], dtype=float32), -1.2039533]. 
=============================================
[2019-03-26 16:21:53,342] A3C_AGENT_WORKER-Thread-14 INFO:Local step 68500, global step 1094764: loss 0.0076
[2019-03-26 16:21:53,344] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 68500, global step 1094765: learning rate 0.0000
[2019-03-26 16:21:54,389] A3C_AGENT_WORKER-Thread-2 INFO:Local step 68500, global step 1095242: loss 0.0076
[2019-03-26 16:21:54,391] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 68500, global step 1095242: learning rate 0.0000
[2019-03-26 16:21:55,134] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.6071997e-16 1.0000000e+00 2.4027707e-20 3.3463568e-19 2.0616269e-30], sum to 1.0000
[2019-03-26 16:21:55,143] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9065
[2019-03-26 16:21:55,148] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.4, 97.0, 1.0, 2.0, 0.3089788912435167, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 491315.4062541475, 491315.4062541469, 166430.3348969855], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1386000.0000, 
sim time next is 1386600.0000, 
raw observation next is [20.36666666666667, 97.16666666666667, 1.0, 2.0, 0.3077219938741986, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 489481.0402173451, 489481.0402173451, 166298.7417298428], 
processed observation next is [0.0, 0.043478260869565216, 0.1642969984202214, 0.9716666666666667, 1.0, 1.0, 0.16593011310144407, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1359669556159292, 0.1359669556159292, 0.2482070772087206], 
reward next is 0.7518, 
noisyNet noise sample is [array([0.03279895], dtype=float32), 0.6496423]. 
=============================================
[2019-03-26 16:21:57,502] A3C_AGENT_WORKER-Thread-9 INFO:Local step 69000, global step 1096646: loss 0.0129
[2019-03-26 16:21:57,505] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 69000, global step 1096647: learning rate 0.0000
[2019-03-26 16:21:58,370] A3C_AGENT_WORKER-Thread-15 INFO:Local step 68500, global step 1097039: loss 0.0082
[2019-03-26 16:21:58,377] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 68500, global step 1097039: learning rate 0.0000
[2019-03-26 16:21:58,514] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.6346879e-16 1.0000000e+00 1.4497639e-19 9.4352423e-18 8.3600677e-30], sum to 1.0000
[2019-03-26 16:21:58,525] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6306
[2019-03-26 16:21:58,531] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.65, 92.66666666666666, 1.0, 2.0, 0.469250363620599, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 660271.5983369732, 660271.5983369732, 179509.6665299839], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1288200.0000, 
sim time next is 1288800.0000, 
raw observation next is [24.6, 93.0, 1.0, 2.0, 0.4694659149801506, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 660759.2801489881, 660759.2801489887, 179565.4305399272], 
processed observation next is [1.0, 0.9565217391304348, 0.36492890995260674, 0.93, 1.0, 1.0, 0.3608023072050008, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18354424448583004, 0.1835442444858302, 0.26800810528347346], 
reward next is 0.7320, 
noisyNet noise sample is [array([1.1476405], dtype=float32), -0.17001168]. 
=============================================
[2019-03-26 16:21:59,264] A3C_AGENT_WORKER-Thread-3 INFO:Local step 68500, global step 1097446: loss 0.0082
[2019-03-26 16:21:59,268] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 68500, global step 1097449: learning rate 0.0000
[2019-03-26 16:21:59,400] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.8017938e-16 1.0000000e+00 2.4203886e-19 3.7680155e-17 1.9731125e-28], sum to 1.0000
[2019-03-26 16:21:59,410] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0344
[2019-03-26 16:21:59,415] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.25, 93.5, 1.0, 2.0, 0.5559673665526376, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 792256.6378224494, 792256.63782245, 194794.0729365264], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1305000.0000, 
sim time next is 1305600.0000, 
raw observation next is [24.26666666666667, 93.33333333333334, 1.0, 2.0, 0.5487567883739879, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 782188.4906874401, 782188.4906874401, 193552.1787014624], 
processed observation next is [1.0, 0.08695652173913043, 0.34913112164297017, 0.9333333333333335, 1.0, 1.0, 0.4563334799686601, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21727458074651115, 0.21727458074651115, 0.2888838488081528], 
reward next is 0.7111, 
noisyNet noise sample is [array([-1.1912832], dtype=float32), -2.38844]. 
=============================================
[2019-03-26 16:22:01,149] A3C_AGENT_WORKER-Thread-22 INFO:Local step 68500, global step 1098287: loss 0.0082
[2019-03-26 16:22:01,154] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 68500, global step 1098291: learning rate 0.0000
[2019-03-26 16:22:01,169] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.5285064e-16 1.0000000e+00 2.9619159e-19 3.0688371e-17 3.3357615e-29], sum to 1.0000
[2019-03-26 16:22:01,179] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5472
[2019-03-26 16:22:01,184] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.98333333333333, 95.0, 1.0, 2.0, 0.8096201733490408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1202973.091506808, 1202973.091506808, 256087.5527103175], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1332600.0000, 
sim time next is 1333200.0000, 
raw observation next is [22.96666666666667, 95.0, 1.0, 2.0, 0.8086954594068322, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1202305.55719818, 1202305.55719818, 255934.45372449], 
processed observation next is [1.0, 0.43478260869565216, 0.2875197472353872, 0.95, 1.0, 1.0, 0.7695126016949785, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3339737658883833, 0.3339737658883833, 0.3819917219768508], 
reward next is 0.6180, 
noisyNet noise sample is [array([0.05756811], dtype=float32), 0.47563002]. 
=============================================
[2019-03-26 16:22:01,343] A3C_AGENT_WORKER-Thread-21 INFO:Local step 68500, global step 1098373: loss 0.0082
[2019-03-26 16:22:01,348] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 68500, global step 1098374: learning rate 0.0000
[2019-03-26 16:22:01,907] A3C_AGENT_WORKER-Thread-18 INFO:Local step 68500, global step 1098633: loss 0.0078
[2019-03-26 16:22:01,910] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 68500, global step 1098634: learning rate 0.0000
[2019-03-26 16:22:02,354] A3C_AGENT_WORKER-Thread-16 INFO:Local step 68500, global step 1098833: loss 0.0079
[2019-03-26 16:22:02,356] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 68500, global step 1098833: learning rate 0.0000
[2019-03-26 16:22:02,380] A3C_AGENT_WORKER-Thread-17 INFO:Local step 68500, global step 1098844: loss 0.0081
[2019-03-26 16:22:02,382] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 68500, global step 1098844: learning rate 0.0000
[2019-03-26 16:22:02,465] A3C_AGENT_WORKER-Thread-10 INFO:Local step 69500, global step 1098884: loss -324.5720
[2019-03-26 16:22:02,469] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 69500, global step 1098885: learning rate 0.0000
[2019-03-26 16:22:02,476] A3C_AGENT_WORKER-Thread-19 INFO:Local step 68500, global step 1098889: loss 0.0079
[2019-03-26 16:22:02,479] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 68500, global step 1098890: learning rate 0.0000
[2019-03-26 16:22:02,509] A3C_AGENT_WORKER-Thread-11 INFO:Local step 68500, global step 1098903: loss 0.0081
[2019-03-26 16:22:02,511] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 68500, global step 1098904: learning rate 0.0000
[2019-03-26 16:22:02,627] A3C_AGENT_WORKER-Thread-20 INFO:Local step 68500, global step 1098957: loss 0.0079
[2019-03-26 16:22:02,633] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 68500, global step 1098960: learning rate 0.0000
[2019-03-26 16:22:02,799] A3C_AGENT_WORKER-Thread-13 INFO:Local step 69000, global step 1099032: loss 0.0086
[2019-03-26 16:22:02,801] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 69000, global step 1099032: learning rate 0.0000
[2019-03-26 16:22:02,879] A3C_AGENT_WORKER-Thread-12 INFO:Local step 68500, global step 1099071: loss 0.0078
[2019-03-26 16:22:02,883] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 68500, global step 1099071: learning rate 0.0000
[2019-03-26 16:22:04,788] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.3589084e-16 1.0000000e+00 5.3940907e-20 6.1258701e-19 3.2079809e-30], sum to 1.0000
[2019-03-26 16:22:04,798] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6700
[2019-03-26 16:22:04,803] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.56666666666667, 94.33333333333334, 1.0, 2.0, 0.4714612128933924, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 659843.0262199509, 659843.0262199515, 179382.6308894302], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1993200.0000, 
sim time next is 1993800.0000, 
raw observation next is [24.63333333333333, 94.16666666666667, 1.0, 2.0, 0.4731523793344512, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 661145.2629780961, 661145.2629780967, 179496.3508108232], 
processed observation next is [0.0, 0.043478260869565216, 0.3665086887835701, 0.9416666666666668, 1.0, 1.0, 0.3652438305234352, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18365146193836004, 0.1836514619383602, 0.2679050012101839], 
reward next is 0.7321, 
noisyNet noise sample is [array([-1.4729191], dtype=float32), 1.2841296]. 
=============================================
[2019-03-26 16:22:04,935] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-26 16:22:04,938] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 16:22:04,939] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 16:22:04,939] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:22:04,941] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 16:22:04,942] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:22:04,939] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 16:22:04,943] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 16:22:04,945] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:22:04,943] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:22:04,947] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:22:04,972] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run45
[2019-03-26 16:22:04,992] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run45
[2019-03-26 16:22:05,015] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run45
[2019-03-26 16:22:05,037] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run45
[2019-03-26 16:22:05,059] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run45
[2019-03-26 16:22:50,123] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10076303], dtype=float32), 0.076418675]
[2019-03-26 16:22:50,124] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.0, 94.00000000000001, 1.0, 2.0, 0.8133363731871163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1213371.377180006, 1213371.377180006, 257710.3713101193]
[2019-03-26 16:22:50,126] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:22:50,127] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.9653570e-16 1.0000000e+00 1.2104684e-19 5.7707480e-19 6.4970321e-30], sampled 0.1763843395278354
[2019-03-26 16:22:52,007] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10076303], dtype=float32), 0.076418675]
[2019-03-26 16:22:52,008] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [34.93333333333334, 56.33333333333333, 1.0, 2.0, 0.6118193344256655, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.948109405641862, 6.9112, 168.9126987768551, 1710659.50345127, 1684474.74071896, 366780.4452849064]
[2019-03-26 16:22:52,009] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:22:52,012] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.9982382e-10 9.9999118e-01 6.7547294e-11 8.8185334e-06 7.6290587e-18], sampled 0.7946388346418902
[2019-03-26 16:22:52,013] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1710659.50345127 W.
[2019-03-26 16:23:37,166] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10076303], dtype=float32), 0.076418675]
[2019-03-26 16:23:37,167] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.39495978, 84.61026422, 1.0, 2.0, 0.5288476193016751, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 738996.4036412296, 738996.403641229, 188239.2664867016]
[2019-03-26 16:23:37,168] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 16:23:37,172] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.6610115e-16 1.0000000e+00 6.2179457e-20 3.3498563e-19 3.1854941e-30], sampled 0.1674217949592658
[2019-03-26 16:23:59,407] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7886.2528 3164139024.7679 1774.0000
[2019-03-26 16:23:59,673] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8252.8347 2927465169.0620 1338.0000
[2019-03-26 16:23:59,701] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.7167 2779131942.0695 933.0000
[2019-03-26 16:23:59,799] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7996.9013 3007699974.1747 1764.0000
[2019-03-26 16:23:59,841] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.8685 2842399926.7353 1129.0000
[2019-03-26 16:24:00,854] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1100000, evaluation results [1100000.0, 7886.252789695813, 3164139024.767947, 1774.0, 8252.834652519048, 2927465169.062039, 1338.0, 8660.716715102415, 2779131942.069542, 933.0, 7996.901346596148, 3007699974.1746917, 1764.0, 8496.86847458536, 2842399926.7353263, 1129.0]
[2019-03-26 16:24:01,232] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.5906337e-11 9.9999273e-01 6.3799688e-11 7.2421813e-06 6.7774977e-17], sum to 1.0000
[2019-03-26 16:24:01,244] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0523
[2019-03-26 16:24:01,252] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1831839.685489041 W.
[2019-03-26 16:24:01,258] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.35, 78.0, 1.0, 2.0, 0.6690643013249189, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.983749576012812, 6.9112, 168.9125241002797, 1831839.685489041, 1780370.651060778, 378893.1070549074], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1697400.0000, 
sim time next is 1698000.0000, 
raw observation next is [28.4, 77.66666666666666, 1.0, 2.0, 0.461394606797559, 1.0, 1.0, 0.461394606797559, 1.0, 2.0, 0.7913792509295365, 6.9112, 6.9112, 170.5573041426782, 1935290.935513873, 1935290.935513873, 387832.9178680396], 
processed observation next is [1.0, 0.6521739130434783, 0.5450236966824644, 0.7766666666666666, 1.0, 1.0, 0.3510778395151314, 1.0, 0.5, 0.3510778395151314, 1.0, 1.0, 0.7455844523530933, 0.0, 0.0, 0.8375144448122397, 0.5375808154205203, 0.5375808154205203, 0.5788551012955815], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6728964], dtype=float32), -0.34909603]. 
=============================================
[2019-03-26 16:24:01,274] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[41.48932 ]
 [42.20744 ]
 [46.00602 ]
 [43.634514]
 [46.362293]], R is [[38.70645142]
 [38.31938553]
 [37.93619156]
 [37.55683136]
 [37.66672134]].
[2019-03-26 16:24:03,076] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.6728133e-16 1.0000000e+00 8.0578623e-20 3.7805934e-20 2.4636259e-30], sum to 1.0000
[2019-03-26 16:24:03,086] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1981
[2019-03-26 16:24:03,090] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 79.0, 1.0, 2.0, 0.4261282500735583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 614974.7235593331, 614974.7235593325, 175353.5020542791], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1429200.0000, 
sim time next is 1429800.0000, 
raw observation next is [26.2, 77.66666666666667, 1.0, 2.0, 0.4281866728004608, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 617379.7461963954, 617379.7461963954, 175569.9693124505], 
processed observation next is [0.0, 0.5652173913043478, 0.44075829383886256, 0.7766666666666667, 1.0, 1.0, 0.3110682804824829, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17149437394344316, 0.17149437394344316, 0.2620447303170903], 
reward next is 0.7380, 
noisyNet noise sample is [array([2.0324793], dtype=float32), -0.828787]. 
=============================================
[2019-03-26 16:24:06,387] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.3345991e-16 1.0000000e+00 1.1213339e-19 7.6834125e-20 3.9260650e-30], sum to 1.0000
[2019-03-26 16:24:06,395] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4209
[2019-03-26 16:24:06,399] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.78333333333333, 85.83333333333334, 1.0, 2.0, 0.3755588372526703, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 566344.9099835204, 566344.9099835197, 171687.0290958794], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1497000.0000, 
sim time next is 1497600.0000, 
raw observation next is [24.0, 85.0, 1.0, 2.0, 0.3788689335744938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 569426.0801235304, 569426.0801235298, 171896.7726663494], 
processed observation next is [0.0, 0.34782608695652173, 0.3364928909952607, 0.85, 1.0, 1.0, 0.2516493175596311, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1581739111454251, 0.15817391114542492, 0.25656234726320803], 
reward next is 0.7434, 
noisyNet noise sample is [array([0.27656677], dtype=float32), 0.5755309]. 
=============================================
[2019-03-26 16:24:06,407] A3C_AGENT_WORKER-Thread-14 INFO:Local step 69000, global step 1102612: loss 0.0151
[2019-03-26 16:24:06,409] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 69000, global step 1102612: learning rate 0.0000
[2019-03-26 16:24:07,506] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.0810954e-16 1.0000000e+00 3.2378127e-19 3.7287756e-19 3.8591562e-30], sum to 1.0000
[2019-03-26 16:24:07,513] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3191
[2019-03-26 16:24:07,516] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.43333333333333, 51.0, 1.0, 2.0, 0.356860421157582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 543278.6023775876, 543278.6023775876, 169886.0060121602], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1515000.0000, 
sim time next is 1515600.0000, 
raw observation next is [29.5, 51.0, 1.0, 2.0, 0.3592854886153388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 546012.8346006966, 546012.8346006966, 170083.2172065805], 
processed observation next is [0.0, 0.5652173913043478, 0.5971563981042655, 0.51, 1.0, 1.0, 0.22805480556064917, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15167023183352682, 0.15167023183352682, 0.25385554806952315], 
reward next is 0.7461, 
noisyNet noise sample is [array([2.1018982], dtype=float32), 0.68036926]. 
=============================================
[2019-03-26 16:24:07,555] A3C_AGENT_WORKER-Thread-2 INFO:Local step 69000, global step 1103147: loss 0.0106
[2019-03-26 16:24:07,557] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 69000, global step 1103147: learning rate 0.0000
[2019-03-26 16:24:09,762] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.5913824e-17 1.0000000e+00 3.3245738e-19 3.2469688e-17 3.8412271e-28], sum to 1.0000
[2019-03-26 16:24:09,772] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1732
[2019-03-26 16:24:09,779] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.7, 82.33333333333334, 1.0, 2.0, 0.944622855265667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1351154.575088492, 1351154.575088492, 287167.0202374759], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1932000.0000, 
sim time next is 1932600.0000, 
raw observation next is [25.75, 82.16666666666667, 1.0, 2.0, 0.9591499955711602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1370467.644170956, 1370467.644170956, 291273.3067042731], 
processed observation next is [1.0, 0.34782608695652173, 0.41943127962085314, 0.8216666666666668, 1.0, 1.0, 0.9507831271941689, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.38068545671415444, 0.38068545671415444, 0.43473627866309417], 
reward next is 0.5653, 
noisyNet noise sample is [array([1.0022991], dtype=float32), -1.5538487]. 
=============================================
[2019-03-26 16:24:11,197] A3C_AGENT_WORKER-Thread-9 INFO:Local step 69500, global step 1104836: loss -296.3582
[2019-03-26 16:24:11,200] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 69500, global step 1104837: learning rate 0.0000
[2019-03-26 16:24:11,706] A3C_AGENT_WORKER-Thread-15 INFO:Local step 69000, global step 1105068: loss 0.0119
[2019-03-26 16:24:11,710] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 69000, global step 1105068: learning rate 0.0000
[2019-03-26 16:24:12,501] A3C_AGENT_WORKER-Thread-3 INFO:Local step 69000, global step 1105434: loss 0.0133
[2019-03-26 16:24:12,502] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 69000, global step 1105434: learning rate 0.0000
[2019-03-26 16:24:12,519] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.3571630e-16 1.0000000e+00 3.6899059e-19 1.5270524e-16 4.2991463e-29], sum to 1.0000
[2019-03-26 16:24:12,531] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9121
[2019-03-26 16:24:12,536] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 85.0, 1.0, 2.0, 0.6383729827092052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 958392.0700820248, 958392.0700820254, 216470.8191801312], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1602000.0000, 
sim time next is 1602600.0000, 
raw observation next is [24.01666666666667, 85.00000000000001, 1.0, 2.0, 0.650490053267038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 975997.7207925948, 975997.7207925948, 219010.5520290937], 
processed observation next is [1.0, 0.5652173913043478, 0.33728278041074267, 0.8500000000000001, 1.0, 1.0, 0.5789036786349855, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.271110477997943, 0.271110477997943, 0.32688142093894584], 
reward next is 0.6731, 
noisyNet noise sample is [array([1.5722216], dtype=float32), -0.2921869]. 
=============================================
[2019-03-26 16:24:14,265] A3C_AGENT_WORKER-Thread-22 INFO:Local step 69000, global step 1106329: loss 0.0121
[2019-03-26 16:24:14,266] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 69000, global step 1106329: learning rate 0.0000
[2019-03-26 16:24:14,281] A3C_AGENT_WORKER-Thread-21 INFO:Local step 69000, global step 1106339: loss 0.0118
[2019-03-26 16:24:14,282] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 69000, global step 1106339: learning rate 0.0000
[2019-03-26 16:24:14,422] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4923784e-16 1.0000000e+00 1.4138105e-19 6.4622410e-19 3.5271507e-30], sum to 1.0000
[2019-03-26 16:24:14,428] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9327
[2019-03-26 16:24:14,433] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 98.0, 1.0, 2.0, 0.4212329881296998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 614862.2907928545, 614862.2907928539, 175547.2019075247], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1640400.0000, 
sim time next is 1641000.0000, 
raw observation next is [23.1, 98.0, 1.0, 2.0, 0.4211168896421672, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 614692.7642501778, 614692.7642501778, 175530.9628274303], 
processed observation next is [1.0, 1.0, 0.2938388625592418, 0.98, 1.0, 1.0, 0.3025504694483942, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17074799006949382, 0.17074799006949382, 0.2619865116827318], 
reward next is 0.7380, 
noisyNet noise sample is [array([0.49369705], dtype=float32), 1.912347]. 
=============================================
[2019-03-26 16:24:14,442] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[75.49997 ]
 [75.4669  ]
 [75.432755]
 [75.40362 ]
 [75.35324 ]], R is [[75.50738525]
 [75.49030304]
 [75.47340393]
 [75.4567337 ]
 [75.44030762]].
[2019-03-26 16:24:14,599] A3C_AGENT_WORKER-Thread-18 INFO:Local step 69000, global step 1106540: loss 0.0085
[2019-03-26 16:24:14,600] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 69000, global step 1106540: learning rate 0.0000
[2019-03-26 16:24:14,901] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.4304674e-16 1.0000000e+00 5.6972517e-20 2.2112932e-18 7.7705924e-30], sum to 1.0000
[2019-03-26 16:24:14,908] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7529
[2019-03-26 16:24:14,912] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.48333333333333, 95.66666666666666, 1.0, 2.0, 0.3424430376351973, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 532482.1838473212, 532482.1838473206, 169345.0301547416], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1810200.0000, 
sim time next is 1810800.0000, 
raw observation next is [21.5, 96.0, 1.0, 2.0, 0.3442140665188314, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 534410.3794460463, 534410.3794460457, 169478.9182617124], 
processed observation next is [1.0, 1.0, 0.21800947867298584, 0.96, 1.0, 1.0, 0.20989646568533904, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14844732762390175, 0.1484473276239016, 0.2529536093458394], 
reward next is 0.7470, 
noisyNet noise sample is [array([-1.0428226], dtype=float32), 1.282093]. 
=============================================
[2019-03-26 16:24:15,043] A3C_AGENT_WORKER-Thread-16 INFO:Local step 69000, global step 1106817: loss 0.0092
[2019-03-26 16:24:15,044] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 69000, global step 1106818: learning rate 0.0000
[2019-03-26 16:24:15,054] A3C_AGENT_WORKER-Thread-19 INFO:Local step 69000, global step 1106822: loss 0.0092
[2019-03-26 16:24:15,057] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 69000, global step 1106823: learning rate 0.0000
[2019-03-26 16:24:15,092] A3C_AGENT_WORKER-Thread-17 INFO:Local step 69000, global step 1106840: loss 0.0086
[2019-03-26 16:24:15,097] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 69000, global step 1106842: learning rate 0.0000
[2019-03-26 16:24:15,107] A3C_AGENT_WORKER-Thread-11 INFO:Local step 69000, global step 1106847: loss 0.0082
[2019-03-26 16:24:15,108] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 69000, global step 1106847: learning rate 0.0000
[2019-03-26 16:24:15,194] A3C_AGENT_WORKER-Thread-20 INFO:Local step 69000, global step 1106886: loss 0.0088
[2019-03-26 16:24:15,196] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 69000, global step 1106886: learning rate 0.0000
[2019-03-26 16:24:15,346] A3C_AGENT_WORKER-Thread-10 INFO:Local step 70000, global step 1106953: loss 0.9519
[2019-03-26 16:24:15,348] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 70000, global step 1106954: learning rate 0.0000
[2019-03-26 16:24:15,478] A3C_AGENT_WORKER-Thread-12 INFO:Local step 69000, global step 1107013: loss 0.0089
[2019-03-26 16:24:15,479] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 69000, global step 1107013: learning rate 0.0000
[2019-03-26 16:24:16,001] A3C_AGENT_WORKER-Thread-13 INFO:Local step 69500, global step 1107247: loss -182.8356
[2019-03-26 16:24:16,005] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 69500, global step 1107247: learning rate 0.0000
[2019-03-26 16:24:22,124] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.3370943e-16 1.0000000e+00 9.8590055e-19 2.7437208e-16 1.3181924e-28], sum to 1.0000
[2019-03-26 16:24:22,134] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3998
[2019-03-26 16:24:22,138] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.96666666666667, 85.16666666666667, 1.0, 2.0, 0.5477983218924735, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 846861.7074088061, 846861.7074088061, 201136.9342255705], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1774200.0000, 
sim time next is 1774800.0000, 
raw observation next is [22.9, 85.0, 1.0, 2.0, 0.5627371642723477, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 872093.8119475187, 872093.8119475187, 204226.336034002], 
processed observation next is [1.0, 0.5652173913043478, 0.2843601895734597, 0.85, 1.0, 1.0, 0.47317730635222605, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.24224828109653299, 0.24224828109653299, 0.3048154269164209], 
reward next is 0.6952, 
noisyNet noise sample is [array([-1.2442788], dtype=float32), 0.16506486]. 
=============================================
[2019-03-26 16:24:23,601] A3C_AGENT_WORKER-Thread-14 INFO:Local step 69500, global step 1110683: loss -84.3124
[2019-03-26 16:24:23,607] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 69500, global step 1110684: learning rate 0.0000
[2019-03-26 16:24:24,737] A3C_AGENT_WORKER-Thread-2 INFO:Local step 69500, global step 1111198: loss -315.7235
[2019-03-26 16:24:24,739] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 69500, global step 1111198: learning rate 0.0000
[2019-03-26 16:24:28,465] A3C_AGENT_WORKER-Thread-9 INFO:Local step 70000, global step 1112875: loss 0.8840
[2019-03-26 16:24:28,467] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 70000, global step 1112876: learning rate 0.0000
[2019-03-26 16:24:29,107] A3C_AGENT_WORKER-Thread-15 INFO:Local step 69500, global step 1113166: loss -307.8635
[2019-03-26 16:24:29,112] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 69500, global step 1113167: learning rate 0.0000
[2019-03-26 16:24:29,734] A3C_AGENT_WORKER-Thread-3 INFO:Local step 69500, global step 1113449: loss -255.9835
[2019-03-26 16:24:29,738] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 69500, global step 1113450: learning rate 0.0000
[2019-03-26 16:24:31,633] A3C_AGENT_WORKER-Thread-22 INFO:Local step 69500, global step 1114302: loss -263.6523
[2019-03-26 16:24:31,636] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 69500, global step 1114302: learning rate 0.0000
[2019-03-26 16:24:31,695] A3C_AGENT_WORKER-Thread-21 INFO:Local step 69500, global step 1114331: loss -386.4901
[2019-03-26 16:24:31,698] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 69500, global step 1114331: learning rate 0.0000
[2019-03-26 16:24:32,335] A3C_AGENT_WORKER-Thread-18 INFO:Local step 69500, global step 1114621: loss -175.5928
[2019-03-26 16:24:32,339] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 69500, global step 1114621: learning rate 0.0000
[2019-03-26 16:24:32,805] A3C_AGENT_WORKER-Thread-19 INFO:Local step 69500, global step 1114826: loss -308.2963
[2019-03-26 16:24:32,809] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 69500, global step 1114828: learning rate 0.0000
[2019-03-26 16:24:32,855] A3C_AGENT_WORKER-Thread-17 INFO:Local step 69500, global step 1114851: loss -400.8682
[2019-03-26 16:24:32,858] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 69500, global step 1114852: learning rate 0.0000
[2019-03-26 16:24:32,861] A3C_AGENT_WORKER-Thread-16 INFO:Local step 69500, global step 1114853: loss -147.6126
[2019-03-26 16:24:32,862] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 69500, global step 1114853: learning rate 0.0000
[2019-03-26 16:24:32,908] A3C_AGENT_WORKER-Thread-11 INFO:Local step 69500, global step 1114870: loss -304.1575
[2019-03-26 16:24:32,914] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 69500, global step 1114872: learning rate 0.0000
[2019-03-26 16:24:32,949] A3C_AGENT_WORKER-Thread-12 INFO:Local step 69500, global step 1114887: loss -384.6458
[2019-03-26 16:24:32,956] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 69500, global step 1114889: learning rate 0.0000
[2019-03-26 16:24:32,967] A3C_AGENT_WORKER-Thread-20 INFO:Local step 69500, global step 1114896: loss -205.7220
[2019-03-26 16:24:32,969] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 69500, global step 1114897: learning rate 0.0000
[2019-03-26 16:24:33,500] A3C_AGENT_WORKER-Thread-10 INFO:Local step 70500, global step 1115136: loss -176.0351
[2019-03-26 16:24:33,505] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 70500, global step 1115137: learning rate 0.0000
[2019-03-26 16:24:33,649] A3C_AGENT_WORKER-Thread-13 INFO:Local step 70000, global step 1115200: loss 0.8295
[2019-03-26 16:24:33,653] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 70000, global step 1115200: learning rate 0.0000
[2019-03-26 16:24:40,049] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.4212631e-16 1.0000000e+00 4.8678990e-19 5.9417277e-18 4.5397838e-28], sum to 1.0000
[2019-03-26 16:24:40,058] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5394
[2019-03-26 16:24:40,062] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.31666666666667, 95.83333333333333, 1.0, 2.0, 0.467735033285475, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 655960.7706544079, 655960.7706544073, 179003.9712951069], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2080200.0000, 
sim time next is 2080800.0000, 
raw observation next is [24.3, 96.0, 1.0, 2.0, 0.4679034022419606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 656059.6261236903, 656059.626123691, 179011.1074033558], 
processed observation next is [0.0, 0.08695652173913043, 0.3507109004739337, 0.96, 1.0, 1.0, 0.3589197617373019, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18223878503435842, 0.1822387850343586, 0.2671807573184415], 
reward next is 0.7328, 
noisyNet noise sample is [array([0.8603776], dtype=float32), -0.60130334]. 
=============================================
[2019-03-26 16:24:41,267] A3C_AGENT_WORKER-Thread-14 INFO:Local step 70000, global step 1118646: loss 0.7269
[2019-03-26 16:24:41,274] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 70000, global step 1118648: learning rate 0.0000
[2019-03-26 16:24:42,488] A3C_AGENT_WORKER-Thread-2 INFO:Local step 70000, global step 1119174: loss 0.7127
[2019-03-26 16:24:42,492] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 70000, global step 1119175: learning rate 0.0000
[2019-03-26 16:24:45,729] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.5692787e-16 1.0000000e+00 7.5516389e-19 9.2172124e-16 1.8703157e-28], sum to 1.0000
[2019-03-26 16:24:45,740] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6659
[2019-03-26 16:24:45,746] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.68333333333333, 80.83333333333333, 1.0, 2.0, 0.5521788851898377, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 771610.6828985944, 771610.682898595, 192175.1877840316], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2328600.0000, 
sim time next is 2329200.0000, 
raw observation next is [28.6, 81.0, 1.0, 2.0, 0.5506626327980185, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 769491.1155753976, 769491.1155753976, 191914.4735542212], 
processed observation next is [1.0, 1.0, 0.5545023696682465, 0.81, 1.0, 1.0, 0.4586296780699018, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2137475321042771, 0.2137475321042771, 0.2864395127674943], 
reward next is 0.7136, 
noisyNet noise sample is [array([-2.2263498], dtype=float32), 1.5215598]. 
=============================================
[2019-03-26 16:24:46,645] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.5583417e-09 6.7563003e-01 2.1212339e-08 3.2437000e-01 3.5704973e-14], sum to 1.0000
[2019-03-26 16:24:46,654] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1220
[2019-03-26 16:24:46,664] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1789301.215075287 W.
[2019-03-26 16:24:46,667] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.56666666666667, 72.66666666666666, 1.0, 2.0, 0.6399219404588744, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.986419925449214, 6.9112, 168.9124936296494, 1789301.215075287, 1735937.757326583, 372808.3086447844], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2551200.0000, 
sim time next is 2551800.0000, 
raw observation next is [29.68333333333333, 71.83333333333334, 1.0, 2.0, 0.625715353318207, 1.0, 1.0, 0.625715353318207, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1749531.180352078, 1749531.180352078, 343943.3738393202], 
processed observation next is [1.0, 0.5217391304347826, 0.6058451816745655, 0.7183333333333334, 1.0, 1.0, 0.5490546425520567, 1.0, 0.5, 0.5490546425520567, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.48598088343113277, 0.48598088343113277, 0.5133483191631645], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7992106], dtype=float32), 0.22567515]. 
=============================================
[2019-03-26 16:24:46,683] A3C_AGENT_WORKER-Thread-15 INFO:Local step 70000, global step 1121067: loss 0.6541
[2019-03-26 16:24:46,685] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 70000, global step 1121068: learning rate 0.0000
[2019-03-26 16:24:46,910] A3C_AGENT_WORKER-Thread-9 INFO:Local step 70500, global step 1121170: loss -180.2457
[2019-03-26 16:24:46,912] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 70500, global step 1121171: learning rate 0.0000
[2019-03-26 16:24:47,520] A3C_AGENT_WORKER-Thread-3 INFO:Local step 70000, global step 1121446: loss 0.6255
[2019-03-26 16:24:47,522] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 70000, global step 1121448: learning rate 0.0000
[2019-03-26 16:24:47,671] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.9699199e-09 2.6253742e-01 1.0703850e-08 7.3746258e-01 1.5973910e-14], sum to 1.0000
[2019-03-26 16:24:47,678] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2729
[2019-03-26 16:24:47,683] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.0, 65.33333333333334, 1.0, 2.0, 0.9138275157054074, 1.0, 1.0, 0.9138275157054074, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2556009.692096905, 2556009.692096906, 479092.0636699713], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2209800.0000, 
sim time next is 2210400.0000, 
raw observation next is [32.1, 65.0, 1.0, 2.0, 0.9015329263763996, 1.0, 2.0, 0.9015329263763996, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2521586.566688023, 2521586.566688023, 472329.5218065752], 
processed observation next is [1.0, 0.6086956521739131, 0.7203791469194314, 0.65, 1.0, 1.0, 0.8813649715378308, 1.0, 1.0, 0.8813649715378308, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7004407129688953, 0.7004407129688953, 0.7049694355322018], 
reward next is 0.2950, 
noisyNet noise sample is [array([-0.23728153], dtype=float32), -0.12291398]. 
=============================================
[2019-03-26 16:24:49,155] A3C_AGENT_WORKER-Thread-22 INFO:Local step 70000, global step 1122185: loss 0.6422
[2019-03-26 16:24:49,158] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 70000, global step 1122185: learning rate 0.0000
[2019-03-26 16:24:49,431] A3C_AGENT_WORKER-Thread-21 INFO:Local step 70000, global step 1122303: loss 0.6380
[2019-03-26 16:24:49,432] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 70000, global step 1122303: learning rate 0.0000
[2019-03-26 16:24:49,858] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.4870486e-15 1.0000000e+00 1.2663850e-18 5.9581441e-16 4.5753921e-27], sum to 1.0000
[2019-03-26 16:24:49,869] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4894
[2019-03-26 16:24:49,873] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.45, 86.0, 1.0, 2.0, 0.913705205082607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1277108.660853028, 1277108.660853029, 273733.0476552404], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2254200.0000, 
sim time next is 2254800.0000, 
raw observation next is [26.4, 86.0, 1.0, 2.0, 0.8730304101673947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1220223.810903348, 1220223.810903349, 262624.1888260762], 
processed observation next is [1.0, 0.08695652173913043, 0.45023696682464454, 0.86, 1.0, 1.0, 0.8470245905631261, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.33895105858426333, 0.3389510585842636, 0.3919764012329496], 
reward next is 0.6080, 
noisyNet noise sample is [array([0.15894389], dtype=float32), -2.1188462]. 
=============================================
[2019-03-26 16:24:49,940] A3C_AGENT_WORKER-Thread-18 INFO:Local step 70000, global step 1122533: loss 0.6189
[2019-03-26 16:24:49,942] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 70000, global step 1122533: learning rate 0.0000
[2019-03-26 16:24:50,343] A3C_AGENT_WORKER-Thread-17 INFO:Local step 70000, global step 1122713: loss 0.6267
[2019-03-26 16:24:50,345] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 70000, global step 1122714: learning rate 0.0000
[2019-03-26 16:24:50,398] A3C_AGENT_WORKER-Thread-19 INFO:Local step 70000, global step 1122737: loss 0.6390
[2019-03-26 16:24:50,400] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 70000, global step 1122738: learning rate 0.0000
[2019-03-26 16:24:50,509] A3C_AGENT_WORKER-Thread-20 INFO:Local step 70000, global step 1122784: loss 0.6274
[2019-03-26 16:24:50,510] A3C_AGENT_WORKER-Thread-16 INFO:Local step 70000, global step 1122784: loss 0.6213
[2019-03-26 16:24:50,512] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 70000, global step 1122786: learning rate 0.0000
[2019-03-26 16:24:50,514] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 70000, global step 1122785: learning rate 0.0000
[2019-03-26 16:24:50,566] A3C_AGENT_WORKER-Thread-12 INFO:Local step 70000, global step 1122813: loss 0.6293
[2019-03-26 16:24:50,568] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 70000, global step 1122813: learning rate 0.0000
[2019-03-26 16:24:50,789] A3C_AGENT_WORKER-Thread-11 INFO:Local step 70000, global step 1122910: loss 0.6191
[2019-03-26 16:24:50,795] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 70000, global step 1122910: learning rate 0.0000
[2019-03-26 16:24:50,939] A3C_AGENT_WORKER-Thread-10 INFO:Local step 71000, global step 1122976: loss 0.0460
[2019-03-26 16:24:50,942] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 71000, global step 1122977: learning rate 0.0000
[2019-03-26 16:24:51,878] A3C_AGENT_WORKER-Thread-13 INFO:Local step 70500, global step 1123401: loss -47.6116
[2019-03-26 16:24:51,884] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 70500, global step 1123401: learning rate 0.0000
[2019-03-26 16:24:55,423] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-26 16:24:55,425] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 16:24:55,426] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:24:55,426] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 16:24:55,428] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:24:55,428] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 16:24:55,429] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 16:24:55,429] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:24:55,430] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:24:55,430] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 16:24:55,432] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:24:55,454] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run46
[2019-03-26 16:24:55,455] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run46
[2019-03-26 16:24:55,455] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run46
[2019-03-26 16:24:55,516] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run46
[2019-03-26 16:24:55,538] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run46
[2019-03-26 16:25:09,108] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10426539], dtype=float32), 0.0731285]
[2019-03-26 16:25:09,109] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [22.15, 90.33333333333333, 1.0, 2.0, 0.3458097086894288, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 537292.6032759936, 537292.6032759942, 169723.2582519426]
[2019-03-26 16:25:09,111] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 16:25:09,114] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.2380708e-15 1.0000000e+00 6.7407201e-19 9.4168278e-19 8.8514783e-29], sampled 0.9565435549559345
[2019-03-26 16:25:23,630] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10426539], dtype=float32), 0.0731285]
[2019-03-26 16:25:23,632] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [24.48333333333333, 90.33333333333333, 1.0, 2.0, 0.8876414164202816, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1275697.956631741, 1275697.956631741, 271685.1948351348]
[2019-03-26 16:25:23,634] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:25:23,638] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.8409029e-15 1.0000000e+00 2.3712406e-18 4.5520004e-17 9.7388596e-28], sampled 0.5140225959534722
[2019-03-26 16:25:32,591] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10426539], dtype=float32), 0.0731285]
[2019-03-26 16:25:32,591] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.022853395, 99.22385886333335, 1.0, 2.0, 0.7827871270988429, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005980453213757, 6.9112, 168.9123160127749, 1990983.614357143, 1923743.353723823, 403643.7094382513]
[2019-03-26 16:25:32,592] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 16:25:32,594] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.2325067e-12 1.0000000e+00 4.0808909e-14 2.2737411e-11 3.4241420e-21], sampled 0.02972109857425187
[2019-03-26 16:25:32,595] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1990983.614357143 W.
[2019-03-26 16:25:36,225] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10426539], dtype=float32), 0.0731285]
[2019-03-26 16:25:36,226] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [24.52096995, 92.40158438666667, 1.0, 2.0, 0.4690171668448264, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 660578.6197217847, 660578.6197217853, 179556.3867193246]
[2019-03-26 16:25:36,227] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 16:25:36,230] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [4.4121711e-16 1.0000000e+00 2.5813600e-19 1.3394890e-18 2.3153968e-29], sampled 0.2914585752274811
[2019-03-26 16:25:40,769] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10426539], dtype=float32), 0.0731285]
[2019-03-26 16:25:40,770] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [35.0, 54.0, 1.0, 2.0, 1.02986704997078, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.9128334880603, 1439581.067655479, 1439581.067655478, 308162.1455561577]
[2019-03-26 16:25:40,770] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 16:25:40,775] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [9.622704e-16 1.000000e+00 1.959800e-18 2.466568e-16 5.512998e-28], sampled 0.3075152504448876
[2019-03-26 16:26:02,393] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10426539], dtype=float32), 0.0731285]
[2019-03-26 16:26:02,394] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.87041063333334, 83.12195080833334, 1.0, 2.0, 0.3831908257769247, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 586536.8313105233, 586536.8313105227, 173714.6306840411]
[2019-03-26 16:26:02,395] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 16:26:02,398] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [6.4045056e-16 1.0000000e+00 4.0666458e-19 1.8431276e-18 4.4633505e-29], sampled 0.6645959634307395
[2019-03-26 16:26:49,926] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.2473 2779215003.4781 933.0000
[2019-03-26 16:26:50,165] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8249.6210 2927701974.9186 1337.0000
[2019-03-26 16:26:50,188] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8003.2478 3006878285.0221 1745.0000
[2019-03-26 16:26:50,397] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8501.5213 2841551709.5489 1112.0000
[2019-03-26 16:26:50,411] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7902.8273 3163290185.8245 1712.0000
[2019-03-26 16:26:51,428] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 1125000, evaluation results [1125000.0, 7902.827282747561, 3163290185.824508, 1712.0, 8249.620964009668, 2927701974.9185534, 1337.0, 8659.247304931096, 2779215003.4781146, 933.0, 8003.247822854154, 3006878285.022058, 1745.0, 8501.521338895667, 2841551709.5488567, 1112.0]
[2019-03-26 16:26:55,332] A3C_AGENT_WORKER-Thread-14 INFO:Local step 70500, global step 1126812: loss -335.8682
[2019-03-26 16:26:55,335] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 70500, global step 1126812: learning rate 0.0000
[2019-03-26 16:26:55,688] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.8449896e-09 9.1383034e-01 1.8809464e-08 8.6169712e-02 6.0914937e-14], sum to 1.0000
[2019-03-26 16:26:55,694] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9688
[2019-03-26 16:26:55,699] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.86666666666667, 87.0, 1.0, 2.0, 0.46553082607109, 1.0, 2.0, 0.46553082607109, 1.0, 2.0, 0.7978902189761374, 6.9112, 6.9112, 170.5573041426782, 1952655.859638104, 1952655.859638104, 390354.1858303783], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2472000.0000, 
sim time next is 2472600.0000, 
raw observation next is [26.98333333333333, 86.5, 1.0, 2.0, 0.7165367968623735, 1.0, 2.0, 0.7165367968623735, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2003709.893070423, 2003709.893070423, 381279.6082482453], 
processed observation next is [1.0, 0.6086956521739131, 0.4778830963665086, 0.865, 1.0, 1.0, 0.6584780685088837, 1.0, 1.0, 0.6584780685088837, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5565860814084509, 0.5565860814084509, 0.5690740421615602], 
reward next is 0.4309, 
noisyNet noise sample is [array([1.4835302], dtype=float32), 0.3639625]. 
=============================================
[2019-03-26 16:26:56,347] A3C_AGENT_WORKER-Thread-2 INFO:Local step 70500, global step 1127282: loss -11.4567
[2019-03-26 16:26:56,349] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 70500, global step 1127282: learning rate 0.0000
[2019-03-26 16:26:59,732] A3C_AGENT_WORKER-Thread-9 INFO:Local step 71000, global step 1128850: loss 0.0522
[2019-03-26 16:26:59,736] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 71000, global step 1128850: learning rate 0.0000
[2019-03-26 16:27:00,549] A3C_AGENT_WORKER-Thread-15 INFO:Local step 70500, global step 1129230: loss -45.3057
[2019-03-26 16:27:00,550] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 70500, global step 1129230: learning rate 0.0000
[2019-03-26 16:27:01,367] A3C_AGENT_WORKER-Thread-3 INFO:Local step 70500, global step 1129609: loss -170.5582
[2019-03-26 16:27:01,368] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 70500, global step 1129610: learning rate 0.0000
[2019-03-26 16:27:02,842] A3C_AGENT_WORKER-Thread-22 INFO:Local step 70500, global step 1130297: loss -371.7676
[2019-03-26 16:27:02,847] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 70500, global step 1130300: learning rate 0.0000
[2019-03-26 16:27:03,288] A3C_AGENT_WORKER-Thread-21 INFO:Local step 70500, global step 1130501: loss -221.2313
[2019-03-26 16:27:03,289] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 70500, global step 1130501: learning rate 0.0000
[2019-03-26 16:27:03,478] A3C_AGENT_WORKER-Thread-10 INFO:Local step 71500, global step 1130589: loss 0.5800
[2019-03-26 16:27:03,479] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 71500, global step 1130589: learning rate 0.0000
[2019-03-26 16:27:03,675] A3C_AGENT_WORKER-Thread-18 INFO:Local step 70500, global step 1130679: loss -46.9595
[2019-03-26 16:27:03,679] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 70500, global step 1130681: learning rate 0.0000
[2019-03-26 16:27:03,948] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.9086455e-16 1.0000000e+00 2.3128838e-19 7.4683589e-19 1.2391871e-28], sum to 1.0000
[2019-03-26 16:27:03,957] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3918
[2019-03-26 16:27:03,959] A3C_AGENT_WORKER-Thread-17 INFO:Local step 70500, global step 1130814: loss -73.3593
[2019-03-26 16:27:03,962] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 95.66666666666666, 1.0, 2.0, 0.450081527216499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 641084.6170913804, 641084.6170913811, 177715.2780156864], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2692200.0000, 
sim time next is 2692800.0000, 
raw observation next is [24.0, 96.0, 1.0, 2.0, 0.4511159980038963, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 641388.0404851104, 641388.0404851097, 177715.9137614352], 
processed observation next is [0.0, 0.17391304347826086, 0.3364928909952607, 0.96, 1.0, 1.0, 0.33869397349867025, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17816334457919733, 0.17816334457919714, 0.265247632479754], 
reward next is 0.7348, 
noisyNet noise sample is [array([0.72475106], dtype=float32), 0.27505642]. 
=============================================
[2019-03-26 16:27:03,963] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 70500, global step 1130814: learning rate 0.0000
[2019-03-26 16:27:03,976] A3C_AGENT_WORKER-Thread-20 INFO:Local step 70500, global step 1130820: loss -52.0166
[2019-03-26 16:27:03,981] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 70500, global step 1130822: learning rate 0.0000
[2019-03-26 16:27:04,038] A3C_AGENT_WORKER-Thread-12 INFO:Local step 70500, global step 1130848: loss -213.9489
[2019-03-26 16:27:04,043] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 70500, global step 1130848: learning rate 0.0000
[2019-03-26 16:27:04,098] A3C_AGENT_WORKER-Thread-19 INFO:Local step 70500, global step 1130876: loss -247.0944
[2019-03-26 16:27:04,102] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 70500, global step 1130877: learning rate 0.0000
[2019-03-26 16:27:04,195] A3C_AGENT_WORKER-Thread-16 INFO:Local step 70500, global step 1130922: loss -475.8858
[2019-03-26 16:27:04,198] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 70500, global step 1130922: learning rate 0.0000
[2019-03-26 16:27:04,300] A3C_AGENT_WORKER-Thread-11 INFO:Local step 70500, global step 1130969: loss -115.4116
[2019-03-26 16:27:04,303] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 70500, global step 1130970: learning rate 0.0000
[2019-03-26 16:27:04,540] A3C_AGENT_WORKER-Thread-13 INFO:Local step 71000, global step 1131076: loss 0.0578
[2019-03-26 16:27:04,543] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 71000, global step 1131076: learning rate 0.0000
[2019-03-26 16:27:05,870] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.9117713e-16 1.0000000e+00 1.0711406e-18 1.1988676e-15 2.6565110e-28], sum to 1.0000
[2019-03-26 16:27:05,877] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8661
[2019-03-26 16:27:05,884] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.98333333333333, 87.33333333333333, 1.0, 2.0, 0.5316337481787876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 742891.0211590385, 742891.0211590378, 188700.5452140872], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2581800.0000, 
sim time next is 2582400.0000, 
raw observation next is [26.86666666666667, 87.66666666666667, 1.0, 2.0, 0.5300133249570241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 740625.8949625496, 740625.8949625501, 188431.7795252927], 
processed observation next is [1.0, 0.9130434782608695, 0.4723538704581361, 0.8766666666666667, 1.0, 1.0, 0.4337509939241254, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20572941526737487, 0.20572941526737504, 0.2812414619780488], 
reward next is 0.7188, 
noisyNet noise sample is [array([-0.7093657], dtype=float32), -1.2934086]. 
=============================================
[2019-03-26 16:27:07,244] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2665173e-15 1.0000000e+00 3.5475600e-19 3.8478023e-18 1.2348176e-28], sum to 1.0000
[2019-03-26 16:27:07,252] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4487
[2019-03-26 16:27:07,260] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.3479686845064236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 536037.1310052006, 536037.1310052006, 169491.6814487811], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2767200.0000, 
sim time next is 2767800.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.3482858314377635, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 536525.5723650093, 536525.57236501, 169531.6095425041], 
processed observation next is [1.0, 0.0, 0.2417061611374408, 0.94, 1.0, 1.0, 0.21480220655152227, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1490348812125026, 0.1490348812125028, 0.25303225304851357], 
reward next is 0.7470, 
noisyNet noise sample is [array([1.1434606], dtype=float32), 0.35446545]. 
=============================================
[2019-03-26 16:27:11,947] A3C_AGENT_WORKER-Thread-14 INFO:Local step 71000, global step 1134707: loss 0.0854
[2019-03-26 16:27:11,952] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 71000, global step 1134707: learning rate 0.0000
[2019-03-26 16:27:12,921] A3C_AGENT_WORKER-Thread-2 INFO:Local step 71000, global step 1135149: loss 0.0946
[2019-03-26 16:27:12,924] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 71000, global step 1135149: learning rate 0.0000
[2019-03-26 16:27:15,306] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.8601449e-16 1.0000000e+00 3.5364533e-19 2.5940982e-16 2.5316910e-28], sum to 1.0000
[2019-03-26 16:27:15,316] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9291
[2019-03-26 16:27:15,321] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.5835624193741584, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 898725.3745763114, 898725.3745763114, 207772.7548374229], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2911800.0000, 
sim time next is 2912400.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.6698743651496316, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1031683.842355097, 1031683.842355097, 226323.6684308749], 
processed observation next is [1.0, 0.7391304347826086, 0.2417061611374408, 0.94, 1.0, 1.0, 0.6022582712646164, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.286578845098638, 0.286578845098638, 0.33779652004608196], 
reward next is 0.6622, 
noisyNet noise sample is [array([1.9378476], dtype=float32), 0.4926765]. 
=============================================
[2019-03-26 16:27:15,755] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.4352000e-17 1.0000000e+00 5.0615052e-19 2.0772566e-16 1.3412922e-28], sum to 1.0000
[2019-03-26 16:27:15,768] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1824
[2019-03-26 16:27:15,773] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 89.0, 1.0, 2.0, 0.7987055202241818, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1176574.980325607, 1176574.980325607, 251876.8028516413], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2826000.0000, 
sim time next is 2826600.0000, 
raw observation next is [24.0, 89.0, 1.0, 2.0, 0.4835738062725922, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 712301.6879033858, 712301.6879033853, 185650.9953942904], 
processed observation next is [1.0, 0.7391304347826086, 0.3364928909952607, 0.89, 1.0, 1.0, 0.37779976659348463, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19786157997316273, 0.19786157997316256, 0.27709103790192596], 
reward next is 0.7229, 
noisyNet noise sample is [array([0.8807105], dtype=float32), 1.1721451]. 
=============================================
[2019-03-26 16:27:16,233] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.5560182e-16 1.0000000e+00 6.0135302e-19 5.7228107e-17 6.3173083e-28], sum to 1.0000
[2019-03-26 16:27:16,242] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4385
[2019-03-26 16:27:16,248] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.777874993083416, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1160367.133498401, 1160367.1334984, 248408.0798749535], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3064800.0000, 
sim time next is 3065400.0000, 
raw observation next is [23.0, 94.0, 1.0, 2.0, 0.7874252853470698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1174616.704686965, 1174616.704686964, 250870.7695471696], 
processed observation next is [1.0, 0.4782608695652174, 0.28909952606635075, 0.94, 1.0, 1.0, 0.743885885960325, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3262824179686014, 0.3262824179686011, 0.3744339843987606], 
reward next is 0.6256, 
noisyNet noise sample is [array([-0.18074158], dtype=float32), 0.17755507]. 
=============================================
[2019-03-26 16:27:16,528] A3C_AGENT_WORKER-Thread-9 INFO:Local step 71500, global step 1136777: loss 0.5041
[2019-03-26 16:27:16,529] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 71500, global step 1136777: learning rate 0.0000
[2019-03-26 16:27:17,506] A3C_AGENT_WORKER-Thread-15 INFO:Local step 71000, global step 1137218: loss 0.0829
[2019-03-26 16:27:17,510] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 71000, global step 1137218: learning rate 0.0000
[2019-03-26 16:27:18,410] A3C_AGENT_WORKER-Thread-3 INFO:Local step 71000, global step 1137625: loss 0.0839
[2019-03-26 16:27:18,411] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 71000, global step 1137625: learning rate 0.0000
[2019-03-26 16:27:19,707] A3C_AGENT_WORKER-Thread-22 INFO:Local step 71000, global step 1138208: loss 0.0855
[2019-03-26 16:27:19,710] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 71000, global step 1138209: learning rate 0.0000
[2019-03-26 16:27:20,206] A3C_AGENT_WORKER-Thread-21 INFO:Local step 71000, global step 1138438: loss 0.0907
[2019-03-26 16:27:20,210] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 71000, global step 1138439: learning rate 0.0000
[2019-03-26 16:27:20,754] A3C_AGENT_WORKER-Thread-10 INFO:Local step 72000, global step 1138687: loss 0.9169
[2019-03-26 16:27:20,758] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 72000, global step 1138687: learning rate 0.0000
[2019-03-26 16:27:20,852] A3C_AGENT_WORKER-Thread-18 INFO:Local step 71000, global step 1138726: loss 0.0906
[2019-03-26 16:27:20,857] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 71000, global step 1138727: learning rate 0.0000
[2019-03-26 16:27:20,956] A3C_AGENT_WORKER-Thread-20 INFO:Local step 71000, global step 1138776: loss 0.0909
[2019-03-26 16:27:20,958] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 71000, global step 1138776: learning rate 0.0000
[2019-03-26 16:27:20,972] A3C_AGENT_WORKER-Thread-17 INFO:Local step 71000, global step 1138781: loss 0.0931
[2019-03-26 16:27:20,975] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 71000, global step 1138781: learning rate 0.0000
[2019-03-26 16:27:21,127] A3C_AGENT_WORKER-Thread-12 INFO:Local step 71000, global step 1138849: loss 0.0913
[2019-03-26 16:27:21,131] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 71000, global step 1138850: learning rate 0.0000
[2019-03-26 16:27:21,185] A3C_AGENT_WORKER-Thread-19 INFO:Local step 71000, global step 1138872: loss 0.0877
[2019-03-26 16:27:21,187] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 71000, global step 1138872: learning rate 0.0000
[2019-03-26 16:27:21,280] A3C_AGENT_WORKER-Thread-16 INFO:Local step 71000, global step 1138920: loss 0.0887
[2019-03-26 16:27:21,282] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 71000, global step 1138920: learning rate 0.0000
[2019-03-26 16:27:21,419] A3C_AGENT_WORKER-Thread-11 INFO:Local step 71000, global step 1138977: loss 0.0889
[2019-03-26 16:27:21,422] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 71000, global step 1138978: learning rate 0.0000
[2019-03-26 16:27:21,592] A3C_AGENT_WORKER-Thread-13 INFO:Local step 71500, global step 1139057: loss 0.4719
[2019-03-26 16:27:21,596] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 71500, global step 1139057: learning rate 0.0000
[2019-03-26 16:27:29,604] A3C_AGENT_WORKER-Thread-14 INFO:Local step 71500, global step 1142673: loss 0.4353
[2019-03-26 16:27:29,609] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 71500, global step 1142674: learning rate 0.0000
[2019-03-26 16:27:30,608] A3C_AGENT_WORKER-Thread-2 INFO:Local step 71500, global step 1143122: loss 0.4264
[2019-03-26 16:27:30,609] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 71500, global step 1143122: learning rate 0.0000
[2019-03-26 16:27:31,524] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.4281895e-16 1.0000000e+00 3.7018757e-19 2.4718119e-18 2.9987832e-28], sum to 1.0000
[2019-03-26 16:27:31,533] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5291
[2019-03-26 16:27:31,540] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.3275383449927264, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 521563.783305758, 521563.783305758, 168714.6045830214], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3032400.0000, 
sim time next is 3033000.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.3136293636407088, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 499421.3290167285, 499421.3290167285, 167037.5342275142], 
processed observation next is [1.0, 0.08695652173913043, 0.1469194312796209, 1.0, 1.0, 1.0, 0.17304742607314313, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13872814694909125, 0.13872814694909125, 0.2493097525783794], 
reward next is 0.7507, 
noisyNet noise sample is [array([2.7371635], dtype=float32), 0.046620756]. 
=============================================
[2019-03-26 16:27:31,559] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[72.28601]
 [72.07881]
 [72.11538]
 [71.95483]
 [71.93104]], R is [[72.40853119]
 [72.43263245]
 [72.45146179]
 [72.47976685]
 [72.50782013]].
[2019-03-26 16:27:33,633] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.0713458e-16 1.0000000e+00 3.9288585e-19 6.1403820e-17 3.0654136e-29], sum to 1.0000
[2019-03-26 16:27:33,644] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2017
[2019-03-26 16:27:33,652] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.4581022426458296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 683473.5253452257, 683473.5253452263, 182696.7856311444], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3070800.0000, 
sim time next is 3071400.0000, 
raw observation next is [23.0, 95.0, 1.0, 2.0, 0.5296480638879271, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 787887.8744350799, 787887.8744350792, 194310.1199839892], 
processed observation next is [1.0, 0.5652173913043478, 0.28909952606635075, 0.95, 1.0, 1.0, 0.43331092034690005, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2188577428986333, 0.2188577428986331, 0.2900151044537152], 
reward next is 0.7100, 
noisyNet noise sample is [array([-1.0302455], dtype=float32), 1.0067061]. 
=============================================
[2019-03-26 16:27:34,136] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.3845044e-16 1.0000000e+00 3.9028352e-20 4.4630835e-19 2.8919849e-30], sum to 1.0000
[2019-03-26 16:27:34,147] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3856
[2019-03-26 16:27:34,151] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.5, 76.5, 1.0, 2.0, 0.5067806721666409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 708150.4100429899, 708150.4100429906, 184666.289243801], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3231000.0000, 
sim time next is 3231600.0000, 
raw observation next is [28.66666666666666, 77.33333333333333, 1.0, 2.0, 0.5156798263094226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 720589.8685582536, 720589.8685582536, 186090.4566880261], 
processed observation next is [0.0, 0.391304347826087, 0.5576619273301735, 0.7733333333333333, 1.0, 1.0, 0.41648171844508736, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20016385237729267, 0.20016385237729267, 0.277746950280636], 
reward next is 0.7223, 
noisyNet noise sample is [array([0.20156212], dtype=float32), 0.01034415]. 
=============================================
[2019-03-26 16:27:34,554] A3C_AGENT_WORKER-Thread-9 INFO:Local step 72000, global step 1144893: loss 0.9784
[2019-03-26 16:27:34,556] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 72000, global step 1144893: learning rate 0.0000
[2019-03-26 16:27:35,262] A3C_AGENT_WORKER-Thread-15 INFO:Local step 71500, global step 1145211: loss 0.4437
[2019-03-26 16:27:35,267] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 71500, global step 1145214: learning rate 0.0000
[2019-03-26 16:27:36,147] A3C_AGENT_WORKER-Thread-3 INFO:Local step 71500, global step 1145610: loss 0.4434
[2019-03-26 16:27:36,149] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 71500, global step 1145610: learning rate 0.0000
[2019-03-26 16:27:37,491] A3C_AGENT_WORKER-Thread-22 INFO:Local step 71500, global step 1146184: loss 0.4499
[2019-03-26 16:27:37,492] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 71500, global step 1146185: learning rate 0.0000
[2019-03-26 16:27:37,923] A3C_AGENT_WORKER-Thread-21 INFO:Local step 71500, global step 1146379: loss 0.4467
[2019-03-26 16:27:37,926] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 71500, global step 1146379: learning rate 0.0000
[2019-03-26 16:27:38,121] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0490144e-16 1.0000000e+00 9.2357817e-19 1.6144400e-16 3.3911257e-28], sum to 1.0000
[2019-03-26 16:27:38,130] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0721
[2019-03-26 16:27:38,135] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666666, 85.0, 1.0, 2.0, 0.6745084869485554, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 989521.3541769555, 989521.3541769562, 221548.375659918], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3148800.0000, 
sim time next is 3149400.0000, 
raw observation next is [24.83333333333334, 84.0, 1.0, 2.0, 0.6496299206387757, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 952143.2767183082, 952143.2767183089, 216070.7810334703], 
processed observation next is [1.0, 0.43478260869565216, 0.3759873617693526, 0.84, 1.0, 1.0, 0.5778673742635851, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2644842435328634, 0.2644842435328636, 0.3224937030350303], 
reward next is 0.6775, 
noisyNet noise sample is [array([1.1939173], dtype=float32), -1.8781441]. 
=============================================
[2019-03-26 16:27:38,533] A3C_AGENT_WORKER-Thread-18 INFO:Local step 71500, global step 1146655: loss 0.4592
[2019-03-26 16:27:38,536] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 71500, global step 1146655: learning rate 0.0000
[2019-03-26 16:27:38,639] A3C_AGENT_WORKER-Thread-17 INFO:Local step 71500, global step 1146700: loss 0.4690
[2019-03-26 16:27:38,641] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 71500, global step 1146700: learning rate 0.0000
[2019-03-26 16:27:38,768] A3C_AGENT_WORKER-Thread-20 INFO:Local step 71500, global step 1146757: loss 0.4656
[2019-03-26 16:27:38,772] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 71500, global step 1146758: learning rate 0.0000
[2019-03-26 16:27:38,874] A3C_AGENT_WORKER-Thread-19 INFO:Local step 71500, global step 1146808: loss 0.4627
[2019-03-26 16:27:38,878] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 71500, global step 1146810: learning rate 0.0000
[2019-03-26 16:27:38,969] A3C_AGENT_WORKER-Thread-12 INFO:Local step 71500, global step 1146846: loss 0.4619
[2019-03-26 16:27:38,975] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 71500, global step 1146846: learning rate 0.0000
[2019-03-26 16:27:39,066] A3C_AGENT_WORKER-Thread-16 INFO:Local step 71500, global step 1146894: loss 0.4635
[2019-03-26 16:27:39,070] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 71500, global step 1146895: learning rate 0.0000
[2019-03-26 16:27:39,072] A3C_AGENT_WORKER-Thread-11 INFO:Local step 71500, global step 1146896: loss 0.4718
[2019-03-26 16:27:39,076] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 71500, global step 1146898: learning rate 0.0000
[2019-03-26 16:27:39,188] A3C_AGENT_WORKER-Thread-10 INFO:Local step 72500, global step 1146946: loss 37.4685
[2019-03-26 16:27:39,192] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 72500, global step 1146946: learning rate 0.0000
[2019-03-26 16:27:39,611] A3C_AGENT_WORKER-Thread-13 INFO:Local step 72000, global step 1147137: loss 0.9283
[2019-03-26 16:27:39,615] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 72000, global step 1147137: learning rate 0.0000
[2019-03-26 16:27:42,952] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.2495398e-15 1.0000000e+00 3.2393478e-17 3.0909869e-15 4.9101800e-26], sum to 1.0000
[2019-03-26 16:27:42,962] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9076
[2019-03-26 16:27:42,970] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 94.0, 1.0, 2.0, 0.8665246254648504, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1211125.569893053, 1211125.569893053, 260894.5689703876], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3380400.0000, 
sim time next is 3381000.0000, 
raw observation next is [26.0, 94.00000000000001, 1.0, 2.0, 0.8334391817192299, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1164857.286118297, 1164857.286118297, 252283.6448708558], 
processed observation next is [1.0, 0.13043478260869565, 0.4312796208530806, 0.9400000000000002, 1.0, 1.0, 0.7993243153243734, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3235714683661936, 0.3235714683661936, 0.37654275353859074], 
reward next is 0.6235, 
noisyNet noise sample is [array([-1.1133442], dtype=float32), 1.2670465]. 
=============================================
[2019-03-26 16:27:42,982] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[66.55526 ]
 [66.30343 ]
 [66.18809 ]
 [66.559875]
 [69.89906 ]], R is [[66.74556732]
 [66.68871307]
 [66.60797119]
 [65.94189453]
 [65.8254776 ]].
[2019-03-26 16:27:45,765] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.3209124e-16 1.0000000e+00 7.0044517e-20 3.1021213e-18 2.6257194e-30], sum to 1.0000
[2019-03-26 16:27:45,770] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2939
[2019-03-26 16:27:45,775] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.83333333333334, 79.00000000000001, 1.0, 2.0, 0.5146523632729149, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 719153.6477883166, 719153.647788316, 185923.4973853219], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3276600.0000, 
sim time next is 3277200.0000, 
raw observation next is [27.66666666666667, 79.0, 1.0, 2.0, 0.5115656084541126, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 714838.8946300927, 714838.8946300927, 185427.6951711184], 
processed observation next is [0.0, 0.9565217391304348, 0.5102685624012641, 0.79, 1.0, 1.0, 0.41152482946278623, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1985663596194702, 0.1985663596194702, 0.27675775398674385], 
reward next is 0.7232, 
noisyNet noise sample is [array([0.8391176], dtype=float32), 0.742164]. 
=============================================
[2019-03-26 16:27:45,967] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-26 16:27:45,969] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 16:27:45,970] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:27:45,970] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 16:27:45,971] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 16:27:45,972] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 16:27:45,973] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:27:45,971] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 16:27:45,974] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:27:45,974] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:27:45,976] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:27:45,996] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run47
[2019-03-26 16:27:46,019] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run47
[2019-03-26 16:27:46,020] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run47
[2019-03-26 16:27:46,062] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run47
[2019-03-26 16:27:46,063] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run47
[2019-03-26 16:28:35,250] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10216083], dtype=float32), 0.07524981]
[2019-03-26 16:28:35,252] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.83907307, 80.40393479, 1.0, 2.0, 0.4969878397627452, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 694461.914221721, 694461.9142217203, 183124.6987117255]
[2019-03-26 16:28:35,253] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 16:28:35,255] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [5.6390996e-16 1.0000000e+00 3.4342445e-19 1.3100080e-18 3.1878179e-29], sampled 0.5697303096129589
[2019-03-26 16:28:49,085] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10216083], dtype=float32), 0.07524981]
[2019-03-26 16:28:49,085] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.879776, 73.45459468, 1.0, 2.0, 0.7193258964216762, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.977596742567062, 6.9112, 168.9125065922566, 1902172.908619476, 1855068.89970991, 389890.9880124031]
[2019-03-26 16:28:49,088] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 16:28:49,093] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0187160e-09 9.9959248e-01 6.4565087e-10 4.0748707e-04 8.4963817e-17], sampled 0.7436556814092866
[2019-03-26 16:28:49,095] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1902172.908619476 W.
[2019-03-26 16:28:56,542] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10216083], dtype=float32), 0.07524981]
[2019-03-26 16:28:56,544] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.48961219333334, 84.56296287333333, 1.0, 2.0, 0.8500465971707009, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1188081.646612529, 1188081.646612528, 256568.4897693513]
[2019-03-26 16:28:56,546] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 16:28:56,550] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [7.5342998e-16 1.0000000e+00 7.5826995e-19 2.5867054e-17 1.7806284e-28], sampled 0.6423565409912528
[2019-03-26 16:29:06,353] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10216083], dtype=float32), 0.07524981]
[2019-03-26 16:29:06,355] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [36.76666666666667, 48.0, 1.0, 2.0, 1.007495861515072, 1.0, 2.0, 1.007495861515072, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2818299.063193251, 2818299.06319325, 533533.9739734461]
[2019-03-26 16:29:06,356] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:29:06,360] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.8669747e-10 3.4505787e-01 1.1159436e-09 6.5494215e-01 2.9038060e-16], sampled 0.8996757129145733
[2019-03-26 16:29:08,164] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10216083], dtype=float32), 0.07524981]
[2019-03-26 16:29:08,165] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [30.77180274166667, 59.55360259, 1.0, 2.0, 0.6391447397777439, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 893187.2213038772, 893187.2213038766, 208255.3715802316]
[2019-03-26 16:29:08,166] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 16:29:08,169] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.5522540e-16 1.0000000e+00 2.1770758e-19 1.6003180e-17 3.3806748e-29], sampled 0.20211035126036314
[2019-03-26 16:29:12,005] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10216083], dtype=float32), 0.07524981]
[2019-03-26 16:29:12,006] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [34.3, 65.66666666666667, 1.0, 2.0, 0.6600181231586669, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 922369.8680147933, 922369.8680147927, 212460.6593411297]
[2019-03-26 16:29:12,007] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:29:12,010] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.5518255e-16 1.0000000e+00 5.9485965e-19 1.2360888e-15 4.7672040e-30], sampled 0.08664342801975067
[2019-03-26 16:29:21,587] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10216083], dtype=float32), 0.07524981]
[2019-03-26 16:29:21,589] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [32.3, 59.5, 1.0, 2.0, 0.7838187879994748, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.989982096802004, 6.9112, 168.9124232850764, 1992427.430548078, 1936536.876042393, 404479.2524644883]
[2019-03-26 16:29:21,591] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:29:21,594] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.8019909e-10 9.9998236e-01 5.4609140e-11 1.7586213e-05 4.8971716e-17], sampled 0.30111617102120014
[2019-03-26 16:29:21,595] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1992427.430548078 W.
[2019-03-26 16:29:39,953] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10216083], dtype=float32), 0.07524981]
[2019-03-26 16:29:39,953] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [30.32545999, 70.46009339333332, 1.0, 2.0, 0.7260106157792297, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.993096809690691, 6.9112, 168.9124049904031, 1911527.477712468, 1853427.251951705, 390878.3551623547]
[2019-03-26 16:29:39,957] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 16:29:39,961] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [6.7888289e-13 1.0000000e+00 2.1651716e-14 7.4331596e-11 5.4009825e-22], sampled 0.7876113968214057
[2019-03-26 16:29:39,962] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1911527.477712468 W.
[2019-03-26 16:29:40,875] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7895.2536 3163028484.4406 1730.0000
[2019-03-26 16:29:41,128] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8252.8057 2927459229.0443 1336.0000
[2019-03-26 16:29:41,216] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8000.5912 3007257711.1523 1760.0000
[2019-03-26 16:29:41,263] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.2711 2779256177.9474 933.0000
[2019-03-26 16:29:41,266] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.9591 2842164176.1200 1122.0000
[2019-03-26 16:29:42,281] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 1150000, evaluation results [1150000.0, 7895.253644176873, 3163028484.440598, 1730.0, 8252.805670579359, 2927459229.0443363, 1336.0, 8661.271088261434, 2779256177.947352, 933.0, 8000.591190850894, 3007257711.152323, 1760.0, 8496.95912157449, 2842164176.1199527, 1122.0]
[2019-03-26 16:29:43,807] A3C_AGENT_WORKER-Thread-14 INFO:Local step 72000, global step 1150716: loss 0.8131
[2019-03-26 16:29:43,811] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 72000, global step 1150716: learning rate 0.0000
[2019-03-26 16:29:44,580] A3C_AGENT_WORKER-Thread-2 INFO:Local step 72000, global step 1151068: loss 0.7934
[2019-03-26 16:29:44,581] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 72000, global step 1151068: learning rate 0.0000
[2019-03-26 16:29:44,832] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.8676021e-15 1.0000000e+00 2.2343133e-19 5.9611842e-18 3.4664208e-29], sum to 1.0000
[2019-03-26 16:29:44,842] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3022
[2019-03-26 16:29:44,847] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.66666666666667, 72.66666666666667, 1.0, 2.0, 0.5287594422156511, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 738873.1446716838, 738873.1446716838, 188225.5981751533], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3320400.0000, 
sim time next is 3321000.0000, 
raw observation next is [30.0, 72.0, 1.0, 2.0, 0.5350461803463259, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 747661.1423160979, 747661.1423160972, 189270.173455255], 
processed observation next is [0.0, 0.43478260869565216, 0.6208530805687204, 0.72, 1.0, 1.0, 0.43981467511605526, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20768365064336053, 0.20768365064336033, 0.2824927962018731], 
reward next is 0.7175, 
noisyNet noise sample is [array([-0.27486187], dtype=float32), -1.8671248]. 
=============================================
[2019-03-26 16:29:44,868] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[73.30882 ]
 [73.27366 ]
 [73.21271 ]
 [73.15738 ]
 [73.125275]], R is [[73.33016205]
 [73.3159256 ]
 [73.30373383]
 [73.29267883]
 [73.28260803]].
[2019-03-26 16:29:46,213] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.2340080e-16 1.0000000e+00 5.2629946e-18 2.2924645e-16 2.9034395e-28], sum to 1.0000
[2019-03-26 16:29:46,223] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4869
[2019-03-26 16:29:46,231] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 79.0, 1.0, 2.0, 0.5192437556441211, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 725571.6582813936, 725571.6582813943, 186666.0397329655], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3624600.0000, 
sim time next is 3625200.0000, 
raw observation next is [28.0, 79.0, 1.0, 2.0, 0.5191185488877897, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 725396.6393389122, 725396.6393389116, 186645.7186011872], 
processed observation next is [1.0, 1.0, 0.5260663507109005, 0.79, 1.0, 1.0, 0.42062475769613217, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20149906648303118, 0.201499066483031, 0.278575699404757], 
reward next is 0.7214, 
noisyNet noise sample is [array([-0.1689058], dtype=float32), -0.12279543]. 
=============================================
[2019-03-26 16:29:48,947] A3C_AGENT_WORKER-Thread-9 INFO:Local step 72500, global step 1153094: loss 42.9330
[2019-03-26 16:29:48,951] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 72500, global step 1153095: learning rate 0.0000
[2019-03-26 16:29:49,235] A3C_AGENT_WORKER-Thread-15 INFO:Local step 72000, global step 1153230: loss 0.6935
[2019-03-26 16:29:49,237] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 72000, global step 1153231: learning rate 0.0000
[2019-03-26 16:29:49,807] A3C_AGENT_WORKER-Thread-3 INFO:Local step 72000, global step 1153497: loss 0.6708
[2019-03-26 16:29:49,812] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 72000, global step 1153499: learning rate 0.0000
[2019-03-26 16:29:51,096] A3C_AGENT_WORKER-Thread-22 INFO:Local step 72000, global step 1154096: loss 0.7130
[2019-03-26 16:29:51,099] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 72000, global step 1154097: learning rate 0.0000
[2019-03-26 16:29:51,540] A3C_AGENT_WORKER-Thread-21 INFO:Local step 72000, global step 1154302: loss 0.7240
[2019-03-26 16:29:51,545] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 72000, global step 1154303: learning rate 0.0000
[2019-03-26 16:29:51,551] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.3540914e-16 1.0000000e+00 1.7005097e-18 2.2437720e-16 1.2746037e-27], sum to 1.0000
[2019-03-26 16:29:51,558] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0180
[2019-03-26 16:29:51,561] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.5016900063401247, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 701034.6165113848, 701034.6165113841, 183861.1716263127], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3463200.0000, 
sim time next is 3463800.0000, 
raw observation next is [26.16666666666667, 87.33333333333334, 1.0, 2.0, 0.9440242841929092, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1319512.732405236, 1319512.732405236, 282332.0423234189], 
processed observation next is [1.0, 0.08695652173913043, 0.4391785150078992, 0.8733333333333334, 1.0, 1.0, 0.9325593785456737, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.36653131455701, 0.36653131455701, 0.42139110794540136], 
reward next is 0.5786, 
noisyNet noise sample is [array([-1.0489038], dtype=float32), -0.39862397]. 
=============================================
[2019-03-26 16:29:52,240] A3C_AGENT_WORKER-Thread-18 INFO:Local step 72000, global step 1154627: loss 0.7061
[2019-03-26 16:29:52,244] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 72000, global step 1154627: learning rate 0.0000
[2019-03-26 16:29:52,259] A3C_AGENT_WORKER-Thread-17 INFO:Local step 72000, global step 1154633: loss 0.7133
[2019-03-26 16:29:52,262] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 72000, global step 1154634: learning rate 0.0000
[2019-03-26 16:29:52,434] A3C_AGENT_WORKER-Thread-20 INFO:Local step 72000, global step 1154716: loss 0.7085
[2019-03-26 16:29:52,435] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 72000, global step 1154717: learning rate 0.0000
[2019-03-26 16:29:52,514] A3C_AGENT_WORKER-Thread-19 INFO:Local step 72000, global step 1154749: loss 0.6927
[2019-03-26 16:29:52,517] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 72000, global step 1154750: learning rate 0.0000
[2019-03-26 16:29:52,721] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.0744648e-15 1.0000000e+00 5.3114409e-18 1.0463732e-15 1.1715540e-26], sum to 1.0000
[2019-03-26 16:29:52,729] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4132
[2019-03-26 16:29:52,739] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666667, 85.66666666666667, 1.0, 2.0, 0.5068390298243134, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 708231.9833506766, 708231.983350676, 184674.5551597565], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3460800.0000, 
sim time next is 3461400.0000, 
raw observation next is [26.5, 86.5, 1.0, 2.0, 0.5054346614254485, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 706268.9355070761, 706268.9355070768, 184451.9452195093], 
processed observation next is [1.0, 0.043478260869565216, 0.4549763033175356, 0.865, 1.0, 1.0, 0.40413814629572103, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19618581541863225, 0.19618581541863245, 0.275301410775387], 
reward next is 0.7247, 
noisyNet noise sample is [array([-0.9495822], dtype=float32), 0.42771342]. 
=============================================
[2019-03-26 16:29:52,751] A3C_AGENT_WORKER-Thread-12 INFO:Local step 72000, global step 1154860: loss 0.7054
[2019-03-26 16:29:52,754] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 72000, global step 1154861: learning rate 0.0000
[2019-03-26 16:29:52,766] A3C_AGENT_WORKER-Thread-16 INFO:Local step 72000, global step 1154869: loss 0.7052
[2019-03-26 16:29:52,769] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 72000, global step 1154870: learning rate 0.0000
[2019-03-26 16:29:52,821] A3C_AGENT_WORKER-Thread-11 INFO:Local step 72000, global step 1154889: loss 0.7056
[2019-03-26 16:29:52,826] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 72000, global step 1154890: learning rate 0.0000
[2019-03-26 16:29:53,155] A3C_AGENT_WORKER-Thread-10 INFO:Local step 73000, global step 1155040: loss 0.0146
[2019-03-26 16:29:53,157] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 73000, global step 1155041: learning rate 0.0000
[2019-03-26 16:29:53,792] A3C_AGENT_WORKER-Thread-13 INFO:Local step 72500, global step 1155338: loss 31.7926
[2019-03-26 16:29:53,796] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 72500, global step 1155339: learning rate 0.0000
[2019-03-26 16:30:00,763] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.8561910e-10 5.1529527e-01 4.0081347e-09 4.8470473e-01 1.3229946e-15], sum to 1.0000
[2019-03-26 16:30:00,774] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2529
[2019-03-26 16:30:00,782] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1887138.000924879 W.
[2019-03-26 16:30:00,788] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.0, 67.0, 1.0, 2.0, 0.7085819154582687, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.005975775970263, 6.9112, 168.912393233097, 1887138.000924879, 1819901.027738303, 386512.2445942333], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3589200.0000, 
sim time next is 3589800.0000, 
raw observation next is [32.16666666666667, 66.33333333333334, 1.0, 2.0, 0.6838908026762961, 1.0, 1.0, 0.6838908026762961, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1912337.779371456, 1912337.779371456, 367312.5392333333], 
processed observation next is [1.0, 0.5652173913043478, 0.7235387045813588, 0.6633333333333334, 1.0, 1.0, 0.6191455453931278, 1.0, 0.5, 0.6191455453931278, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5312049387142933, 0.5312049387142933, 0.5482276704975124], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2184654], dtype=float32), -0.3735798]. 
=============================================
[2019-03-26 16:30:01,328] A3C_AGENT_WORKER-Thread-14 INFO:Local step 72500, global step 1158780: loss 30.2216
[2019-03-26 16:30:01,329] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 72500, global step 1158780: learning rate 0.0000
[2019-03-26 16:30:01,917] A3C_AGENT_WORKER-Thread-2 INFO:Local step 72500, global step 1159120: loss -154.7239
[2019-03-26 16:30:01,919] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 72500, global step 1159121: learning rate 0.0000
[2019-03-26 16:30:04,550] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.5230230e-12 9.9992275e-01 5.0503707e-12 7.7298544e-05 1.6423631e-20], sum to 1.0000
[2019-03-26 16:30:04,555] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8455
[2019-03-26 16:30:04,562] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 71.0, 1.0, 2.0, 0.541114419470237, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129565103935, 756143.7772767822, 756143.7772767822, 190291.0985817922], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3691800.0000, 
sim time next is 3692400.0000, 
raw observation next is [30.66666666666667, 72.33333333333334, 1.0, 2.0, 0.5447880589871578, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 761279.0961260742, 761279.0961260748, 190912.9574864072], 
processed observation next is [1.0, 0.7391304347826086, 0.6524486571879939, 0.7233333333333334, 1.0, 1.0, 0.45155187829778043, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21146641559057616, 0.21146641559057633, 0.2849447126662794], 
reward next is 0.7151, 
noisyNet noise sample is [array([-0.34251827], dtype=float32), 0.6645039]. 
=============================================
[2019-03-26 16:30:05,113] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.8181871e-10 1.2914625e-02 4.0100359e-10 9.8708540e-01 9.1146420e-16], sum to 1.0000
[2019-03-26 16:30:05,124] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9625
[2019-03-26 16:30:05,131] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.0, 59.0, 1.0, 2.0, 0.8915140380165107, 1.0, 2.0, 0.8915140380165107, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2493535.786022185, 2493535.786022185, 466882.0653749225], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3682200.0000, 
sim time next is 3682800.0000, 
raw observation next is [33.0, 59.0, 1.0, 2.0, 0.8930537484918772, 1.0, 2.0, 0.8930537484918772, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2497846.61063589, 2497846.61063589, 467715.0676949511], 
processed observation next is [1.0, 0.6521739130434783, 0.7630331753554502, 0.59, 1.0, 1.0, 0.8711490945685267, 1.0, 1.0, 0.8711490945685267, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6938462807321917, 0.6938462807321917, 0.6980821905894792], 
reward next is 0.3019, 
noisyNet noise sample is [array([-1.2059413], dtype=float32), -0.435303]. 
=============================================
[2019-03-26 16:30:05,831] A3C_AGENT_WORKER-Thread-9 INFO:Local step 73000, global step 1161033: loss 0.0124
[2019-03-26 16:30:05,834] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 73000, global step 1161033: learning rate 0.0000
[2019-03-26 16:30:06,386] A3C_AGENT_WORKER-Thread-15 INFO:Local step 72500, global step 1161286: loss 20.1120
[2019-03-26 16:30:06,388] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 72500, global step 1161286: learning rate 0.0000
[2019-03-26 16:30:06,812] A3C_AGENT_WORKER-Thread-3 INFO:Local step 72500, global step 1161476: loss -60.7837
[2019-03-26 16:30:06,814] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 72500, global step 1161476: learning rate 0.0000
[2019-03-26 16:30:08,316] A3C_AGENT_WORKER-Thread-22 INFO:Local step 72500, global step 1162154: loss 15.0424
[2019-03-26 16:30:08,322] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 72500, global step 1162155: learning rate 0.0000
[2019-03-26 16:30:08,722] A3C_AGENT_WORKER-Thread-21 INFO:Local step 72500, global step 1162343: loss 76.8061
[2019-03-26 16:30:08,728] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 72500, global step 1162344: learning rate 0.0000
[2019-03-26 16:30:09,336] A3C_AGENT_WORKER-Thread-18 INFO:Local step 72500, global step 1162622: loss 79.3310
[2019-03-26 16:30:09,337] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 72500, global step 1162622: learning rate 0.0000
[2019-03-26 16:30:09,405] A3C_AGENT_WORKER-Thread-17 INFO:Local step 72500, global step 1162651: loss -195.7275
[2019-03-26 16:30:09,410] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 72500, global step 1162651: learning rate 0.0000
[2019-03-26 16:30:09,654] A3C_AGENT_WORKER-Thread-19 INFO:Local step 72500, global step 1162761: loss 51.9179
[2019-03-26 16:30:09,656] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 72500, global step 1162761: learning rate 0.0000
[2019-03-26 16:30:09,729] A3C_AGENT_WORKER-Thread-20 INFO:Local step 72500, global step 1162795: loss 45.0621
[2019-03-26 16:30:09,731] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 72500, global step 1162795: learning rate 0.0000
[2019-03-26 16:30:09,880] A3C_AGENT_WORKER-Thread-12 INFO:Local step 72500, global step 1162863: loss 45.3390
[2019-03-26 16:30:09,882] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 72500, global step 1162863: learning rate 0.0000
[2019-03-26 16:30:09,983] A3C_AGENT_WORKER-Thread-16 INFO:Local step 72500, global step 1162910: loss 30.8338
[2019-03-26 16:30:09,985] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 72500, global step 1162911: learning rate 0.0000
[2019-03-26 16:30:10,151] A3C_AGENT_WORKER-Thread-11 INFO:Local step 72500, global step 1162985: loss 30.0023
[2019-03-26 16:30:10,154] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 72500, global step 1162986: learning rate 0.0000
[2019-03-26 16:30:10,288] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.6364190e-14 1.0000000e+00 5.2352843e-17 1.4576979e-10 4.3737045e-27], sum to 1.0000
[2019-03-26 16:30:10,296] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7995
[2019-03-26 16:30:10,302] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 78.33333333333334, 1.0, 2.0, 0.6175177135275672, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 862951.7678225458, 862951.7678225458, 204055.3345715999], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4129800.0000, 
sim time next is 4130400.0000, 
raw observation next is [31.0, 77.66666666666667, 1.0, 2.0, 0.6134229029188494, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 857227.1546310324, 857227.1546310324, 203273.6847184633], 
processed observation next is [1.0, 0.8260869565217391, 0.6682464454976303, 0.7766666666666667, 1.0, 1.0, 0.5342444613480113, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23811865406417565, 0.23811865406417565, 0.3033935592812885], 
reward next is 0.6966, 
noisyNet noise sample is [array([1.197018], dtype=float32), -2.1002333]. 
=============================================
[2019-03-26 16:30:10,428] A3C_AGENT_WORKER-Thread-13 INFO:Local step 73000, global step 1163108: loss 0.0122
[2019-03-26 16:30:10,429] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 73000, global step 1163108: learning rate 0.0000
[2019-03-26 16:30:10,863] A3C_AGENT_WORKER-Thread-10 INFO:Local step 73500, global step 1163265: loss -39.1127
[2019-03-26 16:30:10,866] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 73500, global step 1163265: learning rate 0.0000
[2019-03-26 16:30:17,924] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.1081328e-15 1.0000000e+00 3.4417988e-19 4.2143285e-18 2.1623899e-29], sum to 1.0000
[2019-03-26 16:30:17,934] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3200
[2019-03-26 16:30:17,945] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 75.0, 1.0, 2.0, 0.598966487685373, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 837017.0929512661, 837017.0929512654, 200553.6879196656], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3918600.0000, 
sim time next is 3919200.0000, 
raw observation next is [31.33333333333334, 73.66666666666666, 1.0, 2.0, 0.6007832373284243, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 839556.8869685862, 839556.8869685855, 200892.2111110543], 
processed observation next is [0.0, 0.34782608695652173, 0.6840442338072673, 0.7366666666666666, 1.0, 1.0, 0.519015948588463, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.23321024638016286, 0.23321024638016266, 0.2998391210612751], 
reward next is 0.7002, 
noisyNet noise sample is [array([-0.58960867], dtype=float32), -0.5730721]. 
=============================================
[2019-03-26 16:30:18,612] A3C_AGENT_WORKER-Thread-14 INFO:Local step 73000, global step 1166766: loss 0.0124
[2019-03-26 16:30:18,614] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 73000, global step 1166767: learning rate 0.0000
[2019-03-26 16:30:19,420] A3C_AGENT_WORKER-Thread-2 INFO:Local step 73000, global step 1167129: loss 0.0396
[2019-03-26 16:30:19,425] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 73000, global step 1167129: learning rate 0.0000
[2019-03-26 16:30:23,977] A3C_AGENT_WORKER-Thread-15 INFO:Local step 73000, global step 1169183: loss 0.0179
[2019-03-26 16:30:23,979] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 73000, global step 1169183: learning rate 0.0000
[2019-03-26 16:30:24,096] A3C_AGENT_WORKER-Thread-9 INFO:Local step 73500, global step 1169238: loss -37.7872
[2019-03-26 16:30:24,100] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 73500, global step 1169241: learning rate 0.0000
[2019-03-26 16:30:24,426] A3C_AGENT_WORKER-Thread-3 INFO:Local step 73000, global step 1169389: loss 0.0170
[2019-03-26 16:30:24,429] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 73000, global step 1169390: learning rate 0.0000
[2019-03-26 16:30:26,047] A3C_AGENT_WORKER-Thread-22 INFO:Local step 73000, global step 1170101: loss 0.0129
[2019-03-26 16:30:26,049] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 73000, global step 1170101: learning rate 0.0000
[2019-03-26 16:30:26,309] A3C_AGENT_WORKER-Thread-21 INFO:Local step 73000, global step 1170218: loss 0.0129
[2019-03-26 16:30:26,314] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 73000, global step 1170218: learning rate 0.0000
[2019-03-26 16:30:27,099] A3C_AGENT_WORKER-Thread-18 INFO:Local step 73000, global step 1170577: loss 0.0130
[2019-03-26 16:30:27,103] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 73000, global step 1170577: learning rate 0.0000
[2019-03-26 16:30:27,281] A3C_AGENT_WORKER-Thread-20 INFO:Local step 73000, global step 1170653: loss 0.0132
[2019-03-26 16:30:27,287] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 73000, global step 1170654: learning rate 0.0000
[2019-03-26 16:30:27,297] A3C_AGENT_WORKER-Thread-17 INFO:Local step 73000, global step 1170659: loss 0.0127
[2019-03-26 16:30:27,299] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 73000, global step 1170659: learning rate 0.0000
[2019-03-26 16:30:27,497] A3C_AGENT_WORKER-Thread-19 INFO:Local step 73000, global step 1170747: loss 0.0128
[2019-03-26 16:30:27,500] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 73000, global step 1170748: learning rate 0.0000
[2019-03-26 16:30:27,564] A3C_AGENT_WORKER-Thread-12 INFO:Local step 73000, global step 1170779: loss 0.0130
[2019-03-26 16:30:27,566] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 73000, global step 1170780: learning rate 0.0000
[2019-03-26 16:30:27,610] A3C_AGENT_WORKER-Thread-16 INFO:Local step 73000, global step 1170802: loss 0.0213
[2019-03-26 16:30:27,612] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 73000, global step 1170804: learning rate 0.0000
[2019-03-26 16:30:27,927] A3C_AGENT_WORKER-Thread-11 INFO:Local step 73000, global step 1170944: loss 0.0124
[2019-03-26 16:30:27,931] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 73000, global step 1170944: learning rate 0.0000
[2019-03-26 16:30:28,433] A3C_AGENT_WORKER-Thread-10 INFO:Local step 74000, global step 1171169: loss 3.2972
[2019-03-26 16:30:28,435] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 74000, global step 1171170: learning rate 0.0000
[2019-03-26 16:30:28,955] A3C_AGENT_WORKER-Thread-13 INFO:Local step 73500, global step 1171409: loss -72.5378
[2019-03-26 16:30:28,958] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 73500, global step 1171411: learning rate 0.0000
[2019-03-26 16:30:32,444] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.2884062e-15 1.0000000e+00 1.3050259e-17 7.3573578e-15 5.0151872e-26], sum to 1.0000
[2019-03-26 16:30:32,453] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9943
[2019-03-26 16:30:32,460] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 89.0, 1.0, 2.0, 0.7628519214237435, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1066151.38796621, 1066151.38796621, 234999.4652535192], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4164000.0000, 
sim time next is 4164600.0000, 
raw observation next is [28.0, 89.0, 1.0, 2.0, 0.7562996446112641, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1056989.458223951, 1056989.45822395, 233469.5705925064], 
processed observation next is [1.0, 0.17391304347826086, 0.5260663507109005, 0.89, 1.0, 1.0, 0.7063851139894748, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2936081828399864, 0.2936081828399861, 0.34846204566045735], 
reward next is 0.6515, 
noisyNet noise sample is [array([0.85519737], dtype=float32), -0.49372578]. 
=============================================
[2019-03-26 16:30:32,717] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.8116711e-15 1.0000000e+00 9.2232177e-18 2.5506396e-15 6.1703360e-27], sum to 1.0000
[2019-03-26 16:30:32,727] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1450
[2019-03-26 16:30:32,732] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.33333333333334, 88.16666666666667, 1.0, 2.0, 0.8064759847043237, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1127152.139103602, 1127152.139103602, 245509.9468453412], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4169400.0000, 
sim time next is 4170000.0000, 
raw observation next is [28.66666666666667, 87.33333333333334, 1.0, 2.0, 0.7760527835367242, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1084610.153922436, 1084610.153922437, 238121.4827969765], 
processed observation next is [1.0, 0.2608695652173913, 0.5576619273301741, 0.8733333333333334, 1.0, 1.0, 0.7301840765502702, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3012805983117878, 0.30128059831178805, 0.3554051982044425], 
reward next is 0.6446, 
noisyNet noise sample is [array([0.3790458], dtype=float32), 0.17710342]. 
=============================================
[2019-03-26 16:30:32,744] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[65.43922 ]
 [65.656906]
 [65.844986]
 [65.97982 ]
 [65.98816 ]], R is [[65.25943756]
 [65.24040985]
 [65.19155884]
 [65.14450836]
 [65.08989716]].
[2019-03-26 16:30:32,931] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.8770974e-16 1.0000000e+00 1.4700301e-18 1.5195041e-16 7.7048621e-29], sum to 1.0000
[2019-03-26 16:30:32,943] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0722
[2019-03-26 16:30:32,948] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 84.0, 1.0, 2.0, 0.582306080816264, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 813726.3289594805, 813726.3289594812, 197495.79698268], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4146000.0000, 
sim time next is 4146600.0000, 
raw observation next is [29.0, 84.0, 1.0, 2.0, 0.5812969940711078, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 812315.6714570721, 812315.6714570721, 197313.3088154392], 
processed observation next is [1.0, 1.0, 0.5734597156398105, 0.84, 1.0, 1.0, 0.4955385470736238, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22564324207140893, 0.22564324207140893, 0.2944974758439391], 
reward next is 0.7055, 
noisyNet noise sample is [array([-1.420409], dtype=float32), 0.011155852]. 
=============================================
[2019-03-26 16:30:36,645] A3C_AGENT_WORKER-Thread-14 INFO:Local step 73500, global step 1174876: loss -28.3582
[2019-03-26 16:30:36,648] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 73500, global step 1174877: learning rate 0.0000
[2019-03-26 16:30:36,925] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-26 16:30:36,927] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 16:30:36,929] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 16:30:36,930] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:30:36,930] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 16:30:36,931] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:30:36,933] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 16:30:36,933] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:30:36,935] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:30:36,931] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 16:30:36,938] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:30:36,963] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run48
[2019-03-26 16:30:36,984] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run48
[2019-03-26 16:30:37,004] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run48
[2019-03-26 16:30:37,023] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run48
[2019-03-26 16:30:37,024] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run48
[2019-03-26 16:30:55,541] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10600296], dtype=float32), 0.0724769]
[2019-03-26 16:30:55,543] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [21.75, 94.33333333333334, 1.0, 2.0, 0.3727137809671536, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 577912.448543163, 577912.448543163, 173118.2213656409]
[2019-03-26 16:30:55,545] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:30:55,548] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.2657559e-16 1.0000000e+00 4.5144700e-19 8.2029821e-19 1.5505817e-28], sampled 0.3876141168298991
[2019-03-26 16:31:06,549] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10600296], dtype=float32), 0.0724769]
[2019-03-26 16:31:06,551] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [24.5, 94.66666666666667, 1.0, 2.0, 0.4901127252223682, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 684935.2604486288, 684935.2604486294, 182071.0434753259]
[2019-03-26 16:31:06,553] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:31:06,555] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.4865489e-16 1.0000000e+00 1.6606668e-19 3.6516384e-18 3.3825580e-29], sampled 0.3748417881100511
[2019-03-26 16:31:11,160] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10600296], dtype=float32), 0.0724769]
[2019-03-26 16:31:11,161] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [27.0, 71.0, 1.0, 2.0, 0.7822345040312195, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1137638.169215022, 1137638.169215021, 245698.3375146263]
[2019-03-26 16:31:11,162] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:31:11,166] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [6.5742663e-16 1.0000000e+00 7.1453040e-19 2.6910925e-17 2.9593047e-28], sampled 0.06495291466243869
[2019-03-26 16:31:39,137] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10600296], dtype=float32), 0.0724769]
[2019-03-26 16:31:39,138] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [35.20766330666666, 72.64765927333333, 1.0, 2.0, 0.7334375200326421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1025022.38343965, 1025022.383439649, 228243.1130378239]
[2019-03-26 16:31:39,138] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 16:31:39,143] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.3161705e-16 1.0000000e+00 2.8301747e-19 1.5245379e-16 4.5813585e-30], sampled 0.531576000799634
[2019-03-26 16:31:40,945] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10600296], dtype=float32), 0.0724769]
[2019-03-26 16:31:40,947] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.95, 65.66666666666667, 1.0, 2.0, 1.012139244219367, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.98836422623591, 6.9112, 168.9123958194149, 2311993.225285127, 2257250.44911988, 467717.1326427145]
[2019-03-26 16:31:40,947] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 16:31:40,951] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.7668935e-09 9.9236017e-01 2.1768716e-09 7.6398742e-03 4.6826649e-15], sampled 0.5037497778708727
[2019-03-26 16:31:40,953] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2311993.225285127 W.
[2019-03-26 16:32:09,038] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10600296], dtype=float32), 0.0724769]
[2019-03-26 16:32:09,041] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [24.34857371333333, 83.37905751, 1.0, 2.0, 0.408562484920957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 611595.4608427007, 611595.4608427007, 175661.4161264974]
[2019-03-26 16:32:09,042] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 16:32:09,046] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.6436886e-16 1.0000000e+00 1.3833955e-19 1.4278708e-18 2.2574508e-29], sampled 0.21516000480288378
[2019-03-26 16:32:11,155] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10600296], dtype=float32), 0.0724769]
[2019-03-26 16:32:11,157] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [30.0, 68.0, 1.0, 2.0, 0.9833426485416242, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.980306985514623, 6.9112, 168.9124894128745, 2271687.256482946, 2222660.518054749, 459135.7402112418]
[2019-03-26 16:32:11,158] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:32:11,161] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.9826438e-10 9.9760890e-01 4.7228138e-10 2.3911374e-03 2.7926372e-16], sampled 0.9165817859584253
[2019-03-26 16:32:11,163] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2271687.256482946 W.
[2019-03-26 16:32:15,558] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10600296], dtype=float32), 0.0724769]
[2019-03-26 16:32:15,559] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.37235893, 77.15583996000001, 1.0, 2.0, 0.3315306942700088, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 522202.6785252492, 522202.6785252486, 168685.0423402189]
[2019-03-26 16:32:15,559] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 16:32:15,562] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0876078e-15 1.0000000e+00 5.3419784e-19 9.9296612e-19 1.7886481e-28], sampled 0.16845562301842676
[2019-03-26 16:32:16,775] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10600296], dtype=float32), 0.0724769]
[2019-03-26 16:32:16,776] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [24.18333333333333, 80.33333333333334, 1.0, 2.0, 0.3659376522105902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 557897.4955679895, 557897.4955679895, 171147.5153622031]
[2019-03-26 16:32:16,776] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:32:16,780] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.6988788e-16 1.0000000e+00 4.2112569e-19 5.6240098e-19 1.1847162e-28], sampled 0.8459509067554132
[2019-03-26 16:32:23,749] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10600296], dtype=float32), 0.0724769]
[2019-03-26 16:32:23,749] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [24.57921246, 85.25996527333334, 1.0, 2.0, 0.4437718931748252, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 646250.2171337155, 646250.2171337155, 178589.9772888324]
[2019-03-26 16:32:23,751] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 16:32:23,754] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.0600129e-16 1.0000000e+00 1.7914491e-19 2.7035311e-18 4.2424192e-29], sampled 0.9963915115776503
[2019-03-26 16:32:31,931] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8499.4815 2842150884.1894 1122.0000
[2019-03-26 16:32:31,989] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.7901 2927238668.9976 1337.0000
[2019-03-26 16:32:32,074] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7893.9344 3163404186.0725 1747.0000
[2019-03-26 16:32:32,086] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.7827 3007379498.7956 1761.0000
[2019-03-26 16:32:32,097] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.2328 2779531394.0975 933.0000
[2019-03-26 16:32:33,111] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1175000, evaluation results [1175000.0, 7893.934410129969, 3163404186.07248, 1747.0, 8254.79005782866, 2927238668.9976296, 1337.0, 8660.232755099281, 2779531394.0975146, 933.0, 7998.782714487672, 3007379498.7955604, 1761.0, 8499.48145248179, 2842150884.189442, 1122.0]
[2019-03-26 16:32:33,604] A3C_AGENT_WORKER-Thread-2 INFO:Local step 73500, global step 1175236: loss -64.7049
[2019-03-26 16:32:33,610] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 73500, global step 1175236: learning rate 0.0000
[2019-03-26 16:32:33,688] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.2882277e-17 1.0000000e+00 1.2541971e-19 1.9257342e-16 9.6007144e-29], sum to 1.0000
[2019-03-26 16:32:33,696] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8062
[2019-03-26 16:32:33,701] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.5, 73.0, 1.0, 2.0, 0.6022286390928935, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 841577.5454832029, 841577.5454832029, 201162.1590519047], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4228200.0000, 
sim time next is 4228800.0000, 
raw observation next is [31.33333333333333, 73.66666666666667, 1.0, 2.0, 0.6003760123385354, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 838987.5908322779, 838987.5908322772, 200816.3024063902], 
processed observation next is [1.0, 0.9565217391304348, 0.6840442338072668, 0.7366666666666667, 1.0, 1.0, 0.5185253160705245, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.23305210856452163, 0.23305210856452144, 0.2997258244871496], 
reward next is 0.7003, 
noisyNet noise sample is [array([0.6614402], dtype=float32), 0.15472409]. 
=============================================
[2019-03-26 16:32:37,507] A3C_AGENT_WORKER-Thread-9 INFO:Local step 74000, global step 1177045: loss 2.4300
[2019-03-26 16:32:37,512] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 74000, global step 1177048: learning rate 0.0000
[2019-03-26 16:32:37,975] A3C_AGENT_WORKER-Thread-15 INFO:Local step 73500, global step 1177266: loss -36.4725
[2019-03-26 16:32:37,978] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 73500, global step 1177267: learning rate 0.0000
[2019-03-26 16:32:38,405] A3C_AGENT_WORKER-Thread-3 INFO:Local step 73500, global step 1177459: loss -72.5791
[2019-03-26 16:32:38,409] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 73500, global step 1177461: learning rate 0.0000
[2019-03-26 16:32:39,886] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.5898420e-12 1.0000000e+00 1.7845239e-14 3.3677023e-09 1.1992481e-21], sum to 1.0000
[2019-03-26 16:32:39,895] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3518
[2019-03-26 16:32:39,900] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1679671.732310315 W.
[2019-03-26 16:32:39,903] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.0, 89.0, 1.0, 2.0, 0.6007498663309814, 1.0, 1.0, 0.6007498663309814, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1679671.732310315, 1679671.732310315, 334542.7377532729], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4339200.0000, 
sim time next is 4339800.0000, 
raw observation next is [29.0, 89.0, 1.0, 2.0, 0.4019467811944097, 1.0, 2.0, 0.4019467811944097, 1.0, 1.0, 0.698048633102923, 6.911200000000001, 6.9112, 170.5573041426782, 1685744.589183545, 1685744.589183544, 353970.0940448357], 
processed observation next is [1.0, 0.21739130434782608, 0.5734597156398105, 0.89, 1.0, 1.0, 0.27945395324627675, 1.0, 1.0, 0.27945395324627675, 1.0, 0.5, 0.631766625735272, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.46826238588431807, 0.4682623858843178, 0.5283135732012474], 
reward next is 0.4717, 
noisyNet noise sample is [array([-0.10660386], dtype=float32), 0.048156835]. 
=============================================
[2019-03-26 16:32:39,981] A3C_AGENT_WORKER-Thread-22 INFO:Local step 73500, global step 1178190: loss -32.4304
[2019-03-26 16:32:39,984] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 73500, global step 1178191: learning rate 0.0000
[2019-03-26 16:32:40,426] A3C_AGENT_WORKER-Thread-21 INFO:Local step 73500, global step 1178399: loss -54.9568
[2019-03-26 16:32:40,428] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 73500, global step 1178399: learning rate 0.0000
[2019-03-26 16:32:40,887] A3C_AGENT_WORKER-Thread-18 INFO:Local step 73500, global step 1178611: loss -20.8628
[2019-03-26 16:32:40,889] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 73500, global step 1178611: learning rate 0.0000
[2019-03-26 16:32:41,107] A3C_AGENT_WORKER-Thread-17 INFO:Local step 73500, global step 1178715: loss -18.9371
[2019-03-26 16:32:41,110] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 73500, global step 1178716: learning rate 0.0000
[2019-03-26 16:32:41,124] A3C_AGENT_WORKER-Thread-20 INFO:Local step 73500, global step 1178725: loss -34.7367
[2019-03-26 16:32:41,126] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 73500, global step 1178725: learning rate 0.0000
[2019-03-26 16:32:41,176] A3C_AGENT_WORKER-Thread-12 INFO:Local step 73500, global step 1178748: loss -17.8990
[2019-03-26 16:32:41,178] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 73500, global step 1178749: learning rate 0.0000
[2019-03-26 16:32:41,309] A3C_AGENT_WORKER-Thread-16 INFO:Local step 73500, global step 1178811: loss -53.9870
[2019-03-26 16:32:41,311] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 73500, global step 1178811: learning rate 0.0000
[2019-03-26 16:32:41,337] A3C_AGENT_WORKER-Thread-19 INFO:Local step 73500, global step 1178822: loss -25.3194
[2019-03-26 16:32:41,339] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 73500, global step 1178822: learning rate 0.0000
[2019-03-26 16:32:41,672] A3C_AGENT_WORKER-Thread-11 INFO:Local step 73500, global step 1178979: loss -37.5882
[2019-03-26 16:32:41,674] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 73500, global step 1178980: learning rate 0.0000
[2019-03-26 16:32:41,818] A3C_AGENT_WORKER-Thread-10 INFO:Local step 74500, global step 1179045: loss -131.5985
[2019-03-26 16:32:41,822] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 74500, global step 1179047: learning rate 0.0000
[2019-03-26 16:32:42,205] A3C_AGENT_WORKER-Thread-13 INFO:Local step 74000, global step 1179226: loss 2.5988
[2019-03-26 16:32:42,207] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 74000, global step 1179227: learning rate 0.0000
[2019-03-26 16:32:49,759] A3C_AGENT_WORKER-Thread-14 INFO:Local step 74000, global step 1182733: loss 2.9844
[2019-03-26 16:32:49,762] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 74000, global step 1182733: learning rate 0.0000
[2019-03-26 16:32:50,627] A3C_AGENT_WORKER-Thread-2 INFO:Local step 74000, global step 1183141: loss 2.8484
[2019-03-26 16:32:50,629] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 74000, global step 1183141: learning rate 0.0000
[2019-03-26 16:32:52,431] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.3548302e-10 9.9985719e-01 3.4441072e-10 1.4284602e-04 5.9781718e-15], sum to 1.0000
[2019-03-26 16:32:52,438] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4281
[2019-03-26 16:32:52,451] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2843444.466549881 W.
[2019-03-26 16:32:52,457] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.66666666666667, 76.5, 1.0, 2.0, 0.7141195387178196, 1.0, 2.0, 0.6776498088731725, 1.0, 2.0, 1.03, 7.005098845494876, 6.9112, 170.5573041426782, 2843444.466549881, 2776180.903961074, 525827.013055517], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4611000.0000, 
sim time next is 4611600.0000, 
raw observation next is [32.0, 75.0, 1.0, 2.0, 0.9917534246079148, 1.0, 2.0, 0.9917534246079148, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2774213.364263965, 2774213.364263965, 524031.7513671489], 
processed observation next is [1.0, 0.391304347826087, 0.7156398104265403, 0.75, 1.0, 1.0, 0.9900643669974878, 1.0, 1.0, 0.9900643669974878, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7706148234066569, 0.7706148234066569, 0.7821369423390282], 
reward next is 0.2179, 
noisyNet noise sample is [array([0.9261753], dtype=float32), -0.647364]. 
=============================================
[2019-03-26 16:32:54,946] A3C_AGENT_WORKER-Thread-15 INFO:Local step 74000, global step 1185152: loss 3.8018
[2019-03-26 16:32:54,948] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 74000, global step 1185152: learning rate 0.0000
[2019-03-26 16:32:54,964] A3C_AGENT_WORKER-Thread-9 INFO:Local step 74500, global step 1185158: loss -111.5380
[2019-03-26 16:32:54,969] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 74500, global step 1185160: learning rate 0.0000
[2019-03-26 16:32:55,464] A3C_AGENT_WORKER-Thread-3 INFO:Local step 74000, global step 1185389: loss 2.8674
[2019-03-26 16:32:55,465] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 74000, global step 1185389: learning rate 0.0000
[2019-03-26 16:32:56,688] A3C_AGENT_WORKER-Thread-22 INFO:Local step 74000, global step 1186166: loss 2.8211
[2019-03-26 16:32:56,690] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 74000, global step 1186167: learning rate 0.0000
[2019-03-26 16:32:57,031] A3C_AGENT_WORKER-Thread-21 INFO:Local step 74000, global step 1186327: loss 2.7945
[2019-03-26 16:32:57,033] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 74000, global step 1186328: learning rate 0.0000
[2019-03-26 16:32:57,446] A3C_AGENT_WORKER-Thread-18 INFO:Local step 74000, global step 1186511: loss 2.8470
[2019-03-26 16:32:57,449] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 74000, global step 1186511: learning rate 0.0000
[2019-03-26 16:32:57,731] A3C_AGENT_WORKER-Thread-17 INFO:Local step 74000, global step 1186636: loss 4.0396
[2019-03-26 16:32:57,735] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 74000, global step 1186639: learning rate 0.0000
[2019-03-26 16:32:57,746] A3C_AGENT_WORKER-Thread-20 INFO:Local step 74000, global step 1186645: loss 3.7457
[2019-03-26 16:32:57,751] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 74000, global step 1186646: learning rate 0.0000
[2019-03-26 16:32:57,895] A3C_AGENT_WORKER-Thread-19 INFO:Local step 74000, global step 1186710: loss 3.7323
[2019-03-26 16:32:57,897] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 74000, global step 1186710: learning rate 0.0000
[2019-03-26 16:32:57,961] A3C_AGENT_WORKER-Thread-12 INFO:Local step 74000, global step 1186739: loss 3.2614
[2019-03-26 16:32:57,963] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 74000, global step 1186740: learning rate 0.0000
[2019-03-26 16:32:58,053] A3C_AGENT_WORKER-Thread-16 INFO:Local step 74000, global step 1186783: loss 2.7948
[2019-03-26 16:32:58,054] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 74000, global step 1186784: learning rate 0.0000
[2019-03-26 16:32:58,396] A3C_AGENT_WORKER-Thread-11 INFO:Local step 74000, global step 1186942: loss 2.7630
[2019-03-26 16:32:58,398] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 74000, global step 1186942: learning rate 0.0000
[2019-03-26 16:32:58,750] A3C_AGENT_WORKER-Thread-10 INFO:Local step 75000, global step 1187099: loss 3.7263
[2019-03-26 16:32:58,755] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 75000, global step 1187100: learning rate 0.0000
[2019-03-26 16:32:59,582] A3C_AGENT_WORKER-Thread-13 INFO:Local step 74500, global step 1187474: loss -131.3178
[2019-03-26 16:32:59,589] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 74500, global step 1187474: learning rate 0.0000
[2019-03-26 16:33:06,629] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.3370767e-10 4.4174427e-01 3.8617052e-09 5.5825573e-01 6.5344217e-15], sum to 1.0000
[2019-03-26 16:33:06,638] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1290
[2019-03-26 16:33:06,645] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2306693.616142664 W.
[2019-03-26 16:33:06,649] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.0, 66.0, 1.0, 2.0, 0.8247739413991345, 1.0, 2.0, 0.8247739413991345, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2306693.616142664, 2306693.616142663, 432109.5211915452], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4806000.0000, 
sim time next is 4806600.0000, 
raw observation next is [31.16666666666667, 65.5, 1.0, 2.0, 0.5651586703169824, 1.0, 2.0, 0.5651586703169824, 1.0, 1.0, 0.9800015934702914, 6.911200000000001, 6.9112, 170.5573041426782, 2370979.486042202, 2370979.486042201, 462820.3238829591], 
processed observation next is [1.0, 0.6521739130434783, 0.6761453396524489, 0.655, 1.0, 1.0, 0.4760947835144366, 1.0, 1.0, 0.4760947835144366, 1.0, 0.5, 0.9756116993540137, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6586054127895006, 0.6586054127895002, 0.6907766028103867], 
reward next is 0.3092, 
noisyNet noise sample is [array([-0.2860328], dtype=float32), -0.4661383]. 
=============================================
[2019-03-26 16:33:06,893] A3C_AGENT_WORKER-Thread-14 INFO:Local step 74500, global step 1190784: loss -104.3041
[2019-03-26 16:33:06,895] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 74500, global step 1190784: learning rate 0.0000
[2019-03-26 16:33:07,768] A3C_AGENT_WORKER-Thread-2 INFO:Local step 74500, global step 1191173: loss -111.6501
[2019-03-26 16:33:07,773] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 74500, global step 1191174: learning rate 0.0000
[2019-03-26 16:33:12,248] A3C_AGENT_WORKER-Thread-9 INFO:Local step 75000, global step 1193098: loss 3.5733
[2019-03-26 16:33:12,253] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 75000, global step 1193099: learning rate 0.0000
[2019-03-26 16:33:12,374] A3C_AGENT_WORKER-Thread-15 INFO:Local step 74500, global step 1193155: loss -103.9770
[2019-03-26 16:33:12,380] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 74500, global step 1193156: learning rate 0.0000
[2019-03-26 16:33:12,900] A3C_AGENT_WORKER-Thread-3 INFO:Local step 74500, global step 1193395: loss -146.2318
[2019-03-26 16:33:12,902] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 74500, global step 1193395: learning rate 0.0000
[2019-03-26 16:33:14,443] A3C_AGENT_WORKER-Thread-22 INFO:Local step 74500, global step 1194091: loss -131.1688
[2019-03-26 16:33:14,446] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 74500, global step 1194091: learning rate 0.0000
[2019-03-26 16:33:15,016] A3C_AGENT_WORKER-Thread-21 INFO:Local step 74500, global step 1194354: loss -110.7506
[2019-03-26 16:33:15,022] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 74500, global step 1194355: learning rate 0.0000
[2019-03-26 16:33:15,364] A3C_AGENT_WORKER-Thread-18 INFO:Local step 74500, global step 1194511: loss -111.7818
[2019-03-26 16:33:15,369] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 74500, global step 1194511: learning rate 0.0000
[2019-03-26 16:33:15,636] A3C_AGENT_WORKER-Thread-17 INFO:Local step 74500, global step 1194633: loss -110.7330
[2019-03-26 16:33:15,640] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 74500, global step 1194634: learning rate 0.0000
[2019-03-26 16:33:15,649] A3C_AGENT_WORKER-Thread-20 INFO:Local step 74500, global step 1194637: loss -99.7857
[2019-03-26 16:33:15,650] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 74500, global step 1194637: learning rate 0.0000
[2019-03-26 16:33:15,820] A3C_AGENT_WORKER-Thread-19 INFO:Local step 74500, global step 1194716: loss -131.2259
[2019-03-26 16:33:15,823] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 74500, global step 1194716: learning rate 0.0000
[2019-03-26 16:33:15,882] A3C_AGENT_WORKER-Thread-12 INFO:Local step 74500, global step 1194741: loss -146.2721
[2019-03-26 16:33:15,885] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 74500, global step 1194741: learning rate 0.0000
[2019-03-26 16:33:16,074] A3C_AGENT_WORKER-Thread-16 INFO:Local step 74500, global step 1194828: loss -99.9341
[2019-03-26 16:33:16,078] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 74500, global step 1194829: learning rate 0.0000
[2019-03-26 16:33:16,265] A3C_AGENT_WORKER-Thread-11 INFO:Local step 74500, global step 1194915: loss -111.2478
[2019-03-26 16:33:16,269] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 74500, global step 1194915: learning rate 0.0000
[2019-03-26 16:33:16,583] A3C_AGENT_WORKER-Thread-10 INFO:Local step 75500, global step 1195057: loss 0.5109
[2019-03-26 16:33:16,587] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 75500, global step 1195057: learning rate 0.0000
[2019-03-26 16:33:17,158] A3C_AGENT_WORKER-Thread-13 INFO:Local step 75000, global step 1195316: loss 4.4657
[2019-03-26 16:33:17,163] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 75000, global step 1195316: learning rate 0.0000
[2019-03-26 16:33:19,812] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0470554e-16 1.0000000e+00 4.8936276e-20 8.2197093e-19 3.0410116e-30], sum to 1.0000
[2019-03-26 16:33:19,822] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3168
[2019-03-26 16:33:19,831] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.5, 66.5, 1.0, 2.0, 0.5255378022905445, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 734369.7620977546, 734369.7620977546, 187694.3964935441], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5070600.0000, 
sim time next is 5071200.0000, 
raw observation next is [30.33333333333334, 67.66666666666667, 1.0, 2.0, 0.5266637652255756, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 735943.6918311836, 735943.6918311842, 187879.5799000853], 
processed observation next is [0.0, 0.6956521739130435, 0.6366508688783573, 0.6766666666666667, 1.0, 1.0, 0.42971537978985, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2044288032864399, 0.20442880328644006, 0.2804172834329631], 
reward next is 0.7196, 
noisyNet noise sample is [array([-1.2232131], dtype=float32), -0.09496957]. 
=============================================
[2019-03-26 16:33:21,908] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.1958610e-13 4.2711711e-04 1.2234814e-11 9.9957293e-01 2.1311370e-17], sum to 1.0000
[2019-03-26 16:33:21,917] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7435
[2019-03-26 16:33:21,921] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [35.4, 56.33333333333334, 1.0, 2.0, 0.2935827622544146, 1.0, 2.0, 0.2935827622544146, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 820516.5815665348, 820516.5815665348, 248664.4836073102], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5332800.0000, 
sim time next is 5333400.0000, 
raw observation next is [35.15, 57.5, 1.0, 2.0, 0.2877002821926469, 1.0, 2.0, 0.2877002821926469, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 804069.8334483217, 804069.8334483217, 247560.5917818137], 
processed observation next is [1.0, 0.7391304347826086, 0.8649289099526066, 0.575, 1.0, 1.0, 0.14180756890680346, 1.0, 1.0, 0.14180756890680346, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.2233527315134227, 0.2233527315134227, 0.3694934205698712], 
reward next is 0.6305, 
noisyNet noise sample is [array([-1.6442027], dtype=float32), -1.5679342]. 
=============================================
[2019-03-26 16:33:22,968] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.708324e-10 4.741518e-01 8.893070e-10 5.258482e-01 9.669873e-16], sum to 1.0000
[2019-03-26 16:33:22,978] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1744
[2019-03-26 16:33:22,986] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2753789.579225951 W.
[2019-03-26 16:33:22,995] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.0, 67.0, 1.0, 2.0, 0.9844601649614716, 1.0, 2.0, 0.9844601649614716, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2753789.579225951, 2753789.579225951, 519665.8535308305], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5227800.0000, 
sim time next is 5228400.0000, 
raw observation next is [32.0, 67.0, 1.0, 2.0, 0.5807397220388059, 1.0, 2.0, 0.5807397220388059, 1.0, 1.0, 1.008552843620577, 6.9112, 6.9112, 170.5573041426782, 2436409.549828943, 2436409.549828943, 475468.5439661973], 
processed observation next is [1.0, 0.5217391304347826, 0.7156398104265403, 0.67, 1.0, 1.0, 0.4948671349865131, 1.0, 1.0, 0.4948671349865131, 1.0, 0.5, 1.0104302970982648, 0.0, 0.0, 0.8375144448122397, 0.6767804305080397, 0.6767804305080397, 0.7096545432331303], 
reward next is 0.2903, 
noisyNet noise sample is [array([-0.79481715], dtype=float32), 0.14630385]. 
=============================================
[2019-03-26 16:33:24,673] A3C_AGENT_WORKER-Thread-14 INFO:Local step 75000, global step 1198715: loss 5.5535
[2019-03-26 16:33:24,674] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 75000, global step 1198715: learning rate 0.0000
[2019-03-26 16:33:25,740] A3C_AGENT_WORKER-Thread-2 INFO:Local step 75000, global step 1199196: loss 4.6886
[2019-03-26 16:33:25,745] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 75000, global step 1199197: learning rate 0.0000
[2019-03-26 16:33:26,749] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.4810617e-15 1.0000000e+00 1.1140740e-17 2.5900552e-15 4.8567504e-27], sum to 1.0000
[2019-03-26 16:33:26,756] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4182
[2019-03-26 16:33:26,763] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.754391280153617, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1054321.041703857, 1054321.041703857, 233021.1802759033], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5201400.0000, 
sim time next is 5202000.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.7360339888944364, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1028652.85997724, 1028652.859977241, 228813.0086104057], 
processed observation next is [1.0, 0.21739130434782608, 0.4312796208530806, 0.89, 1.0, 1.0, 0.681968661318598, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2857369055492333, 0.28573690554923364, 0.34151195314985927], 
reward next is 0.6585, 
noisyNet noise sample is [array([-1.6125497], dtype=float32), -0.5861418]. 
=============================================
[2019-03-26 16:33:26,780] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[67.75114]
 [67.0067 ]
 [66.10303]
 [64.78769]
 [63.52318]], R is [[68.58307648]
 [68.54945374]
 [68.51379395]
 [68.47737122]
 [68.43862152]].
[2019-03-26 16:33:27,522] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-26 16:33:27,523] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 16:33:27,524] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 16:33:27,526] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:33:27,526] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 16:33:27,526] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:33:27,525] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 16:33:27,527] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 16:33:27,532] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:33:27,533] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:33:27,533] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:33:27,552] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run49
[2019-03-26 16:33:27,552] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run49
[2019-03-26 16:33:27,591] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run49
[2019-03-26 16:33:27,613] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run49
[2019-03-26 16:33:27,630] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run49
[2019-03-26 16:33:43,158] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10302577], dtype=float32), 0.07589751]
[2019-03-26 16:33:43,160] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [21.95, 79.5, 1.0, 2.0, 0.2944164624273032, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 474313.4534726765, 474313.4534726765, 165260.5082189013]
[2019-03-26 16:33:43,161] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 16:33:43,168] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.1000837e-16 1.0000000e+00 8.0292341e-20 4.0480728e-19 9.0618984e-30], sampled 0.034670415686332445
[2019-03-26 16:33:50,547] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10302577], dtype=float32), 0.07589751]
[2019-03-26 16:33:50,550] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.732897495, 65.303204445, 1.0, 2.0, 0.4629629512606956, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 656336.0540307141, 656336.0540307135, 179211.5399929832]
[2019-03-26 16:33:50,551] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 16:33:50,554] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.3387408e-16 1.0000000e+00 9.2185647e-20 3.1100466e-19 9.5257420e-30], sampled 0.11468164824317773
[2019-03-26 16:34:09,781] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10302577], dtype=float32), 0.07589751]
[2019-03-26 16:34:09,784] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.62348037, 84.39454139, 1.0, 2.0, 0.6695321802352471, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 940807.3417369244, 940807.341736925, 215086.6468978947]
[2019-03-26 16:34:09,785] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 16:34:09,787] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.8050547e-16 1.0000000e+00 1.1096915e-19 1.9180854e-18 1.5603060e-29], sampled 0.081993474997196
[2019-03-26 16:34:48,692] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10302577], dtype=float32), 0.07589751]
[2019-03-26 16:34:48,694] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.2, 83.16666666666667, 1.0, 2.0, 0.9019687565190204, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1260694.593087808, 1260694.593087808, 270483.3989518216]
[2019-03-26 16:34:48,697] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:34:48,699] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [8.6733151e-16 1.0000000e+00 1.1395840e-18 1.2128229e-16 6.6761755e-28], sampled 0.913608524745611
[2019-03-26 16:34:50,198] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10302577], dtype=float32), 0.07589751]
[2019-03-26 16:34:50,200] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.8, 91.66666666666666, 1.0, 2.0, 0.588099491679951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 821825.2908412658, 821825.2908412658, 198549.1645279602]
[2019-03-26 16:34:50,201] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 16:34:50,203] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [8.7511123e-17 1.0000000e+00 4.0779064e-20 4.6616854e-19 2.5795738e-30], sampled 0.18813848955887602
[2019-03-26 16:34:51,835] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10302577], dtype=float32), 0.07589751]
[2019-03-26 16:34:51,837] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.72522042, 84.85031599499999, 1.0, 2.0, 0.5459937381791996, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 762964.5001869327, 762964.5001869327, 191115.6808953146]
[2019-03-26 16:34:51,839] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 16:34:51,841] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.4870896e-16 1.0000000e+00 1.1261694e-19 1.0970105e-18 1.7348666e-29], sampled 0.6050004358633995
[2019-03-26 16:35:00,148] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10302577], dtype=float32), 0.07589751]
[2019-03-26 16:35:00,152] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [32.2, 63.0, 1.0, 2.0, 0.5685148611813282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 794446.9915819418, 794446.9915819411, 195026.4879099278]
[2019-03-26 16:35:00,153] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:35:00,155] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.8734476e-16 1.0000000e+00 9.0931797e-20 7.0140273e-19 8.4838839e-30], sampled 0.38213886218929294
[2019-03-26 16:35:01,148] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10302577], dtype=float32), 0.07589751]
[2019-03-26 16:35:01,150] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.17940121333334, 74.92568613, 1.0, 2.0, 0.3937611717358115, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 598254.5354903827, 598254.5354903827, 174664.1006643864]
[2019-03-26 16:35:01,151] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 16:35:01,155] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [8.8080475e-17 1.0000000e+00 3.5632504e-20 3.5201136e-19 1.9766361e-30], sampled 0.3209188425408118
[2019-03-26 16:35:14,256] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10302577], dtype=float32), 0.07589751]
[2019-03-26 16:35:14,257] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [20.40072336666667, 98.60526859333334, 1.0, 2.0, 0.314253276262367, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 499737.8766250802, 499737.8766250802, 167052.857810573]
[2019-03-26 16:35:14,257] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 16:35:14,259] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.5398060e-16 1.0000000e+00 1.1664789e-19 1.4408487e-19 1.3926120e-29], sampled 0.22254267807476646
[2019-03-26 16:35:20,754] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10302577], dtype=float32), 0.07589751]
[2019-03-26 16:35:20,755] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.49062875666667, 83.69218250333333, 1.0, 2.0, 0.5120066432230643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 715455.3844264414, 715455.3844264408, 185497.2878485436]
[2019-03-26 16:35:20,758] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 16:35:20,760] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.1646325e-16 1.0000000e+00 1.6764839e-19 4.8032666e-18 3.3913697e-29], sampled 0.5112552938550874
[2019-03-26 16:35:20,905] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10302577], dtype=float32), 0.07589751]
[2019-03-26 16:35:20,906] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.23038761, 63.88220597333333, 1.0, 2.0, 0.5389858626664674, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 788536.5509692334, 788536.5509692334, 194384.7873145565]
[2019-03-26 16:35:20,907] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 16:35:20,912] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.3430771e-16 1.0000000e+00 1.0641959e-19 6.3485529e-18 1.1205158e-29], sampled 0.7374564971234412
[2019-03-26 16:35:22,228] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.4842 2927222304.8781 1337.0000
[2019-03-26 16:35:22,436] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7995.9889 3007753666.8803 1762.0000
[2019-03-26 16:35:22,753] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7887.7964 3164248752.8776 1757.0000
[2019-03-26 16:35:22,766] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8499.5716 2842227245.7273 1127.0000
[2019-03-26 16:35:22,892] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.8524 2779356575.1369 933.0000
[2019-03-26 16:35:23,907] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1200000, evaluation results [1200000.0, 7887.796376420363, 3164248752.877568, 1757.0, 8255.484181756856, 2927222304.8781376, 1337.0, 8659.852403126195, 2779356575.136891, 933.0, 7995.988898693103, 3007753666.880293, 1762.0, 8499.571610501936, 2842227245.727275, 1127.0]
[2019-03-26 16:35:24,097] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2997510e-15 1.0000000e+00 5.8422002e-20 1.5583331e-19 1.6559772e-29], sum to 1.0000
[2019-03-26 16:35:24,106] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5646
[2019-03-26 16:35:24,109] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 66.0, 1.0, 2.0, 0.5504419427918837, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 769182.6136442873, 769182.6136442866, 191876.0730203338], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5159400.0000, 
sim time next is 5160000.0000, 
raw observation next is [31.0, 66.0, 1.0, 2.0, 0.5427956296079233, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 758493.9095505218, 758493.9095505225, 190572.9430491542], 
processed observation next is [0.0, 0.7391304347826086, 0.6682464454976303, 0.66, 1.0, 1.0, 0.4491513609734015, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2106927526529227, 0.2106927526529229, 0.28443722843157343], 
reward next is 0.7156, 
noisyNet noise sample is [array([-1.7594258], dtype=float32), 0.012433281]. 
=============================================
[2019-03-26 16:35:24,127] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[75.354324]
 [75.323135]
 [75.2763  ]
 [75.25423 ]
 [75.219696]], R is [[75.34586334]
 [75.30602264]
 [75.26873779]
 [75.23136139]
 [75.19394684]].
[2019-03-26 16:35:26,447] A3C_AGENT_WORKER-Thread-15 INFO:Local step 75000, global step 1201179: loss 4.9700
[2019-03-26 16:35:26,451] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 75000, global step 1201180: learning rate 0.0000
[2019-03-26 16:35:26,582] A3C_AGENT_WORKER-Thread-9 INFO:Local step 75500, global step 1201245: loss 0.9935
[2019-03-26 16:35:26,586] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 75500, global step 1201246: learning rate 0.0000
[2019-03-26 16:35:26,984] A3C_AGENT_WORKER-Thread-3 INFO:Local step 75000, global step 1201429: loss 5.6851
[2019-03-26 16:35:26,986] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 75000, global step 1201429: learning rate 0.0000
[2019-03-26 16:35:28,346] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.2014638e-12 1.0000000e+00 1.1773406e-14 1.5481549e-10 8.6705807e-21], sum to 1.0000
[2019-03-26 16:35:28,355] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6160
[2019-03-26 16:35:28,359] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.6, 87.0, 1.0, 2.0, 0.3427378448783446, 1.0, 2.0, 0.3427378448783446, 1.0, 1.0, 0.5952222914163681, 6.9112, 6.9112, 170.5573041426782, 1437258.785037503, 1437258.785037503, 323456.2877626756], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5280000.0000, 
sim time next is 5280600.0000, 
raw observation next is [28.6, 87.0, 1.0, 2.0, 0.9857881139295678, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 168.9129565104309, 1377926.133029666, 1377926.133029666, 294629.1729232091], 
processed observation next is [1.0, 0.08695652173913043, 0.5545023696682465, 0.87, 1.0, 1.0, 0.9828772456982744, 0.0, 0.5, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523021, 0.3827572591749072, 0.3827572591749072, 0.4397450342137449], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.63425285], dtype=float32), -0.5898544]. 
=============================================
[2019-03-26 16:35:28,378] A3C_AGENT_WORKER-Thread-22 INFO:Local step 75000, global step 1202070: loss 3.5829
[2019-03-26 16:35:28,379] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 75000, global step 1202070: learning rate 0.0000
[2019-03-26 16:35:28,899] A3C_AGENT_WORKER-Thread-21 INFO:Local step 75000, global step 1202311: loss 7.1807
[2019-03-26 16:35:28,901] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 75000, global step 1202311: learning rate 0.0000
[2019-03-26 16:35:29,199] A3C_AGENT_WORKER-Thread-18 INFO:Local step 75000, global step 1202452: loss 6.5865
[2019-03-26 16:35:29,201] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 75000, global step 1202453: learning rate 0.0000
[2019-03-26 16:35:29,640] A3C_AGENT_WORKER-Thread-17 INFO:Local step 75000, global step 1202653: loss 6.2784
[2019-03-26 16:35:29,642] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 75000, global step 1202654: learning rate 0.0000
[2019-03-26 16:35:29,685] A3C_AGENT_WORKER-Thread-20 INFO:Local step 75000, global step 1202671: loss 9.8405
[2019-03-26 16:35:29,690] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 75000, global step 1202674: learning rate 0.0000
[2019-03-26 16:35:29,860] A3C_AGENT_WORKER-Thread-19 INFO:Local step 75000, global step 1202752: loss 6.0002
[2019-03-26 16:35:29,864] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 75000, global step 1202753: learning rate 0.0000
[2019-03-26 16:35:29,920] A3C_AGENT_WORKER-Thread-12 INFO:Local step 75000, global step 1202778: loss 8.7871
[2019-03-26 16:35:29,922] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 75000, global step 1202779: learning rate 0.0000
[2019-03-26 16:35:30,033] A3C_AGENT_WORKER-Thread-16 INFO:Local step 75000, global step 1202827: loss 7.6377
[2019-03-26 16:35:30,036] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 75000, global step 1202827: learning rate 0.0000
[2019-03-26 16:35:30,260] A3C_AGENT_WORKER-Thread-11 INFO:Local step 75000, global step 1202935: loss 3.9089
[2019-03-26 16:35:30,261] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 75000, global step 1202935: learning rate 0.0000
[2019-03-26 16:35:30,481] A3C_AGENT_WORKER-Thread-10 INFO:Local step 76000, global step 1203034: loss 68.4614
[2019-03-26 16:35:30,485] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 76000, global step 1203037: learning rate 0.0000
[2019-03-26 16:35:31,453] A3C_AGENT_WORKER-Thread-13 INFO:Local step 75500, global step 1203484: loss 0.9572
[2019-03-26 16:35:31,455] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 75500, global step 1203484: learning rate 0.0000
[2019-03-26 16:35:38,604] A3C_AGENT_WORKER-Thread-14 INFO:Local step 75500, global step 1206758: loss 0.8135
[2019-03-26 16:35:38,606] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 75500, global step 1206759: learning rate 0.0000
[2019-03-26 16:35:39,560] A3C_AGENT_WORKER-Thread-2 INFO:Local step 75500, global step 1207197: loss 0.3934
[2019-03-26 16:35:39,566] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 75500, global step 1207197: learning rate 0.0000
[2019-03-26 16:35:39,598] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.9288552e-17 1.0000000e+00 1.7720512e-19 5.8331040e-16 1.9556676e-28], sum to 1.0000
[2019-03-26 16:35:39,605] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2888
[2019-03-26 16:35:39,611] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.2, 82.0, 1.0, 2.0, 0.6140203050687977, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 858062.3308292129, 858062.3308292129, 203387.1720910434], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5434200.0000, 
sim time next is 5434800.0000, 
raw observation next is [30.13333333333333, 82.0, 1.0, 2.0, 0.6126570811800243, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 856156.5265548864, 856156.5265548864, 203127.7324299772], 
processed observation next is [1.0, 0.9130434782608695, 0.6271721958925749, 0.82, 1.0, 1.0, 0.5333217845542461, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23782125737635731, 0.23782125737635731, 0.3031757200447421], 
reward next is 0.6968, 
noisyNet noise sample is [array([1.7398437], dtype=float32), 0.19373384]. 
=============================================
[2019-03-26 16:35:43,574] A3C_AGENT_WORKER-Thread-15 INFO:Local step 75500, global step 1209072: loss 0.3937
[2019-03-26 16:35:43,577] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 75500, global step 1209073: learning rate 0.0000
[2019-03-26 16:35:43,814] A3C_AGENT_WORKER-Thread-9 INFO:Local step 76000, global step 1209185: loss 63.3369
[2019-03-26 16:35:43,816] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 76000, global step 1209185: learning rate 0.0000
[2019-03-26 16:35:44,294] A3C_AGENT_WORKER-Thread-3 INFO:Local step 75500, global step 1209408: loss 0.9435
[2019-03-26 16:35:44,296] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 75500, global step 1209408: learning rate 0.0000
[2019-03-26 16:35:45,717] A3C_AGENT_WORKER-Thread-22 INFO:Local step 75500, global step 1210063: loss 0.9424
[2019-03-26 16:35:45,719] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 75500, global step 1210064: learning rate 0.0000
[2019-03-26 16:35:46,226] A3C_AGENT_WORKER-Thread-21 INFO:Local step 75500, global step 1210302: loss 1.0273
[2019-03-26 16:35:46,230] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 75500, global step 1210302: learning rate 0.0000
[2019-03-26 16:35:46,534] A3C_AGENT_WORKER-Thread-18 INFO:Local step 75500, global step 1210445: loss 1.0157
[2019-03-26 16:35:46,537] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 75500, global step 1210445: learning rate 0.0000
[2019-03-26 16:35:46,981] A3C_AGENT_WORKER-Thread-17 INFO:Local step 75500, global step 1210648: loss 1.0229
[2019-03-26 16:35:46,983] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 75500, global step 1210649: learning rate 0.0000
[2019-03-26 16:35:47,097] A3C_AGENT_WORKER-Thread-20 INFO:Local step 75500, global step 1210704: loss 0.6890
[2019-03-26 16:35:47,099] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 75500, global step 1210705: learning rate 0.0000
[2019-03-26 16:35:47,203] A3C_AGENT_WORKER-Thread-12 INFO:Local step 75500, global step 1210753: loss 0.3921
[2019-03-26 16:35:47,206] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 75500, global step 1210753: learning rate 0.0000
[2019-03-26 16:35:47,395] A3C_AGENT_WORKER-Thread-19 INFO:Local step 75500, global step 1210840: loss 1.0206
[2019-03-26 16:35:47,396] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 75500, global step 1210841: learning rate 0.0000
[2019-03-26 16:35:47,457] A3C_AGENT_WORKER-Thread-16 INFO:Local step 75500, global step 1210864: loss 0.5527
[2019-03-26 16:35:47,460] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 75500, global step 1210865: learning rate 0.0000
[2019-03-26 16:35:47,588] A3C_AGENT_WORKER-Thread-11 INFO:Local step 75500, global step 1210929: loss 0.9454
[2019-03-26 16:35:47,589] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 75500, global step 1210929: learning rate 0.0000
[2019-03-26 16:35:47,969] A3C_AGENT_WORKER-Thread-10 INFO:Local step 76500, global step 1211105: loss 0.0350
[2019-03-26 16:35:47,972] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 76500, global step 1211105: learning rate 0.0000
[2019-03-26 16:35:48,022] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.3120277e-12 1.0000000e+00 7.9038761e-13 2.7883804e-08 5.9807924e-19], sum to 1.0000
[2019-03-26 16:35:48,029] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1846
[2019-03-26 16:35:48,037] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2334772.598952138 W.
[2019-03-26 16:35:48,043] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.43333333333334, 72.66666666666667, 1.0, 2.0, 0.8348044022522506, 1.0, 2.0, 0.8348044022522506, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2334772.598952138, 2334772.598952138, 437172.3667502844], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5563200.0000, 
sim time next is 5563800.0000, 
raw observation next is [30.65, 71.5, 1.0, 2.0, 0.868527702156885, 1.0, 2.0, 0.868527702156885, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2429181.258728443, 2429181.258728443, 454612.6015786537], 
processed observation next is [1.0, 0.391304347826087, 0.6516587677725119, 0.715, 1.0, 1.0, 0.8415996411528736, 1.0, 1.0, 0.8415996411528736, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.674772571869012, 0.674772571869012, 0.678526271012916], 
reward next is 0.3215, 
noisyNet noise sample is [array([-2.0715065], dtype=float32), -1.2099357]. 
=============================================
[2019-03-26 16:35:48,503] A3C_AGENT_WORKER-Thread-13 INFO:Local step 76000, global step 1211352: loss 51.7351
[2019-03-26 16:35:48,507] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 76000, global step 1211352: learning rate 0.0000
[2019-03-26 16:35:51,758] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.7251783e-17 1.0000000e+00 4.1349250e-20 1.3373490e-19 9.3213091e-31], sum to 1.0000
[2019-03-26 16:35:51,763] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3175
[2019-03-26 16:35:51,773] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 83.33333333333334, 1.0, 2.0, 0.5460980681589057, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 763110.3419035353, 763110.3419035347, 191133.5679550873], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5776800.0000, 
sim time next is 5777400.0000, 
raw observation next is [27.95, 83.66666666666666, 1.0, 2.0, 0.5459092085017889, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 762846.3371070576, 762846.337107057, 191101.417540158], 
processed observation next is [0.0, 0.8695652173913043, 0.523696682464455, 0.8366666666666666, 1.0, 1.0, 0.45290266084552877, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21190176030751598, 0.21190176030751584, 0.285225996328594], 
reward next is 0.7148, 
noisyNet noise sample is [array([0.33594957], dtype=float32), -1.0595824]. 
=============================================
[2019-03-26 16:35:51,833] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.8608940e-09 9.9642062e-01 1.7833783e-09 3.5793723e-03 2.2592083e-14], sum to 1.0000
[2019-03-26 16:35:51,842] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2326
[2019-03-26 16:35:51,851] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2209629.630646077 W.
[2019-03-26 16:35:51,857] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.76666666666667, 74.33333333333333, 1.0, 2.0, 0.790098867097114, 1.0, 2.0, 0.790098867097114, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2209629.630646077, 2209629.630646078, 415086.3746947704], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5998200.0000, 
sim time next is 5998800.0000, 
raw observation next is [30.93333333333334, 73.66666666666667, 1.0, 2.0, 0.5725884041137808, 1.0, 2.0, 0.5725884041137808, 1.0, 1.0, 0.9943967000668387, 6.911199999999999, 6.9112, 170.5573041426782, 2402179.003685755, 2402179.003685756, 468971.5618581095], 
processed observation next is [1.0, 0.43478260869565216, 0.6650868878357034, 0.7366666666666667, 1.0, 1.0, 0.4850462700166033, 1.0, 1.0, 0.4850462700166033, 1.0, 0.5, 0.9931667073985836, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6672719454682653, 0.6672719454682656, 0.6999575550121037], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.32136884], dtype=float32), -1.0615301]. 
=============================================
[2019-03-26 16:35:53,360] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.3239252e-16 1.0000000e+00 1.6969568e-20 1.3135101e-19 1.6362404e-30], sum to 1.0000
[2019-03-26 16:35:53,369] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3775
[2019-03-26 16:35:53,373] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.8, 79.0, 1.0, 2.0, 0.5423574187596366, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 757881.3422833523, 757881.3422833523, 190499.0285411303], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6253200.0000, 
sim time next is 6253800.0000, 
raw observation next is [28.95, 78.16666666666667, 1.0, 2.0, 0.5422915011280068, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 757789.1972115706, 757789.19721157, 190487.9171281811], 
processed observation next is [0.0, 0.391304347826087, 0.5710900473933649, 0.7816666666666667, 1.0, 1.0, 0.4485439772626588, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21049699922543627, 0.2104969992254361, 0.2843103240719121], 
reward next is 0.7157, 
noisyNet noise sample is [array([-1.1431869], dtype=float32), 0.87851423]. 
=============================================
[2019-03-26 16:35:55,334] A3C_AGENT_WORKER-Thread-14 INFO:Local step 76000, global step 1214643: loss 46.2491
[2019-03-26 16:35:55,337] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 76000, global step 1214645: learning rate 0.0000
[2019-03-26 16:35:55,770] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.5660904e-17 1.0000000e+00 2.9085506e-20 1.2071530e-19 2.3471523e-30], sum to 1.0000
[2019-03-26 16:35:55,781] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0210
[2019-03-26 16:35:55,788] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.73333333333333, 59.16666666666667, 1.0, 2.0, 0.5643201405193947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 788583.0810784464, 788583.0810784464, 194286.3640795134], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5760600.0000, 
sim time next is 5761200.0000, 
raw observation next is [32.56666666666666, 60.33333333333334, 1.0, 2.0, 0.5521515385808276, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 771572.4550705901, 771572.4550705901, 192170.8571111246], 
processed observation next is [0.0, 0.6956521739130435, 0.7424960505529224, 0.6033333333333334, 1.0, 1.0, 0.46042354045882833, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21432568196405283, 0.21432568196405283, 0.2868221747927233], 
reward next is 0.7132, 
noisyNet noise sample is [array([1.4740603], dtype=float32), 0.49016476]. 
=============================================
[2019-03-26 16:35:56,306] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.4184495e-17 1.0000000e+00 4.1426118e-21 9.1724022e-20 2.8534211e-31], sum to 1.0000
[2019-03-26 16:35:56,307] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9557
[2019-03-26 16:35:56,315] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.3, 85.0, 1.0, 2.0, 0.5301995827677464, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 740886.2572201214, 740886.2572201214, 188462.7370218643], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6303600.0000, 
sim time next is 6304200.0000, 
raw observation next is [27.3, 85.00000000000001, 1.0, 2.0, 0.5290250267399023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 739244.3939393072, 739244.3939393079, 188268.4774222132], 
processed observation next is [0.0, 1.0, 0.4928909952606636, 0.8500000000000001, 1.0, 1.0, 0.4325602731806051, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20534566498314089, 0.20534566498314108, 0.2809977274958406], 
reward next is 0.7190, 
noisyNet noise sample is [array([-0.20142166], dtype=float32), -0.41427413]. 
=============================================
[2019-03-26 16:35:56,549] A3C_AGENT_WORKER-Thread-2 INFO:Local step 76000, global step 1215190: loss 74.2517
[2019-03-26 16:35:56,554] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 76000, global step 1215190: learning rate 0.0000
[2019-03-26 16:36:00,450] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.5401705e-16 1.0000000e+00 5.2147492e-19 1.3080968e-16 4.4606122e-28], sum to 1.0000
[2019-03-26 16:36:00,459] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2719
[2019-03-26 16:36:00,462] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.8, 91.0, 1.0, 2.0, 0.538071823698464, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 751890.6026538422, 751890.6026538422, 189776.2377056621], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6139800.0000, 
sim time next is 6140400.0000, 
raw observation next is [26.76666666666667, 91.33333333333333, 1.0, 2.0, 0.5392792475745962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 753578.4306708007, 753578.4306708013, 189979.2090079504], 
processed observation next is [1.0, 0.043478260869565216, 0.46761453396524505, 0.9133333333333333, 1.0, 1.0, 0.4449147561139713, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2093273418530002, 0.20932734185300036, 0.2835510582208215], 
reward next is 0.7164, 
noisyNet noise sample is [array([0.09945635], dtype=float32), -0.21030478]. 
=============================================
[2019-03-26 16:36:00,895] A3C_AGENT_WORKER-Thread-15 INFO:Local step 76000, global step 1217153: loss 46.0230
[2019-03-26 16:36:00,898] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 76000, global step 1217153: learning rate 0.0000
[2019-03-26 16:36:01,372] A3C_AGENT_WORKER-Thread-9 INFO:Local step 76500, global step 1217368: loss 0.0879
[2019-03-26 16:36:01,374] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 76500, global step 1217368: learning rate 0.0000
[2019-03-26 16:36:01,530] A3C_AGENT_WORKER-Thread-3 INFO:Local step 76000, global step 1217440: loss 61.6527
[2019-03-26 16:36:01,534] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 76000, global step 1217440: learning rate 0.0000
[2019-03-26 16:36:02,645] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.600230e-16 1.000000e+00 7.443667e-20 9.834519e-18 5.515330e-29], sum to 1.0000
[2019-03-26 16:36:02,658] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2405
[2019-03-26 16:36:02,663] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333334, 91.0, 1.0, 2.0, 0.5601860517267772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 782803.9611360257, 782803.9611360257, 193562.9574364171], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5956800.0000, 
sim time next is 5957400.0000, 
raw observation next is [27.26666666666667, 91.5, 1.0, 2.0, 0.5597967599242398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 782259.7644736514, 782259.764473652, 193495.0799336155], 
processed observation next is [1.0, 0.9565217391304348, 0.4913112164297, 0.915, 1.0, 1.0, 0.4696346505111323, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21729437902045873, 0.2172943790204589, 0.2887986267665903], 
reward next is 0.7112, 
noisyNet noise sample is [array([-0.4492566], dtype=float32), -1.2503651]. 
=============================================
[2019-03-26 16:36:02,912] A3C_AGENT_WORKER-Thread-22 INFO:Local step 76000, global step 1218068: loss 51.5984
[2019-03-26 16:36:02,914] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 76000, global step 1218068: learning rate 0.0000
[2019-03-26 16:36:03,456] A3C_AGENT_WORKER-Thread-21 INFO:Local step 76000, global step 1218309: loss 49.7187
[2019-03-26 16:36:03,460] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 76000, global step 1218312: learning rate 0.0000
[2019-03-26 16:36:03,656] A3C_AGENT_WORKER-Thread-18 INFO:Local step 76000, global step 1218400: loss 50.8550
[2019-03-26 16:36:03,657] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 76000, global step 1218400: learning rate 0.0000
[2019-03-26 16:36:04,273] A3C_AGENT_WORKER-Thread-17 INFO:Local step 76000, global step 1218685: loss 59.2958
[2019-03-26 16:36:04,275] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 76000, global step 1218685: learning rate 0.0000
[2019-03-26 16:36:04,301] A3C_AGENT_WORKER-Thread-20 INFO:Local step 76000, global step 1218696: loss 40.0414
[2019-03-26 16:36:04,303] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 76000, global step 1218697: learning rate 0.0000
[2019-03-26 16:36:04,725] A3C_AGENT_WORKER-Thread-12 INFO:Local step 76000, global step 1218737: loss 53.3725
[2019-03-26 16:36:04,726] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 76000, global step 1218737: learning rate 0.0000
[2019-03-26 16:36:04,849] A3C_AGENT_WORKER-Thread-16 INFO:Local step 76000, global step 1218788: loss 64.2918
[2019-03-26 16:36:04,853] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 76000, global step 1218789: learning rate 0.0000
[2019-03-26 16:36:04,871] A3C_AGENT_WORKER-Thread-19 INFO:Local step 76000, global step 1218801: loss 66.3660
[2019-03-26 16:36:04,875] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 76000, global step 1218802: learning rate 0.0000
[2019-03-26 16:36:05,089] A3C_AGENT_WORKER-Thread-11 INFO:Local step 76000, global step 1218899: loss 63.7842
[2019-03-26 16:36:05,091] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 76000, global step 1218900: learning rate 0.0000
[2019-03-26 16:36:05,585] A3C_AGENT_WORKER-Thread-10 INFO:Local step 77000, global step 1219121: loss 428.5773
[2019-03-26 16:36:05,588] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 77000, global step 1219121: learning rate 0.0000
[2019-03-26 16:36:06,465] A3C_AGENT_WORKER-Thread-13 INFO:Local step 76500, global step 1219525: loss 0.1226
[2019-03-26 16:36:06,467] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 76500, global step 1219526: learning rate 0.0000
[2019-03-26 16:36:06,564] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.0210881e-16 1.0000000e+00 1.5347361e-18 7.8361321e-17 1.3268655e-27], sum to 1.0000
[2019-03-26 16:36:06,572] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1485
[2019-03-26 16:36:06,578] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.7, 95.0, 1.0, 2.0, 0.8046205679501416, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1124557.586466148, 1124557.586466147, 245046.9223346355], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5889600.0000, 
sim time next is 5890200.0000, 
raw observation next is [25.68333333333333, 95.16666666666667, 1.0, 2.0, 0.6947619233359846, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 970946.2365854465, 970946.2365854458, 219717.5590062633], 
processed observation next is [1.0, 0.17391304347826086, 0.41627172195892564, 0.9516666666666667, 1.0, 1.0, 0.6322432811276923, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.26970728794040183, 0.2697072879404016, 0.3279366552332288], 
reward next is 0.6721, 
noisyNet noise sample is [array([-0.88942254], dtype=float32), 1.1241047]. 
=============================================
[2019-03-26 16:36:12,758] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.6345639e-11 1.0000000e+00 2.3384424e-12 2.7224164e-08 5.0438330e-18], sum to 1.0000
[2019-03-26 16:36:12,766] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0192
[2019-03-26 16:36:12,773] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2802218.175403484 W.
[2019-03-26 16:36:12,778] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.0, 77.66666666666667, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.641464537806089, 6.9112, 168.9089419581729, 2802218.175403484, 2284155.691595801, 474453.6636772135], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5995200.0000, 
sim time next is 5995800.0000, 
raw observation next is [30.15, 77.0, 1.0, 2.0, 0.899313266700667, 1.0, 1.0, 0.899313266700667, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2515371.93203655, 2515371.93203655, 471119.8298456098], 
processed observation next is [1.0, 0.391304347826087, 0.6279620853080569, 0.77, 1.0, 1.0, 0.878690682771888, 1.0, 0.5, 0.878690682771888, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6987144255657083, 0.6987144255657083, 0.7031639251427012], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6301619], dtype=float32), -2.4851716]. 
=============================================
[2019-03-26 16:36:13,645] A3C_AGENT_WORKER-Thread-14 INFO:Local step 76500, global step 1222767: loss 0.0952
[2019-03-26 16:36:13,647] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 76500, global step 1222767: learning rate 0.0000
[2019-03-26 16:36:14,680] A3C_AGENT_WORKER-Thread-2 INFO:Local step 76500, global step 1223230: loss 0.1836
[2019-03-26 16:36:14,683] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 76500, global step 1223231: learning rate 0.0000
[2019-03-26 16:36:16,841] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.3185951e-15 1.0000000e+00 9.2852740e-19 3.2915044e-16 1.6319479e-27], sum to 1.0000
[2019-03-26 16:36:16,850] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3000
[2019-03-26 16:36:16,853] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.18333333333333, 93.0, 1.0, 2.0, 0.7186882424336557, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1004399.64630749, 1004399.64630749, 224930.2274513614], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6059400.0000, 
sim time next is 6060000.0000, 
raw observation next is [26.16666666666667, 93.0, 1.0, 2.0, 0.6952603385547894, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 971643.1022969646, 971643.1022969646, 219824.931110276], 
processed observation next is [1.0, 0.13043478260869565, 0.4391785150078992, 0.93, 1.0, 1.0, 0.6328437813913125, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.26990086174915684, 0.26990086174915684, 0.32809691210488956], 
reward next is 0.6719, 
noisyNet noise sample is [array([-2.47966], dtype=float32), 0.5730986]. 
=============================================
[2019-03-26 16:36:16,869] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[66.79065]
 [66.71132]
 [66.62885]
 [66.4638 ]
 [66.45501]], R is [[66.92107391]
 [66.91614532]
 [66.89757538]
 [66.87821198]
 [66.84268951]].
[2019-03-26 16:36:18,609] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-26 16:36:18,611] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 16:36:18,612] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:36:18,613] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 16:36:18,613] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:36:18,615] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 16:36:18,616] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:36:18,617] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 16:36:18,618] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 16:36:18,618] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:36:18,618] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:36:18,640] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run50
[2019-03-26 16:36:18,661] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run50
[2019-03-26 16:36:18,663] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run50
[2019-03-26 16:36:18,704] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run50
[2019-03-26 16:36:18,733] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run50
[2019-03-26 16:36:19,977] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10387772], dtype=float32), 0.07548572]
[2019-03-26 16:36:19,978] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [20.68553208833334, 84.29898758, 1.0, 2.0, 0.2880251448112878, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 467284.1374560404, 467284.1374560404, 164743.0475203943]
[2019-03-26 16:36:19,979] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 16:36:19,983] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.9872962e-16 1.0000000e+00 1.1540989e-19 1.6149488e-19 3.2615976e-29], sampled 0.5841101583334649
[2019-03-26 16:36:33,060] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10387772], dtype=float32), 0.07548572]
[2019-03-26 16:36:33,061] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [24.88515229666667, 70.79165513, 1.0, 2.0, 0.3445118619406191, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 534860.6236192174, 534860.6236192181, 169514.8897195338]
[2019-03-26 16:36:33,062] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 16:36:33,065] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.5095726e-16 1.0000000e+00 3.6441897e-20 1.2927268e-19 6.2234910e-30], sampled 0.24078320471326387
[2019-03-26 16:36:35,516] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10387772], dtype=float32), 0.07548572]
[2019-03-26 16:36:35,516] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.83359279, 70.06159575, 1.0, 2.0, 0.4642415959788546, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 704725.6063871232, 704725.6063871239, 185040.424480232]
[2019-03-26 16:36:35,517] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 16:36:35,521] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.95312028e-16 1.00000000e+00 1.07596836e-19 7.96566038e-19
 3.75333112e-29], sampled 0.8366359003467856
[2019-03-26 16:36:49,731] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10387772], dtype=float32), 0.07548572]
[2019-03-26 16:36:49,733] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.58703426333334, 91.18452229666666, 1.0, 2.0, 0.5132403476359001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 717179.8902337747, 717179.8902337747, 185697.9433770522]
[2019-03-26 16:36:49,734] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 16:36:49,736] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [4.7021072e-17 1.0000000e+00 1.3393139e-20 2.0528177e-19 1.2266754e-30], sampled 0.47416689338477946
[2019-03-26 16:38:13,102] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7885.0228 3164325308.4136 1763.0000
[2019-03-26 16:38:13,490] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8000.0023 3007449296.9924 1762.0000
[2019-03-26 16:38:13,760] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.7897 2779322429.0906 933.0000
[2019-03-26 16:38:13,787] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8495.7454 2842330049.1281 1124.0000
[2019-03-26 16:38:13,957] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.2545 2927573791.5075 1338.0000
[2019-03-26 16:38:14,974] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1225000, evaluation results [1225000.0, 7885.022764544682, 3164325308.4136066, 1763.0, 8255.254530099177, 2927573791.5074577, 1338.0, 8659.789741210254, 2779322429.090567, 933.0, 8000.0023453748245, 3007449296.992351, 1762.0, 8495.745354041803, 2842330049.1280875, 1124.0]
[2019-03-26 16:38:15,110] A3C_AGENT_WORKER-Thread-15 INFO:Local step 76500, global step 1225067: loss 0.1601
[2019-03-26 16:38:15,113] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 76500, global step 1225067: learning rate 0.0000
[2019-03-26 16:38:15,655] A3C_AGENT_WORKER-Thread-9 INFO:Local step 77000, global step 1225320: loss 196.0026
[2019-03-26 16:38:15,661] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 77000, global step 1225320: learning rate 0.0000
[2019-03-26 16:38:15,739] A3C_AGENT_WORKER-Thread-3 INFO:Local step 76500, global step 1225357: loss 0.1434
[2019-03-26 16:38:15,741] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 76500, global step 1225357: learning rate 0.0000
[2019-03-26 16:38:17,249] A3C_AGENT_WORKER-Thread-22 INFO:Local step 76500, global step 1226064: loss 0.2054
[2019-03-26 16:38:17,252] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 76500, global step 1226065: learning rate 0.0000
[2019-03-26 16:38:17,852] A3C_AGENT_WORKER-Thread-21 INFO:Local step 76500, global step 1226339: loss 0.1089
[2019-03-26 16:38:17,853] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 76500, global step 1226339: learning rate 0.0000
[2019-03-26 16:38:17,994] A3C_AGENT_WORKER-Thread-18 INFO:Local step 76500, global step 1226406: loss 0.1483
[2019-03-26 16:38:17,996] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 76500, global step 1226406: learning rate 0.0000
[2019-03-26 16:38:18,585] A3C_AGENT_WORKER-Thread-20 INFO:Local step 76500, global step 1226679: loss 0.2104
[2019-03-26 16:38:18,588] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 76500, global step 1226681: learning rate 0.0000
[2019-03-26 16:38:18,632] A3C_AGENT_WORKER-Thread-17 INFO:Local step 76500, global step 1226702: loss 0.1154
[2019-03-26 16:38:18,635] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 76500, global step 1226702: learning rate 0.0000
[2019-03-26 16:38:18,792] A3C_AGENT_WORKER-Thread-12 INFO:Local step 76500, global step 1226778: loss 0.0664
[2019-03-26 16:38:18,795] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 76500, global step 1226779: learning rate 0.0000
[2019-03-26 16:38:18,831] A3C_AGENT_WORKER-Thread-16 INFO:Local step 76500, global step 1226794: loss 0.0960
[2019-03-26 16:38:18,835] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 76500, global step 1226795: learning rate 0.0000
[2019-03-26 16:38:18,861] A3C_AGENT_WORKER-Thread-19 INFO:Local step 76500, global step 1226807: loss 0.2160
[2019-03-26 16:38:18,864] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 76500, global step 1226808: learning rate 0.0000
[2019-03-26 16:38:18,939] A3C_AGENT_WORKER-Thread-11 INFO:Local step 76500, global step 1226846: loss 0.0921
[2019-03-26 16:38:18,941] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 76500, global step 1226847: learning rate 0.0000
[2019-03-26 16:38:19,485] A3C_AGENT_WORKER-Thread-10 INFO:Local step 77500, global step 1227099: loss 0.0080
[2019-03-26 16:38:19,486] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 77500, global step 1227100: learning rate 0.0000
[2019-03-26 16:38:20,028] A3C_AGENT_WORKER-Thread-13 INFO:Local step 77000, global step 1227350: loss 149.9267
[2019-03-26 16:38:20,031] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 77000, global step 1227350: learning rate 0.0000
[2019-03-26 16:38:20,740] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.2814906e-10 1.5262032e-02 2.9779526e-10 9.8473799e-01 8.6014311e-16], sum to 1.0000
[2019-03-26 16:38:20,754] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1478
[2019-03-26 16:38:20,759] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.2, 71.0, 1.0, 2.0, 0.8257608599833262, 1.0, 2.0, 0.8257608599833262, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2309456.339578586, 2309456.339578586, 432605.513446602], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6188400.0000, 
sim time next is 6189000.0000, 
raw observation next is [30.1, 71.33333333333334, 1.0, 2.0, 0.804651528650909, 1.0, 2.0, 0.804651528650909, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2250365.416539561, 2250365.416539561, 422140.4453303681], 
processed observation next is [1.0, 0.6521739130434783, 0.6255924170616115, 0.7133333333333334, 1.0, 1.0, 0.7646403959649507, 1.0, 1.0, 0.7646403959649507, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6251015045943225, 0.6251015045943225, 0.6300603661647285], 
reward next is 0.3699, 
noisyNet noise sample is [array([-1.0522789], dtype=float32), -1.5446967]. 
=============================================
[2019-03-26 16:38:20,779] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[43.559834]
 [42.427666]
 [41.6895  ]
 [40.801006]
 [40.063324]], R is [[44.54262924]
 [44.45152283]
 [44.34496307]
 [44.24167252]
 [44.15304947]].
[2019-03-26 16:38:23,052] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.9355219e-16 1.0000000e+00 7.6942945e-20 7.8999074e-18 4.7570879e-29], sum to 1.0000
[2019-03-26 16:38:23,059] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7381
[2019-03-26 16:38:23,067] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.43333333333333, 90.66666666666667, 1.0, 2.0, 0.521970848881068, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 729383.7039258432, 729383.7039258427, 187110.2387879196], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6226800.0000, 
sim time next is 6227400.0000, 
raw observation next is [26.41666666666666, 90.83333333333334, 1.0, 2.0, 0.5222044214293757, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 729710.2020953537, 729710.202095353, 187148.3660790444], 
processed observation next is [0.0, 0.043478260869565216, 0.4510268562401261, 0.9083333333333334, 1.0, 1.0, 0.4243426764209346, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2026972783598205, 0.2026972783598203, 0.2793259195209618], 
reward next is 0.7207, 
noisyNet noise sample is [array([-0.22758295], dtype=float32), 0.7254907]. 
=============================================
[2019-03-26 16:38:25,756] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.9334582e-10 9.9998093e-01 4.5358765e-11 1.9106803e-05 3.3647690e-16], sum to 1.0000
[2019-03-26 16:38:25,765] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0426
[2019-03-26 16:38:25,773] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2119940.508405899 W.
[2019-03-26 16:38:25,780] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.08333333333333, 73.66666666666667, 1.0, 2.0, 0.8749260601757459, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.981577507887976, 6.9112, 168.9124795445616, 2119940.508405899, 2070012.423087494, 428070.965652642], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6429000.0000, 
sim time next is 6429600.0000, 
raw observation next is [29.2, 73.0, 1.0, 2.0, 0.7461308583182963, 1.0, 1.0, 0.7461308583182963, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2086546.758129857, 2086546.758129857, 394493.7314483719], 
processed observation next is [1.0, 0.43478260869565216, 0.5829383886255924, 0.73, 1.0, 1.0, 0.6941335642389111, 1.0, 0.5, 0.6941335642389111, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.579596321702738, 0.579596321702738, 0.5887966141020476], 
reward next is 0.4112, 
noisyNet noise sample is [array([0.80160505], dtype=float32), 1.2734476]. 
=============================================
[2019-03-26 16:38:27,406] A3C_AGENT_WORKER-Thread-14 INFO:Local step 77000, global step 1230777: loss 167.0818
[2019-03-26 16:38:27,411] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 77000, global step 1230779: learning rate 0.0000
[2019-03-26 16:38:28,336] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.4971048e-17 1.0000000e+00 7.8065222e-20 3.6273266e-19 2.4992850e-29], sum to 1.0000
[2019-03-26 16:38:28,348] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7677
[2019-03-26 16:38:28,358] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.9, 80.5, 1.0, 2.0, 0.5284218663403171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 738401.2619552452, 738401.2619552445, 188168.6547549789], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6377400.0000, 
sim time next is 6378000.0000, 
raw observation next is [27.83333333333334, 81.0, 1.0, 2.0, 0.5292891957104711, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 739613.664593591, 739613.664593591, 188311.9368965194], 
processed observation next is [0.0, 0.8260869565217391, 0.5181674565560824, 0.81, 1.0, 1.0, 0.4328785490487603, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2054482401648864, 0.2054482401648864, 0.28106259238286474], 
reward next is 0.7189, 
noisyNet noise sample is [array([0.32494253], dtype=float32), 0.0019215017]. 
=============================================
[2019-03-26 16:38:28,372] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[74.75234 ]
 [74.74417 ]
 [74.73889 ]
 [74.718666]
 [74.696815]], R is [[74.7281723 ]
 [74.70004272]
 [74.6723175 ]
 [74.64468384]
 [74.61765289]].
[2019-03-26 16:38:28,386] A3C_AGENT_WORKER-Thread-2 INFO:Local step 77000, global step 1231230: loss 114.8965
[2019-03-26 16:38:28,388] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 77000, global step 1231230: learning rate 0.0000
[2019-03-26 16:38:32,446] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.3917535e-17 1.0000000e+00 2.1551541e-19 1.3817190e-18 1.5813624e-29], sum to 1.0000
[2019-03-26 16:38:32,455] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5091
[2019-03-26 16:38:32,459] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.1, 83.0, 1.0, 2.0, 0.5126055159279782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 716292.5047409645, 716292.5047409652, 185594.4002182946], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6394200.0000, 
sim time next is 6394800.0000, 
raw observation next is [27.1, 83.0, 1.0, 2.0, 0.5124905265649867, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 716131.769476908, 716131.769476908, 185575.9632581578], 
processed observation next is [1.0, 0.0, 0.4834123222748816, 0.83, 1.0, 1.0, 0.4126391886325141, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19892549152136335, 0.19892549152136335, 0.2769790496390415], 
reward next is 0.7230, 
noisyNet noise sample is [array([1.1038718], dtype=float32), -0.13476993]. 
=============================================
[2019-03-26 16:38:32,556] A3C_AGENT_WORKER-Thread-15 INFO:Local step 77000, global step 1233168: loss 188.8711
[2019-03-26 16:38:32,558] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 77000, global step 1233169: learning rate 0.0000
[2019-03-26 16:38:33,291] A3C_AGENT_WORKER-Thread-3 INFO:Local step 77000, global step 1233393: loss 114.2160
[2019-03-26 16:38:33,298] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 77000, global step 1233394: learning rate 0.0000
[2019-03-26 16:38:33,669] A3C_AGENT_WORKER-Thread-9 INFO:Local step 77500, global step 1233570: loss 0.0092
[2019-03-26 16:38:33,672] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 77500, global step 1233572: learning rate 0.0000
[2019-03-26 16:38:34,742] A3C_AGENT_WORKER-Thread-22 INFO:Local step 77000, global step 1234072: loss 187.4773
[2019-03-26 16:38:34,749] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 77000, global step 1234072: learning rate 0.0000
[2019-03-26 16:38:35,441] A3C_AGENT_WORKER-Thread-21 INFO:Local step 77000, global step 1234398: loss 159.0528
[2019-03-26 16:38:35,443] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 77000, global step 1234400: learning rate 0.0000
[2019-03-26 16:38:35,457] A3C_AGENT_WORKER-Thread-18 INFO:Local step 77000, global step 1234404: loss 137.9385
[2019-03-26 16:38:35,459] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 77000, global step 1234404: learning rate 0.0000
[2019-03-26 16:38:36,004] A3C_AGENT_WORKER-Thread-20 INFO:Local step 77000, global step 1234657: loss 173.3059
[2019-03-26 16:38:36,009] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 77000, global step 1234658: learning rate 0.0000
[2019-03-26 16:38:36,028] A3C_AGENT_WORKER-Thread-17 INFO:Local step 77000, global step 1234668: loss 123.8134
[2019-03-26 16:38:36,029] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 77000, global step 1234668: learning rate 0.0000
[2019-03-26 16:38:36,277] A3C_AGENT_WORKER-Thread-16 INFO:Local step 77000, global step 1234781: loss 68.1816
[2019-03-26 16:38:36,281] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 77000, global step 1234782: learning rate 0.0000
[2019-03-26 16:38:36,294] A3C_AGENT_WORKER-Thread-12 INFO:Local step 77000, global step 1234789: loss 128.9597
[2019-03-26 16:38:36,295] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 77000, global step 1234789: learning rate 0.0000
[2019-03-26 16:38:36,376] A3C_AGENT_WORKER-Thread-19 INFO:Local step 77000, global step 1234831: loss 161.9048
[2019-03-26 16:38:36,385] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 77000, global step 1234833: learning rate 0.0000
[2019-03-26 16:38:36,389] A3C_AGENT_WORKER-Thread-11 INFO:Local step 77000, global step 1234834: loss 194.9182
[2019-03-26 16:38:36,392] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 77000, global step 1234835: learning rate 0.0000
[2019-03-26 16:38:36,800] A3C_AGENT_WORKER-Thread-10 INFO:Local step 78000, global step 1235023: loss 16.3940
[2019-03-26 16:38:36,803] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 78000, global step 1235023: learning rate 0.0000
[2019-03-26 16:38:37,062] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.2842763e-16 1.0000000e+00 1.4685329e-19 4.0429227e-17 2.4507119e-28], sum to 1.0000
[2019-03-26 16:38:37,068] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3112
[2019-03-26 16:38:37,073] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.4, 84.33333333333334, 1.0, 2.0, 0.5257489392812211, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 734664.9002209393, 734664.9002209399, 187728.8035180014], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6474000.0000, 
sim time next is 6474600.0000, 
raw observation next is [27.35, 85.0, 1.0, 2.0, 0.5270079968073125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 736424.87716059, 736424.8771605907, 187935.9629441486], 
processed observation next is [1.0, 0.9565217391304348, 0.4952606635071091, 0.85, 1.0, 1.0, 0.4301301166353162, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20456246587794166, 0.20456246587794186, 0.28050143723007254], 
reward next is 0.7195, 
noisyNet noise sample is [array([0.6506895], dtype=float32), 0.10380239]. 
=============================================
[2019-03-26 16:38:37,407] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.0933056e-16 1.0000000e+00 3.9224641e-19 6.0347270e-16 2.6584981e-28], sum to 1.0000
[2019-03-26 16:38:37,415] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2250
[2019-03-26 16:38:37,421] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.3, 85.66666666666667, 1.0, 2.0, 0.5281113209620603, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 737967.1641867617, 737967.1641867611, 188117.8992521968], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6475200.0000, 
sim time next is 6475800.0000, 
raw observation next is [27.25, 86.33333333333333, 1.0, 2.0, 0.5293408073653753, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 739685.8103626199, 739685.8103626193, 188321.0480314826], 
processed observation next is [1.0, 0.9565217391304348, 0.490521327014218, 0.8633333333333333, 1.0, 1.0, 0.43294073176551234, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2054682806562833, 0.20546828065628314, 0.28107619109176507], 
reward next is 0.7189, 
noisyNet noise sample is [array([-0.38764825], dtype=float32), -0.08488613]. 
=============================================
[2019-03-26 16:38:37,763] A3C_AGENT_WORKER-Thread-13 INFO:Local step 77500, global step 1235461: loss 0.0077
[2019-03-26 16:38:37,764] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 77500, global step 1235461: learning rate 0.0000
[2019-03-26 16:38:40,142] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.8173303e-16 1.0000000e+00 5.1040254e-19 2.1186308e-16 6.5853953e-28], sum to 1.0000
[2019-03-26 16:38:40,153] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1437
[2019-03-26 16:38:40,162] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.73333333333333, 92.83333333333333, 1.0, 2.0, 0.5478756560373194, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 765595.215277056, 765595.2152770566, 191434.3419718563], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6583800.0000, 
sim time next is 6584400.0000, 
raw observation next is [25.7, 93.0, 1.0, 2.0, 0.5747600634431401, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 803177.384302047, 803177.3843020463, 196133.1431390801], 
processed observation next is [1.0, 0.21739130434782608, 0.4170616113744076, 0.93, 1.0, 1.0, 0.48766272703992786, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22310482897279083, 0.22310482897279063, 0.29273603453594044], 
reward next is 0.7073, 
noisyNet noise sample is [array([2.1674426], dtype=float32), -0.18488167]. 
=============================================
[2019-03-26 16:38:43,040] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.4269905e-14 1.0000000e+00 3.7119093e-15 4.1347272e-09 2.0355635e-24], sum to 1.0000
[2019-03-26 16:38:43,048] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7404
[2019-03-26 16:38:43,053] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.8, 67.0, 1.0, 2.0, 0.4688729788307622, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 655163.7272999878, 655163.7272999872, 178862.8796721483], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6717600.0000, 
sim time next is 6718200.0000, 
raw observation next is [28.66666666666666, 67.0, 1.0, 2.0, 0.4681830520642268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 655446.089847496, 655446.0898474953, 178922.3800539128], 
processed observation next is [1.0, 0.782608695652174, 0.5576619273301735, 0.67, 1.0, 1.0, 0.3592566892340082, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18206835829097112, 0.18206835829097093, 0.2670483284386758], 
reward next is 0.7330, 
noisyNet noise sample is [array([0.8514652], dtype=float32), -1.6057599]. 
=============================================
[2019-03-26 16:38:44,059] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.9805829e-14 1.0000000e+00 1.9151117e-16 5.5007404e-13 1.4800752e-24], sum to 1.0000
[2019-03-26 16:38:44,065] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7057
[2019-03-26 16:38:44,072] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1906747.598914323 W.
[2019-03-26 16:38:44,075] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.5, 82.0, 1.0, 2.0, 0.4545956120194626, 1.0, 1.0, 0.4545956120194626, 1.0, 1.0, 0.7770760437964779, 6.9112, 6.9112, 170.5573041426782, 1906747.598914323, 1906747.598914323, 383139.351758034], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6597000.0000, 
sim time next is 6597600.0000, 
raw observation next is [27.66666666666666, 81.0, 1.0, 2.0, 0.442293185584554, 1.0, 2.0, 0.442293185584554, 1.0, 2.0, 0.7570622679083344, 6.9112, 6.9112, 170.5573041426782, 1855101.852803709, 1855101.852803709, 375785.571011896], 
processed observation next is [1.0, 0.34782608695652173, 0.5102685624012636, 0.81, 1.0, 1.0, 0.3280640790175349, 1.0, 1.0, 0.3280640790175349, 1.0, 1.0, 0.7037344730589443, 0.0, 0.0, 0.8375144448122397, 0.5153060702232525, 0.5153060702232525, 0.5608739865849194], 
reward next is 0.4391, 
noisyNet noise sample is [array([0.52988243], dtype=float32), -0.13214937]. 
=============================================
[2019-03-26 16:38:44,747] A3C_AGENT_WORKER-Thread-14 INFO:Local step 77500, global step 1238862: loss 0.0039
[2019-03-26 16:38:44,748] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 77500, global step 1238862: learning rate 0.0000
[2019-03-26 16:38:45,332] A3C_AGENT_WORKER-Thread-2 INFO:Local step 77500, global step 1239172: loss 0.0026
[2019-03-26 16:38:45,334] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 77500, global step 1239174: learning rate 0.0000
[2019-03-26 16:38:46,822] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.726044e-17 1.000000e+00 2.466809e-19 5.467411e-18 2.926623e-29], sum to 1.0000
[2019-03-26 16:38:46,831] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3715
[2019-03-26 16:38:46,834] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.2, 79.0, 1.0, 2.0, 0.4527797744168931, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 647631.4518774964, 647631.451877497, 178451.0905255409], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7000200.0000, 
sim time next is 7000800.0000, 
raw observation next is [26.16666666666666, 79.33333333333333, 1.0, 2.0, 0.4525203593305189, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 646806.3773682071, 646806.3773682065, 178355.5033537819], 
processed observation next is [1.0, 0.0, 0.4391785150078987, 0.7933333333333333, 1.0, 1.0, 0.34038597509701074, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17966843815783531, 0.17966843815783515, 0.2662022438116148], 
reward next is 0.7338, 
noisyNet noise sample is [array([0.2672963], dtype=float32), 1.0546598]. 
=============================================
[2019-03-26 16:38:49,959] A3C_AGENT_WORKER-Thread-15 INFO:Local step 77500, global step 1241164: loss 0.0018
[2019-03-26 16:38:49,960] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 77500, global step 1241164: learning rate 0.0000
[2019-03-26 16:38:50,414] A3C_AGENT_WORKER-Thread-9 INFO:Local step 78000, global step 1241365: loss -42.1573
[2019-03-26 16:38:50,416] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 78000, global step 1241365: learning rate 0.0000
[2019-03-26 16:38:50,531] A3C_AGENT_WORKER-Thread-3 INFO:Local step 77500, global step 1241419: loss 0.0016
[2019-03-26 16:38:50,533] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 77500, global step 1241419: learning rate 0.0000
[2019-03-26 16:38:51,914] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.9578218e-16 1.0000000e+00 4.7740734e-19 1.3679419e-14 2.3614884e-28], sum to 1.0000
[2019-03-26 16:38:51,925] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2785
[2019-03-26 16:38:51,929] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.6, 67.0, 1.0, 2.0, 0.4229472398859402, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 616878.4965556355, 616878.4965556355, 175726.7397801907], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6723000.0000, 
sim time next is 6723600.0000, 
raw observation next is [27.46666666666667, 67.0, 1.0, 2.0, 0.4170665138822869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 611146.1835130262, 611146.1835130256, 175261.3542101542], 
processed observation next is [1.0, 0.8260869565217391, 0.500789889415482, 0.67, 1.0, 1.0, 0.2976704986533577, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1697628287536184, 0.16976282875361823, 0.2615841107614242], 
reward next is 0.7384, 
noisyNet noise sample is [array([0.34137395], dtype=float32), 0.13375942]. 
=============================================
[2019-03-26 16:38:52,086] A3C_AGENT_WORKER-Thread-22 INFO:Local step 77500, global step 1242120: loss 0.0018
[2019-03-26 16:38:52,087] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 77500, global step 1242120: learning rate 0.0000
[2019-03-26 16:38:52,703] A3C_AGENT_WORKER-Thread-21 INFO:Local step 77500, global step 1242392: loss 0.0023
[2019-03-26 16:38:52,705] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 77500, global step 1242392: learning rate 0.0000
[2019-03-26 16:38:53,020] A3C_AGENT_WORKER-Thread-18 INFO:Local step 77500, global step 1242536: loss 0.0032
[2019-03-26 16:38:53,022] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 77500, global step 1242536: learning rate 0.0000
[2019-03-26 16:38:53,263] A3C_AGENT_WORKER-Thread-20 INFO:Local step 77500, global step 1242646: loss 0.0042
[2019-03-26 16:38:53,266] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 77500, global step 1242647: learning rate 0.0000
[2019-03-26 16:38:53,388] A3C_AGENT_WORKER-Thread-17 INFO:Local step 77500, global step 1242701: loss 0.0048
[2019-03-26 16:38:53,392] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 77500, global step 1242701: learning rate 0.0000
[2019-03-26 16:38:53,642] A3C_AGENT_WORKER-Thread-16 INFO:Local step 77500, global step 1242813: loss 0.0049
[2019-03-26 16:38:53,647] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 77500, global step 1242814: learning rate 0.0000
[2019-03-26 16:38:53,790] A3C_AGENT_WORKER-Thread-11 INFO:Local step 77500, global step 1242880: loss 0.0050
[2019-03-26 16:38:53,791] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 77500, global step 1242880: learning rate 0.0000
[2019-03-26 16:38:53,818] A3C_AGENT_WORKER-Thread-19 INFO:Local step 77500, global step 1242894: loss 0.0054
[2019-03-26 16:38:53,821] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 77500, global step 1242894: learning rate 0.0000
[2019-03-26 16:38:53,887] A3C_AGENT_WORKER-Thread-12 INFO:Local step 77500, global step 1242920: loss 0.0055
[2019-03-26 16:38:53,889] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 77500, global step 1242920: learning rate 0.0000
[2019-03-26 16:38:53,982] A3C_AGENT_WORKER-Thread-10 INFO:Local step 78500, global step 1242969: loss 0.1514
[2019-03-26 16:38:53,985] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 78500, global step 1242970: learning rate 0.0000
[2019-03-26 16:38:54,234] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.1881693e-16 1.0000000e+00 3.8042074e-18 1.5675717e-15 5.0558692e-27], sum to 1.0000
[2019-03-26 16:38:54,240] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6820
[2019-03-26 16:38:54,244] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.6, 60.0, 1.0, 2.0, 0.90258380193979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1407133.517729242, 1407133.517729242, 290494.4822122137], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6775200.0000, 
sim time next is 6775800.0000, 
raw observation next is [26.83333333333334, 59.0, 1.0, 2.0, 0.8645799067913562, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1346991.566433011, 1346991.566433011, 278907.3893654358], 
processed observation next is [1.0, 0.43478260869565216, 0.4707740916271725, 0.59, 1.0, 1.0, 0.8368432611944051, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.37416432400916977, 0.37416432400916977, 0.41627968562005346], 
reward next is 0.5837, 
noisyNet noise sample is [array([-0.21933834], dtype=float32), -0.26785725]. 
=============================================
[2019-03-26 16:38:54,647] A3C_AGENT_WORKER-Thread-13 INFO:Local step 78000, global step 1243267: loss 14.8068
[2019-03-26 16:38:54,653] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 78000, global step 1243268: learning rate 0.0000
[2019-03-26 16:38:56,307] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.4956919e-15 1.0000000e+00 5.6705418e-19 4.9002688e-16 3.6952418e-28], sum to 1.0000
[2019-03-26 16:38:56,317] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6199
[2019-03-26 16:38:56,321] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.8, 56.0, 1.0, 2.0, 0.3208807839871262, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 506548.4462990309, 506548.4462990315, 167501.6409878361], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6810000.0000, 
sim time next is 6810600.0000, 
raw observation next is [26.65, 56.5, 1.0, 2.0, 0.3188316578683428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 503857.9567020479, 503857.9567020485, 167308.9110961396], 
processed observation next is [1.0, 0.8260869565217391, 0.462085308056872, 0.565, 1.0, 1.0, 0.17931525044378646, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13996054352834664, 0.1399605435283468, 0.24971479268080538], 
reward next is 0.7503, 
noisyNet noise sample is [array([1.7333145], dtype=float32), -0.6844987]. 
=============================================
[2019-03-26 16:38:56,698] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.4934643e-16 1.0000000e+00 3.6370514e-20 5.3150051e-19 9.6572394e-30], sum to 1.0000
[2019-03-26 16:38:56,705] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8045
[2019-03-26 16:38:56,710] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.25, 61.5, 1.0, 2.0, 0.4478497822007853, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 639732.0855265777, 639732.0855265782, 177625.4804319562], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6948600.0000, 
sim time next is 6949200.0000, 
raw observation next is [29.4, 61.0, 1.0, 2.0, 0.4492118888303161, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 640416.241973249, 640416.2419732496, 177662.1532866675], 
processed observation next is [0.0, 0.43478260869565216, 0.5924170616113744, 0.61, 1.0, 1.0, 0.33639986606062183, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17789340054812472, 0.17789340054812489, 0.2651673929651754], 
reward next is 0.7348, 
noisyNet noise sample is [array([0.52969486], dtype=float32), 0.16045672]. 
=============================================
[2019-03-26 16:38:58,894] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.7632676e-16 1.0000000e+00 3.9793107e-20 6.3287434e-20 1.0638693e-30], sum to 1.0000
[2019-03-26 16:38:58,904] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6303
[2019-03-26 16:38:58,912] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 82.0, 1.0, 2.0, 0.3373104225798131, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 526188.2841999789, 526188.2841999796, 168885.4356389139], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6840000.0000, 
sim time next is 6840600.0000, 
raw observation next is [23.08333333333334, 82.33333333333334, 1.0, 2.0, 0.3384398181616116, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 527583.3709242905, 527583.3709242905, 168987.0938982597], 
processed observation next is [0.0, 0.17391304347826086, 0.2930489731437602, 0.8233333333333335, 1.0, 1.0, 0.20293953995374894, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1465509363678585, 0.1465509363678585, 0.2522195431317309], 
reward next is 0.7478, 
noisyNet noise sample is [array([0.4009657], dtype=float32), -0.78969765]. 
=============================================
[2019-03-26 16:38:59,084] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.5079340e-16 1.0000000e+00 4.8048014e-20 1.3278734e-19 5.5937033e-30], sum to 1.0000
[2019-03-26 16:38:59,086] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2288
[2019-03-26 16:38:59,092] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.01666666666667, 83.66666666666666, 1.0, 2.0, 0.3419692216390004, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 531489.2801868112, 531489.2801868106, 169258.3029952292], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6843000.0000, 
sim time next is 6843600.0000, 
raw observation next is [23.0, 84.0, 1.0, 2.0, 0.3425703354289968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 532022.6739180152, 532022.6739180159, 169290.5005890343], 
processed observation next is [0.0, 0.21739130434782608, 0.28909952606635075, 0.84, 1.0, 1.0, 0.20791606678192384, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14778407608833755, 0.14778407608833774, 0.25267238893885713], 
reward next is 0.7473, 
noisyNet noise sample is [array([1.2970546], dtype=float32), 0.12662248]. 
=============================================
[2019-03-26 16:39:02,615] A3C_AGENT_WORKER-Thread-14 INFO:Local step 78000, global step 1246876: loss -26.4352
[2019-03-26 16:39:02,618] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 78000, global step 1246877: learning rate 0.0000
[2019-03-26 16:39:03,260] A3C_AGENT_WORKER-Thread-2 INFO:Local step 78000, global step 1247166: loss -54.8470
[2019-03-26 16:39:03,262] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 78000, global step 1247166: learning rate 0.0000
[2019-03-26 16:39:07,240] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.4616212e-16 1.0000000e+00 1.5285595e-19 1.9328268e-18 2.9235754e-30], sum to 1.0000
[2019-03-26 16:39:07,255] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6781
[2019-03-26 16:39:07,258] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.88333333333334, 63.16666666666667, 1.0, 2.0, 0.399229534664357, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 591997.600673984, 591997.6006739847, 173689.046321372], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6988200.0000, 
sim time next is 6988800.0000, 
raw observation next is [27.76666666666667, 64.33333333333334, 1.0, 2.0, 0.4067242851163128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 601176.8986169929, 601176.8986169929, 174480.027484207], 
processed observation next is [0.0, 0.9130434782608695, 0.515007898894155, 0.6433333333333334, 1.0, 1.0, 0.28520998206784676, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1669935829491647, 0.1669935829491647, 0.2604179514689657], 
reward next is 0.7396, 
noisyNet noise sample is [array([-0.4805761], dtype=float32), -0.2683029]. 
=============================================
[2019-03-26 16:39:07,695] A3C_AGENT_WORKER-Thread-15 INFO:Local step 78000, global step 1249178: loss 17.9452
[2019-03-26 16:39:07,699] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 78000, global step 1249178: learning rate 0.0000
[2019-03-26 16:39:08,246] A3C_AGENT_WORKER-Thread-3 INFO:Local step 78000, global step 1249428: loss -117.3296
[2019-03-26 16:39:08,250] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 78000, global step 1249429: learning rate 0.0000
[2019-03-26 16:39:08,468] A3C_AGENT_WORKER-Thread-9 INFO:Local step 78500, global step 1249534: loss 0.1276
[2019-03-26 16:39:08,471] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 78500, global step 1249534: learning rate 0.0000
[2019-03-26 16:39:09,498] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-26 16:39:09,498] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 16:39:09,499] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 16:39:09,499] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:39:09,501] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 16:39:09,502] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 16:39:09,502] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:39:09,504] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:39:09,505] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:39:09,504] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 16:39:09,510] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:39:09,543] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run51
[2019-03-26 16:39:09,565] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run51
[2019-03-26 16:39:09,567] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run51
[2019-03-26 16:39:09,586] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run51
[2019-03-26 16:39:09,629] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run51
[2019-03-26 16:39:32,618] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.1009252], dtype=float32), 0.0784016]
[2019-03-26 16:39:32,619] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [24.626076585, 77.16599694, 1.0, 2.0, 0.3782490592017724, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 576090.5624227447, 576090.5624227453, 172712.0309514317]
[2019-03-26 16:39:32,622] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 16:39:32,625] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.4924865e-16 1.0000000e+00 5.9402031e-20 6.2988325e-19 4.0655527e-30], sampled 0.3563341790648913
[2019-03-26 16:39:34,773] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.1009252], dtype=float32), 0.0784016]
[2019-03-26 16:39:34,775] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.83333333333334, 81.0, 1.0, 2.0, 0.4904203902853876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 703559.4342506217, 703559.4342506217, 184438.2952024887]
[2019-03-26 16:39:34,775] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 16:39:34,777] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.7820845e-16 1.0000000e+00 1.4924842e-19 1.5107693e-18 1.8243078e-29], sampled 0.7289480820694739
[2019-03-26 16:39:42,131] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.1009252], dtype=float32), 0.0784016]
[2019-03-26 16:39:42,133] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [23.6, 92.0, 1.0, 2.0, 0.410782559466611, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 606048.2071702421, 606048.2071702421, 174901.1016503148]
[2019-03-26 16:39:42,134] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 16:39:42,138] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.0424489e-16 1.0000000e+00 1.3752452e-19 6.0177984e-19 1.6373089e-29], sampled 0.7532400014603321
[2019-03-26 16:39:53,587] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.1009252], dtype=float32), 0.0784016]
[2019-03-26 16:39:53,589] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [21.0, 100.0, 1.0, 2.0, 0.3387240040536023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 526098.6374142431, 526098.6374142431, 168816.9948964921]
[2019-03-26 16:39:53,591] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:39:53,593] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.9907246e-16 1.0000000e+00 1.1980650e-19 3.6318264e-19 1.3439293e-29], sampled 0.2754263128032467
[2019-03-26 16:39:56,747] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.1009252], dtype=float32), 0.0784016]
[2019-03-26 16:39:56,748] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [24.16183716, 96.16165566, 1.0, 2.0, 0.4673711913282579, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 661358.5576797657, 661358.557679765, 179710.060863382]
[2019-03-26 16:39:56,748] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 16:39:56,754] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.2624917e-16 1.0000000e+00 1.6625746e-19 5.1501067e-18 1.6126258e-29], sampled 0.9798260171586147
[2019-03-26 16:40:02,594] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.1009252], dtype=float32), 0.0784016]
[2019-03-26 16:40:02,595] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [30.19709817, 71.09333791333333, 1.0, 2.0, 0.5317277529877558, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 743022.4269502746, 743022.4269502746, 188717.7213974983]
[2019-03-26 16:40:02,597] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 16:40:02,599] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [6.3416645e-15 1.0000000e+00 4.4074082e-17 1.0429596e-12 1.3941077e-26], sampled 0.369353493879123
[2019-03-26 16:40:09,613] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.1009252], dtype=float32), 0.0784016]
[2019-03-26 16:40:09,614] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.58333333333334, 74.0, 1.0, 2.0, 0.581282154685205, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 812294.9266826016, 812294.9266826016, 197310.4755393545]
[2019-03-26 16:40:09,615] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 16:40:09,619] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.2586220e-16 1.0000000e+00 3.4621303e-19 3.1305468e-17 6.2872777e-29], sampled 0.26822855421415026
[2019-03-26 16:40:23,331] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.1009252], dtype=float32), 0.0784016]
[2019-03-26 16:40:23,332] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.16666666666667, 73.33333333333334, 1.0, 2.0, 0.5169787342217955, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 722405.5264565716, 722405.5264565722, 186299.7380690597]
[2019-03-26 16:40:23,335] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:40:23,339] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.8087650e-16 1.0000000e+00 1.4402560e-18 3.7535174e-14 1.5050259e-29], sampled 0.8771864027247891
[2019-03-26 16:40:24,293] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.1009252], dtype=float32), 0.0784016]
[2019-03-26 16:40:24,296] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.66666666666666, 63.0, 1.0, 2.0, 0.5346565109051925, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 747116.4357692233, 747116.4357692233, 189205.0323169144]
[2019-03-26 16:40:24,298] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:40:24,302] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.07432678e-16 1.00000000e+00 1.04604776e-19 1.40810056e-18
 8.28779715e-30], sampled 0.6256882772459962
[2019-03-26 16:40:25,843] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.1009252], dtype=float32), 0.0784016]
[2019-03-26 16:40:25,845] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.0, 66.0, 1.0, 2.0, 0.5409040698056533, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 755849.733772564, 755849.7337725633, 190253.2434629186]
[2019-03-26 16:40:25,846] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:40:25,850] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.1272070e-16 1.0000000e+00 6.1165735e-20 1.7425968e-18 3.4938596e-30], sampled 0.17358758441520905
[2019-03-26 16:40:37,227] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.1009252], dtype=float32), 0.0784016]
[2019-03-26 16:40:37,230] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.35807142333334, 85.52336166, 1.0, 2.0, 0.7409632481195138, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1035545.162400652, 1035545.162400652, 229937.9629401986]
[2019-03-26 16:40:37,231] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 16:40:37,234] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.1196010e-16 1.0000000e+00 2.0378763e-19 1.1815139e-17 2.0540998e-29], sampled 0.5120063211081233
[2019-03-26 16:40:54,957] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.1009252], dtype=float32), 0.0784016]
[2019-03-26 16:40:54,958] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.8, 90.5, 1.0, 2.0, 0.4939772251370141, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 690253.6895862136, 690253.6895862136, 182658.1550271027]
[2019-03-26 16:40:54,958] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:40:54,961] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.9971088e-16 1.0000000e+00 1.7050687e-19 1.7420850e-18 2.0157075e-29], sampled 0.5747950051955028
[2019-03-26 16:40:56,177] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.1009252], dtype=float32), 0.0784016]
[2019-03-26 16:40:56,178] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.5, 79.33333333333334, 1.0, 2.0, 0.7887187485458809, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1102321.274875499, 1102321.274875499, 241163.3347037958]
[2019-03-26 16:40:56,179] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:40:56,181] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.5681438e-16 1.0000000e+00 3.1241371e-19 2.1663083e-17 3.7513844e-29], sampled 0.7186038958327368
[2019-03-26 16:41:03,383] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.1009252], dtype=float32), 0.0784016]
[2019-03-26 16:41:03,384] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [25.25624836, 85.64216934666666, 1.0, 2.0, 0.4806690822234055, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 682284.3891971563, 682284.389197157, 181986.4453762198]
[2019-03-26 16:41:03,386] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 16:41:03,388] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [8.4586047e-17 1.0000000e+00 5.3096526e-20 3.5146677e-18 3.9081339e-30], sampled 0.2647074305729752
[2019-03-26 16:41:04,660] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.5927 2779281048.9555 933.0000
[2019-03-26 16:41:04,928] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8505.6008 2841375179.4752 1107.0000
[2019-03-26 16:41:05,070] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8258.4672 2927259853.6513 1336.0000
[2019-03-26 16:41:05,169] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8006.5288 3006460255.8432 1741.0000
[2019-03-26 16:41:05,212] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7904.4233 3162214867.2101 1701.0000
[2019-03-26 16:41:06,228] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 1250000, evaluation results [1250000.0, 7904.423335762378, 3162214867.2100515, 1701.0, 8258.467174007417, 2927259853.6512628, 1336.0, 8660.592666056795, 2779281048.95547, 933.0, 8006.5288133069425, 3006460255.8431964, 1741.0, 8505.600827166141, 2841375179.4752226, 1107.0]
[2019-03-26 16:41:06,415] A3C_AGENT_WORKER-Thread-22 INFO:Local step 78000, global step 1250090: loss -10.0550
[2019-03-26 16:41:06,418] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 78000, global step 1250091: learning rate 0.0000
[2019-03-26 16:41:06,507] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.6185886e-13 1.0000000e+00 1.7933920e-14 7.2178763e-11 3.5682930e-22], sum to 1.0000
[2019-03-26 16:41:06,521] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7333
[2019-03-26 16:41:06,531] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1717814.266363557 W.
[2019-03-26 16:41:06,535] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.7, 63.0, 1.0, 2.0, 0.6111007628569611, 1.0, 2.0, 0.6111007628569611, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1717814.266363557, 1717814.266363557, 339498.0200613058], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7030800.0000, 
sim time next is 7031400.0000, 
raw observation next is [28.85, 62.33333333333333, 1.0, 2.0, 0.4376940948454341, 1.0, 2.0, 0.4376940948454341, 1.0, 1.0, 0.729907413528337, 6.9112, 6.9112, 170.5573041426782, 1835795.449341929, 1835795.449341929, 369873.6617325301], 
processed observation next is [1.0, 0.391304347826087, 0.5663507109004741, 0.6233333333333333, 1.0, 1.0, 0.32252300583787236, 1.0, 1.0, 0.32252300583787236, 1.0, 0.5, 0.6706187969857769, 0.0, 0.0, 0.8375144448122397, 0.5099431803727581, 0.5099431803727581, 0.552050241391836], 
reward next is 0.4479, 
noisyNet noise sample is [array([-0.41394904], dtype=float32), -0.015079672]. 
=============================================
[2019-03-26 16:41:06,942] A3C_AGENT_WORKER-Thread-21 INFO:Local step 78000, global step 1250331: loss -62.6555
[2019-03-26 16:41:06,944] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 78000, global step 1250332: learning rate 0.0000
[2019-03-26 16:41:07,260] A3C_AGENT_WORKER-Thread-18 INFO:Local step 78000, global step 1250478: loss -119.1184
[2019-03-26 16:41:07,263] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 78000, global step 1250478: learning rate 0.0000
[2019-03-26 16:41:07,590] A3C_AGENT_WORKER-Thread-20 INFO:Local step 78000, global step 1250628: loss -68.4037
[2019-03-26 16:41:07,593] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 78000, global step 1250629: learning rate 0.0000
[2019-03-26 16:41:07,731] A3C_AGENT_WORKER-Thread-17 INFO:Local step 78000, global step 1250695: loss 5.9867
[2019-03-26 16:41:07,734] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 78000, global step 1250697: learning rate 0.0000
[2019-03-26 16:41:07,874] A3C_AGENT_WORKER-Thread-11 INFO:Local step 78000, global step 1250760: loss -40.7399
[2019-03-26 16:41:07,880] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 78000, global step 1250761: learning rate 0.0000
[2019-03-26 16:41:07,996] A3C_AGENT_WORKER-Thread-16 INFO:Local step 78000, global step 1250817: loss -57.5998
[2019-03-26 16:41:07,997] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 78000, global step 1250818: learning rate 0.0000
[2019-03-26 16:41:08,102] A3C_AGENT_WORKER-Thread-19 INFO:Local step 78000, global step 1250867: loss 9.8855
[2019-03-26 16:41:08,103] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 78000, global step 1250867: learning rate 0.0000
[2019-03-26 16:41:08,121] A3C_AGENT_WORKER-Thread-12 INFO:Local step 78000, global step 1250876: loss -112.8455
[2019-03-26 16:41:08,125] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 78000, global step 1250876: learning rate 0.0000
[2019-03-26 16:41:08,231] A3C_AGENT_WORKER-Thread-10 INFO:Local step 79000, global step 1250924: loss -570.5324
[2019-03-26 16:41:08,233] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 79000, global step 1250925: learning rate 0.0000
[2019-03-26 16:41:09,179] A3C_AGENT_WORKER-Thread-13 INFO:Local step 78500, global step 1251369: loss 0.1313
[2019-03-26 16:41:09,182] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 78500, global step 1251370: learning rate 0.0000
[2019-03-26 16:41:13,199] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.7654753e-16 1.0000000e+00 3.3874951e-19 5.1644711e-17 1.4990277e-28], sum to 1.0000
[2019-03-26 16:41:13,208] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2317
[2019-03-26 16:41:13,213] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.05, 94.5, 1.0, 2.0, 0.3186843401584374, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 502615.6106929396, 502615.6106929396, 167194.6153053548], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7428600.0000, 
sim time next is 7429200.0000, 
raw observation next is [21.06666666666667, 94.33333333333334, 1.0, 2.0, 0.3181200173644202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 501764.1874958618, 501764.1874958611, 167131.322666799], 
processed observation next is [1.0, 1.0, 0.19747235387045833, 0.9433333333333335, 1.0, 1.0, 0.17845785224628938, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13937894097107273, 0.13937894097107253, 0.2494497353235806], 
reward next is 0.7506, 
noisyNet noise sample is [array([-0.17283101], dtype=float32), -0.4720885]. 
=============================================
[2019-03-26 16:41:16,796] A3C_AGENT_WORKER-Thread-14 INFO:Local step 78500, global step 1254903: loss 0.1091
[2019-03-26 16:41:16,802] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 78500, global step 1254905: learning rate 0.0000
[2019-03-26 16:41:17,195] A3C_AGENT_WORKER-Thread-2 INFO:Local step 78500, global step 1255089: loss 0.1076
[2019-03-26 16:41:17,198] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 78500, global step 1255089: learning rate 0.0000
[2019-03-26 16:41:21,559] A3C_AGENT_WORKER-Thread-15 INFO:Local step 78500, global step 1257124: loss 0.0746
[2019-03-26 16:41:21,562] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 78500, global step 1257126: learning rate 0.0000
[2019-03-26 16:41:22,037] A3C_AGENT_WORKER-Thread-9 INFO:Local step 79000, global step 1257340: loss -611.5226
[2019-03-26 16:41:22,042] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 79000, global step 1257340: learning rate 0.0000
[2019-03-26 16:41:22,198] A3C_AGENT_WORKER-Thread-3 INFO:Local step 78500, global step 1257417: loss 0.0773
[2019-03-26 16:41:22,202] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 78500, global step 1257419: learning rate 0.0000
[2019-03-26 16:41:23,601] A3C_AGENT_WORKER-Thread-22 INFO:Local step 78500, global step 1258061: loss 0.0719
[2019-03-26 16:41:23,602] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 78500, global step 1258061: learning rate 0.0000
[2019-03-26 16:41:23,659] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.8157631e-17 1.0000000e+00 2.6251931e-19 5.2454596e-17 1.4327243e-29], sum to 1.0000
[2019-03-26 16:41:23,668] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1025
[2019-03-26 16:41:23,674] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.7, 78.0, 1.0, 2.0, 0.3764203951355077, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 570445.5446265574, 570445.5446265574, 172133.074487773], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7340400.0000, 
sim time next is 7341000.0000, 
raw observation next is [24.71666666666667, 77.66666666666667, 1.0, 2.0, 0.3752182289529033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 569105.6076972077, 569105.6076972077, 172030.0300545673], 
processed observation next is [1.0, 1.0, 0.3704581358609796, 0.7766666666666667, 1.0, 1.0, 0.24725087825651, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15808489102700216, 0.15808489102700216, 0.25676123888741387], 
reward next is 0.7432, 
noisyNet noise sample is [array([0.5791131], dtype=float32), 0.37540978]. 
=============================================
[2019-03-26 16:41:23,693] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[74.28734 ]
 [74.258644]
 [74.25007 ]
 [74.23629 ]
 [74.22061 ]], R is [[74.32219696]
 [74.32206726]
 [74.32183838]
 [74.3215332 ]
 [74.32115173]].
[2019-03-26 16:41:23,787] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.8298887e-16 1.0000000e+00 2.6351276e-18 2.9944346e-16 7.5115539e-28], sum to 1.0000
[2019-03-26 16:41:23,795] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3249
[2019-03-26 16:41:23,803] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.91666666666667, 72.83333333333333, 1.0, 2.0, 0.5686544204305177, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 876473.0143512196, 876473.0143512203, 204890.7498148936], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7351800.0000, 
sim time next is 7352400.0000, 
raw observation next is [24.83333333333334, 73.66666666666667, 1.0, 2.0, 0.4606569003450017, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 709042.0398696957, 709042.0398696951, 185532.1371341849], 
processed observation next is [1.0, 0.08695652173913043, 0.3759873617693526, 0.7366666666666667, 1.0, 1.0, 0.350189036560243, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19695612218602657, 0.1969561221860264, 0.2769136375137088], 
reward next is 0.7231, 
noisyNet noise sample is [array([0.57559234], dtype=float32), -0.7268029]. 
=============================================
[2019-03-26 16:41:24,009] A3C_AGENT_WORKER-Thread-21 INFO:Local step 78500, global step 1258249: loss 0.0742
[2019-03-26 16:41:24,010] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 78500, global step 1258250: learning rate 0.0000
[2019-03-26 16:41:24,302] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.3450442e-16 1.0000000e+00 4.1844345e-19 5.1030962e-17 3.1009564e-29], sum to 1.0000
[2019-03-26 16:41:24,312] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0465
[2019-03-26 16:41:24,315] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.78333333333333, 76.33333333333333, 1.0, 2.0, 0.3702879380423064, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 563862.3652962283, 563862.3652962289, 171640.7311685271], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7343400.0000, 
sim time next is 7344000.0000, 
raw observation next is [24.8, 76.0, 1.0, 2.0, 0.3686010774412307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 561849.5578281358, 561849.5578281365, 171483.4946955817], 
processed observation next is [1.0, 0.0, 0.3744075829383887, 0.76, 1.0, 1.0, 0.23927840655569965, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15606932161892662, 0.1560693216189268, 0.2559455144710175], 
reward next is 0.7441, 
noisyNet noise sample is [array([0.26091695], dtype=float32), 0.49835688]. 
=============================================
[2019-03-26 16:41:24,329] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[74.37364 ]
 [74.36968 ]
 [74.354866]
 [74.337944]
 [74.325   ]], R is [[73.52644348]
 [73.53500366]
 [73.54330444]
 [73.55142212]
 [73.5593338 ]].
[2019-03-26 16:41:24,569] A3C_AGENT_WORKER-Thread-18 INFO:Local step 78500, global step 1258508: loss 0.0675
[2019-03-26 16:41:24,572] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 78500, global step 1258508: learning rate 0.0000
[2019-03-26 16:41:24,936] A3C_AGENT_WORKER-Thread-20 INFO:Local step 78500, global step 1258678: loss 0.0626
[2019-03-26 16:41:24,938] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 78500, global step 1258678: learning rate 0.0000
[2019-03-26 16:41:25,023] A3C_AGENT_WORKER-Thread-17 INFO:Local step 78500, global step 1258717: loss 0.0651
[2019-03-26 16:41:25,028] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 78500, global step 1258717: learning rate 0.0000
[2019-03-26 16:41:25,177] A3C_AGENT_WORKER-Thread-11 INFO:Local step 78500, global step 1258788: loss 0.0646
[2019-03-26 16:41:25,180] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 78500, global step 1258789: learning rate 0.0000
[2019-03-26 16:41:25,274] A3C_AGENT_WORKER-Thread-16 INFO:Local step 78500, global step 1258835: loss 0.0597
[2019-03-26 16:41:25,278] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 78500, global step 1258835: learning rate 0.0000
[2019-03-26 16:41:25,394] A3C_AGENT_WORKER-Thread-19 INFO:Local step 78500, global step 1258886: loss 0.0624
[2019-03-26 16:41:25,396] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 78500, global step 1258887: learning rate 0.0000
[2019-03-26 16:41:25,499] A3C_AGENT_WORKER-Thread-12 INFO:Local step 78500, global step 1258935: loss 0.0589
[2019-03-26 16:41:25,501] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 78500, global step 1258935: learning rate 0.0000
[2019-03-26 16:41:26,206] A3C_AGENT_WORKER-Thread-13 INFO:Local step 79000, global step 1259270: loss -373.1405
[2019-03-26 16:41:26,209] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 79000, global step 1259272: learning rate 0.0000
[2019-03-26 16:41:26,496] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:41:26,496] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:41:26,576] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run7
[2019-03-26 16:41:29,348] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.9617317e-16 1.0000000e+00 7.2791442e-20 9.4287565e-20 8.1945188e-31], sum to 1.0000
[2019-03-26 16:41:29,358] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6428
[2019-03-26 16:41:29,362] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.53333333333333, 95.0, 1.0, 2.0, 0.3345162116253118, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 520405.6269740293, 520405.6269740287, 168389.496491003], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7456800.0000, 
sim time next is 7457400.0000, 
raw observation next is [21.55, 95.0, 1.0, 2.0, 0.3350454139268377, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 520993.1127877971, 520993.1127877978, 168429.1792240475], 
processed observation next is [0.0, 0.30434782608695654, 0.22037914691943136, 0.95, 1.0, 1.0, 0.19884989629739477, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14472030910772143, 0.14472030910772163, 0.25138683466275746], 
reward next is 0.7486, 
noisyNet noise sample is [array([-0.7958877], dtype=float32), 0.36481294]. 
=============================================
[2019-03-26 16:41:31,221] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.8214549e-16 1.0000000e+00 6.3876082e-20 9.2851980e-20 3.6866054e-31], sum to 1.0000
[2019-03-26 16:41:31,232] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2523
[2019-03-26 16:41:31,237] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.9, 85.66666666666667, 1.0, 2.0, 0.3782545191831634, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 568419.550927521, 568419.550927521, 171805.3013457666], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7472400.0000, 
sim time next is 7473000.0000, 
raw observation next is [24.0, 85.33333333333334, 1.0, 2.0, 0.3808493784763535, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 571294.8606072556, 571294.8606072556, 172026.3435429578], 
processed observation next is [0.0, 0.4782608695652174, 0.3364928909952607, 0.8533333333333334, 1.0, 1.0, 0.25403539575464273, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15869301683534878, 0.15869301683534878, 0.2567557366312803], 
reward next is 0.7432, 
noisyNet noise sample is [array([1.1572413], dtype=float32), 0.557829]. 
=============================================
[2019-03-26 16:41:31,254] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[76.83569 ]
 [76.81468 ]
 [76.793526]
 [76.7769  ]
 [76.74129 ]], R is [[76.82364655]
 [76.79898834]
 [76.77477264]
 [76.75101471]
 [76.72769928]].
[2019-03-26 16:41:33,652] A3C_AGENT_WORKER-Thread-14 INFO:Local step 79000, global step 1262843: loss -146.4121
[2019-03-26 16:41:33,654] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 79000, global step 1262843: learning rate 0.0000
[2019-03-26 16:41:34,112] A3C_AGENT_WORKER-Thread-2 INFO:Local step 79000, global step 1263055: loss -233.5633
[2019-03-26 16:41:34,115] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 79000, global step 1263055: learning rate 0.0000
[2019-03-26 16:41:34,753] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.9153261e-14 1.0000000e+00 5.3976624e-16 1.2952538e-12 7.6245639e-24], sum to 1.0000
[2019-03-26 16:41:34,762] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6128
[2019-03-26 16:41:34,773] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1787247.823966292 W.
[2019-03-26 16:41:34,777] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.2, 79.5, 1.0, 2.0, 0.639193374376579, 1.0, 1.0, 0.639193374376579, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 1787247.823966292, 1787247.823966291, 349177.1550947429], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7807800.0000, 
sim time next is 7808400.0000, 
raw observation next is [28.3, 79.0, 1.0, 2.0, 0.4045006003483426, 1.0, 2.0, 0.4045006003483426, 1.0, 1.0, 0.6946835201418821, 6.9112, 6.9112, 170.5573041426782, 1696463.656148819, 1696463.656148819, 354284.8543304956], 
processed observation next is [1.0, 0.391304347826087, 0.5402843601895735, 0.79, 1.0, 1.0, 0.2825308437931839, 1.0, 1.0, 0.2825308437931839, 1.0, 0.5, 0.6276628294413195, 0.0, 0.0, 0.8375144448122397, 0.47123990448578307, 0.47123990448578307, 0.5287833646723815], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.5938053], dtype=float32), 1.6266398]. 
=============================================
[2019-03-26 16:41:37,221] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.9978179e-16 1.0000000e+00 2.8966162e-19 2.4587493e-18 1.5054788e-30], sum to 1.0000
[2019-03-26 16:41:37,229] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0986
[2019-03-26 16:41:37,234] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.4, 90.0, 1.0, 2.0, 0.4827560712536802, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 674568.9540967228, 674568.9540967228, 180938.2768481406], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7596000.0000, 
sim time next is 7596600.0000, 
raw observation next is [25.33333333333334, 90.5, 1.0, 2.0, 0.4825455214436217, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 674274.6534147309, 674274.6534147315, 180906.3853513518], 
processed observation next is [0.0, 0.9565217391304348, 0.3996840442338076, 0.905, 1.0, 1.0, 0.37656086920918275, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18729851483742527, 0.1872985148374254, 0.27000953037515196], 
reward next is 0.7300, 
noisyNet noise sample is [array([-1.5197954], dtype=float32), 2.2270083]. 
=============================================
[2019-03-26 16:41:38,150] A3C_AGENT_WORKER-Thread-15 INFO:Local step 79000, global step 1265046: loss -428.5179
[2019-03-26 16:41:38,152] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 79000, global step 1265046: learning rate 0.0000
[2019-03-26 16:41:38,594] A3C_AGENT_WORKER-Thread-3 INFO:Local step 79000, global step 1265340: loss -361.3566
[2019-03-26 16:41:38,597] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 79000, global step 1265341: learning rate 0.0000
[2019-03-26 16:41:39,650] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:41:39,651] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:41:39,726] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run7
[2019-03-26 16:41:39,824] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.0762551e-09 9.8923278e-01 1.1181904e-08 1.0767230e-02 9.4578974e-14], sum to 1.0000
[2019-03-26 16:41:39,828] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8320
[2019-03-26 16:41:39,832] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1932457.732776205 W.
[2019-03-26 16:41:39,838] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.93333333333333, 75.33333333333334, 1.0, 2.0, 0.7409670404020064, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.98516773900588, 6.9112, 168.912515585142, 1932457.732776205, 1879982.609932166, 394543.7451587517], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7899000.0000, 
sim time next is 7899600.0000, 
raw observation next is [29.06666666666667, 74.66666666666667, 1.0, 2.0, 0.7395985145984157, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.984021566842385, 6.9112, 168.9124629726033, 1930542.579597602, 1878880.604703543, 394269.260963012], 
processed observation next is [1.0, 0.43478260869565216, 0.5766192733017379, 0.7466666666666667, 1.0, 1.0, 0.6862632706005009, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.007282156684238483, 0.0, 0.829437521655626, 0.5362618276660005, 0.5219112790843174, 0.5884615835268836], 
reward next is 0.0474, 
noisyNet noise sample is [array([0.04832183], dtype=float32), 0.8204647]. 
=============================================
[2019-03-26 16:41:39,925] A3C_AGENT_WORKER-Thread-22 INFO:Local step 79000, global step 1265951: loss -182.7202
[2019-03-26 16:41:39,926] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 79000, global step 1265951: learning rate 0.0000
[2019-03-26 16:41:40,090] A3C_AGENT_WORKER-Thread-21 INFO:Local step 79000, global step 1266040: loss -363.5175
[2019-03-26 16:41:40,092] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 79000, global step 1266040: learning rate 0.0000
[2019-03-26 16:41:40,596] A3C_AGENT_WORKER-Thread-18 INFO:Local step 79000, global step 1266332: loss -341.5486
[2019-03-26 16:41:40,597] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 79000, global step 1266332: learning rate 0.0000
[2019-03-26 16:41:40,883] A3C_AGENT_WORKER-Thread-17 INFO:Local step 79000, global step 1266502: loss -219.3688
[2019-03-26 16:41:40,885] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 79000, global step 1266503: learning rate 0.0000
[2019-03-26 16:41:40,903] A3C_AGENT_WORKER-Thread-20 INFO:Local step 79000, global step 1266513: loss -621.4474
[2019-03-26 16:41:40,906] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 79000, global step 1266514: learning rate 0.0000
[2019-03-26 16:41:40,955] A3C_AGENT_WORKER-Thread-11 INFO:Local step 79000, global step 1266532: loss -305.2924
[2019-03-26 16:41:40,957] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 79000, global step 1266533: learning rate 0.0000
[2019-03-26 16:41:40,987] A3C_AGENT_WORKER-Thread-16 INFO:Local step 79000, global step 1266548: loss -299.5872
[2019-03-26 16:41:40,990] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 79000, global step 1266548: learning rate 0.0000
[2019-03-26 16:41:41,301] A3C_AGENT_WORKER-Thread-12 INFO:Local step 79000, global step 1266690: loss -571.2427
[2019-03-26 16:41:41,304] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 79000, global step 1266691: learning rate 0.0000
[2019-03-26 16:41:41,309] A3C_AGENT_WORKER-Thread-19 INFO:Local step 79000, global step 1266693: loss -321.4431
[2019-03-26 16:41:41,311] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 79000, global step 1266694: learning rate 0.0000
[2019-03-26 16:41:43,393] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:41:43,394] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:41:43,465] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run7
[2019-03-26 16:41:43,749] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.1993927e-17 1.0000000e+00 7.0576684e-19 1.2276263e-14 1.3700176e-29], sum to 1.0000
[2019-03-26 16:41:43,756] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9959
[2019-03-26 16:41:43,759] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.36666666666667, 83.66666666666667, 1.0, 2.0, 0.5151455530457196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 719843.044020643, 719843.044020643, 186003.5474558465], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7761000.0000, 
sim time next is 7761600.0000, 
raw observation next is [27.2, 85.0, 1.0, 2.0, 0.5165411808302021, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 721793.8990162755, 721793.899016275, 186228.7630499495], 
processed observation next is [1.0, 0.8695652173913043, 0.4881516587677725, 0.85, 1.0, 1.0, 0.41751949497614704, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20049830528229876, 0.2004983052822986, 0.2779533776864918], 
reward next is 0.7220, 
noisyNet noise sample is [array([-0.55080414], dtype=float32), -0.87974167]. 
=============================================
[2019-03-26 16:41:50,794] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:41:50,794] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:41:50,865] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run7
[2019-03-26 16:41:51,304] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:41:51,305] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:41:51,373] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run7
[2019-03-26 16:41:53,965] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.5821447e-14 1.0000000e+00 2.4645459e-16 3.9895387e-13 1.4219200e-24], sum to 1.0000
[2019-03-26 16:41:53,975] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4110
[2019-03-26 16:41:53,982] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1968746.647557265 W.
[2019-03-26 16:41:53,987] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.7, 80.5, 1.0, 2.0, 0.4693634940104383, 1.0, 1.0, 0.4693634940104383, 1.0, 1.0, 0.8022767838473979, 6.9112, 6.9112, 170.5573041426782, 1968746.647557265, 1968746.647557265, 392426.6513499136], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7893000.0000, 
sim time next is 7893600.0000, 
raw observation next is [27.83333333333334, 80.0, 1.0, 2.0, 0.45315124900771, 1.0, 2.0, 0.45315124900771, 1.0, 2.0, 0.7760241790166063, 6.9112, 6.9112, 170.5573041426782, 1900684.015231694, 1900684.015231694, 382480.0463863561], 
processed observation next is [1.0, 0.34782608695652173, 0.5181674565560824, 0.8, 1.0, 1.0, 0.3411460831418192, 1.0, 1.0, 0.3411460831418192, 1.0, 1.0, 0.7268587548983003, 0.0, 0.0, 0.8375144448122397, 0.5279677820088039, 0.5279677820088039, 0.5708657408751584], 
reward next is 0.4291, 
noisyNet noise sample is [array([0.80850536], dtype=float32), -0.3026063]. 
=============================================
[2019-03-26 16:41:54,753] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:41:54,754] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:41:54,822] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run7
[2019-03-26 16:41:55,332] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:41:55,333] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:41:55,397] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run7
[2019-03-26 16:41:56,746] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:41:56,747] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:41:56,773] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:41:56,773] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:41:56,817] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run7
[2019-03-26 16:41:56,880] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run7
[2019-03-26 16:41:57,207] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:41:57,207] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:41:57,261] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run7
[2019-03-26 16:41:57,304] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:41:57,304] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:41:57,356] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run7
[2019-03-26 16:41:57,381] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:41:57,383] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:41:57,391] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:41:57,393] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:41:57,392] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:41:57,396] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:41:57,438] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run7
[2019-03-26 16:41:57,467] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:41:57,470] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:41:57,475] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run7
[2019-03-26 16:41:57,505] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run7
[2019-03-26 16:41:57,539] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run7
[2019-03-26 16:41:57,567] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:41:57,568] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:41:57,580] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run7
[2019-03-26 16:41:58,467] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-26 16:41:58,468] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 16:41:58,469] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:41:58,470] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 16:41:58,471] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 16:41:58,471] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:41:58,471] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:41:58,472] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 16:41:58,473] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:41:58,472] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 16:41:58,475] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:41:58,494] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run52
[2019-03-26 16:41:58,511] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run52
[2019-03-26 16:41:58,530] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run52
[2019-03-26 16:41:58,551] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run52
[2019-03-26 16:41:58,553] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run52
[2019-03-26 16:42:35,032] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.09932698], dtype=float32), 0.08044742]
[2019-03-26 16:42:35,035] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [25.46666666666667, 80.0, 1.0, 2.0, 0.619072964369631, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 905319.4735754896, 905319.4735754896, 209495.8625768595]
[2019-03-26 16:42:35,036] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:42:35,038] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.2276445e-16 1.0000000e+00 1.3392328e-19 7.8454261e-19 1.2419739e-29], sampled 0.8095721010629726
[2019-03-26 16:42:35,202] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.09932698], dtype=float32), 0.08044742]
[2019-03-26 16:42:35,203] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.90000000000001, 73.33333333333334, 1.0, 2.0, 0.5193391340725887, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 748101.5960767273, 748101.5960767273, 189526.5221361314]
[2019-03-26 16:42:35,204] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:42:35,207] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.8478322e-16 1.0000000e+00 1.5182966e-19 3.1978108e-18 1.3674697e-29], sampled 0.9316227189973018
[2019-03-26 16:42:39,758] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.09932698], dtype=float32), 0.08044742]
[2019-03-26 16:42:39,759] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.98333333333333, 89.83333333333333, 1.0, 2.0, 0.8326230106367334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1163715.938506755, 1163715.938506755, 252076.434983796]
[2019-03-26 16:42:39,759] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:42:39,761] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.26867981e-16 1.00000000e+00 2.42465818e-19 1.03142755e-17
 2.88609028e-29], sampled 0.022610624910466504
[2019-03-26 16:43:35,163] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.09932698], dtype=float32), 0.08044742]
[2019-03-26 16:43:35,165] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.2, 77.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.790160512010134, 6.9112, 168.9085059135791, 2077730.477419473, 1454182.068688675, 311351.6601434972]
[2019-03-26 16:43:35,166] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:43:35,167] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.6330656e-12 1.0000000e+00 1.8905586e-13 2.6315547e-08 1.9303629e-21], sampled 0.7041168602326522
[2019-03-26 16:43:35,168] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2077730.477419473 W.
[2019-03-26 16:43:41,009] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.09932698], dtype=float32), 0.08044742]
[2019-03-26 16:43:41,010] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [22.430717885, 83.57282772, 1.0, 2.0, 0.4042529658377738, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 641432.6315279538, 641432.6315279538, 178878.0545799623]
[2019-03-26 16:43:41,011] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 16:43:41,016] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.3740396e-16 1.0000000e+00 1.5602901e-19 1.2961345e-18 1.3907327e-29], sampled 0.13059594961579502
[2019-03-26 16:43:51,360] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.09932698], dtype=float32), 0.08044742]
[2019-03-26 16:43:51,362] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.4, 88.66666666666667, 1.0, 2.0, 0.5131699739753436, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 717081.5199289086, 717081.5199289093, 185685.245727635]
[2019-03-26 16:43:51,363] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:43:51,366] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.2284663e-17 1.0000000e+00 7.3743100e-20 3.3191393e-18 4.3617348e-30], sampled 0.6190802337959301
[2019-03-26 16:43:53,709] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8003.9608 3006460625.4641 1737.0000
[2019-03-26 16:43:53,764] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7912.4205 3162076449.5956 1689.0000
[2019-03-26 16:43:53,981] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8504.5073 2841944193.8002 1117.0000
[2019-03-26 16:43:54,101] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8258.7670 2927229296.1421 1334.0000
[2019-03-26 16:43:54,132] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.9158 2779082306.2839 931.0000
[2019-03-26 16:43:55,146] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1275000, evaluation results [1275000.0, 7912.420474372286, 3162076449.5955596, 1689.0, 8258.767013603008, 2927229296.1420856, 1334.0, 8659.915808927808, 2779082306.2839, 931.0, 8003.960762671948, 3006460625.4640865, 1737.0, 8504.50732488689, 2841944193.8002386, 1117.0]
[2019-03-26 16:43:55,823] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.2331824e-12 1.0000000e+00 1.4364674e-14 1.6593863e-13 1.9360920e-22], sum to 1.0000
[2019-03-26 16:43:55,831] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4487
[2019-03-26 16:43:55,834] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.06666666666667, 85.0, 1.0, 2.0, 0.3192476490435595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 515866.1548263548, 515866.1548263548, 168264.9272104955], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 12000.0000, 
sim time next is 12600.0000, 
raw observation next is [21.1, 85.0, 1.0, 2.0, 0.320415590663457, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 517453.0357388292, 517453.0357388292, 168388.7975307324], 
processed observation next is [1.0, 0.13043478260869565, 0.1990521327014219, 0.85, 1.0, 1.0, 0.1812236032089843, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14373695437189699, 0.14373695437189699, 0.2513265634787051], 
reward next is 0.7487, 
noisyNet noise sample is [array([-0.21491553], dtype=float32), 0.35257083]. 
=============================================
[2019-03-26 16:44:04,107] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.4763024e-17 1.0000000e+00 2.2639463e-20 2.7153108e-20 2.3512926e-30], sum to 1.0000
[2019-03-26 16:44:04,115] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9462
[2019-03-26 16:44:04,123] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.9, 96.0, 1.0, 2.0, 0.2869226459956143, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 462157.2970068382, 462157.2970068382, 164420.2911017553], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 184200.0000, 
sim time next is 184800.0000, 
raw observation next is [19.9, 96.0, 1.0, 2.0, 0.2866967877716635, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 461796.446713019, 461796.446713019, 164395.6499334722], 
processed observation next is [0.0, 0.13043478260869565, 0.14218009478672985, 0.96, 1.0, 1.0, 0.14059853948393194, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1282767907536164, 0.1282767907536164, 0.24536664169174954], 
reward next is 0.7546, 
noisyNet noise sample is [array([-0.19006605], dtype=float32), 0.251566]. 
=============================================
[2019-03-26 16:44:09,219] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.5007002e-17 1.0000000e+00 1.5285879e-20 5.6398622e-20 5.0910825e-31], sum to 1.0000
[2019-03-26 16:44:09,231] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8359
[2019-03-26 16:44:09,236] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.93333333333333, 89.83333333333333, 1.0, 2.0, 0.2929882873432826, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 469089.0690366681, 469089.0690366681, 164883.7680691813], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 247800.0000, 
sim time next is 248400.0000, 
raw observation next is [20.9, 90.0, 1.0, 2.0, 0.2924557214353884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 468358.5032334123, 468358.5032334116, 164834.0716436225], 
processed observation next is [0.0, 0.9130434782608695, 0.1895734597156398, 0.9, 1.0, 1.0, 0.14753701377757636, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13009958423150342, 0.13009958423150322, 0.2460210024531679], 
reward next is 0.7540, 
noisyNet noise sample is [array([0.44760495], dtype=float32), 1.7127007]. 
=============================================
[2019-03-26 16:44:14,407] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.2453512e-15 1.0000000e+00 4.1517601e-19 5.0761841e-18 4.2903649e-29], sum to 1.0000
[2019-03-26 16:44:14,419] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3999
[2019-03-26 16:44:14,424] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.68333333333333, 83.16666666666667, 1.0, 2.0, 0.2306033050243999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 381086.0892401392, 381086.0892401392, 158990.3042123528], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 445800.0000, 
sim time next is 446400.0000, 
raw observation next is [19.7, 83.0, 1.0, 2.0, 0.2300859453973368, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 380247.7930478861, 380247.7930478854, 158941.7683913859], 
processed observation next is [1.0, 0.17391304347826086, 0.1327014218009479, 0.83, 1.0, 1.0, 0.07239270529799612, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.10562438695774615, 0.10562438695774595, 0.23722651998714314], 
reward next is 0.7628, 
noisyNet noise sample is [array([1.4261905], dtype=float32), 1.8220688]. 
=============================================
[2019-03-26 16:44:15,311] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.5611630e-16 1.0000000e+00 9.4350578e-19 2.7537226e-17 6.8034083e-29], sum to 1.0000
[2019-03-26 16:44:15,323] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3680
[2019-03-26 16:44:15,328] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.65, 83.5, 1.0, 2.0, 0.231066934285603, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 381818.5767483634, 381818.5767483634, 159035.0682385594], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 444600.0000, 
sim time next is 445200.0000, 
raw observation next is [19.66666666666667, 83.33333333333333, 1.0, 2.0, 0.230959230019219, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 381657.6106084033, 381657.6106084033, 159024.0760276225], 
processed observation next is [1.0, 0.13043478260869565, 0.1311216429699845, 0.8333333333333333, 1.0, 1.0, 0.07344485544484217, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1060160029467787, 0.1060160029467787, 0.23734936720540672], 
reward next is 0.7627, 
noisyNet noise sample is [array([1.1885467], dtype=float32), 1.035008]. 
=============================================
[2019-03-26 16:44:15,591] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.3173426e-16 1.0000000e+00 8.6352047e-19 1.3769466e-18 1.3047647e-28], sum to 1.0000
[2019-03-26 16:44:15,604] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2989
[2019-03-26 16:44:15,613] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.05, 89.5, 1.0, 2.0, 0.2566018689352981, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 417774.758054382, 417774.758054382, 161494.9195042748], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 361800.0000, 
sim time next is 362400.0000, 
raw observation next is [20.03333333333333, 89.66666666666667, 1.0, 2.0, 0.2571424099729964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 418631.7409646709, 418631.7409646703, 161548.2531185804], 
processed observation next is [1.0, 0.17391304347826086, 0.14849921011058448, 0.8966666666666667, 1.0, 1.0, 0.1049908553891523, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11628659471240858, 0.11628659471240842, 0.24111679569937375], 
reward next is 0.7589, 
noisyNet noise sample is [array([0.6831578], dtype=float32), -1.1653656]. 
=============================================
[2019-03-26 16:44:18,256] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.8078318e-16 1.0000000e+00 5.7726417e-19 1.2822724e-16 7.7563512e-29], sum to 1.0000
[2019-03-26 16:44:18,258] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6968
[2019-03-26 16:44:18,260] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.43333333333333, 59.83333333333334, 1.0, 2.0, 0.244318525826496, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 402209.6093739917, 402209.6093739923, 160344.6921515403], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 496200.0000, 
sim time next is 496800.0000, 
raw observation next is [23.2, 61.0, 1.0, 2.0, 0.2450129090338873, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 403502.7665618007, 403502.7665618007, 160408.1908090874], 
processed observation next is [1.0, 0.782608695652174, 0.29857819905213273, 0.61, 1.0, 1.0, 0.0903769988360088, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.11208410182272241, 0.11208410182272241, 0.239415210162817], 
reward next is 0.7606, 
noisyNet noise sample is [array([-0.10368233], dtype=float32), -0.3889807]. 
=============================================
[2019-03-26 16:44:25,836] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.8275450e-16 1.0000000e+00 1.1064372e-18 7.7775531e-17 2.5314592e-28], sum to 1.0000
[2019-03-26 16:44:25,838] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3368
[2019-03-26 16:44:25,841] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.98333333333333, 58.5, 1.0, 2.0, 0.6424025593383613, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1053425.796239427, 1053425.796239427, 225013.9144379167], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 568200.0000, 
sim time next is 568800.0000, 
raw observation next is [23.9, 59.0, 1.0, 2.0, 0.6052822334205809, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 992495.5967563349, 992495.5967563356, 216736.5010347012], 
processed observation next is [1.0, 0.6086956521739131, 0.33175355450236965, 0.59, 1.0, 1.0, 0.5244364258079287, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2756932213212041, 0.27569322132120433, 0.323487314977166], 
reward next is 0.6765, 
noisyNet noise sample is [array([-1.005317], dtype=float32), -0.8830354]. 
=============================================
[2019-03-26 16:44:28,057] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.2714790e-17 1.0000000e+00 1.2964950e-19 4.3588319e-19 1.5206075e-29], sum to 1.0000
[2019-03-26 16:44:28,060] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1454
[2019-03-26 16:44:28,063] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.96666666666667, 92.0, 1.0, 2.0, 0.2007718088497139, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 335655.8152497928, 335655.8152497928, 155379.4642532544], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 620400.0000, 
sim time next is 621000.0000, 
raw observation next is [16.95, 92.0, 1.0, 2.0, 0.2012261717516125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 336434.2421623027, 336434.2421623032, 155399.7682012333], 
processed observation next is [1.0, 0.17391304347826086, 0.002369668246445531, 0.92, 1.0, 1.0, 0.03762189367664156, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.0934539561561952, 0.09345395615619533, 0.23193995253915417], 
reward next is 0.7681, 
noisyNet noise sample is [array([-0.23922494], dtype=float32), 0.5691745]. 
=============================================
[2019-03-26 16:44:28,077] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[74.22088 ]
 [74.26821 ]
 [74.3687  ]
 [74.4418  ]
 [74.563416]], R is [[74.10919952]
 [74.13619995]
 [74.16230774]
 [74.18865204]
 [74.2146759 ]].
[2019-03-26 16:44:38,957] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.5801305e-17 1.0000000e+00 9.5501265e-21 1.7451362e-20 1.6716085e-30], sum to 1.0000
[2019-03-26 16:44:38,965] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2310
[2019-03-26 16:44:38,970] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 79.00000000000001, 1.0, 2.0, 0.2925385832152782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 466982.5633899804, 466982.5633899804, 164720.0440739929], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 893400.0000, 
sim time next is 894000.0000, 
raw observation next is [22.5, 79.0, 1.0, 2.0, 0.2926940999104102, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 467221.1734289101, 467221.1734289107, 164736.5207204623], 
processed observation next is [0.0, 0.34782608695652173, 0.2654028436018958, 0.79, 1.0, 1.0, 0.14782421675953034, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12978365928580834, 0.12978365928580854, 0.24587540406039146], 
reward next is 0.7541, 
noisyNet noise sample is [array([1.30717], dtype=float32), 0.19495615]. 
=============================================
[2019-03-26 16:44:38,991] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[77.92392]
 [77.89473]
 [77.87598]
 [77.87842]
 [77.87515]], R is [[77.9131012 ]
 [77.88812256]
 [77.86342621]
 [77.8391037 ]
 [77.81523132]].
[2019-03-26 16:44:41,305] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.8959437e-17 1.0000000e+00 1.2945866e-20 3.7721517e-20 2.2722148e-30], sum to 1.0000
[2019-03-26 16:44:41,315] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7023
[2019-03-26 16:44:41,318] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.3, 76.33333333333334, 1.0, 2.0, 0.3101469496316649, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 490613.1999019503, 490613.1999019509, 166332.5888356419], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 841200.0000, 
sim time next is 841800.0000, 
raw observation next is [23.15, 77.16666666666666, 1.0, 2.0, 0.3103404121180225, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 491231.2380670637, 491231.2380670637, 166384.4380141593], 
processed observation next is [0.0, 0.7391304347826086, 0.2962085308056872, 0.7716666666666666, 1.0, 1.0, 0.16908483387713552, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13645312168529547, 0.13645312168529547, 0.24833498211068553], 
reward next is 0.7517, 
noisyNet noise sample is [array([-2.1300006], dtype=float32), -0.87418044]. 
=============================================
[2019-03-26 16:44:41,945] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.4163843e-18 1.0000000e+00 6.3478167e-21 7.7283840e-21 3.1809390e-31], sum to 1.0000
[2019-03-26 16:44:41,953] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8820
[2019-03-26 16:44:41,956] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.03333333333333, 83.5, 1.0, 2.0, 0.3008289006429775, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 478878.6753059169, 478878.6753059163, 165538.9578176553], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 852600.0000, 
sim time next is 853200.0000, 
raw observation next is [22.0, 84.0, 1.0, 2.0, 0.3029436973056214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 481905.6715583483, 481905.6715583489, 165750.4613694883], 
processed observation next is [0.0, 0.9130434782608695, 0.2417061611374408, 0.84, 1.0, 1.0, 0.16017312928388117, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13386268654398564, 0.1338626865439858, 0.2473887483126691], 
reward next is 0.7526, 
noisyNet noise sample is [array([-0.58191526], dtype=float32), -0.519922]. 
=============================================
[2019-03-26 16:44:42,090] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.7988267e-16 1.0000000e+00 1.3215460e-20 1.2577233e-19 1.8534022e-31], sum to 1.0000
[2019-03-26 16:44:42,099] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9848
[2019-03-26 16:44:42,110] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.76666666666667, 86.5, 1.0, 2.0, 0.30570397604334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 485300.621686416, 485300.6216864154, 165978.5317422042], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 857400.0000, 
sim time next is 858000.0000, 
raw observation next is [21.73333333333333, 87.0, 1.0, 2.0, 0.3062337674882957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 485812.4309306119, 485812.4309306126, 166009.607308925], 
processed observation next is [0.0, 0.9565217391304348, 0.22906793048973137, 0.87, 1.0, 1.0, 0.1641370692630069, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13494789748072553, 0.13494789748072572, 0.247775533296903], 
reward next is 0.7522, 
noisyNet noise sample is [array([-0.39927003], dtype=float32), 0.51568186]. 
=============================================
[2019-03-26 16:44:42,118] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[79.66977 ]
 [79.633316]
 [79.60524 ]
 [79.59768 ]
 [79.581055]], R is [[79.64472198]
 [79.60054779]
 [79.55693817]
 [79.51397705]
 [79.47161102]].
[2019-03-26 16:44:46,770] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-26 16:44:46,771] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 16:44:46,772] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:44:46,772] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 16:44:46,774] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:44:46,775] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 16:44:46,775] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:44:46,776] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 16:44:46,777] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 16:44:46,778] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:44:46,779] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:44:46,806] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run53
[2019-03-26 16:44:46,831] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run53
[2019-03-26 16:44:46,833] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run53
[2019-03-26 16:44:46,833] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run53
[2019-03-26 16:44:46,833] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run53
[2019-03-26 16:44:49,692] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.09836868], dtype=float32), 0.08152943]
[2019-03-26 16:44:49,694] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.2, 96.0, 1.0, 2.0, 0.3823336231515572, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 580484.6837537085, 580484.6837537085, 173051.690156466]
[2019-03-26 16:44:49,698] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:44:49,702] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [4.4578987e-17 1.0000000e+00 2.5211386e-20 3.7316074e-19 8.0151430e-31], sampled 0.5621464621794589
[2019-03-26 16:46:06,099] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.09836868], dtype=float32), 0.08152943]
[2019-03-26 16:46:06,100] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [30.8, 83.0, 1.0, 2.0, 0.6339479583494733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 885921.8330604339, 885921.8330604339, 207241.9374351025]
[2019-03-26 16:46:06,101] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:46:06,104] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.3625313e-17 1.0000000e+00 1.8590277e-20 3.1841424e-17 7.1964916e-32], sampled 0.049032418475128736
[2019-03-26 16:46:20,083] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.09836868], dtype=float32), 0.08152943]
[2019-03-26 16:46:20,087] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [30.76666666666667, 69.66666666666667, 1.0, 2.0, 0.5658626486392517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 790739.3900459354, 790739.3900459347, 194557.9795274649]
[2019-03-26 16:46:20,088] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:46:20,091] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [5.9564138e-17 1.0000000e+00 3.1783368e-20 2.2953838e-19 1.1437099e-30], sampled 0.7166170597778834
[2019-03-26 16:46:42,290] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7895.9873 3164025154.7393 1744.0000
[2019-03-26 16:46:42,510] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.6173 2927495018.5334 1337.0000
[2019-03-26 16:46:42,756] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7999.4125 3007285072.4488 1754.0000
[2019-03-26 16:46:42,881] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8502.5054 2841780215.3712 1119.0000
[2019-03-26 16:46:42,926] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.2362 2779222250.9599 933.0000
[2019-03-26 16:46:43,942] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1300000, evaluation results [1300000.0, 7895.987255011995, 3164025154.739337, 1744.0, 8255.617340382343, 2927495018.5333767, 1337.0, 8659.236209269342, 2779222250.9598985, 933.0, 7999.412451514885, 3007285072.4487615, 1754.0, 8502.505415330772, 2841780215.3712225, 1119.0]
[2019-03-26 16:46:48,890] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3405083e-15 1.0000000e+00 1.1434813e-18 4.0272089e-16 2.6651070e-29], sum to 1.0000
[2019-03-26 16:46:48,899] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9904
[2019-03-26 16:46:48,907] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.96666666666667, 79.33333333333334, 1.0, 2.0, 0.3564349496608108, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 548636.0145774892, 548636.0145774886, 170519.9841451461], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1200000.0000, 
sim time next is 1200600.0000, 
raw observation next is [23.85, 80.0, 1.0, 2.0, 0.355786980345851, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 547949.502035673, 547949.502035673, 170471.4634428558], 
processed observation next is [1.0, 0.9130434782608695, 0.3293838862559243, 0.8, 1.0, 1.0, 0.22383973535644697, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15220819500990918, 0.15220819500990918, 0.2544350200639639], 
reward next is 0.7456, 
noisyNet noise sample is [array([0.73466116], dtype=float32), -0.1821668]. 
=============================================
[2019-03-26 16:47:05,161] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.5050716e-16 1.0000000e+00 5.1121318e-19 1.7628237e-16 3.1650998e-28], sum to 1.0000
[2019-03-26 16:47:05,171] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4263
[2019-03-26 16:47:05,178] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.3, 94.0, 1.0, 2.0, 0.45971656316523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 651988.9023952944, 651988.902395295, 178765.3062099393], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1299600.0000, 
sim time next is 1300200.0000, 
raw observation next is [24.28333333333333, 94.00000000000001, 1.0, 2.0, 0.4590338509617207, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 651345.2800327229, 651345.2800327229, 178706.4688538504], 
processed observation next is [1.0, 0.043478260869565216, 0.34992101105845175, 0.9400000000000002, 1.0, 1.0, 0.34823355537556716, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18092924445353412, 0.18092924445353412, 0.26672607291619466], 
reward next is 0.7333, 
noisyNet noise sample is [array([0.5253684], dtype=float32), 0.31016055]. 
=============================================
[2019-03-26 16:47:09,244] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.1340379e-17 1.0000000e+00 2.1990600e-20 2.1067080e-19 2.8356593e-30], sum to 1.0000
[2019-03-26 16:47:09,252] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5879
[2019-03-26 16:47:09,257] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.1, 91.0, 1.0, 2.0, 0.3421657492197361, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 531002.4731346571, 531002.4731346571, 169197.6043721182], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1551600.0000, 
sim time next is 1552200.0000, 
raw observation next is [22.06666666666667, 91.00000000000001, 1.0, 2.0, 0.3411531859773741, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 529851.4239202309, 529851.4239202302, 169116.6463757893], 
processed observation next is [0.0, 1.0, 0.2448657187993683, 0.9100000000000001, 1.0, 1.0, 0.20620865780406517, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14718095108895304, 0.14718095108895285, 0.2524129050384915], 
reward next is 0.7476, 
noisyNet noise sample is [array([-0.50960517], dtype=float32), -0.77382845]. 
=============================================
[2019-03-26 16:47:12,444] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.9115818e-17 1.0000000e+00 1.4663720e-19 1.6603454e-17 1.9553756e-29], sum to 1.0000
[2019-03-26 16:47:12,452] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3891
[2019-03-26 16:47:12,458] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.91666666666666, 94.66666666666667, 1.0, 2.0, 0.3638138941523408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 560595.237147645, 560595.237147645, 171545.0667072892], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1824600.0000, 
sim time next is 1825200.0000, 
raw observation next is [21.9, 95.0, 1.0, 2.0, 0.3646920546257617, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 561563.3696320932, 561563.3696320932, 171617.7061094161], 
processed observation next is [1.0, 0.13043478260869565, 0.23696682464454974, 0.95, 1.0, 1.0, 0.23456874051296592, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15598982489780366, 0.15598982489780366, 0.2561458300140539], 
reward next is 0.7439, 
noisyNet noise sample is [array([0.45473576], dtype=float32), 0.7999253]. 
=============================================
[2019-03-26 16:47:13,833] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.0024266e-17 1.0000000e+00 1.9210491e-20 7.3402386e-20 4.4842006e-31], sum to 1.0000
[2019-03-26 16:47:13,838] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0532
[2019-03-26 16:47:13,846] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.25, 90.66666666666667, 1.0, 2.0, 0.3877274178202514, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 581494.2746672592, 581494.2746672592, 172934.328901482], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1453800.0000, 
sim time next is 1454400.0000, 
raw observation next is [23.0, 92.0, 1.0, 2.0, 0.3844789086674804, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 578128.2771486635, 578128.2771486642, 172678.2718035859], 
processed observation next is [0.0, 0.8695652173913043, 0.28909952606635075, 0.92, 1.0, 1.0, 0.25840832369575956, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16059118809685097, 0.16059118809685116, 0.2577287638859491], 
reward next is 0.7423, 
noisyNet noise sample is [array([0.02137974], dtype=float32), 0.42759043]. 
=============================================
[2019-03-26 16:47:15,563] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.5624014e-16 1.0000000e+00 2.6034712e-20 1.2859738e-19 8.9314475e-31], sum to 1.0000
[2019-03-26 16:47:15,573] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7615
[2019-03-26 16:47:15,581] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.26666666666667, 98.83333333333333, 1.0, 2.0, 0.3089550858985022, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 490307.2586242497, 490307.2586242491, 166340.6201551674], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1486200.0000, 
sim time next is 1486800.0000, 
raw observation next is [20.2, 99.0, 1.0, 2.0, 0.3072791896070122, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 488180.2791504993, 488180.2791505, 166194.4007160553], 
processed observation next is [0.0, 0.21739130434782608, 0.15639810426540288, 0.99, 1.0, 1.0, 0.16539661398435207, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13560563309736093, 0.13560563309736112, 0.24805134435232135], 
reward next is 0.7519, 
noisyNet noise sample is [array([0.27768904], dtype=float32), 0.41835275]. 
=============================================
[2019-03-26 16:47:20,627] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.5917244e-16 1.0000000e+00 2.9068218e-19 1.0904606e-17 1.8074484e-28], sum to 1.0000
[2019-03-26 16:47:20,635] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3200
[2019-03-26 16:47:20,642] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 89.16666666666667, 1.0, 2.0, 0.3066885794240479, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 484786.7941328553, 484786.7941328558, 165898.6661183088], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1572600.0000, 
sim time next is 1573200.0000, 
raw observation next is [21.6, 89.0, 1.0, 2.0, 0.3058931738368764, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 483763.8062439788, 483763.8062439788, 165829.6271591172], 
processed observation next is [1.0, 0.21739130434782608, 0.22274881516587688, 0.89, 1.0, 1.0, 0.16372671546611617, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13437883506777187, 0.13437883506777187, 0.2475069062076376], 
reward next is 0.7525, 
noisyNet noise sample is [array([0.36784187], dtype=float32), 0.2039017]. 
=============================================
[2019-03-26 16:47:21,756] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.2760411e-16 1.0000000e+00 4.8346623e-19 4.4331417e-16 2.9217833e-28], sum to 1.0000
[2019-03-26 16:47:21,763] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5607
[2019-03-26 16:47:21,767] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.8, 85.0, 1.0, 2.0, 0.8248013986985608, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1246279.625636021, 1246279.625636021, 262823.3009326591], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1596600.0000, 
sim time next is 1597200.0000, 
raw observation next is [23.83333333333333, 85.0, 1.0, 2.0, 0.7987309430605135, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1205591.685212153, 1205591.685212153, 255609.3047495016], 
processed observation next is [1.0, 0.4782608695652174, 0.32859399684044216, 0.85, 1.0, 1.0, 0.7575071603138717, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.33488657922559806, 0.33488657922559806, 0.38150642499925613], 
reward next is 0.6185, 
noisyNet noise sample is [array([0.5562673], dtype=float32), 0.17075309]. 
=============================================
[2019-03-26 16:47:22,383] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.5933312e-17 1.0000000e+00 7.6724582e-20 2.0336149e-17 1.6496720e-29], sum to 1.0000
[2019-03-26 16:47:22,392] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7754
[2019-03-26 16:47:22,401] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.3, 85.0, 1.0, 2.0, 0.5280614931723017, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 737897.5121206605, 737897.5121206605, 188109.414758441], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2242800.0000, 
sim time next is 2243400.0000, 
raw observation next is [27.25, 85.00000000000001, 1.0, 2.0, 0.5256722112767287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 734557.6458683417, 734557.6458683423, 187716.0619513254], 
processed observation next is [1.0, 1.0, 0.490521327014218, 0.8500000000000001, 1.0, 1.0, 0.42852073647798633, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2040437905189838, 0.20404379051898397, 0.280173226793023], 
reward next is 0.7198, 
noisyNet noise sample is [array([-0.86673605], dtype=float32), 0.55746466]. 
=============================================
[2019-03-26 16:47:26,171] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0840332e-15 1.0000000e+00 2.6432925e-18 2.3965429e-15 7.1335636e-27], sum to 1.0000
[2019-03-26 16:47:26,185] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2413
[2019-03-26 16:47:26,189] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.06666666666667, 91.5, 1.0, 2.0, 0.8842782891348961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1235953.982577597, 1235953.982577597, 265645.8063424716], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1677000.0000, 
sim time next is 1677600.0000, 
raw observation next is [25.2, 91.0, 1.0, 2.0, 0.8618038511760767, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1204523.687623024, 1204523.687623024, 259643.2187026259], 
processed observation next is [1.0, 0.43478260869565216, 0.3933649289099526, 0.91, 1.0, 1.0, 0.8334986158747912, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.33458991322861775, 0.33458991322861775, 0.3875271920934715], 
reward next is 0.6125, 
noisyNet noise sample is [array([0.39852837], dtype=float32), 0.13284123]. 
=============================================
[2019-03-26 16:47:30,010] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.1619867e-15 1.0000000e+00 1.9621787e-18 2.6843681e-16 2.5969054e-27], sum to 1.0000
[2019-03-26 16:47:30,019] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9488
[2019-03-26 16:47:30,026] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.7, 89.0, 1.0, 2.0, 0.9399990506708054, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1345949.076585921, 1345949.076585922, 286012.9274567739], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1760400.0000, 
sim time next is 1761000.0000, 
raw observation next is [24.63333333333333, 88.83333333333334, 1.0, 2.0, 0.9187482639017539, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1320233.322021872, 1320233.322021871, 280512.9234424909], 
processed observation next is [1.0, 0.391304347826087, 0.3665086887835701, 0.8883333333333334, 1.0, 1.0, 0.9021063420503059, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3667314783394089, 0.36673147833940867, 0.41867600513804615], 
reward next is 0.5813, 
noisyNet noise sample is [array([-1.0370259], dtype=float32), 1.953238]. 
=============================================
[2019-03-26 16:47:30,041] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[69.1117 ]
 [69.2661 ]
 [69.58894]
 [69.98163]
 [70.44998]], R is [[68.889534  ]
 [68.77375031]
 [68.65750885]
 [68.54502869]
 [68.44510651]].
[2019-03-26 16:47:33,130] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.8049851e-16 1.0000000e+00 1.3650114e-19 9.4028689e-18 4.2559055e-29], sum to 1.0000
[2019-03-26 16:47:33,138] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4197
[2019-03-26 16:47:33,143] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.7, 95.0, 1.0, 2.0, 0.3456810437266551, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 535282.4388331014, 535282.4388331014, 169511.2381067662], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1814400.0000, 
sim time next is 1815000.0000, 
raw observation next is [21.71666666666667, 94.83333333333334, 1.0, 2.0, 0.3456467214089191, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 535202.0222888836, 535202.0222888836, 169503.9298815456], 
processed observation next is [1.0, 0.0, 0.22827804107424976, 0.9483333333333335, 1.0, 1.0, 0.21162255591436038, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14866722841357877, 0.14866722841357877, 0.25299094012170986], 
reward next is 0.7470, 
noisyNet noise sample is [array([0.22111613], dtype=float32), 0.100799866]. 
=============================================
[2019-03-26 16:47:33,155] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[71.396866]
 [72.21514 ]
 [72.19402 ]
 [72.165215]
 [72.137276]], R is [[70.80010986]
 [70.83911133]
 [70.87774658]
 [70.91599274]
 [70.95384216]].
[2019-03-26 16:47:38,056] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-26 16:47:38,057] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 16:47:38,058] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:47:38,058] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 16:47:38,059] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:47:38,060] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 16:47:38,060] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 16:47:38,061] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 16:47:38,062] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:47:38,062] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:47:38,065] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:47:38,095] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run54
[2019-03-26 16:47:38,095] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run54
[2019-03-26 16:47:38,136] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run54
[2019-03-26 16:47:38,137] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run54
[2019-03-26 16:47:38,184] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run54
[2019-03-26 16:48:06,372] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10030992], dtype=float32), 0.07950774]
[2019-03-26 16:48:06,373] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.95, 87.0, 1.0, 2.0, 0.6885215501224168, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 6.979947824351965, 6.9112, 168.911757158255, 1859066.509275329, 1810294.782864519, 383108.2460886639]
[2019-03-26 16:48:06,375] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:48:06,378] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.8204063e-11 9.9999952e-01 2.6989938e-12 4.5371294e-07 3.2002359e-19], sampled 0.1647429416852173
[2019-03-26 16:48:06,380] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1859066.509275329 W.
[2019-03-26 16:48:46,703] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10030992], dtype=float32), 0.07950774]
[2019-03-26 16:48:46,704] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [24.82967605, 97.51315836333333, 1.0, 2.0, 0.515789605962901, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 720743.3221919292, 720743.3221919285, 186105.8612090641]
[2019-03-26 16:48:46,704] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 16:48:46,708] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [4.9311886e-17 1.0000000e+00 3.2562172e-20 6.6324691e-19 2.2880625e-30], sampled 0.9338623425181193
[2019-03-26 16:49:00,473] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10030992], dtype=float32), 0.07950774]
[2019-03-26 16:49:00,474] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.35, 94.0, 1.0, 2.0, 0.6201277892156918, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 866600.7130550737, 866600.7130550737, 204555.3409029301]
[2019-03-26 16:49:00,477] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:49:00,481] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [8.6244160e-17 1.0000000e+00 5.3816558e-20 4.6204174e-19 4.1996667e-30], sampled 0.8357555718771709
[2019-03-26 16:49:08,055] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10030992], dtype=float32), 0.07950774]
[2019-03-26 16:49:08,055] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [30.95, 65.5, 1.0, 2.0, 0.9221850138265538, 1.0, 2.0, 0.9221850138265538, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2579410.055890326, 2579410.055890327, 483733.4005910069]
[2019-03-26 16:49:08,056] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:49:08,059] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.0433536e-10 9.9229044e-01 2.7548583e-10 7.7095181e-03 4.8960281e-17], sampled 0.6510847621731249
[2019-03-26 16:49:08,060] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2579410.055890326 W.
[2019-03-26 16:49:25,705] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10030992], dtype=float32), 0.07950774]
[2019-03-26 16:49:25,705] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.76666666666667, 85.66666666666667, 1.0, 2.0, 0.5883105510961432, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 822120.3448191733, 822120.3448191739, 198587.9784815627]
[2019-03-26 16:49:25,705] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:49:25,706] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.4856007e-16 1.0000000e+00 8.9769321e-19 1.2358012e-15 3.7176785e-29], sampled 0.4126002751193597
[2019-03-26 16:49:33,271] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8004.2295 3006873808.0706 1746.0000
[2019-03-26 16:49:33,318] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8503.2368 2841506744.9783 1110.0000
[2019-03-26 16:49:33,542] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.2356 2779347772.7178 931.0000
[2019-03-26 16:49:33,633] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7901.3921 3162412014.5696 1710.0000
[2019-03-26 16:49:33,654] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8252.6669 2927231563.0548 1332.0000
[2019-03-26 16:49:34,670] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1325000, evaluation results [1325000.0, 7901.392137460119, 3162412014.5696006, 1710.0, 8252.66690291297, 2927231563.0547705, 1332.0, 8660.235629322584, 2779347772.7177963, 931.0, 8004.22949729227, 3006873808.070637, 1746.0, 8503.236797865258, 2841506744.978254, 1110.0]
[2019-03-26 16:49:36,657] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.7568338e-17 1.0000000e+00 1.3567358e-20 4.6836433e-20 7.6817282e-31], sum to 1.0000
[2019-03-26 16:49:36,666] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0939
[2019-03-26 16:49:36,670] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 94.16666666666667, 1.0, 2.0, 0.5021788138397962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 701717.8754074966, 701717.8754074973, 183938.4756841463], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2015400.0000, 
sim time next is 2016000.0000, 
raw observation next is [25.6, 94.0, 1.0, 2.0, 0.5037625457317685, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 703931.6310894974, 703931.6310894967, 184188.0953561375], 
processed observation next is [0.0, 0.34782608695652173, 0.4123222748815167, 0.94, 1.0, 1.0, 0.40212354907441983, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19553656419152704, 0.19553656419152685, 0.27490760500916045], 
reward next is 0.7251, 
noisyNet noise sample is [array([-0.00071423], dtype=float32), -1.4420098]. 
=============================================
[2019-03-26 16:49:36,691] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[74.525856]
 [74.52013 ]
 [74.51102 ]
 [74.5016  ]
 [74.49706 ]], R is [[74.53201294]
 [74.51215363]
 [74.4929657 ]
 [74.47467804]
 [74.45735168]].
[2019-03-26 16:49:41,194] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.5072649e-16 1.0000000e+00 4.4430029e-20 5.0928593e-20 3.8858352e-30], sum to 1.0000
[2019-03-26 16:49:41,203] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1861
[2019-03-26 16:49:41,207] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.83333333333333, 95.33333333333333, 1.0, 2.0, 0.4835651054196176, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 675699.8003626856, 675699.8003626862, 181061.2809112976], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2011200.0000, 
sim time next is 2011800.0000, 
raw observation next is [24.91666666666667, 95.16666666666667, 1.0, 2.0, 0.4854643778384652, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 678354.5571582321, 678354.5571582327, 181350.1802974536], 
processed observation next is [0.0, 0.2608695652173913, 0.37993680884676173, 0.9516666666666667, 1.0, 1.0, 0.3800775636608014, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18843182143284223, 0.1884318214328424, 0.27067191089172177], 
reward next is 0.7293, 
noisyNet noise sample is [array([-0.7131475], dtype=float32), 0.5515289]. 
=============================================
[2019-03-26 16:49:42,534] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.5701431e-16 1.0000000e+00 3.0568714e-18 7.9351926e-16 5.0073470e-27], sum to 1.0000
[2019-03-26 16:49:42,541] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9304
[2019-03-26 16:49:42,551] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2228224.112181839 W.
[2019-03-26 16:49:42,556] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.6, 80.5, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 8.002168712470443, 6.9112, 168.9068116577663, 2228224.112181839, 1454281.515446444, 311351.5265186779], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2190600.0000, 
sim time next is 2191200.0000, 
raw observation next is [28.7, 80.0, 1.0, 2.0, 0.8308020888640424, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 6.992143855976874, 6.9112, 168.9115868268401, 2058183.014306735, 2000759.1226476, 416112.479292169], 
processed observation next is [1.0, 0.34782608695652173, 0.5592417061611374, 0.8, 1.0, 1.0, 0.7961470950169185, 0.0, 1.0, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.008094385597687381, 0.0, 0.8294332193788275, 0.571717503974093, 0.5557664229576667, 0.6210634019286104], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.20623107], dtype=float32), 0.7754343]. 
=============================================
[2019-03-26 16:49:45,565] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.6159825e-17 1.0000000e+00 1.9405980e-19 6.4800211e-17 5.4661088e-29], sum to 1.0000
[2019-03-26 16:49:45,578] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5640
[2019-03-26 16:49:45,588] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.63333333333333, 84.33333333333334, 1.0, 2.0, 0.533385824450514, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 745340.1854358703, 745340.1854358697, 188992.3759554533], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2240400.0000, 
sim time next is 2241000.0000, 
raw observation next is [27.55, 84.5, 1.0, 2.0, 0.531361632074012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 742510.6403696458, 742510.6403696451, 188655.7856488573], 
processed observation next is [1.0, 0.9565217391304348, 0.504739336492891, 0.845, 1.0, 1.0, 0.4353754603301349, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20625295565823493, 0.20625295565823476, 0.28157579947590644], 
reward next is 0.7184, 
noisyNet noise sample is [array([-1.2704029], dtype=float32), 0.414406]. 
=============================================
[2019-03-26 16:49:45,601] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[72.788414]
 [72.797035]
 [72.64505 ]
 [72.62705 ]
 [72.43253 ]], R is [[72.77899933]
 [72.76912689]
 [72.75865173]
 [72.74774933]
 [72.73677826]].
[2019-03-26 16:50:00,240] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.2057520e-16 1.0000000e+00 3.2110965e-19 5.6834794e-16 6.2486657e-28], sum to 1.0000
[2019-03-26 16:50:00,247] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9840
[2019-03-26 16:50:00,252] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.68333333333333, 80.83333333333333, 1.0, 2.0, 0.5521788851898377, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 771610.6828985944, 771610.682898595, 192175.1877840316], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2328600.0000, 
sim time next is 2329200.0000, 
raw observation next is [28.6, 81.0, 1.0, 2.0, 0.5506626327980185, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 769491.1155753976, 769491.1155753976, 191914.4735542212], 
processed observation next is [1.0, 1.0, 0.5545023696682465, 0.81, 1.0, 1.0, 0.4586296780699018, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2137475321042771, 0.2137475321042771, 0.2864395127674943], 
reward next is 0.7136, 
noisyNet noise sample is [array([-0.7426145], dtype=float32), -0.75954115]. 
=============================================
[2019-03-26 16:50:00,739] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.6119021e-16 1.0000000e+00 3.8290726e-19 9.1390662e-16 1.9680008e-28], sum to 1.0000
[2019-03-26 16:50:00,749] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7792
[2019-03-26 16:50:00,755] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.68333333333333, 80.83333333333333, 1.0, 2.0, 0.5521788851898377, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 771610.6828985944, 771610.682898595, 192175.1877840316], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2328600.0000, 
sim time next is 2329200.0000, 
raw observation next is [28.6, 81.0, 1.0, 2.0, 0.5506626327980185, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 769491.1155753976, 769491.1155753976, 191914.4735542212], 
processed observation next is [1.0, 1.0, 0.5545023696682465, 0.81, 1.0, 1.0, 0.4586296780699018, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2137475321042771, 0.2137475321042771, 0.2864395127674943], 
reward next is 0.7136, 
noisyNet noise sample is [array([-1.3602128], dtype=float32), -0.33132833]. 
=============================================
[2019-03-26 16:50:20,430] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.43246319e-17 1.00000000e+00 4.07498283e-20 5.91339219e-19
 1.28474075e-30], sum to 1.0000
[2019-03-26 16:50:20,440] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8263
[2019-03-26 16:50:20,445] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.3950281865701634, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 589440.5759568586, 589440.5759568592, 173566.3096669186], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2676000.0000, 
sim time next is 2676600.0000, 
raw observation next is [23.0, 94.0, 1.0, 2.0, 0.3949073917860469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 589260.5812168231, 589260.5812168224, 173549.8204274147], 
processed observation next is [0.0, 1.0, 0.28909952606635075, 0.94, 1.0, 1.0, 0.2709727611880083, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16368349478245087, 0.16368349478245067, 0.2590295827274846], 
reward next is 0.7410, 
noisyNet noise sample is [array([1.3872937], dtype=float32), 0.5837148]. 
=============================================
[2019-03-26 16:50:21,758] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.5159557e-16 1.0000000e+00 4.3377965e-20 1.0111071e-18 4.4561033e-29], sum to 1.0000
[2019-03-26 16:50:21,770] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1693
[2019-03-26 16:50:21,779] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 94.0, 1.0, 2.0, 0.4420703068049817, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 634967.3739069798, 634967.3739069805, 177237.9213649489], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2687400.0000, 
sim time next is 2688000.0000, 
raw observation next is [24.0, 94.0, 1.0, 2.0, 0.4412583521901511, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 633801.0473858996, 633801.047385899, 177121.2809928687], 
processed observation next is [0.0, 0.08695652173913043, 0.3364928909952607, 0.94, 1.0, 1.0, 0.32681729179536273, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17605584649608322, 0.17605584649608305, 0.26436012088487865], 
reward next is 0.7356, 
noisyNet noise sample is [array([-1.2659919], dtype=float32), 1.9336141]. 
=============================================
[2019-03-26 16:50:21,786] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[74.48307 ]
 [74.38411 ]
 [74.15139 ]
 [74.092995]
 [73.946625]], R is [[74.48374939]
 [74.47438049]
 [74.46504974]
 [74.45597839]
 [74.44723511]].
[2019-03-26 16:50:26,189] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.9641471e-16 1.0000000e+00 8.7224407e-19 6.5244421e-18 6.6419046e-29], sum to 1.0000
[2019-03-26 16:50:26,199] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1429
[2019-03-26 16:50:26,205] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.00000000000001, 1.0, 2.0, 0.3816734370932218, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 587957.306033519, 587957.3060335184, 173925.3497632101], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2866200.0000, 
sim time next is 2866800.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.350244189542749, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 539528.9942654476, 539528.9942654483, 169777.4929953436], 
processed observation next is [1.0, 0.17391304347826086, 0.2417061611374408, 0.94, 1.0, 1.0, 0.21716167414789037, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14986916507373543, 0.14986916507373563, 0.25339924327663227], 
reward next is 0.7466, 
noisyNet noise sample is [array([0.20035164], dtype=float32), -1.1784885]. 
=============================================
[2019-03-26 16:50:28,981] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-26 16:50:28,983] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 16:50:28,985] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:50:28,985] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 16:50:28,986] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 16:50:28,989] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:50:28,987] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 16:50:28,990] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:50:28,990] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:50:28,989] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 16:50:28,993] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:50:29,017] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run55
[2019-03-26 16:50:29,042] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run55
[2019-03-26 16:50:29,043] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run55
[2019-03-26 16:50:29,044] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run55
[2019-03-26 16:50:29,111] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run55
[2019-03-26 16:50:47,518] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.09942822], dtype=float32), 0.08046812]
[2019-03-26 16:50:47,519] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.66913778166667, 66.98598372166667, 1.0, 2.0, 0.2998314409290087, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 483391.9775234224, 483391.9775234218, 165899.2991698456]
[2019-03-26 16:50:47,520] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 16:50:47,523] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.3718886e-16 1.0000000e+00 8.8396411e-20 1.7397077e-18 8.5841511e-30], sampled 0.84554797436829
[2019-03-26 16:50:48,994] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.09942822], dtype=float32), 0.08046812]
[2019-03-26 16:50:48,994] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.22233864166667, 97.31820716666667, 1.0, 2.0, 0.4335332710031229, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 633819.0313225817, 633819.0313225811, 177414.8451557063]
[2019-03-26 16:50:48,996] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 16:50:48,999] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.0098085e-16 1.0000000e+00 1.6025523e-19 3.5609844e-18 3.4953146e-29], sampled 0.8170315579454639
[2019-03-26 16:50:55,538] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.09942822], dtype=float32), 0.08046812]
[2019-03-26 16:50:55,539] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [24.211579495, 90.88135717833335, 1.0, 2.0, 0.6539189359643306, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 940997.0692580433, 940997.0692580433, 214765.6811386638]
[2019-03-26 16:50:55,541] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 16:50:55,544] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.6811240e-16 1.0000000e+00 3.5430428e-19 1.2398230e-17 8.4101948e-29], sampled 0.3055012658912941
[2019-03-26 16:51:21,549] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.09942822], dtype=float32), 0.08046812]
[2019-03-26 16:51:21,550] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [33.35, 62.0, 1.0, 2.0, 0.5909179166011569, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 825765.3610183815, 825765.3610183808, 199066.459187785]
[2019-03-26 16:51:21,550] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:51:21,551] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.0971466e-15 1.0000000e+00 2.6170969e-17 3.9835795e-12 7.2974087e-28], sampled 0.05315431097068235
[2019-03-26 16:51:34,672] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.09942822], dtype=float32), 0.08046812]
[2019-03-26 16:51:34,673] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [36.9, 52.33333333333334, 1.0, 2.0, 0.7519894384160913, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1050962.618233916, 1050962.618233915, 232474.8843307733]
[2019-03-26 16:51:34,675] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 16:51:34,678] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.2912403e-16 1.0000000e+00 1.1979051e-19 6.0218430e-18 1.2998805e-29], sampled 0.5864115771974322
[2019-03-26 16:51:50,631] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.09942822], dtype=float32), 0.08046812]
[2019-03-26 16:51:50,632] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.43141046666667, 81.08400454666666, 1.0, 2.0, 0.5468470663083943, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 764157.3586622536, 764157.358662253, 191261.403111802]
[2019-03-26 16:51:50,633] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 16:51:50,637] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.4048195e-17 1.0000000e+00 3.5631958e-20 2.7809889e-18 2.2111955e-30], sampled 0.9840481922833494
[2019-03-26 16:52:18,885] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.09942822], dtype=float32), 0.08046812]
[2019-03-26 16:52:18,886] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.0, 77.0, 1.0, 2.0, 0.4157413201553971, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 606491.3773013739, 606491.3773013739, 174739.69708899]
[2019-03-26 16:52:18,887] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:52:18,890] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.1400418e-16 1.0000000e+00 5.1047435e-20 2.6387173e-19 5.0278004e-30], sampled 0.4290823534460865
[2019-03-26 16:52:23,927] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8010.5043 3005593381.7138 1719.0000
[2019-03-26 16:52:24,988] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7917.7480 3160973866.6674 1665.0000
[2019-03-26 16:52:24,995] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.8120 2927023672.0473 1328.0000
[2019-03-26 16:52:25,038] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.8262 2779245577.8383 931.0000
[2019-03-26 16:52:25,083] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8505.8745 2841221071.0945 1106.0000
[2019-03-26 16:52:26,100] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1350000, evaluation results [1350000.0, 7917.748003504174, 3160973866.6674423, 1665.0, 8255.811956398722, 2927023672.047316, 1328.0, 8661.826175249742, 2779245577.8382587, 931.0, 8010.504272309805, 3005593381.713787, 1719.0, 8505.87451918498, 2841221071.094504, 1106.0]
[2019-03-26 16:52:26,537] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.4884277e-16 1.0000000e+00 1.6470969e-18 2.1340108e-15 1.3561101e-27], sum to 1.0000
[2019-03-26 16:52:26,545] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6709
[2019-03-26 16:52:26,552] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 93.16666666666667, 1.0, 2.0, 0.6873383385917917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1055878.300810396, 1055878.300810396, 230076.3455917238], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2908200.0000, 
sim time next is 2908800.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.6690594115735722, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1029711.016916511, 1029711.01691651, 226059.0917654377], 
processed observation next is [1.0, 0.6956521739130435, 0.2417061611374408, 0.94, 1.0, 1.0, 0.6012763994862316, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2860308380323642, 0.2860308380323639, 0.3374016295006533], 
reward next is 0.6626, 
noisyNet noise sample is [array([0.78204364], dtype=float32), -0.9058015]. 
=============================================
[2019-03-26 16:52:29,744] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.9260070e-15 1.0000000e+00 4.6454779e-19 5.3817257e-17 1.7535038e-28], sum to 1.0000
[2019-03-26 16:52:29,750] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9357
[2019-03-26 16:52:29,755] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.3648769842953998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 562068.2695467542, 562068.2695467548, 171666.4570487527], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2870400.0000, 
sim time next is 2871000.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.3708309786404282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 571243.1525737698, 571243.1525737704, 172456.0830141283], 
processed observation next is [1.0, 0.21739130434782608, 0.2417061611374408, 0.94, 1.0, 1.0, 0.24196503450653997, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15867865349271384, 0.15867865349271398, 0.25739713882705717], 
reward next is 0.7426, 
noisyNet noise sample is [array([1.1646686], dtype=float32), 0.69077307]. 
=============================================
[2019-03-26 16:52:29,765] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[72.24334 ]
 [72.246124]
 [72.260735]
 [72.242935]
 [72.23732 ]], R is [[72.24687958]
 [72.26819611]
 [72.28553009]
 [72.31028748]
 [72.33469391]].
[2019-03-26 16:52:31,761] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.4162946e-17 1.0000000e+00 1.9731591e-19 1.6642761e-18 2.1413592e-29], sum to 1.0000
[2019-03-26 16:52:31,772] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1286
[2019-03-26 16:52:31,780] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.0, 1.0, 2.0, 0.3156460998602504, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 499135.6107977011, 499135.6107977018, 166960.6386087717], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2934000.0000, 
sim time next is 2934600.0000, 
raw observation next is [20.83333333333333, 95.0, 1.0, 2.0, 0.313909469545086, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 496768.6923173688, 496768.6923173688, 166791.6523966831], 
processed observation next is [1.0, 1.0, 0.1864139020537123, 0.95, 1.0, 1.0, 0.17338490306636864, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13799130342149132, 0.13799130342149132, 0.24894276477116878], 
reward next is 0.7511, 
noisyNet noise sample is [array([0.43953], dtype=float32), 1.5882567]. 
=============================================
[2019-03-26 16:52:36,182] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.3426785e-16 1.0000000e+00 9.5469257e-20 4.3806082e-16 3.8611462e-29], sum to 1.0000
[2019-03-26 16:52:36,196] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3495
[2019-03-26 16:52:36,202] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 79.00000000000001, 1.0, 2.0, 0.5201811884542626, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 726882.0397544084, 726882.0397544084, 186818.3332392653], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3622200.0000, 
sim time next is 3622800.0000, 
raw observation next is [28.0, 79.0, 1.0, 2.0, 0.519067548057568, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 725325.3483750876, 725325.3483750882, 186637.4424858205], 
processed observation next is [1.0, 0.9565217391304348, 0.5260663507109005, 0.79, 1.0, 1.0, 0.4205633109127326, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20147926343752434, 0.2014792634375245, 0.27856334699376195], 
reward next is 0.7214, 
noisyNet noise sample is [array([-0.5291298], dtype=float32), -1.2128906]. 
=============================================
[2019-03-26 16:52:38,507] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.2997876e-17 1.0000000e+00 5.3624746e-20 7.8183581e-19 1.4719129e-29], sum to 1.0000
[2019-03-26 16:52:38,516] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9937
[2019-03-26 16:52:38,522] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 95.0, 1.0, 2.0, 0.3557463601685748, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 548977.406688696, 548977.4066886967, 170587.4430615893], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3052200.0000, 
sim time next is 3052800.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.3514967435835583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 541706.0223128739, 541706.0223128739, 169964.0671676623], 
processed observation next is [1.0, 0.34782608695652173, 0.2417061611374408, 0.94, 1.0, 1.0, 0.2186707754018775, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1504738950869094, 0.1504738950869094, 0.25367771219054075], 
reward next is 0.7463, 
noisyNet noise sample is [array([0.09887274], dtype=float32), -0.27505326]. 
=============================================
[2019-03-26 16:52:50,129] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.1329192e-16 1.0000000e+00 1.2049400e-19 2.5221221e-18 7.4788127e-29], sum to 1.0000
[2019-03-26 16:52:50,137] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5949
[2019-03-26 16:52:50,141] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 79.0, 1.0, 2.0, 0.5348318217707659, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 747361.497230726, 747361.497230726, 189234.8607281175], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3232800.0000, 
sim time next is 3233400.0000, 
raw observation next is [29.16666666666667, 77.50000000000001, 1.0, 2.0, 0.5387596731589183, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 752852.1300982146, 752852.1300982139, 189892.6394897953], 
processed observation next is [0.0, 0.43478260869565216, 0.581358609794629, 0.7750000000000001, 1.0, 1.0, 0.4442887628420702, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2091255916939485, 0.20912559169394832, 0.2834218499847691], 
reward next is 0.7166, 
noisyNet noise sample is [array([-1.1141012], dtype=float32), -0.32852325]. 
=============================================
[2019-03-26 16:52:51,270] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.2707207e-11 1.7299767e-01 1.2528177e-10 8.2700235e-01 9.1678760e-18], sum to 1.0000
[2019-03-26 16:52:51,276] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4562
[2019-03-26 16:52:51,281] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.66666666666666, 64.33333333333334, 1.0, 2.0, 0.9093481827927282, 1.0, 2.0, 0.9093481827927282, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2543468.078494492, 2543468.078494492, 476627.2185255442], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3418800.0000, 
sim time next is 3419400.0000, 
raw observation next is [33.83333333333334, 63.66666666666666, 1.0, 2.0, 0.8979333845384836, 1.0, 2.0, 0.8979333845384836, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2511508.533962273, 2511508.533962273, 470375.712206082], 
processed observation next is [1.0, 0.5652173913043478, 0.8025276461295423, 0.6366666666666666, 1.0, 1.0, 0.8770281741427514, 1.0, 1.0, 0.8770281741427514, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6976412594339647, 0.6976412594339647, 0.7020533018001224], 
reward next is 0.2979, 
noisyNet noise sample is [array([-0.532731], dtype=float32), 1.0418571]. 
=============================================
[2019-03-26 16:52:51,631] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.0603916e-16 1.0000000e+00 9.1891430e-20 6.5431351e-18 5.0031579e-30], sum to 1.0000
[2019-03-26 16:52:51,640] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8636
[2019-03-26 16:52:51,646] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 81.5, 1.0, 2.0, 0.564298204606594, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 788552.4163732312, 788552.4163732312, 194283.4553579785], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3882600.0000, 
sim time next is 3883200.0000, 
raw observation next is [29.0, 82.33333333333334, 1.0, 2.0, 0.5683815247180498, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 794260.5965296457, 794260.5965296457, 195003.5527013623], 
processed observation next is [0.0, 0.9565217391304348, 0.5734597156398105, 0.8233333333333335, 1.0, 1.0, 0.4799777406241564, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22062794348045714, 0.22062794348045714, 0.2910500786587497], 
reward next is 0.7089, 
noisyNet noise sample is [array([-0.7581637], dtype=float32), -0.34867102]. 
=============================================
[2019-03-26 16:52:53,206] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.5560148e-16 1.0000000e+00 2.2385375e-18 2.6647484e-16 2.6196705e-27], sum to 1.0000
[2019-03-26 16:52:53,214] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0529
[2019-03-26 16:52:53,219] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.5078598009336115, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 709658.8352535367, 709658.8352535367, 184836.8505617697], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3459600.0000, 
sim time next is 3460200.0000, 
raw observation next is [26.83333333333333, 84.83333333333333, 1.0, 2.0, 0.5074331952403807, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 709062.5180404293, 709062.5180404286, 184768.9709951507], 
processed observation next is [1.0, 0.043478260869565216, 0.470774091627172, 0.8483333333333333, 1.0, 1.0, 0.4065460183619044, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19696181056678594, 0.19696181056678574, 0.2757745835748518], 
reward next is 0.7242, 
noisyNet noise sample is [array([0.7674189], dtype=float32), 0.4731322]. 
=============================================
[2019-03-26 16:52:58,335] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.1942853e-16 1.0000000e+00 7.7130506e-18 5.7505651e-15 5.0925690e-27], sum to 1.0000
[2019-03-26 16:52:58,343] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4786
[2019-03-26 16:52:58,349] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.66666666666666, 89.0, 1.0, 2.0, 0.8138384672348753, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1137447.650540901, 1137447.650540901, 247337.8339284521], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3393600.0000, 
sim time next is 3394200.0000, 
raw observation next is [27.83333333333334, 89.0, 1.0, 2.0, 0.8402982449068611, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1174449.165960978, 1174449.165960978, 254045.2440379111], 
processed observation next is [1.0, 0.2608695652173913, 0.5181674565560824, 0.89, 1.0, 1.0, 0.8075882468757363, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.326235879433605, 0.326235879433605, 0.37917200602673296], 
reward next is 0.6208, 
noisyNet noise sample is [array([1.1509869], dtype=float32), -1.0034386]. 
=============================================
[2019-03-26 16:53:11,479] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.6660515e-16 1.0000000e+00 7.5865475e-19 8.8793696e-16 5.7624537e-27], sum to 1.0000
[2019-03-26 16:53:11,488] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4593
[2019-03-26 16:53:11,495] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 79.0, 1.0, 2.0, 0.5191185488877897, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 725396.6393389122, 725396.6393389116, 186645.7186011872], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3625200.0000, 
sim time next is 3625800.0000, 
raw observation next is [28.0, 78.16666666666667, 1.0, 2.0, 0.5162032013253437, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 721321.4596799125, 721321.4596799125, 186173.5513085935], 
processed observation next is [1.0, 1.0, 0.5260663507109005, 0.7816666666666667, 1.0, 1.0, 0.4171122907534261, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20036707213330904, 0.20036707213330904, 0.2778709721023784], 
reward next is 0.7221, 
noisyNet noise sample is [array([-0.2821171], dtype=float32), -0.09011852]. 
=============================================
[2019-03-26 16:53:16,240] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.8973020e-12 5.2445565e-05 1.2687020e-11 9.9994755e-01 6.4172221e-18], sum to 1.0000
[2019-03-26 16:53:16,248] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0329
[2019-03-26 16:53:16,253] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.33333333333334, 62.0, 1.0, 2.0, 1.007174547610221, 1.0, 2.0, 1.007174547610221, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2817399.228370426, 2817399.228370425, 533337.8214099769], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3771600.0000, 
sim time next is 3772200.0000, 
raw observation next is [33.16666666666666, 62.5, 1.0, 2.0, 1.004402037435482, 1.0, 2.0, 1.004402037435482, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2809634.881690987, 2809634.881690987, 531652.6620692826], 
processed observation next is [1.0, 0.6521739130434783, 0.7709320695102682, 0.625, 1.0, 1.0, 1.0053036595608218, 1.0, 1.0, 1.0053036595608218, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.780454133803052, 0.780454133803052, 0.7935114359243024], 
reward next is 0.2065, 
noisyNet noise sample is [array([0.3343529], dtype=float32), -1.3874031]. 
=============================================
[2019-03-26 16:53:17,253] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.2793418e-17 1.0000000e+00 2.9627069e-19 2.4935591e-16 1.5729823e-28], sum to 1.0000
[2019-03-26 16:53:17,261] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7253
[2019-03-26 16:53:17,267] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 79.0, 1.0, 2.0, 0.519615069662219, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 726090.6958310549, 726090.6958310549, 186726.3315488285], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3799800.0000, 
sim time next is 3800400.0000, 
raw observation next is [28.0, 79.0, 1.0, 2.0, 0.5184873768171205, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 724514.3625625372, 724514.3625625379, 186543.3496807762], 
processed observation next is [1.0, 1.0, 0.5260663507109005, 0.79, 1.0, 1.0, 0.4198643094182175, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20125398960070479, 0.20125398960070498, 0.2784229099713078], 
reward next is 0.7216, 
noisyNet noise sample is [array([-0.5730889], dtype=float32), 0.04671345]. 
=============================================
[2019-03-26 16:53:20,402] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-26 16:53:20,405] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 16:53:20,406] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 16:53:20,407] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:53:20,407] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:53:20,409] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 16:53:20,409] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 16:53:20,410] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:53:20,410] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:53:20,411] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 16:53:20,414] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:53:20,440] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run56
[2019-03-26 16:53:20,463] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run56
[2019-03-26 16:53:20,485] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run56
[2019-03-26 16:53:20,486] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run56
[2019-03-26 16:53:20,507] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run56
[2019-03-26 16:54:09,832] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10246617], dtype=float32), 0.0777181]
[2019-03-26 16:54:09,834] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [32.46710767666667, 64.05761580166667, 1.0, 2.0, 0.5753568077700782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 804011.5984020887, 804011.5984020887, 196245.0137883986]
[2019-03-26 16:54:09,836] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 16:54:09,840] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.3974743e-16 1.0000000e+00 1.7098627e-19 1.3137864e-18 4.9895708e-29], sampled 0.4149659261964169
[2019-03-26 16:54:40,472] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10246617], dtype=float32), 0.0777181]
[2019-03-26 16:54:40,474] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [35.6, 52.33333333333334, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.002520638672795, 6.9112, 168.9123193723086, 1518585.054601319, 1453799.294885233, 311354.8048258176]
[2019-03-26 16:54:40,475] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 16:54:40,478] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [5.0293709e-16 1.0000000e+00 1.2770527e-18 3.1261567e-16 7.7890298e-28], sampled 0.3059139505018851
[2019-03-26 16:54:51,417] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10246617], dtype=float32), 0.0777181]
[2019-03-26 16:54:51,419] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [30.15, 71.5, 1.0, 2.0, 0.5420248353274145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 757416.4299662584, 757416.4299662578, 190442.9864727354]
[2019-03-26 16:54:51,421] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:54:51,425] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.1491887e-16 1.0000000e+00 1.4351055e-19 7.6482955e-19 4.0741715e-29], sampled 0.4446383394016641
[2019-03-26 16:55:01,128] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10246617], dtype=float32), 0.0777181]
[2019-03-26 16:55:01,130] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.33333333333334, 70.0, 1.0, 2.0, 0.5179901359146026, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 723819.3004784833, 723819.3004784826, 186462.3863505205]
[2019-03-26 16:55:01,132] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 16:55:01,135] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.6113882e-16 1.0000000e+00 1.3881108e-19 3.6282971e-18 3.6165726e-29], sampled 0.8628782319453175
[2019-03-26 16:55:15,778] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7913.8495 3161317741.8503 1684.0000
[2019-03-26 16:55:16,269] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10246617], dtype=float32), 0.0777181]
[2019-03-26 16:55:16,269] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [24.6, 73.33333333333334, 1.0, 2.0, 0.3496700161086808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 542138.5041437336, 542138.5041437331, 170089.4945906696]
[2019-03-26 16:55:16,270] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:55:16,271] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.78006886e-16 1.00000000e+00 1.06387524e-19 7.71254673e-19
 2.96247688e-29], sampled 0.05700505196099637
[2019-03-26 16:55:16,295] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8008.0168 3005895377.4674 1729.0000
[2019-03-26 16:55:16,523] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8507.4276 2841349530.0464 1105.0000
[2019-03-26 16:55:16,568] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.9242 2779049295.4645 931.0000
[2019-03-26 16:55:16,624] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8256.7129 2927338516.2594 1331.0000
[2019-03-26 16:55:17,639] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1375000, evaluation results [1375000.0, 7913.849469963953, 3161317741.850305, 1684.0, 8256.712853376675, 2927338516.259387, 1331.0, 8660.924197519076, 2779049295.4645123, 931.0, 8008.016816146087, 3005895377.4674425, 1729.0, 8507.427571511613, 2841349530.0464177, 1105.0]
[2019-03-26 16:55:19,167] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.4297545e-12 6.5667974e-04 1.7673651e-11 9.9934334e-01 4.2280932e-18], sum to 1.0000
[2019-03-26 16:55:19,172] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5862
[2019-03-26 16:55:19,180] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.16666666666666, 62.5, 1.0, 2.0, 1.004402037435482, 1.0, 2.0, 1.004402037435482, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2809634.881690987, 2809634.881690987, 531652.6620692572], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3772200.0000, 
sim time next is 3772800.0000, 
raw observation next is [33.0, 63.0, 1.0, 2.0, 1.018884787524294, 1.0, 2.0, 1.018884787524294, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2850194.000154648, 2850194.000154647, 540502.8457550863], 
processed observation next is [1.0, 0.6956521739130435, 0.7630331753554502, 0.63, 1.0, 1.0, 1.0227527560533662, 1.0, 1.0, 1.0227527560533662, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.7917205555985133, 0.7917205555985131, 0.8067206653060989], 
reward next is 0.1933, 
noisyNet noise sample is [array([-0.499668], dtype=float32), -0.29273534]. 
=============================================
[2019-03-26 16:55:21,357] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.0607844e-14 1.0000000e+00 8.8763219e-16 2.6243893e-10 2.7408733e-25], sum to 1.0000
[2019-03-26 16:55:21,367] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8989
[2019-03-26 16:55:21,371] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.33333333333334, 84.0, 1.0, 2.0, 0.9560641707630189, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1336352.111159913, 1336352.111159913, 285829.2553981238], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3997200.0000, 
sim time next is 3997800.0000, 
raw observation next is [29.5, 84.0, 1.0, 2.0, 1.003204192902753, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1402286.256768923, 1402286.256768923, 299908.4481120039], 
processed observation next is [1.0, 0.2608695652173913, 0.5971563981042655, 0.84, 1.0, 1.0, 1.003860473376811, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3895239602135897, 0.3895239602135897, 0.44762454942090135], 
reward next is 0.5524, 
noisyNet noise sample is [array([-0.64961666], dtype=float32), 0.17946908]. 
=============================================
[2019-03-26 16:55:26,258] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.3893273e-16 1.0000000e+00 2.3497006e-19 3.7934818e-19 6.3410389e-29], sum to 1.0000
[2019-03-26 16:55:26,269] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4938
[2019-03-26 16:55:26,276] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 91.5, 1.0, 2.0, 0.5593800536740255, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 781677.2450658308, 781677.2450658302, 193421.7347716822], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3907800.0000, 
sim time next is 3908400.0000, 
raw observation next is [27.0, 90.66666666666666, 1.0, 2.0, 0.5548512991716928, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 775346.4573599938, 775346.4573599938, 192635.5245040893], 
processed observation next is [0.0, 0.21739130434782608, 0.4786729857819906, 0.9066666666666666, 1.0, 1.0, 0.4636762640622805, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2153740159333316, 0.2153740159333316, 0.2875157082150586], 
reward next is 0.7125, 
noisyNet noise sample is [array([-1.3795993], dtype=float32), -0.7700848]. 
=============================================
[2019-03-26 16:55:34,583] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.3935352e-16 1.0000000e+00 8.0256558e-19 3.4273658e-16 4.1482422e-28], sum to 1.0000
[2019-03-26 16:55:34,591] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6199
[2019-03-26 16:55:34,596] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 84.0, 1.0, 2.0, 0.5445282443353512, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 760915.9047814367, 760915.9047814367, 190866.8922560311], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4048800.0000, 
sim time next is 4049400.0000, 
raw observation next is [28.0, 84.0, 1.0, 2.0, 0.5435760300077559, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 759584.8184712358, 759584.8184712352, 190705.3339932352], 
processed observation next is [1.0, 0.8695652173913043, 0.5260663507109005, 0.84, 1.0, 1.0, 0.450091602418983, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2109957829086766, 0.21099578290867646, 0.2846348268555749], 
reward next is 0.7154, 
noisyNet noise sample is [array([-0.15652628], dtype=float32), 1.380837]. 
=============================================
[2019-03-26 16:55:37,815] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.7608306e-13 9.1512226e-07 3.6882060e-12 9.9999905e-01 1.9051409e-17], sum to 1.0000
[2019-03-26 16:55:37,819] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2910
[2019-03-26 16:55:37,828] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [34.33333333333334, 66.5, 1.0, 2.0, 0.8281211786031061, 1.0, 2.0, 0.7346506288158156, 1.0, 1.0, 1.03, 7.005107836567204, 6.9112, 170.5573041426782, 3082917.252501472, 3015647.249241824, 564851.6346738633], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4111800.0000, 
sim time next is 4112400.0000, 
raw observation next is [34.66666666666667, 66.0, 1.0, 2.0, 1.009998177070888, 1.0, 2.0, 1.009998177070888, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2825306.78295733, 2825306.78295733, 535072.0806018577], 
processed observation next is [1.0, 0.6086956521739131, 0.8420221169036337, 0.66, 1.0, 1.0, 1.0120459964709492, 1.0, 1.0, 1.0120459964709492, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7848074397103694, 0.7848074397103694, 0.7986150456744145], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.1270363], dtype=float32), -1.1747361]. 
=============================================
[2019-03-26 16:55:41,804] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.3964657e-17 1.0000000e+00 5.7029702e-20 1.3453165e-18 3.2498842e-30], sum to 1.0000
[2019-03-26 16:55:41,816] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1763
[2019-03-26 16:55:41,824] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [34.0, 52.0, 1.0, 2.0, 0.5316923754061694, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 742972.973956, 742972.9739560005, 188711.4153926059], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4545600.0000, 
sim time next is 4546200.0000, 
raw observation next is [34.0, 52.5, 1.0, 2.0, 0.5339334248901505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 746105.6575136452, 746105.657513646, 189084.4687387619], 
processed observation next is [0.0, 0.6086956521739131, 0.8104265402843602, 0.525, 1.0, 1.0, 0.43847400589174756, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20725157153156812, 0.2072515715315683, 0.2822156249832267], 
reward next is 0.7178, 
noisyNet noise sample is [array([0.13814613], dtype=float32), -0.42405453]. 
=============================================
[2019-03-26 16:55:43,387] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.9301868e-16 1.0000000e+00 1.7162555e-17 1.4782512e-11 1.4789386e-27], sum to 1.0000
[2019-03-26 16:55:43,399] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9269
[2019-03-26 16:55:43,405] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [35.66666666666666, 52.16666666666667, 1.0, 2.0, 0.5779194439803232, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 807594.0232497066, 807594.023249706, 196705.767820954], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4302600.0000, 
sim time next is 4303200.0000, 
raw observation next is [35.33333333333334, 54.33333333333334, 1.0, 2.0, 0.5835988815907122, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 815533.6085446333, 815533.6085446333, 197731.5894127022], 
processed observation next is [1.0, 0.8260869565217391, 0.8736176935229073, 0.5433333333333334, 1.0, 1.0, 0.4983119055309785, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22653711348462036, 0.22653711348462036, 0.2951217752428391], 
reward next is 0.7049, 
noisyNet noise sample is [array([-2.3212593], dtype=float32), 0.28028464]. 
=============================================
[2019-03-26 16:55:49,167] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.3498401e-17 1.0000000e+00 4.2380252e-19 2.7154923e-16 1.0928246e-27], sum to 1.0000
[2019-03-26 16:55:49,183] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3858
[2019-03-26 16:55:49,192] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 82.33333333333334, 1.0, 2.0, 0.5030839916098296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 702983.1410419017, 702983.141041901, 184080.5596017292], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4916400.0000, 
sim time next is 4917000.0000, 
raw observation next is [27.0, 83.16666666666666, 1.0, 2.0, 0.5046798576487501, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 705213.8606261248, 705213.8606261241, 184332.621123565], 
processed observation next is [1.0, 0.9130434782608695, 0.4786729857819906, 0.8316666666666666, 1.0, 1.0, 0.4032287441551206, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19589273906281243, 0.19589273906281224, 0.27512331510979854], 
reward next is 0.7249, 
noisyNet noise sample is [array([1.7473633], dtype=float32), -0.55468714]. 
=============================================
[2019-03-26 16:55:49,207] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[67.34382 ]
 [67.18134 ]
 [67.188416]
 [67.37367 ]
 [67.38872 ]], R is [[67.62309265]
 [67.67211151]
 [67.72149658]
 [67.77125549]
 [67.82175446]].
[2019-03-26 16:55:55,772] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0882961e-16 1.0000000e+00 1.1446810e-19 2.4302326e-19 8.6810322e-30], sum to 1.0000
[2019-03-26 16:55:55,785] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0476
[2019-03-26 16:55:55,792] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 87.33333333333334, 1.0, 2.0, 0.5031500513758868, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 703075.4800365015, 703075.4800365015, 184090.356017219], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4504800.0000, 
sim time next is 4505400.0000, 
raw observation next is [26.0, 86.5, 1.0, 2.0, 0.4995824983773147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 698088.7306454465, 698088.730645447, 183529.8919037986], 
processed observation next is [0.0, 0.13043478260869565, 0.4312796208530806, 0.865, 1.0, 1.0, 0.3970873474425478, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19391353629040178, 0.19391353629040195, 0.2739252117967143], 
reward next is 0.7261, 
noisyNet noise sample is [array([0.32525042], dtype=float32), 0.9297525]. 
=============================================
[2019-03-26 16:56:00,340] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.7920876e-17 1.0000000e+00 3.9850508e-21 2.6150670e-20 9.6216028e-31], sum to 1.0000
[2019-03-26 16:56:00,342] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5295
[2019-03-26 16:56:00,348] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 84.0, 1.0, 2.0, 0.5503291039239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 769024.8765466859, 769024.8765466859, 191856.900474853], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4485600.0000, 
sim time next is 4486200.0000, 
raw observation next is [27.83333333333334, 84.0, 1.0, 2.0, 0.5470719723925926, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 764471.7527503562, 764471.7527503555, 191299.3524446019], 
processed observation next is [0.0, 0.9565217391304348, 0.5181674565560824, 0.84, 1.0, 1.0, 0.4543035811958947, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21235326465287674, 0.21235326465287654, 0.2855214215591073], 
reward next is 0.7145, 
noisyNet noise sample is [array([1.5181286], dtype=float32), -0.84863245]. 
=============================================
[2019-03-26 16:56:05,130] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.3308681e-15 1.0000000e+00 1.3910641e-18 8.6852260e-18 3.6885381e-28], sum to 1.0000
[2019-03-26 16:56:05,142] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6888
[2019-03-26 16:56:05,150] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 88.16666666666667, 1.0, 2.0, 0.5706578546402168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 797442.7510791074, 797442.7510791081, 195406.6287452879], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4582200.0000, 
sim time next is 4582800.0000, 
raw observation next is [28.0, 89.0, 1.0, 2.0, 0.5749748095201753, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 803477.5868381604, 803477.5868381604, 196176.1679645576], 
processed observation next is [1.0, 0.043478260869565216, 0.5260663507109005, 0.89, 1.0, 1.0, 0.4879214572532233, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22318821856615567, 0.22318821856615567, 0.29280025069336957], 
reward next is 0.7072, 
noisyNet noise sample is [array([-0.09259386], dtype=float32), 1.21665]. 
=============================================
[2019-03-26 16:56:05,931] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.6573540e-15 1.0000000e+00 2.8529843e-17 8.9287654e-14 2.0489232e-25], sum to 1.0000
[2019-03-26 16:56:05,939] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9907
[2019-03-26 16:56:05,947] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.66666666666667, 85.66666666666667, 1.0, 2.0, 0.5417827096919977, 1.0, 2.0, 0.5417827096919977, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1514685.498569606, 1514685.498569606, 313759.3328913067], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4606800.0000, 
sim time next is 4607400.0000, 
raw observation next is [29.83333333333333, 84.83333333333333, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.136555650542752, 6.9112, 168.9115927618169, 1613738.182714873, 1453864.418856456, 311356.3845316944], 
processed observation next is [1.0, 0.30434782608695654, 0.6129541864139019, 0.8483333333333333, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.022535565054275165, 0.0, 0.8294332485222806, 0.44826060630968695, 0.40385122746012664, 0.4647110216890961], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1407521], dtype=float32), -0.30718097]. 
=============================================
[2019-03-26 16:56:06,841] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.3054741e-17 1.0000000e+00 4.1199850e-19 3.0804603e-17 3.5880879e-28], sum to 1.0000
[2019-03-26 16:56:06,848] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2090
[2019-03-26 16:56:06,853] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.5095729359178413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 712053.4899285479, 712053.4899285479, 185109.5844097558], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4925400.0000, 
sim time next is 4926000.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.5092655411012385, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 711623.8068491325, 711623.806849132, 185060.582680728], 
processed observation next is [1.0, 0.0, 0.4786729857819906, 0.84, 1.0, 1.0, 0.4087536639773957, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1976732796803146, 0.19767327968031442, 0.27620982489660895], 
reward next is 0.7238, 
noisyNet noise sample is [array([0.43031052], dtype=float32), 0.38364133]. 
=============================================
[2019-03-26 16:56:06,878] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[67.81592 ]
 [68.438736]
 [69.255226]
 [69.24567 ]
 [69.23332 ]], R is [[67.30414581]
 [67.35482025]
 [67.40498352]
 [67.45469666]
 [67.50392151]].
[2019-03-26 16:56:09,524] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0796545e-15 1.0000000e+00 5.1008527e-19 9.6487601e-17 5.7497372e-28], sum to 1.0000
[2019-03-26 16:56:09,537] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0766
[2019-03-26 16:56:09,543] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.6, 86.83333333333333, 1.0, 2.0, 0.5786719237302794, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 808645.950957457, 808645.950957457, 196840.0829238772], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5277000.0000, 
sim time next is 5277600.0000, 
raw observation next is [28.6, 87.0, 1.0, 2.0, 0.5802270925260518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 810819.9996689438, 810819.9996689438, 197120.3107537131], 
processed observation next is [1.0, 0.08695652173913043, 0.5545023696682465, 0.87, 1.0, 1.0, 0.49424950906753223, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22522777768581773, 0.22522777768581773, 0.29420941903539266], 
reward next is 0.7058, 
noisyNet noise sample is [array([-0.13455357], dtype=float32), 1.1179928]. 
=============================================
[2019-03-26 16:56:09,698] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.6958266e-17 1.0000000e+00 4.1055512e-19 2.7384925e-16 2.8930913e-28], sum to 1.0000
[2019-03-26 16:56:09,706] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5104
[2019-03-26 16:56:09,712] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666666, 90.0, 1.0, 2.0, 0.4572043061861639, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 651777.7078058596, 651777.7078058602, 178824.3913709563], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4654200.0000, 
sim time next is 4654800.0000, 
raw observation next is [24.0, 94.0, 1.0, 2.0, 0.4518132224550012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 647699.9483840843, 647699.9483840849, 178493.5296850415], 
processed observation next is [1.0, 0.9130434782608695, 0.3364928909952607, 0.94, 1.0, 1.0, 0.33953400295783276, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1799166523289123, 0.17991665232891246, 0.26640825326125595], 
reward next is 0.7336, 
noisyNet noise sample is [array([-0.226738], dtype=float32), 0.41765752]. 
=============================================
[2019-03-26 16:56:11,544] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-26 16:56:11,546] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 16:56:11,547] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:56:11,547] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 16:56:11,548] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 16:56:11,549] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 16:56:11,549] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:56:11,548] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 16:56:11,551] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:56:11,552] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:56:11,550] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:56:11,572] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run57
[2019-03-26 16:56:11,595] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run57
[2019-03-26 16:56:11,621] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run57
[2019-03-26 16:56:11,622] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run57
[2019-03-26 16:56:11,643] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run57
[2019-03-26 16:56:31,683] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10271902], dtype=float32), 0.07790198]
[2019-03-26 16:56:31,685] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.32264789, 86.47138281833332, 1.0, 2.0, 0.5014159488188403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 700651.536984976, 700651.5369849754, 183818.0317262632]
[2019-03-26 16:56:31,691] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 16:56:31,693] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.4191730e-16 1.0000000e+00 6.5915548e-20 8.1859732e-20 2.4253303e-29], sampled 0.285955177221779
[2019-03-26 16:56:37,951] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10271902], dtype=float32), 0.07790198]
[2019-03-26 16:56:37,955] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [24.7002348, 90.48378865666666, 1.0, 2.0, 0.4655132811802227, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 657784.4342594763, 657784.4342594763, 179312.1096321404]
[2019-03-26 16:56:37,957] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 16:56:37,960] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.2880279e-16 1.0000000e+00 6.0899156e-20 8.7437909e-20 2.3584533e-29], sampled 0.04389632104059882
[2019-03-26 16:57:46,251] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10271902], dtype=float32), 0.07790198]
[2019-03-26 16:57:46,251] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [31.23333333333333, 64.5, 1.0, 2.0, 0.5437998805275853, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 759897.7356486351, 759897.7356486351, 190742.9608123895]
[2019-03-26 16:57:46,251] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:57:46,255] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.7354453e-15 1.0000000e+00 3.0678071e-17 1.5633848e-12 3.9534234e-27], sampled 0.9180365063496316
[2019-03-26 16:57:52,632] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10271902], dtype=float32), 0.07790198]
[2019-03-26 16:57:52,633] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [30.95, 70.0, 1.0, 2.0, 0.5846867661586173, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 817054.4265157406, 817054.4265157412, 197926.4658634719]
[2019-03-26 16:57:52,634] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:57:52,637] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.5684108e-17 1.0000000e+00 1.9793248e-20 2.4743107e-19 3.4028884e-30], sampled 0.4682957935051827
[2019-03-26 16:58:07,419] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8252.9975 2927547432.8278 1337.0000
[2019-03-26 16:58:07,691] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.5980 3007332863.3769 1757.0000
[2019-03-26 16:58:07,838] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7887.6400 3163973294.9166 1761.0000
[2019-03-26 16:58:07,951] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8500.0720 2842158154.8699 1124.0000
[2019-03-26 16:58:07,980] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.3694 2779190338.1949 933.0000
[2019-03-26 16:58:08,995] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 1400000, evaluation results [1400000.0, 7887.639993954778, 3163973294.9166384, 1761.0, 8252.997529007436, 2927547432.8277974, 1337.0, 8661.369356548688, 2779190338.194891, 933.0, 7998.598046027171, 3007332863.376906, 1757.0, 8500.071963036788, 2842158154.8699193, 1124.0]
[2019-03-26 16:58:10,055] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.7288226e-13 1.0000000e+00 1.8293244e-15 4.7936148e-09 8.5238058e-25], sum to 1.0000
[2019-03-26 16:58:10,063] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5575
[2019-03-26 16:58:10,067] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 70.0, 1.0, 2.0, 0.5176365907795337, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 723325.102033454, 723325.1020334547, 186406.7668424019], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4730400.0000, 
sim time next is 4731000.0000, 
raw observation next is [29.83333333333333, 70.66666666666667, 1.0, 2.0, 0.5197230506336421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 726241.6359888734, 726241.635988874, 186744.9725686727], 
processed observation next is [1.0, 0.782608695652174, 0.6129541864139019, 0.7066666666666667, 1.0, 1.0, 0.4213530730525808, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20173378777468706, 0.20173378777468723, 0.2787238396547354], 
reward next is 0.7213, 
noisyNet noise sample is [array([-0.8239275], dtype=float32), 0.8571619]. 
=============================================
[2019-03-26 16:58:10,074] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[71.11627 ]
 [68.53131 ]
 [65.6564  ]
 [61.66802 ]
 [57.126945]], R is [[73.11396027]
 [73.104599  ]
 [73.09571838]
 [73.08752441]
 [73.08098602]].
[2019-03-26 16:58:15,691] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.7327843e-16 1.0000000e+00 1.7305536e-18 4.2511453e-13 2.3679111e-28], sum to 1.0000
[2019-03-26 16:58:15,698] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8146
[2019-03-26 16:58:15,703] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 70.0, 1.0, 2.0, 0.4941468644663641, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 690490.8102938831, 690490.8102938831, 182684.461295626], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4905600.0000, 
sim time next is 4906200.0000, 
raw observation next is [29.0, 70.0, 1.0, 2.0, 0.4959905872453618, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 693067.9569431343, 693067.9569431336, 182970.5333577358], 
processed observation next is [1.0, 0.782608695652174, 0.5734597156398105, 0.7, 1.0, 1.0, 0.3927597436691106, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1925188769286484, 0.19251887692864822, 0.27309034829512807], 
reward next is 0.7269, 
noisyNet noise sample is [array([1.1650745], dtype=float32), 1.1032034]. 
=============================================
[2019-03-26 16:58:18,587] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.6804558e-16 1.0000000e+00 9.5277941e-19 7.4887645e-17 2.0530521e-27], sum to 1.0000
[2019-03-26 16:58:18,598] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5426
[2019-03-26 16:58:18,605] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 86.5, 1.0, 2.0, 0.7083731187865361, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 989977.070556159, 989977.0705561584, 222660.9216113446], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4948200.0000, 
sim time next is 4948800.0000, 
raw observation next is [26.66666666666667, 85.66666666666667, 1.0, 2.0, 0.6938076321160952, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 969611.9831980718, 969611.9831980718, 219512.3938610719], 
processed observation next is [1.0, 0.2608695652173913, 0.4628751974723541, 0.8566666666666667, 1.0, 1.0, 0.6310935326699942, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2693366619994644, 0.2693366619994644, 0.3276304385986148], 
reward next is 0.6724, 
noisyNet noise sample is [array([-0.6607252], dtype=float32), 0.63645726]. 
=============================================
[2019-03-26 16:58:21,398] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.6957015e-10 3.6636144e-02 8.9832314e-10 9.6336383e-01 3.0149610e-15], sum to 1.0000
[2019-03-26 16:58:21,407] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0924
[2019-03-26 16:58:21,412] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.33333333333334, 69.0, 1.0, 2.0, 0.9116494391763527, 1.0, 2.0, 0.9116494391763527, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2549911.314238071, 2549911.314238071, 477887.7171638847], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5224800.0000, 
sim time next is 5225400.0000, 
raw observation next is [31.5, 68.5, 1.0, 2.0, 0.9144349289049969, 1.0, 2.0, 0.9144349289049969, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2557710.388431021, 2557710.388431021, 479429.1317396939], 
processed observation next is [1.0, 0.4782608695652174, 0.6919431279620853, 0.685, 1.0, 1.0, 0.8969095528975866, 1.0, 1.0, 0.8969095528975866, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7104751078975058, 0.7104751078975058, 0.7155658682681999], 
reward next is 0.2844, 
noisyNet noise sample is [array([0.49726632], dtype=float32), 1.3231584]. 
=============================================
[2019-03-26 16:58:26,158] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.0253631e-16 1.0000000e+00 2.2371437e-20 2.1786211e-19 1.4682565e-29], sum to 1.0000
[2019-03-26 16:58:26,168] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4584
[2019-03-26 16:58:26,171] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.66666666666667, 75.66666666666667, 1.0, 2.0, 0.5237618848688189, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 731887.2968138687, 731887.2968138687, 187402.7654888128], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5080800.0000, 
sim time next is 5081400.0000, 
raw observation next is [28.5, 76.5, 1.0, 2.0, 0.5227962368662996, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 730537.4686691919, 730537.4686691919, 187244.7937217077], 
processed observation next is [0.0, 0.8260869565217391, 0.5497630331753555, 0.765, 1.0, 1.0, 0.42505570706783086, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2029270746303311, 0.2029270746303311, 0.27946984137568315], 
reward next is 0.7205, 
noisyNet noise sample is [array([1.5098329], dtype=float32), -0.0442381]. 
=============================================
[2019-03-26 16:58:29,335] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.6833681e-17 1.0000000e+00 2.4928501e-20 1.3257882e-19 2.5615310e-30], sum to 1.0000
[2019-03-26 16:58:29,350] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7216
[2019-03-26 16:58:29,359] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 63.0, 1.0, 2.0, 0.5177056254068089, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 723421.6011666113, 723421.6011666113, 186417.1241739583], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5054400.0000, 
sim time next is 5055000.0000, 
raw observation next is [31.16666666666667, 63.0, 1.0, 2.0, 0.5227724539329466, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 730504.2237892565, 730504.2237892571, 187241.4677359061], 
processed observation next is [0.0, 0.5217391304347826, 0.6761453396524489, 0.63, 1.0, 1.0, 0.4250270529312609, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20291783994146015, 0.20291783994146032, 0.2794648772177703], 
reward next is 0.7205, 
noisyNet noise sample is [array([-1.6797243], dtype=float32), 1.4571369]. 
=============================================
[2019-03-26 16:58:29,376] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[73.22033]
 [73.17277]
 [73.1531 ]
 [73.12869]
 [73.10436]], R is [[73.2600708 ]
 [73.24923706]
 [73.23841095]
 [73.22764587]
 [73.21704102]].
[2019-03-26 16:58:30,004] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.0656883e-17 1.0000000e+00 3.7203059e-20 7.7864178e-20 3.9868570e-30], sum to 1.0000
[2019-03-26 16:58:30,013] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9019
[2019-03-26 16:58:30,018] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.33333333333334, 65.0, 1.0, 2.0, 0.508066914699337, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 709948.342770735, 709948.3427707345, 184870.064162707], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5048400.0000, 
sim time next is 5049000.0000, 
raw observation next is [30.5, 64.5, 1.0, 2.0, 0.5102633896284433, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 713018.6215941472, 713018.6215941465, 185220.1944383688], 
processed observation next is [0.0, 0.43478260869565216, 0.6445497630331753, 0.645, 1.0, 1.0, 0.40995589111860636, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19806072822059645, 0.19806072822059625, 0.27644805140055045], 
reward next is 0.7236, 
noisyNet noise sample is [array([-0.06761702], dtype=float32), 0.1656163]. 
=============================================
[2019-03-26 16:58:30,030] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[73.33045 ]
 [73.305534]
 [73.25496 ]
 [73.209816]
 [73.19093 ]], R is [[73.34528351]
 [73.33590698]
 [73.32726288]
 [73.31867218]
 [73.30984497]].
[2019-03-26 16:58:31,339] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.7830283e-17 1.0000000e+00 4.8835548e-21 4.9620921e-19 1.8105726e-30], sum to 1.0000
[2019-03-26 16:58:31,348] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2485
[2019-03-26 16:58:31,352] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.16666666666666, 68.83333333333333, 1.0, 2.0, 0.5281310652742466, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 737994.7638898012, 737994.7638898012, 188121.4172582703], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5071800.0000, 
sim time next is 5072400.0000, 
raw observation next is [30.0, 70.0, 1.0, 2.0, 0.5299414630530386, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 740525.4421315795, 740525.4421315801, 188420.6451424913], 
processed observation next is [0.0, 0.7391304347826086, 0.6208530805687204, 0.7, 1.0, 1.0, 0.4336644133169139, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20570151170321652, 0.20570151170321668, 0.28122484349625565], 
reward next is 0.7188, 
noisyNet noise sample is [array([1.2120435], dtype=float32), 0.74215144]. 
=============================================
[2019-03-26 16:58:33,799] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.3633812e-17 1.0000000e+00 4.9812067e-20 3.2739411e-20 4.3973720e-29], sum to 1.0000
[2019-03-26 16:58:33,803] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9396
[2019-03-26 16:58:33,811] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.83333333333333, 66.33333333333333, 1.0, 2.0, 0.5587821854353346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 780841.4773765682, 780841.4773765688, 193319.4404316455], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5140200.0000, 
sim time next is 5140800.0000, 
raw observation next is [32.0, 67.0, 1.0, 2.0, 0.5682425839325336, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 794066.3670615365, 794066.3670615365, 194979.8072214978], 
processed observation next is [0.0, 0.5217391304347826, 0.7156398104265403, 0.67, 1.0, 1.0, 0.4798103420873898, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2205739908504268, 0.2205739908504268, 0.2910146376440266], 
reward next is 0.7090, 
noisyNet noise sample is [array([0.732573], dtype=float32), -0.24234585]. 
=============================================
[2019-03-26 16:58:40,830] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.2334700e-15 1.0000000e+00 3.6967448e-16 1.0503771e-10 5.8937528e-27], sum to 1.0000
[2019-03-26 16:58:40,839] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4159
[2019-03-26 16:58:40,842] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.81666666666667, 75.5, 1.0, 2.0, 0.5517074822705876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 770951.708893965, 770951.7088939657, 192094.7839103541], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5249400.0000, 
sim time next is 5250000.0000, 
raw observation next is [29.63333333333334, 76.0, 1.0, 2.0, 0.5546064227251032, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 775004.1433910981, 775004.1433910981, 192594.1976803819], 
processed observation next is [1.0, 0.782608695652174, 0.6034755134281204, 0.76, 1.0, 1.0, 0.46338123219891947, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2152789287197495, 0.2152789287197495, 0.2874540263886297], 
reward next is 0.7125, 
noisyNet noise sample is [array([0.06202946], dtype=float32), 2.0541608]. 
=============================================
[2019-03-26 16:58:40,856] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[76.82098 ]
 [75.17824 ]
 [73.047356]
 [70.55742 ]
 [67.14399 ]], R is [[77.90698242]
 [77.84120941]
 [77.77759552]
 [77.71617126]
 [77.6559906 ]].
[2019-03-26 16:58:57,828] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.3942844e-17 1.0000000e+00 4.7223405e-20 1.9832233e-14 1.1603793e-29], sum to 1.0000
[2019-03-26 16:58:57,834] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5150
[2019-03-26 16:58:57,840] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.2, 80.66666666666667, 1.0, 2.0, 0.5614014571686536, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 784502.9958421707, 784502.9958421714, 193776.0405801369], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5858400.0000, 
sim time next is 5859000.0000, 
raw observation next is [29.0, 82.0, 1.0, 2.0, 0.5623294158321821, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 785800.2059291066, 785800.2059291066, 193938.4094615908], 
processed observation next is [1.0, 0.8260869565217391, 0.5734597156398105, 0.82, 1.0, 1.0, 0.4726860431713037, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21827783498030737, 0.21827783498030737, 0.28946031262924], 
reward next is 0.7105, 
noisyNet noise sample is [array([-0.270392], dtype=float32), 0.7460478]. 
=============================================
[2019-03-26 16:58:57,849] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[77.83316 ]
 [78.49355 ]
 [78.7822  ]
 [79.044876]
 [79.00287 ]], R is [[76.89814758]
 [76.83995056]
 [76.78232574]
 [76.72589111]
 [76.67020416]].
[2019-03-26 16:59:02,825] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-26 16:59:02,826] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 16:59:02,827] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:59:02,827] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 16:59:02,828] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 16:59:02,828] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 16:59:02,829] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:59:02,829] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:59:02,832] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:59:02,832] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 16:59:02,836] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:59:02,867] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run58
[2019-03-26 16:59:02,888] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run58
[2019-03-26 16:59:02,889] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run58
[2019-03-26 16:59:02,927] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run58
[2019-03-26 16:59:02,956] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run58
[2019-03-26 16:59:04,963] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10167703], dtype=float32), 0.07923472]
[2019-03-26 16:59:04,964] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [22.63333333333333, 86.33333333333334, 1.0, 2.0, 0.3558315640011204, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 553045.5382695739, 553045.5382695745, 171025.2410456562]
[2019-03-26 16:59:04,966] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 16:59:04,967] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.2027790e-16 1.0000000e+00 5.0857342e-20 4.5760892e-20 1.6689778e-29], sampled 0.5661607726972209
[2019-03-26 16:59:18,096] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10167703], dtype=float32), 0.07923472]
[2019-03-26 16:59:18,097] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [21.9, 93.0, 1.0, 2.0, 0.5464192945959767, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 846897.5477797518, 846897.5477797525, 201097.2470592801]
[2019-03-26 16:59:18,098] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:59:18,102] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.2733618e-16 1.0000000e+00 5.4198108e-20 5.5837541e-20 2.0056901e-29], sampled 0.9102954588280112
[2019-03-26 17:00:02,348] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10167703], dtype=float32), 0.07923472]
[2019-03-26 17:00:02,350] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [35.35, 51.66666666666666, 1.0, 2.0, 0.3531845484049549, 0.0, 2.0, 0.0, 1.0, 1.0, 0.6133647606644418, 6.911200000000001, 6.9112, 168.9126187535634, 987175.0765233679, 987175.0765233673, 240587.3901249541]
[2019-03-26 17:00:02,352] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:00:02,354] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.6512862e-11 9.9997628e-01 1.3718517e-11 2.3715414e-05 2.3834984e-19], sampled 0.5725947476152934
[2019-03-26 17:00:25,620] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10167703], dtype=float32), 0.07923472]
[2019-03-26 17:00:25,621] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.91773, 56.91287737, 1.0, 2.0, 0.846771609331462, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1212709.262106378, 1212709.262106378, 259901.4790350065]
[2019-03-26 17:00:25,622] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 17:00:25,625] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.0239188e-16 1.0000000e+00 2.3400224e-19 1.0177946e-17 1.3205579e-28], sampled 0.5220766124402281
[2019-03-26 17:00:38,066] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10167703], dtype=float32), 0.07923472]
[2019-03-26 17:00:38,069] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.3, 91.0, 1.0, 2.0, 0.6832307646945794, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 954823.9250331098, 954823.9250331093, 217266.3017586991]
[2019-03-26 17:00:38,070] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:00:38,073] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.4974879e-16 1.0000000e+00 1.1580372e-19 1.3737882e-18 6.6836383e-29], sampled 0.14691860747441665
[2019-03-26 17:00:58,376] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8499.8642 2842031122.9930 1123.0000
[2019-03-26 17:00:58,564] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7999.8908 3007214625.5272 1753.0000
[2019-03-26 17:00:58,909] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7897.7283 3162998041.8406 1734.0000
[2019-03-26 17:00:58,987] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8257.4687 2927439398.9100 1336.0000
[2019-03-26 17:00:59,077] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.3694 2779190338.1949 933.0000
[2019-03-26 17:01:00,095] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 1425000, evaluation results [1425000.0, 7897.728331800345, 3162998041.840623, 1734.0, 8257.468659012906, 2927439398.909958, 1336.0, 8661.369356548688, 2779190338.194891, 933.0, 7999.890806861943, 3007214625.5272303, 1753.0, 8499.864174347162, 2842031122.993008, 1123.0]
[2019-03-26 17:01:03,715] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.2412427e-17 1.0000000e+00 2.3582932e-20 2.1078817e-19 1.5002503e-30], sum to 1.0000
[2019-03-26 17:01:03,726] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5522
[2019-03-26 17:01:03,734] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.9, 59.0, 1.0, 2.0, 0.5238388434764223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 731994.8732449397, 731994.8732449391, 187415.6523649558], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5677200.0000, 
sim time next is 5677800.0000, 
raw observation next is [31.68333333333333, 60.33333333333334, 1.0, 2.0, 0.5257630584048668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 734684.6366596281, 734684.6366596281, 187731.3094257401], 
processed observation next is [0.0, 0.7391304347826086, 0.7006319115323854, 0.6033333333333334, 1.0, 1.0, 0.4286301908492371, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2040790657387856, 0.2040790657387856, 0.2801959842175225], 
reward next is 0.7198, 
noisyNet noise sample is [array([0.03270363], dtype=float32), -0.30194747]. 
=============================================
[2019-03-26 17:01:05,616] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.8898707e-09 9.8754346e-01 4.2299136e-10 1.2456568e-02 6.9618432e-17], sum to 1.0000
[2019-03-26 17:01:05,626] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0482
[2019-03-26 17:01:05,638] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1898447.998633239 W.
[2019-03-26 17:01:05,643] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.0, 65.0, 1.0, 2.0, 0.6789279320736686, 1.0, 1.0, 0.6789279320736686, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 1898447.998633239, 1898447.998633238, 365233.1048724839], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6087600.0000, 
sim time next is 6088200.0000, 
raw observation next is [31.0, 65.0, 1.0, 2.0, 0.560358287749044, 1.0, 2.0, 0.560358287749044, 1.0, 1.0, 0.967852634430178, 6.9112, 6.9112, 170.5573041426782, 2350821.75937666, 2350821.75937666, 458306.7459876636], 
processed observation next is [1.0, 0.4782608695652174, 0.6682464454976303, 0.65, 1.0, 1.0, 0.47031119005908906, 1.0, 1.0, 0.47031119005908906, 1.0, 0.5, 0.9607958956465584, 0.0, 0.0, 0.8375144448122397, 0.6530060442712945, 0.6530060442712945, 0.6840399193845725], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1058834], dtype=float32), 2.8545082]. 
=============================================
[2019-03-26 17:01:14,582] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.3936284e-16 1.0000000e+00 1.4213657e-18 7.8130928e-16 2.7716139e-27], sum to 1.0000
[2019-03-26 17:01:14,592] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5611
[2019-03-26 17:01:14,599] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.8, 95.0, 1.0, 2.0, 0.9620627942517301, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1344742.081665313, 1344742.081665313, 287578.9995235306], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5887800.0000, 
sim time next is 5888400.0000, 
raw observation next is [25.76666666666667, 95.0, 1.0, 2.0, 0.8652177586961459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1209297.945986567, 1209297.945986568, 260548.0217877897], 
processed observation next is [1.0, 0.13043478260869565, 0.42022116903633505, 0.95, 1.0, 1.0, 0.8376117574652361, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3359160961073797, 0.33591609610738, 0.3888776444593876], 
reward next is 0.6111, 
noisyNet noise sample is [array([-1.6815624], dtype=float32), 1.3871752]. 
=============================================
[2019-03-26 17:01:15,488] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.6424439e-15 1.0000000e+00 8.2559772e-18 4.1525130e-15 2.6774614e-26], sum to 1.0000
[2019-03-26 17:01:15,498] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5329
[2019-03-26 17:01:15,507] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1963679.944062809 W.
[2019-03-26 17:01:15,514] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.6, 83.5, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.629502893913581, 6.9112, 168.9087034292206, 1963679.944062809, 1454103.98004513, 311352.6526017103], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5902200.0000, 
sim time next is 5902800.0000, 
raw observation next is [28.8, 82.66666666666667, 1.0, 2.0, 0.5185958919217424, 1.0, 1.0, 0.5185958919217424, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1449817.260646099, 1449817.260646099, 306136.8853373613], 
processed observation next is [1.0, 0.30434782608695654, 0.5639810426540285, 0.8266666666666667, 1.0, 1.0, 0.4199950505081233, 1.0, 0.5, 0.4199950505081233, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.4027270168461386, 0.4027270168461386, 0.45692072438412135], 
reward next is 0.5431, 
noisyNet noise sample is [array([2.5248444], dtype=float32), -1.1517259]. 
=============================================
[2019-03-26 17:01:15,981] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.2692681e-16 1.0000000e+00 8.0595268e-19 7.1104867e-15 2.4649902e-29], sum to 1.0000
[2019-03-26 17:01:15,992] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7266
[2019-03-26 17:01:15,998] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.66666666666666, 84.0, 1.0, 2.0, 0.5296840628485503, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 740165.6329392651, 740165.6329392645, 188378.0031029248], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6205200.0000, 
sim time next is 6205800.0000, 
raw observation next is [27.58333333333334, 84.5, 1.0, 2.0, 0.530354557545269, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 741102.8902399419, 741102.8902399419, 188488.9550259797], 
processed observation next is [1.0, 0.8260869565217391, 0.506319115323855, 0.845, 1.0, 1.0, 0.4341621175244204, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2058619139555394, 0.2058619139555394, 0.2813267985462384], 
reward next is 0.7187, 
noisyNet noise sample is [array([-0.2650562], dtype=float32), 0.08883007]. 
=============================================
[2019-03-26 17:01:20,093] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.8313632e-15 1.0000000e+00 6.9461825e-19 4.3041450e-17 5.6235339e-28], sum to 1.0000
[2019-03-26 17:01:20,103] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3459
[2019-03-26 17:01:20,108] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 91.33333333333334, 1.0, 2.0, 0.6156870231956513, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 860392.4285413763, 860392.4285413756, 203698.7310376298], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5982000.0000, 
sim time next is 5982600.0000, 
raw observation next is [26.65, 90.66666666666666, 1.0, 2.0, 0.6207729797828606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 867502.7060887204, 867502.7060887197, 204673.5221518826], 
processed observation next is [1.0, 0.21739130434782608, 0.462085308056872, 0.9066666666666666, 1.0, 1.0, 0.5430999756420007, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.24097297391353342, 0.24097297391353323, 0.30548286888340687], 
reward next is 0.6945, 
noisyNet noise sample is [array([0.59399796], dtype=float32), 0.8032584]. 
=============================================
[2019-03-26 17:01:23,975] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.4446760e-16 1.0000000e+00 7.2546428e-19 1.5898349e-16 2.1001199e-27], sum to 1.0000
[2019-03-26 17:01:23,982] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0203
[2019-03-26 17:01:23,987] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.2, 93.0, 1.0, 2.0, 0.8073139519324175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1128323.926483824, 1128323.926483823, 245713.4375419818], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6057600.0000, 
sim time next is 6058200.0000, 
raw observation next is [26.2, 93.0, 1.0, 2.0, 0.7618482518234919, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1064747.969854066, 1064747.969854066, 234760.9513913244], 
processed observation next is [1.0, 0.08695652173913043, 0.44075829383886256, 0.93, 1.0, 1.0, 0.7130701829198698, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2957633249594628, 0.2957633249594628, 0.3503894796885439], 
reward next is 0.6496, 
noisyNet noise sample is [array([-0.79271495], dtype=float32), -0.12199193]. 
=============================================
[2019-03-26 17:01:33,126] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.3200804e-16 1.0000000e+00 2.2840463e-19 1.3046582e-16 9.5036111e-28], sum to 1.0000
[2019-03-26 17:01:33,133] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3105
[2019-03-26 17:01:33,136] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.56666666666667, 63.66666666666667, 1.0, 2.0, 0.3230403350281488, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 508310.362703042, 508310.362703042, 167600.9344674215], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6816000.0000, 
sim time next is 6816600.0000, 
raw observation next is [25.45, 64.5, 1.0, 2.0, 0.3244562366740797, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 510224.5839530903, 510224.5839530903, 167740.2925411642], 
processed observation next is [1.0, 0.9130434782608695, 0.4052132701421801, 0.645, 1.0, 1.0, 0.18609185141455384, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14172905109808065, 0.14172905109808065, 0.2503586455838272], 
reward next is 0.7496, 
noisyNet noise sample is [array([1.19202], dtype=float32), -1.0874892]. 
=============================================
[2019-03-26 17:01:37,131] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.8441007e-17 1.0000000e+00 3.1428304e-20 5.1082523e-19 2.5145861e-29], sum to 1.0000
[2019-03-26 17:01:37,141] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0362
[2019-03-26 17:01:37,147] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.43333333333333, 63.0, 1.0, 2.0, 0.5033983038012505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 703422.489804685, 703422.4898046857, 184130.3470710506], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6281400.0000, 
sim time next is 6282000.0000, 
raw observation next is [30.4, 63.0, 1.0, 2.0, 0.5024094626308534, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 702040.278220611, 702040.278220611, 183974.5543643206], 
processed observation next is [0.0, 0.7391304347826086, 0.6398104265402843, 0.63, 1.0, 1.0, 0.4004933284709077, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19501118839461418, 0.19501118839461418, 0.27458888711092627], 
reward next is 0.7254, 
noisyNet noise sample is [array([0.93739045], dtype=float32), 0.87378025]. 
=============================================
[2019-03-26 17:01:37,156] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[74.48034]
 [74.46775]
 [74.44819]
 [74.42891]
 [74.41347]], R is [[74.49269104]
 [74.47294617]
 [74.45315552]
 [74.43334198]
 [74.41342163]].
[2019-03-26 17:01:41,643] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.4007662e-10 4.0846761e-02 1.3753277e-09 9.5915318e-01 5.5942852e-16], sum to 1.0000
[2019-03-26 17:01:41,653] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8058
[2019-03-26 17:01:41,661] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.93333333333334, 63.66666666666667, 1.0, 2.0, 0.703499407849553, 1.0, 2.0, 0.703499407849553, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1967218.913604855, 1967218.913604855, 375616.2287322386], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6708000.0000, 
sim time next is 6708600.0000, 
raw observation next is [29.9, 64.0, 1.0, 2.0, 0.7217128441906745, 1.0, 2.0, 0.7217128441906745, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2018197.727295577, 2018197.727295577, 383548.1398486932], 
processed observation next is [1.0, 0.6521739130434783, 0.6161137440758293, 0.64, 1.0, 1.0, 0.6647142701092463, 1.0, 1.0, 0.6647142701092463, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.560610479804327, 0.560610479804327, 0.5724599102219302], 
reward next is 0.4275, 
noisyNet noise sample is [array([0.9159547], dtype=float32), -0.11725937]. 
=============================================
[2019-03-26 17:01:50,983] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.5630771e-16 1.0000000e+00 1.3914674e-18 7.4859692e-16 2.7013640e-27], sum to 1.0000
[2019-03-26 17:01:50,990] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3007
[2019-03-26 17:01:50,993] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.8, 89.0, 1.0, 2.0, 0.721828431112643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1008790.287836454, 1008790.287836454, 225627.0331261216], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6505200.0000, 
sim time next is 6505800.0000, 
raw observation next is [26.86666666666667, 88.66666666666667, 1.0, 2.0, 0.6540641099500806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 914045.6032298539, 914045.6032298539, 211242.1877923063], 
processed observation next is [1.0, 0.30434782608695654, 0.4723538704581361, 0.8866666666666667, 1.0, 1.0, 0.5832097710241935, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2539015564527372, 0.2539015564527372, 0.31528684745120344], 
reward next is 0.6847, 
noisyNet noise sample is [array([0.1039307], dtype=float32), 0.08386878]. 
=============================================
[2019-03-26 17:01:51,102] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.1479498e-16 1.0000000e+00 2.4656341e-18 3.0096673e-15 4.0126488e-27], sum to 1.0000
[2019-03-26 17:01:51,108] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8722
[2019-03-26 17:01:51,111] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.51666666666667, 88.33333333333334, 1.0, 2.0, 0.6823152980453945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 953543.9740699849, 953543.9740699856, 217072.957834213], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6591000.0000, 
sim time next is 6591600.0000, 
raw observation next is [26.6, 88.0, 1.0, 2.0, 0.6854201674262496, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 957885.0238343929, 957885.0238343923, 217728.3920143394], 
processed observation next is [1.0, 0.30434782608695654, 0.4597156398104266, 0.88, 1.0, 1.0, 0.6209881535256019, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2660791732873314, 0.2660791732873312, 0.32496774927513344], 
reward next is 0.6750, 
noisyNet noise sample is [array([-0.3170606], dtype=float32), -1.1154201]. 
=============================================
[2019-03-26 17:01:54,136] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-26 17:01:54,139] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 17:01:54,140] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 17:01:54,140] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:01:54,142] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:01:54,142] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 17:01:54,144] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 17:01:54,146] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:01:54,147] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:01:54,146] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 17:01:54,150] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:01:54,169] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run59
[2019-03-26 17:01:54,196] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run59
[2019-03-26 17:01:54,197] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run59
[2019-03-26 17:01:54,240] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run59
[2019-03-26 17:01:54,242] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run59
[2019-03-26 17:01:58,693] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10071862], dtype=float32), 0.08101803]
[2019-03-26 17:01:58,694] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [20.87510871666667, 87.97822355666668, 1.0, 2.0, 0.2878938100896964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 464070.1139696843, 464070.1139696837, 164551.0303857623]
[2019-03-26 17:01:58,697] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 17:01:58,702] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.3029820e-16 1.0000000e+00 5.6273549e-20 2.3325095e-19 1.1309423e-29], sampled 0.1464793093799015
[2019-03-26 17:02:14,542] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10071862], dtype=float32), 0.08101803]
[2019-03-26 17:02:14,542] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [19.630273045, 91.56461546666668, 1.0, 2.0, 0.3564977498666805, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 579175.7549256656, 579175.7549256656, 173208.8043238732]
[2019-03-26 17:02:14,543] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 17:02:14,544] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.0548658e-16 1.0000000e+00 1.4455007e-19 1.9547974e-18 4.9401018e-29], sampled 0.4694450519830782
[2019-03-26 17:02:26,465] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10071862], dtype=float32), 0.08101803]
[2019-03-26 17:02:26,466] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.15, 94.5, 1.0, 2.0, 0.8989701569902202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1256500.92769338, 1256500.92769338, 269651.8516837089]
[2019-03-26 17:02:26,470] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:02:26,472] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.4840021e-16 1.0000000e+00 6.1060627e-19 2.2906802e-17 3.9804937e-28], sampled 0.9320005744048933
[2019-03-26 17:03:17,380] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10071862], dtype=float32), 0.08101803]
[2019-03-26 17:03:17,383] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.65, 92.5, 1.0, 2.0, 0.6239838598120022, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 871991.6104770519, 871991.6104770513, 205298.8977992869]
[2019-03-26 17:03:17,383] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 17:03:17,386] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.1337921e-16 1.0000000e+00 8.5042755e-20 2.5180941e-18 1.8482218e-29], sampled 0.46017758989848123
[2019-03-26 17:03:20,585] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10071862], dtype=float32), 0.08101803]
[2019-03-26 17:03:20,588] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.97807888333333, 89.39497907333333, 1.0, 2.0, 0.6581575628725888, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 919768.6245078623, 919768.624507863, 212073.1312463491]
[2019-03-26 17:03:20,590] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 17:03:20,594] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.9821349e-16 1.0000000e+00 3.7528207e-19 9.8904265e-18 1.0691185e-28], sampled 0.6628933150870967
[2019-03-26 17:03:41,428] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10071862], dtype=float32), 0.08101803]
[2019-03-26 17:03:41,429] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [21.246137965, 72.517301555, 1.0, 2.0, 0.2854141871270234, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 471466.2360592862, 471466.2360592862, 164558.9010110297]
[2019-03-26 17:03:41,429] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 17:03:41,431] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.9817820e-16 1.0000000e+00 1.5758063e-19 5.2889148e-19 5.7828394e-29], sampled 0.052707549975713475
[2019-03-26 17:03:46,583] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10071862], dtype=float32), 0.08101803]
[2019-03-26 17:03:46,585] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.69740173, 95.733727285, 1.0, 2.0, 0.4737488705826101, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 674895.7591070528, 674895.7591070534, 181240.6018213682]
[2019-03-26 17:03:46,586] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 17:03:46,592] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.9825330e-16 1.0000000e+00 2.9488606e-19 1.1421784e-17 1.4838145e-28], sampled 0.314505039997551
[2019-03-26 17:03:50,287] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8512.5883 2840200266.7792 1082.0000
[2019-03-26 17:03:50,296] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8030.3807 3002794628.1458 1653.0000
[2019-03-26 17:03:50,609] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.1006 2779348375.0645 931.0000
[2019-03-26 17:03:50,618] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7936.2243 3158378255.1402 1587.0000
[2019-03-26 17:03:50,630] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8263.5982 2926523803.2231 1304.0000
[2019-03-26 17:03:51,646] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1450000, evaluation results [1450000.0, 7936.224259103343, 3158378255.140163, 1587.0, 8263.598208003881, 2926523803.223148, 1304.0, 8660.100564852899, 2779348375.064466, 931.0, 8030.38072090942, 3002794628.1458364, 1653.0, 8512.588326880164, 2840200266.779223, 1082.0]
[2019-03-26 17:03:53,776] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.6191669e-15 1.0000000e+00 4.0216891e-20 1.6525850e-18 3.5556167e-29], sum to 1.0000
[2019-03-26 17:03:53,784] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7181
[2019-03-26 17:03:53,789] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.8, 58.5, 1.0, 2.0, 0.4528090363367156, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 646873.6021973578, 646873.6021973571, 178353.7599114793], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6975000.0000, 
sim time next is 6975600.0000, 
raw observation next is [29.73333333333333, 58.33333333333333, 1.0, 2.0, 0.4491489299046257, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 644025.8896477638, 644025.8896477632, 178122.9336700251], 
processed observation next is [0.0, 0.7391304347826086, 0.6082148499210109, 0.5833333333333333, 1.0, 1.0, 0.336324011933284, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17889608045771216, 0.17889608045771202, 0.26585512488063445], 
reward next is 0.7341, 
noisyNet noise sample is [array([-1.9296662], dtype=float32), -0.808785]. 
=============================================
[2019-03-26 17:03:57,472] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.1627614e-10 9.9930739e-01 5.7388638e-10 6.9260242e-04 1.2115808e-16], sum to 1.0000
[2019-03-26 17:03:57,478] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5648
[2019-03-26 17:03:57,486] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1832055.164685911 W.
[2019-03-26 17:03:57,494] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.03333333333333, 73.0, 1.0, 2.0, 0.6692182922043648, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.978613444019171, 6.9112, 168.9125004626346, 1832055.164685911, 1784229.876430792, 379086.3285847919], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6691800.0000, 
sim time next is 6692400.0000, 
raw observation next is [29.2, 72.0, 1.0, 2.0, 0.6509726926757813, 1.0, 1.0, 0.6509726926757813, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 1820211.936533318, 1820211.936533319, 353837.9996042703], 
processed observation next is [1.0, 0.4782608695652174, 0.5829383886255924, 0.72, 1.0, 1.0, 0.5794851718985317, 1.0, 0.5, 0.5794851718985317, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5056144268148105, 0.5056144268148108, 0.5281164173198064], 
reward next is 0.4719, 
noisyNet noise sample is [array([1.5851154], dtype=float32), 0.15987964]. 
=============================================
[2019-03-26 17:03:59,325] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.6383382e-10 3.1796002e-01 7.0609762e-10 6.8203998e-01 5.7534587e-17], sum to 1.0000
[2019-03-26 17:03:59,333] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1517
[2019-03-26 17:03:59,343] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1788461.199348829 W.
[2019-03-26 17:03:59,349] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.6, 67.0, 1.0, 2.0, 0.6396269655001854, 1.0, 2.0, 0.6396269655001854, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 1788461.199348829, 1788461.199348829, 349342.2243697831], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6714000.0000, 
sim time next is 6714600.0000, 
raw observation next is [29.46666666666667, 67.0, 1.0, 2.0, 0.3149593240538673, 1.0, 2.0, 0.3149593240538673, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 880285.1513359863, 880285.1513359863, 252823.1786913608], 
processed observation next is [1.0, 0.7391304347826086, 0.5955766192733019, 0.67, 1.0, 1.0, 0.17464978801670755, 1.0, 1.0, 0.17464978801670755, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.24452365314888508, 0.24452365314888508, 0.37734802789755345], 
reward next is 0.6227, 
noisyNet noise sample is [array([-0.12820771], dtype=float32), -0.21475914]. 
=============================================
[2019-03-26 17:04:00,024] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.7469801e-11 9.8912114e-01 9.5432759e-11 1.0878797e-02 9.4215591e-18], sum to 1.0000
[2019-03-26 17:04:00,032] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2258
[2019-03-26 17:04:00,039] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.95, 63.33333333333334, 1.0, 2.0, 0.9045784569321986, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510392, 1264344.380474621, 1264344.380474621, 271197.2001315001], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6700200.0000, 
sim time next is 6700800.0000, 
raw observation next is [30.0, 62.66666666666667, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 8.03159548825477, 6.9112, 168.9070445953937, 2249113.076035518, 1454293.775099188, 311347.5224892116], 
processed observation next is [1.0, 0.5652173913043478, 0.6208530805687204, 0.6266666666666667, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.11203954882547693, 0.0, 0.8294109149429831, 0.6247536322320884, 0.4039704930831078, 0.46469779476001727], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.14003435], dtype=float32), -0.30445883]. 
=============================================
[2019-03-26 17:04:00,484] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.6219778e-16 1.0000000e+00 1.1703081e-18 3.8701708e-14 3.6690774e-26], sum to 1.0000
[2019-03-26 17:04:00,491] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7383
[2019-03-26 17:04:00,495] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.35, 51.66666666666667, 1.0, 2.0, 0.3243064040085726, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 504533.2938966963, 504533.2938966957, 167156.2665330617], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6803400.0000, 
sim time next is 6804000.0000, 
raw observation next is [28.2, 52.0, 1.0, 2.0, 0.3260153737455134, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 508090.75159728, 508090.7515972807, 167456.6544811524], 
processed observation next is [1.0, 0.782608695652174, 0.5355450236966824, 0.52, 1.0, 1.0, 0.1879703298138716, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14113631988813333, 0.14113631988813352, 0.24993530519574983], 
reward next is 0.7501, 
noisyNet noise sample is [array([1.5744559], dtype=float32), 1.3438209]. 
=============================================
[2019-03-26 17:04:00,526] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[70.81736 ]
 [70.618935]
 [70.18285 ]
 [69.53057 ]
 [68.667206]], R is [[71.00012207]
 [71.04063416]
 [71.08140564]
 [71.12239838]
 [71.16197205]].
[2019-03-26 17:04:02,752] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.7770812e-15 1.0000000e+00 4.4479590e-18 1.0554855e-15 3.7285757e-27], sum to 1.0000
[2019-03-26 17:04:02,761] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9029
[2019-03-26 17:04:02,766] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.3, 83.0, 1.0, 2.0, 0.3713267419586213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 588655.5383960996, 588655.5383960996, 174206.078532564], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6760800.0000, 
sim time next is 6761400.0000, 
raw observation next is [22.41666666666667, 82.33333333333334, 1.0, 2.0, 0.3960332664974838, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 627250.7252275207, 627250.7252275207, 177594.4617805309], 
processed observation next is [1.0, 0.2608695652173913, 0.26145339652448685, 0.8233333333333335, 1.0, 1.0, 0.2723292367439564, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17423631256320019, 0.17423631256320019, 0.265066360866464], 
reward next is 0.7349, 
noisyNet noise sample is [array([-1.0367], dtype=float32), -0.49286374]. 
=============================================
[2019-03-26 17:04:08,719] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.4608755e-17 1.0000000e+00 3.2145143e-20 6.3065956e-20 6.7085399e-30], sum to 1.0000
[2019-03-26 17:04:08,729] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1855
[2019-03-26 17:04:08,735] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.81666666666667, 31.16666666666666, 1.0, 2.0, 0.2536829169178785, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 417426.2472565491, 417426.2472565497, 161267.5597546505], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6875400.0000, 
sim time next is 6876000.0000, 
raw observation next is [29.9, 30.0, 1.0, 2.0, 0.2544687688644385, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 419707.3587315264, 419707.3587315264, 161319.5096549368], 
processed observation next is [0.0, 0.6086956521739131, 0.6161137440758293, 0.3, 1.0, 1.0, 0.10176960104149213, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.116585377425424, 0.116585377425424, 0.24077538754468178], 
reward next is 0.7592, 
noisyNet noise sample is [array([-1.0372636], dtype=float32), 1.1554546]. 
=============================================
[2019-03-26 17:04:08,755] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[75.68663 ]
 [75.679756]
 [75.65723 ]
 [75.63211 ]
 [75.60849 ]], R is [[75.70666504]
 [75.70890045]
 [75.71095276]
 [75.71206665]
 [75.71259308]].
[2019-03-26 17:04:13,674] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.7054788e-10 7.7708834e-01 2.9875177e-10 2.2291169e-01 9.1160052e-18], sum to 1.0000
[2019-03-26 17:04:13,684] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8837
[2019-03-26 17:04:13,693] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.98333333333333, 45.33333333333334, 1.0, 2.0, 0.6451515999148651, 1.0, 2.0, 0.6451515999148651, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1849313.284525486, 1849313.284525486, 357063.2292432474], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7049400.0000, 
sim time next is 7050000.0000, 
raw observation next is [31.76666666666667, 46.66666666666667, 1.0, 2.0, 0.6506475173951483, 1.0, 2.0, 0.6506475173951483, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1857689.932711321, 1857689.932711321, 358413.54203617], 
processed observation next is [1.0, 0.6086956521739131, 0.7045813586097948, 0.46666666666666673, 1.0, 1.0, 0.5790933944519858, 1.0, 1.0, 0.5790933944519858, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5160249813087002, 0.5160249813087002, 0.534945585128612], 
reward next is 0.4651, 
noisyNet noise sample is [array([0.6935129], dtype=float32), -0.42955515]. 
=============================================
[2019-03-26 17:04:13,706] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[58.1206  ]
 [57.539467]
 [56.665096]
 [56.290306]
 [58.404667]], R is [[58.33779144]
 [58.22148514]
 [58.11164474]
 [58.00347137]
 [57.87435913]].
[2019-03-26 17:04:17,613] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.3199120e-15 1.0000000e+00 5.0103124e-18 3.7566938e-16 4.5081875e-27], sum to 1.0000
[2019-03-26 17:04:17,621] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2389
[2019-03-26 17:04:17,626] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.9, 81.0, 1.0, 2.0, 0.580456258075747, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 829709.4124886855, 829709.4124886855, 199544.0875822252], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7020000.0000, 
sim time next is 7020600.0000, 
raw observation next is [26.05, 80.0, 1.0, 2.0, 0.6126808539520981, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 876006.4563941075, 876006.4563941075, 205693.3901600246], 
processed observation next is [1.0, 0.2608695652173913, 0.43364928909952616, 0.8, 1.0, 1.0, 0.533350426448311, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.243335126776141, 0.243335126776141, 0.3070050599403352], 
reward next is 0.6930, 
noisyNet noise sample is [array([-3.0773146], dtype=float32), 0.42855027]. 
=============================================
[2019-03-26 17:04:24,990] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.7069807e-16 1.0000000e+00 3.3371656e-19 2.7004740e-15 1.9057728e-27], sum to 1.0000
[2019-03-26 17:04:25,001] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1186
[2019-03-26 17:04:25,005] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 89.33333333333334, 1.0, 2.0, 0.3710377579367017, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 564517.6232246225, 564517.6232246218, 171683.0425482135], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7240800.0000, 
sim time next is 7241400.0000, 
raw observation next is [22.9, 90.0, 1.0, 2.0, 0.3708435981218985, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 564455.160426847, 564455.1604268476, 171684.5546397817], 
processed observation next is [1.0, 0.8260869565217391, 0.2843601895734597, 0.9, 1.0, 1.0, 0.2419802387010825, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15679310011856862, 0.15679310011856878, 0.2562456039399727], 
reward next is 0.7438, 
noisyNet noise sample is [array([-1.0022107], dtype=float32), 0.38388467]. 
=============================================
[2019-03-26 17:04:37,168] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:04:37,168] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:04:37,247] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run8
[2019-03-26 17:04:38,231] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.0286224e-16 1.0000000e+00 1.1747719e-18 1.5909156e-15 3.0132331e-27], sum to 1.0000
[2019-03-26 17:04:38,237] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2893
[2019-03-26 17:04:38,243] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.9, 92.0, 1.0, 2.0, 0.6590100484177079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1049587.856301528, 1049587.856301527, 227189.844411565], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7394400.0000, 
sim time next is 7395000.0000, 
raw observation next is [20.86666666666667, 91.83333333333334, 1.0, 2.0, 0.5525854446070985, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 880894.8556144383, 880894.8556144377, 204494.5465874934], 
processed observation next is [1.0, 0.6086956521739131, 0.18799368088467638, 0.9183333333333334, 1.0, 1.0, 0.46094631880373305, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2446930154484551, 0.24469301544845493, 0.30521574117536326], 
reward next is 0.6948, 
noisyNet noise sample is [array([-0.24513431], dtype=float32), -0.8923712]. 
=============================================
[2019-03-26 17:04:38,256] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[71.795616]
 [71.89632 ]
 [72.08147 ]
 [72.267494]
 [72.5048  ]], R is [[71.87425232]
 [71.81642151]
 [71.7470932 ]
 [71.68305969]
 [71.63277435]].
[2019-03-26 17:04:39,453] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.4641780e-17 1.0000000e+00 4.4645800e-20 1.0860058e-18 3.1433900e-30], sum to 1.0000
[2019-03-26 17:04:39,463] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5235
[2019-03-26 17:04:39,467] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.35, 86.0, 1.0, 2.0, 0.4029091002163428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 594852.926062885, 594852.926062885, 173873.9932508516], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7504200.0000, 
sim time next is 7504800.0000, 
raw observation next is [24.3, 86.33333333333334, 1.0, 2.0, 0.4027598588474285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 594720.212489671, 594720.2124896715, 173864.3419595282], 
processed observation next is [0.0, 0.8695652173913043, 0.3507109004739337, 0.8633333333333334, 1.0, 1.0, 0.28043356487641985, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1652000590249086, 0.16520005902490875, 0.2594990178500421], 
reward next is 0.7405, 
noisyNet noise sample is [array([-0.50255114], dtype=float32), 1.2114061]. 
=============================================
[2019-03-26 17:04:39,883] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.1993569e-17 1.0000000e+00 6.0487505e-20 8.3367980e-20 1.2550851e-30], sum to 1.0000
[2019-03-26 17:04:39,893] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9067
[2019-03-26 17:04:39,898] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.48333333333333, 75.5, 1.0, 2.0, 0.4253355507484468, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 614370.1557356397, 614370.1557356397, 175311.0352889171], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7492200.0000, 
sim time next is 7492800.0000, 
raw observation next is [26.36666666666667, 76.0, 1.0, 2.0, 0.4240355883393812, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 613336.4816620288, 613336.4816620282, 175236.5273522121], 
processed observation next is [0.0, 0.7391304347826086, 0.4486571879936811, 0.76, 1.0, 1.0, 0.30606697390286897, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17037124490611913, 0.17037124490611896, 0.2615470557495703], 
reward next is 0.7385, 
noisyNet noise sample is [array([0.39336532], dtype=float32), 1.2478299]. 
=============================================
[2019-03-26 17:04:45,644] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-26 17:04:45,645] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 17:04:45,646] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:04:45,646] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 17:04:45,649] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:04:45,649] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 17:04:45,650] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:04:45,651] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.9449299e-15 1.0000000e+00 4.5031895e-18 5.8662893e-15 2.2801110e-27], sum to 1.0000
[2019-03-26 17:04:45,651] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 17:04:45,652] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 17:04:45,652] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:04:45,653] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:04:45,655] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7230
[2019-03-26 17:04:45,659] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.8, 95.5, 1.0, 2.0, 0.9552732516788897, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1425884.400256732, 1425884.400256732, 298995.2809642474], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 127800.0000, 
sim time next is 128400.0000, 
raw observation next is [22.8, 95.66666666666667, 1.0, 2.0, 0.9088440893745711, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1355578.060794108, 1355578.060794109, 284677.1901405191], 
processed observation next is [1.0, 0.4782608695652174, 0.2796208530805688, 0.9566666666666667, 1.0, 1.0, 0.8901736016561097, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3765494613316967, 0.3765494613316969, 0.424891328567939], 
reward next is 0.5751, 
noisyNet noise sample is [array([-0.36213148], dtype=float32), 0.5278844]. 
=============================================
[2019-03-26 17:04:45,667] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run60
[2019-03-26 17:04:45,686] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run60
[2019-03-26 17:04:45,686] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run60
[2019-03-26 17:04:45,706] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run60
[2019-03-26 17:04:45,739] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run60
[2019-03-26 17:04:46,719] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.1039739], dtype=float32), 0.08414433]
[2019-03-26 17:04:46,720] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [20.9, 85.66666666666667, 1.0, 2.0, 0.2945587816193727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 475247.639200479, 475247.6392004797, 165323.0175125609]
[2019-03-26 17:04:46,720] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:04:46,721] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.0165715e-03 9.9170458e-01 1.1771880e-03 4.0622558e-03 3.9424936e-05], sampled 0.7604213269329045
[2019-03-26 17:04:51,574] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.1039739], dtype=float32), 0.08414433]
[2019-03-26 17:04:51,575] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [21.76666666666667, 61.33333333333334, 1.0, 2.0, 0.2185770911272426, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 364126.7014546487, 364126.7014546487, 157471.612183309]
[2019-03-26 17:04:51,575] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 17:04:51,577] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.581017e-16 1.000000e+00 7.316449e-20 1.469452e-19 7.867890e-30], sampled 0.6541585976550097
[2019-03-26 17:04:52,295] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.1039739], dtype=float32), 0.08414433]
[2019-03-26 17:04:52,297] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.8, 73.0, 1.0, 2.0, 0.4791762917907562, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 773024.1119324766, 773024.1119324766, 191641.6318986931]
[2019-03-26 17:04:52,298] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:04:52,302] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.8270175e-16 1.0000000e+00 2.5404384e-19 1.7255305e-18 4.1064389e-29], sampled 0.14133537036675903
[2019-03-26 17:05:05,978] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.1039739], dtype=float32), 0.08414433]
[2019-03-26 17:05:05,980] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [24.51732955, 93.69666812, 1.0, 2.0, 0.5454568610347357, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 770748.3812361368, 770748.3812361374, 192118.5241627425]
[2019-03-26 17:05:05,981] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 17:05:05,987] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.6260907e-16 1.0000000e+00 1.2692329e-19 6.9541100e-19 1.5310612e-29], sampled 0.8388820771885382
[2019-03-26 17:05:16,792] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.1039739], dtype=float32), 0.08414433]
[2019-03-26 17:05:16,795] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.23353223833334, 94.05207972000001, 1.0, 2.0, 0.4204436800415708, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 619379.3050941653, 619379.3050941647, 176137.1342907275]
[2019-03-26 17:05:16,796] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 17:05:16,798] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.3918829e-16 1.0000000e+00 8.7466265e-20 8.7227405e-19 1.3654888e-29], sampled 0.23610591660977476
[2019-03-26 17:05:22,838] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.1039739], dtype=float32), 0.08414433]
[2019-03-26 17:05:22,841] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.9, 93.0, 1.0, 2.0, 0.552380441864277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 771892.4390403318, 771892.4390403318, 192209.9112043129]
[2019-03-26 17:05:22,841] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:05:22,844] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [7.3411181e-17 1.0000000e+00 7.3307240e-20 3.7509191e-18 5.8293254e-30], sampled 0.16055041304956075
[2019-03-26 17:05:30,074] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.1039739], dtype=float32), 0.08414433]
[2019-03-26 17:05:30,075] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [21.0, 94.0, 1.0, 2.0, 0.5774007155431474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 912828.1563987812, 912828.1563987806, 208833.6884110711]
[2019-03-26 17:05:30,076] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:05:30,084] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.0487841e-16 1.0000000e+00 2.4135753e-19 6.1635184e-18 3.6458835e-29], sampled 0.17233067707921212
[2019-03-26 17:06:08,230] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.1039739], dtype=float32), 0.08414433]
[2019-03-26 17:06:08,231] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.76666666666667, 91.66666666666666, 1.0, 2.0, 0.6207986674549771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 867538.6181319352, 867538.6181319352, 204684.5773250865]
[2019-03-26 17:06:08,232] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 17:06:08,234] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [5.6163188e-17 1.0000000e+00 7.7544047e-20 2.2959204e-17 9.6989576e-30], sampled 0.2884976925260092
[2019-03-26 17:06:15,106] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.1039739], dtype=float32), 0.08414433]
[2019-03-26 17:06:15,108] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.0, 82.0, 1.0, 2.0, 0.6340546983997495, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 886071.0610622374, 886071.0610622374, 207255.0587607958]
[2019-03-26 17:06:15,109] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 17:06:15,113] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.9526902e-16 1.0000000e+00 2.2074744e-19 3.5573866e-18 3.1109327e-29], sampled 0.5968851303513923
[2019-03-26 17:06:41,977] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7949.7582 3158126646.8788 1588.0000
[2019-03-26 17:06:42,049] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8266.0030 2926104923.2716 1296.0000
[2019-03-26 17:06:42,099] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8027.0974 3002578761.5894 1650.0000
[2019-03-26 17:06:42,131] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8521.7993 2839729340.6328 1069.0000
[2019-03-26 17:06:42,208] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.4133 2779098889.8186 927.0000
[2019-03-26 17:06:43,223] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1475000, evaluation results [1475000.0, 7949.758188672578, 3158126646.8788238, 1588.0, 8266.003001788396, 2926104923.271583, 1296.0, 8661.413341507687, 2779098889.8185697, 927.0, 8027.097440219485, 3002578761.589367, 1650.0, 8521.799339123801, 2839729340.632832, 1069.0]
[2019-03-26 17:06:43,477] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.7562242e-16 1.0000000e+00 3.5080105e-18 2.0359534e-15 2.7620079e-28], sum to 1.0000
[2019-03-26 17:06:43,487] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5358
[2019-03-26 17:06:43,493] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.2, 90.0, 1.0, 2.0, 0.7379057646237581, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1031270.052102532, 1031270.052102532, 229238.3073111918], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7876800.0000, 
sim time next is 7877400.0000, 
raw observation next is [26.21666666666667, 89.83333333333333, 1.0, 2.0, 0.6508600437936357, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 909566.0474464631, 909566.0474464631, 210594.4513989143], 
processed observation next is [1.0, 0.17391304347826086, 0.44154818325434453, 0.8983333333333333, 1.0, 1.0, 0.5793494503537779, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2526572354017953, 0.2526572354017953, 0.31432007671479745], 
reward next is 0.6857, 
noisyNet noise sample is [array([-1.5001184], dtype=float32), 0.46335012]. 
=============================================
[2019-03-26 17:06:43,539] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.6368230e-16 1.0000000e+00 5.1717183e-20 2.0909835e-19 1.6190487e-29], sum to 1.0000
[2019-03-26 17:06:43,542] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8250
[2019-03-26 17:06:43,558] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.3, 90.0, 1.0, 2.0, 0.3786747759208431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 569430.3873835728, 569430.3873835728, 171906.6431254898], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7538400.0000, 
sim time next is 7539000.0000, 
raw observation next is [23.33333333333334, 90.0, 1.0, 2.0, 0.3805791359382132, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 571559.6915575337, 571559.6915575344, 172071.3743986867], 
processed observation next is [0.0, 0.2608695652173913, 0.3048973143759877, 0.9, 1.0, 1.0, 0.25370980233519663, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15876658098820381, 0.158766580988204, 0.2568229468637115], 
reward next is 0.7432, 
noisyNet noise sample is [array([1.8691947], dtype=float32), 0.86254454]. 
=============================================
[2019-03-26 17:06:43,578] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[75.40213]
 [75.38932]
 [75.39469]
 [75.39187]
 [75.38627]], R is [[75.40859222]
 [75.39793396]
 [75.38768768]
 [75.37776184]
 [75.36805725]].
[2019-03-26 17:06:48,643] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:06:48,643] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:06:48,714] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run8
[2019-03-26 17:06:49,015] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.0156140e-15 1.0000000e+00 7.0422625e-18 3.1076794e-16 3.2492568e-27], sum to 1.0000
[2019-03-26 17:06:49,020] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4441
[2019-03-26 17:06:49,024] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.73333333333333, 95.0, 1.0, 2.0, 0.5076060487552021, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 732893.2444389308, 732893.2444389308, 187789.0648705919], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7613400.0000, 
sim time next is 7614000.0000, 
raw observation next is [23.7, 95.0, 1.0, 2.0, 0.4901608647690107, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 708669.5828691515, 708669.5828691515, 185082.6332041952], 
processed observation next is [1.0, 0.13043478260869565, 0.3222748815165877, 0.95, 1.0, 1.0, 0.38573598164941053, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19685266190809764, 0.19685266190809764, 0.2762427361256645], 
reward next is 0.7238, 
noisyNet noise sample is [array([0.5710513], dtype=float32), 0.22372201]. 
=============================================
[2019-03-26 17:06:49,035] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[71.00194 ]
 [70.931786]
 [71.02928 ]
 [70.944016]
 [70.99429 ]], R is [[71.0835495 ]
 [71.09243011]
 [71.09741974]
 [71.100914  ]
 [71.08306885]].
[2019-03-26 17:06:51,839] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:06:51,839] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:06:51,915] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run8
[2019-03-26 17:06:59,082] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.4412758e-10 2.3681070e-01 3.5202097e-09 7.6318938e-01 4.6561798e-16], sum to 1.0000
[2019-03-26 17:06:59,092] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0936
[2019-03-26 17:06:59,098] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2159901.868087334 W.
[2019-03-26 17:06:59,103] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.53333333333333, 70.66666666666667, 1.0, 2.0, 0.7723355845948116, 1.0, 2.0, 0.7723355845948116, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2159901.868087334, 2159901.868087334, 406629.0771621791], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7818000.0000, 
sim time next is 7818600.0000, 
raw observation next is [30.76666666666667, 70.33333333333333, 1.0, 2.0, 0.9544370239964273, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.001205959165949, 6.9112, 168.9124212446389, 2231230.004383312, 2167376.881528812, 449779.2589020277], 
processed observation next is [1.0, 0.4782608695652174, 0.6571879936808849, 0.7033333333333333, 1.0, 1.0, 0.9451048481884666, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.0090005959165949, 0.0, 0.8294373167522177, 0.6197861123286978, 0.6020491337580033, 0.6713123267194443], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.4819254], dtype=float32), 0.331702]. 
=============================================
[2019-03-26 17:06:59,112] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:06:59,114] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:06:59,197] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run8
[2019-03-26 17:06:59,947] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:06:59,948] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:07:00,003] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run8
[2019-03-26 17:07:01,580] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.2573063e-15 1.0000000e+00 5.8369710e-18 2.3325229e-15 2.4002154e-27], sum to 1.0000
[2019-03-26 17:07:01,590] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9086
[2019-03-26 17:07:01,597] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.3, 62.66666666666667, 1.0, 2.0, 0.502009538323531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 823132.6356550305, 823132.6356550305, 196186.0062237576], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 474000.0000, 
sim time next is 474600.0000, 
raw observation next is [23.45, 61.83333333333334, 1.0, 2.0, 0.5168262526456806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 847277.1018349476, 847277.1018349469, 198908.6540762966], 
processed observation next is [1.0, 0.4782608695652174, 0.3104265402843602, 0.6183333333333334, 1.0, 1.0, 0.41786295499479587, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.23535475050970767, 0.23535475050970747, 0.29687858817357704], 
reward next is 0.7031, 
noisyNet noise sample is [array([0.10941951], dtype=float32), 1.0912986]. 
=============================================
[2019-03-26 17:07:02,439] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:07:02,440] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:07:02,506] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run8
[2019-03-26 17:07:02,950] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.0135305e-15 1.0000000e+00 2.4676207e-17 9.3788104e-15 7.9099471e-26], sum to 1.0000
[2019-03-26 17:07:02,957] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2851
[2019-03-26 17:07:02,961] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333334, 70.33333333333334, 1.0, 2.0, 0.7384114937585701, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1137441.175536041, 1137441.175536041, 242812.8783525481], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 37200.0000, 
sim time next is 37800.0000, 
raw observation next is [25.55, 69.5, 1.0, 2.0, 0.7432295329360913, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1142410.468538642, 1142410.468538642, 243752.7884550088], 
processed observation next is [1.0, 0.43478260869565216, 0.40995260663507116, 0.695, 1.0, 1.0, 0.6906379914892666, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.31733624126073384, 0.31733624126073384, 0.3638101320224012], 
reward next is 0.6362, 
noisyNet noise sample is [array([0.5218549], dtype=float32), -0.7230881]. 
=============================================
[2019-03-26 17:07:03,772] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:07:03,773] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:07:03,844] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run8
[2019-03-26 17:07:06,099] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.6692221e-16 1.0000000e+00 1.6462857e-19 5.4357357e-19 8.9464900e-30], sum to 1.0000
[2019-03-26 17:07:06,104] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3917
[2019-03-26 17:07:06,110] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 80.33333333333334, 1.0, 2.0, 0.2961812381097969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 472566.5188263085, 472566.5188263085, 165107.7572076377], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 322800.0000, 
sim time next is 323400.0000, 
raw observation next is [22.26666666666667, 80.66666666666666, 1.0, 2.0, 0.2954624317198164, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 471619.8540841072, 471619.8540841072, 165043.9769706901], 
processed observation next is [0.0, 0.7391304347826086, 0.2543443917851502, 0.8066666666666665, 1.0, 1.0, 0.1511595562889354, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1310055150233631, 0.1310055150233631, 0.24633429398610462], 
reward next is 0.7537, 
noisyNet noise sample is [array([-0.19177367], dtype=float32), -0.44216448]. 
=============================================
[2019-03-26 17:07:06,143] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:07:06,145] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:07:06,215] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run8
[2019-03-26 17:07:06,546] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:07:06,546] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:07:06,601] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run8
[2019-03-26 17:07:06,938] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:07:06,940] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:07:06,996] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run8
[2019-03-26 17:07:07,267] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:07:07,268] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:07:07,330] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:07:07,331] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:07:07,335] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run8
[2019-03-26 17:07:07,403] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run8
[2019-03-26 17:07:07,418] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:07:07,421] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:07:07,457] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:07:07,458] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:07:07,484] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run8
[2019-03-26 17:07:07,525] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run8
[2019-03-26 17:07:07,589] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:07:07,589] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:07:07,594] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run8
[2019-03-26 17:07:07,721] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:07:07,721] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:07:07,740] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run8
[2019-03-26 17:07:07,854] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.3212361e-16 1.0000000e+00 6.8076195e-20 1.0909672e-19 2.2569352e-28], sum to 1.0000
[2019-03-26 17:07:07,858] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4196
[2019-03-26 17:07:07,863] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.9, 96.0, 1.0, 2.0, 0.2863924508741391, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 461306.5985648271, 461306.5985648271, 164362.226335434], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 185400.0000, 
sim time next is 186000.0000, 
raw observation next is [19.9, 96.0, 1.0, 2.0, 0.2860759064107357, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 460796.9032282293, 460796.9032282293, 164327.4826521666], 
processed observation next is [0.0, 0.13043478260869565, 0.14218009478672985, 0.96, 1.0, 1.0, 0.1398504896514888, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.12799913978561925, 0.12799913978561925, 0.24526489948084568], 
reward next is 0.7547, 
noisyNet noise sample is [array([0.67901695], dtype=float32), -0.35425884]. 
=============================================
[2019-03-26 17:07:07,870] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[75.588165]
 [75.66889 ]
 [75.84525 ]
 [75.883224]
 [75.91133 ]], R is [[75.37516785]
 [75.37609863]
 [75.37696838]
 [75.37779236]
 [75.37856293]].
[2019-03-26 17:07:08,398] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.4692531e-12 1.0000000e+00 4.4066665e-14 5.3610724e-13 2.2110116e-21], sum to 1.0000
[2019-03-26 17:07:08,399] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6008
[2019-03-26 17:07:08,404] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.03333333333333, 85.00000000000001, 1.0, 2.0, 0.3447617013393483, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 557446.6730675341, 557446.6730675341, 171503.7292665901], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 11400.0000, 
sim time next is 12000.0000, 
raw observation next is [21.06666666666667, 85.0, 1.0, 2.0, 0.3192476490437965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 515866.1548263548, 515866.1548263548, 168264.927210501], 
processed observation next is [1.0, 0.13043478260869565, 0.19747235387045833, 0.85, 1.0, 1.0, 0.1798164446310801, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14329615411843188, 0.14329615411843188, 0.2511416824037328], 
reward next is 0.7489, 
noisyNet noise sample is [array([0.9834339], dtype=float32), 0.13546343]. 
=============================================
[2019-03-26 17:07:08,412] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[54.221798]
 [52.11429 ]
 [49.861263]
 [47.791206]
 [45.232246]], R is [[56.47486115]
 [56.65413666]
 [56.84097672]
 [57.02661514]
 [57.20987701]].
[2019-03-26 17:07:15,117] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.5869404e-16 1.0000000e+00 5.2933149e-19 1.2835589e-17 6.1067302e-29], sum to 1.0000
[2019-03-26 17:07:15,128] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8656
[2019-03-26 17:07:15,135] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.61666666666667, 91.00000000000001, 1.0, 2.0, 0.4082551616796137, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 624520.2171965144, 624520.2171965144, 177155.8088613652], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 105000.0000, 
sim time next is 105600.0000, 
raw observation next is [22.63333333333334, 91.0, 1.0, 2.0, 0.3737406723380176, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 571415.3344075446, 571415.3344075446, 172361.6639726915], 
processed observation next is [1.0, 0.21739130434782608, 0.27172195892575074, 0.91, 1.0, 1.0, 0.24547068956387663, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1587264817798735, 0.1587264817798735, 0.25725621488461414], 
reward next is 0.7427, 
noisyNet noise sample is [array([-0.16047128], dtype=float32), -0.548537]. 
=============================================
[2019-03-26 17:07:21,607] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.4757004e-17 1.0000000e+00 4.8163257e-20 8.1705612e-20 3.0923196e-30], sum to 1.0000
[2019-03-26 17:07:21,617] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7945
[2019-03-26 17:07:21,620] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.86666666666667, 90.16666666666667, 1.0, 2.0, 0.2918847654377892, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 467566.0319162112, 467566.0319162112, 164780.12513733], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 249000.0000, 
sim time next is 249600.0000, 
raw observation next is [20.83333333333333, 90.33333333333334, 1.0, 2.0, 0.2896693116080126, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 464138.3264318929, 464138.3264318929, 164544.0127841447], 
processed observation next is [0.0, 0.9130434782608695, 0.1864139020537123, 0.9033333333333334, 1.0, 1.0, 0.14417989350362967, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.12892731289774803, 0.12892731289774803, 0.2455880787823055], 
reward next is 0.7544, 
noisyNet noise sample is [array([-0.69745445], dtype=float32), 0.26314634]. 
=============================================
[2019-03-26 17:07:35,014] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-26 17:07:35,017] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 17:07:35,018] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 17:07:35,019] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:07:35,021] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 17:07:35,022] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:07:35,023] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 17:07:35,024] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 17:07:35,023] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:07:35,053] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:07:35,054] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:07:35,904] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run61
[2019-03-26 17:07:35,929] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run61
[2019-03-26 17:07:35,930] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run61
[2019-03-26 17:07:35,963] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run61
[2019-03-26 17:07:35,965] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run61
[2019-03-26 17:07:45,834] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10787461], dtype=float32), 0.08673362]
[2019-03-26 17:07:45,835] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [18.92180509, 81.04648785666666, 1.0, 2.0, 0.2313820606062741, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 385336.3322663032, 385336.3322663025, 158651.6875926993]
[2019-03-26 17:07:45,836] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 17:07:45,839] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [8.7968660e-17 1.0000000e+00 4.8438899e-20 2.3371497e-19 3.1013688e-30], sampled 0.25306653890478803
[2019-03-26 17:07:53,445] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10787461], dtype=float32), 0.08673362]
[2019-03-26 17:07:53,447] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [21.1, 87.0, 1.0, 2.0, 0.2984903380911043, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 479685.8282257493, 479685.8282257493, 165638.8104085509]
[2019-03-26 17:07:53,448] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 17:07:53,452] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [8.4291319e-17 1.0000000e+00 5.6103150e-20 3.9516452e-19 3.2709035e-30], sampled 0.3354169542613644
[2019-03-26 17:08:17,502] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10787461], dtype=float32), 0.08673362]
[2019-03-26 17:08:17,502] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.8, 68.66666666666667, 1.0, 2.0, 0.6152075104115894, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 859722.0617312401, 859722.0617312401, 203606.4892857031]
[2019-03-26 17:08:17,504] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:08:17,508] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.6671625e-16 1.0000000e+00 2.1957835e-19 5.7373438e-18 1.6932180e-29], sampled 0.12576866055001112
[2019-03-26 17:08:27,620] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10787461], dtype=float32), 0.08673362]
[2019-03-26 17:08:27,621] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [28.66666666666666, 74.66666666666667, 1.0, 2.0, 0.5153499496873493, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 720128.7562293817, 720128.7562293817, 186036.1550820503]
[2019-03-26 17:08:27,622] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:08:27,625] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.6896740e-16 1.0000000e+00 2.0568938e-19 4.2170143e-18 1.7797108e-29], sampled 0.36392524904922374
[2019-03-26 17:08:37,381] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10787461], dtype=float32), 0.08673362]
[2019-03-26 17:08:37,382] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.0, 84.0, 1.0, 2.0, 1.007196723122814, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.91295651035, 1407870.745796616, 1407870.745796616, 301129.7500083922]
[2019-03-26 17:08:37,385] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:08:37,387] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.0794766e-15 1.0000000e+00 4.0543513e-17 1.2375851e-14 5.0350850e-26], sampled 0.690855127273705
[2019-03-26 17:09:32,162] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.5141 2779112466.9553 930.0000
[2019-03-26 17:09:32,310] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8021.3921 3003187571.3499 1662.0000
[2019-03-26 17:09:32,489] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7929.5651 3159364792.5000 1612.0000
[2019-03-26 17:09:32,501] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8265.1437 2926424516.3715 1308.0000
[2019-03-26 17:09:32,505] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8508.3409 2840566759.9377 1088.0000
[2019-03-26 17:09:33,522] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1500000, evaluation results [1500000.0, 7929.565060649745, 3159364792.4999957, 1612.0, 8265.143665587468, 2926424516.371472, 1308.0, 8659.514140040634, 2779112466.9552565, 930.0, 8021.392087272583, 3003187571.349944, 1662.0, 8508.340925608833, 2840566759.937731, 1088.0]
[2019-03-26 17:09:38,276] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.6855489e-17 1.0000000e+00 1.3492572e-20 8.6466715e-20 9.1521846e-31], sum to 1.0000
[2019-03-26 17:09:38,287] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0680
[2019-03-26 17:09:38,295] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.05, 70.66666666666667, 1.0, 2.0, 0.3027321731922025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 480197.6300833625, 480197.6300833632, 165602.6905125778], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 910200.0000, 
sim time next is 910800.0000, 
raw observation next is [24.2, 70.0, 1.0, 2.0, 0.3041022323692932, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 481904.677424536, 481904.677424536, 165716.1897875097], 
processed observation next is [0.0, 0.5652173913043478, 0.3459715639810427, 0.7, 1.0, 1.0, 0.161568954661799, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13386241039570446, 0.13386241039570446, 0.2473375966977757], 
reward next is 0.7527, 
noisyNet noise sample is [array([-0.64054567], dtype=float32), -1.1732222]. 
=============================================
[2019-03-26 17:09:41,949] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.8823795e-16 1.0000000e+00 3.4324745e-20 2.2245937e-18 7.5020141e-29], sum to 1.0000
[2019-03-26 17:09:41,955] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6800
[2019-03-26 17:09:41,961] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 93.0, 1.0, 2.0, 0.3465987208241847, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 537278.6143519953, 537278.6143519959, 169689.4048091901], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 979800.0000, 
sim time next is 980400.0000, 
raw observation next is [21.9, 93.0, 1.0, 2.0, 0.4178152766427087, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 647662.1629634791, 647662.1629634791, 179440.0576613458], 
processed observation next is [1.0, 0.34782608695652173, 0.23696682464454974, 0.93, 1.0, 1.0, 0.2985726224610948, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1799061563787442, 0.1799061563787442, 0.2678209815840982], 
reward next is 0.7322, 
noisyNet noise sample is [array([2.330961], dtype=float32), 0.5026656]. 
=============================================
[2019-03-26 17:09:42,444] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.5025586e-16 1.0000000e+00 1.6347529e-18 9.3564710e-16 7.1379427e-28], sum to 1.0000
[2019-03-26 17:09:42,457] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9932
[2019-03-26 17:09:42,464] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.3, 59.0, 1.0, 2.0, 0.238348831635207, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 393603.927885861, 393603.9278858616, 159728.2855683296], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 756000.0000, 
sim time next is 756600.0000, 
raw observation next is [23.1, 60.5, 1.0, 2.0, 0.2436747180262885, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 402194.8189099152, 402194.8189099146, 160246.7239985138], 
processed observation next is [1.0, 0.782608695652174, 0.2938388625592418, 0.605, 1.0, 1.0, 0.08876472051360061, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11172078303053201, 0.11172078303053183, 0.23917421492315494], 
reward next is 0.7608, 
noisyNet noise sample is [array([0.26120803], dtype=float32), -1.9415629]. 
=============================================
[2019-03-26 17:09:45,948] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.8667276e-16 1.0000000e+00 2.3780047e-20 1.4007815e-19 7.3968076e-31], sum to 1.0000
[2019-03-26 17:09:45,956] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7960
[2019-03-26 17:09:45,960] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.25, 68.5, 1.0, 2.0, 0.3016818828715538, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 479914.674252031, 479914.6742520316, 165607.8170877082], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 833400.0000, 
sim time next is 834000.0000, 
raw observation next is [24.2, 69.0, 1.0, 2.0, 0.3017484013843819, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 479727.3012637906, 479727.3012637906, 165589.387032358], 
processed observation next is [0.0, 0.6521739130434783, 0.3459715639810427, 0.69, 1.0, 1.0, 0.15873301371612278, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13325758368438628, 0.13325758368438628, 0.24714833885426568], 
reward next is 0.7529, 
noisyNet noise sample is [array([0.5584412], dtype=float32), -0.19151102]. 
=============================================
[2019-03-26 17:09:45,971] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[79.03298 ]
 [79.00645 ]
 [78.98556 ]
 [78.943695]
 [78.902664]], R is [[79.02113342]
 [78.98374939]
 [78.94685364]
 [78.91068268]
 [78.87521362]].
[2019-03-26 17:09:48,418] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.4689777e-16 1.0000000e+00 2.4384788e-19 1.0394650e-18 1.5290417e-29], sum to 1.0000
[2019-03-26 17:09:48,429] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1580
[2019-03-26 17:09:48,434] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.36666666666667, 88.0, 1.0, 2.0, 0.2197230140345048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 365581.3865665816, 365581.386566581, 157686.2080604718], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 711600.0000, 
sim time next is 712200.0000, 
raw observation next is [18.58333333333334, 87.0, 1.0, 2.0, 0.221775458374074, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 368721.5013603071, 368721.5013603077, 157924.3054245826], 
processed observation next is [1.0, 0.21739130434782608, 0.07977883096366543, 0.87, 1.0, 1.0, 0.06238007033020963, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.10242263926675198, 0.10242263926675213, 0.23570791854415313], 
reward next is 0.7643, 
noisyNet noise sample is [array([0.1225632], dtype=float32), 0.20061377]. 
=============================================
[2019-03-26 17:09:49,854] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.6984340e-17 1.0000000e+00 1.2504995e-19 7.9589524e-18 3.2635891e-29], sum to 1.0000
[2019-03-26 17:09:49,867] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3411
[2019-03-26 17:09:49,871] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.2, 88.33333333333334, 1.0, 2.0, 0.2985829738507878, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 477188.8610938953, 477188.8610938959, 165444.4198335722], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1120800.0000, 
sim time next is 1121400.0000, 
raw observation next is [21.15, 88.5, 1.0, 2.0, 0.2980085863276811, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 476556.6058885139, 476556.6058885139, 165402.6710470118], 
processed observation next is [1.0, 1.0, 0.2014218009478673, 0.885, 1.0, 1.0, 0.1542272124429893, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13237683496903163, 0.13237683496903163, 0.24686965827912208], 
reward next is 0.7531, 
noisyNet noise sample is [array([-1.3863688], dtype=float32), -0.7294732]. 
=============================================
[2019-03-26 17:09:50,158] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.0660112e-16 1.0000000e+00 5.9085894e-19 3.1834139e-17 2.9607952e-28], sum to 1.0000
[2019-03-26 17:09:50,164] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0301
[2019-03-26 17:09:50,167] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.73333333333333, 79.50000000000001, 1.0, 2.0, 0.2547506679787006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 418193.4120498577, 418193.4120498583, 161382.8575435627], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 763800.0000, 
sim time next is 764400.0000, 
raw observation next is [20.66666666666667, 80.0, 1.0, 2.0, 0.2553848248439695, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 419233.0722709419, 419233.0722709419, 161446.3840239161], 
processed observation next is [1.0, 0.8695652173913043, 0.17851500789889443, 0.8, 1.0, 1.0, 0.10287328294454158, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.11645363118637275, 0.11645363118637275, 0.24096475227450162], 
reward next is 0.7590, 
noisyNet noise sample is [array([-0.658425], dtype=float32), 0.20034574]. 
=============================================
[2019-03-26 17:09:53,625] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.76383631e-18 1.00000000e+00 3.45201372e-20 1.00320465e-17
 2.98014619e-30], sum to 1.0000
[2019-03-26 17:09:53,633] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6386
[2019-03-26 17:09:53,641] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666666, 97.16666666666667, 1.0, 2.0, 0.3735297665692196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 565849.4265649362, 565849.4265649356, 171724.4730006552], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1036200.0000, 
sim time next is 1036800.0000, 
raw observation next is [22.2, 97.0, 1.0, 2.0, 0.3745609537191627, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 567166.5495109085, 567166.5495109091, 171831.886341989], 
processed observation next is [1.0, 0.0, 0.2511848341232228, 0.97, 1.0, 1.0, 0.24645898038453337, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15754626375303016, 0.15754626375303032, 0.2564655020029687], 
reward next is 0.7435, 
noisyNet noise sample is [array([0.8604453], dtype=float32), 0.2313109]. 
=============================================
[2019-03-26 17:09:53,762] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.2740311e-17 1.0000000e+00 3.6031354e-20 4.6085683e-20 2.8384732e-30], sum to 1.0000
[2019-03-26 17:09:53,769] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2930
[2019-03-26 17:09:53,773] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.73333333333333, 63.00000000000001, 1.0, 2.0, 0.288240026047877, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 462102.2383976206, 462102.2383976199, 164406.2240309341], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 825600.0000, 
sim time next is 826200.0000, 
raw observation next is [24.7, 63.0, 1.0, 2.0, 0.2869081936848457, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 460245.8817735857, 460245.8817735857, 164281.435198904], 
processed observation next is [0.0, 0.5652173913043478, 0.3696682464454976, 0.63, 1.0, 1.0, 0.14085324540342856, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.12784607827044048, 0.12784607827044048, 0.24519617193866267], 
reward next is 0.7548, 
noisyNet noise sample is [array([1.5321785], dtype=float32), -0.07976864]. 
=============================================
[2019-03-26 17:09:57,973] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.7683913e-16 1.0000000e+00 1.2127933e-19 4.6526252e-19 7.2597755e-31], sum to 1.0000
[2019-03-26 17:09:57,979] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4302
[2019-03-26 17:09:57,983] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.86666666666667, 75.33333333333334, 1.0, 2.0, 0.321265914935068, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 503540.6873273724, 503540.6873273718, 167189.2669613167], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 926400.0000, 
sim time next is 927000.0000, 
raw observation next is [23.8, 76.0, 1.0, 2.0, 0.3223766121397979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 504887.1789225037, 504887.1789225037, 167281.2224847983], 
processed observation next is [0.0, 0.7391304347826086, 0.3270142180094788, 0.76, 1.0, 1.0, 0.18358627968650348, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14024643858958435, 0.14024643858958435, 0.2496734663952213], 
reward next is 0.7503, 
noisyNet noise sample is [array([-0.72116804], dtype=float32), -0.5499224]. 
=============================================
[2019-03-26 17:09:57,995] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[78.077286]
 [78.04368 ]
 [77.98235 ]
 [77.92568 ]
 [77.8874  ]], R is [[78.08423615]
 [78.05386353]
 [78.02442169]
 [77.99520111]
 [77.966362  ]].
[2019-03-26 17:10:24,648] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.2972158e-17 1.0000000e+00 2.3921459e-18 4.2014594e-16 6.2769042e-28], sum to 1.0000
[2019-03-26 17:10:24,655] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2556
[2019-03-26 17:10:24,661] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 96.0, 1.0, 2.0, 0.4087115546040583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 602338.6898745953, 602338.6898745946, 174535.2351880883], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1620000.0000, 
sim time next is 1620600.0000, 
raw observation next is [23.1, 95.83333333333333, 1.0, 2.0, 0.4117678222217412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 607040.0174464448, 607040.0174464448, 174980.6030411718], 
processed observation next is [1.0, 0.782608695652174, 0.2938388625592418, 0.9583333333333333, 1.0, 1.0, 0.29128653279727856, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1686222270684569, 0.1686222270684569, 0.26116507916592807], 
reward next is 0.7388, 
noisyNet noise sample is [array([0.03831968], dtype=float32), -0.84177804]. 
=============================================
[2019-03-26 17:10:24,829] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-26 17:10:24,831] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 17:10:24,832] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 17:10:24,833] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:10:24,833] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 17:10:24,835] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:10:24,834] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 17:10:24,836] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:10:24,837] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 17:10:24,838] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:10:24,840] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:10:24,868] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run62
[2019-03-26 17:10:24,893] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run62
[2019-03-26 17:10:24,916] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run62
[2019-03-26 17:10:24,917] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run62
[2019-03-26 17:10:24,918] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run62
[2019-03-26 17:10:26,216] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10635775], dtype=float32), 0.0853094]
[2019-03-26 17:10:26,217] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.45, 81.0, 1.0, 2.0, 0.38215314143027, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 576096.4269521997, 576096.4269521991, 172541.7991773979]
[2019-03-26 17:10:26,217] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:10:26,219] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [5.7438532e-16 1.0000000e+00 4.8810082e-19 1.8470763e-18 1.4560589e-28], sampled 0.4578921006433
[2019-03-26 17:10:49,282] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10635775], dtype=float32), 0.0853094]
[2019-03-26 17:10:49,284] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [23.03333333333333, 96.0, 1.0, 2.0, 0.4111051205245455, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 607126.3332731394, 607126.33327314, 175019.3857618279]
[2019-03-26 17:10:49,285] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 17:10:49,286] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.3149792e-16 1.0000000e+00 2.1627639e-19 3.4547178e-18 4.7921308e-29], sampled 0.8007521603814992
[2019-03-26 17:10:50,255] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10635775], dtype=float32), 0.0853094]
[2019-03-26 17:10:50,256] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.4198978, 91.29894763333334, 1.0, 2.0, 0.5102718187372938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 713030.4039967618, 713030.4039967612, 185219.8510105734]
[2019-03-26 17:10:50,258] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 17:10:50,260] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.13197271e-16 1.00000000e+00 1.34295719e-19 9.21748367e-18
 1.24770085e-29], sampled 0.6861051705159726
[2019-03-26 17:10:55,922] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10635775], dtype=float32), 0.0853094]
[2019-03-26 17:10:55,923] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.13333333333334, 89.0, 1.0, 2.0, 0.4750743144276407, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 668905.1853856562, 668905.1853856555, 180436.7041365251]
[2019-03-26 17:10:55,925] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:10:55,930] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.4773173e-16 1.0000000e+00 1.0417669e-19 5.3569773e-19 1.0714084e-29], sampled 0.9892301437854987
[2019-03-26 17:11:07,458] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10635775], dtype=float32), 0.0853094]
[2019-03-26 17:11:07,461] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [17.80676755333333, 99.9201719, 1.0, 2.0, 0.2477251618098149, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 409128.8062574231, 409128.8062574231, 160627.5350752715]
[2019-03-26 17:11:07,462] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 17:11:07,466] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.9390691e-16 1.0000000e+00 1.4346786e-19 1.4373141e-18 2.1398731e-29], sampled 0.9499715029208208
[2019-03-26 17:11:10,146] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10635775], dtype=float32), 0.0853094]
[2019-03-26 17:11:10,149] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.5, 97.0, 1.0, 2.0, 0.7606526954542268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1097199.113658899, 1097199.113658899, 239146.6568780977]
[2019-03-26 17:11:10,153] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:11:10,158] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.7181766e-16 1.0000000e+00 5.7423111e-19 9.3480111e-17 1.0685641e-28], sampled 0.3983556105529229
[2019-03-26 17:11:29,553] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10635775], dtype=float32), 0.0853094]
[2019-03-26 17:11:29,553] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [32.03226731666666, 68.35072897, 1.0, 2.0, 0.6009258881276264, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 839756.3113168743, 839756.3113168743, 200918.0856256251]
[2019-03-26 17:11:29,556] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 17:11:29,558] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [9.2333255e-17 1.0000000e+00 9.8317712e-20 4.4820583e-18 6.8607681e-30], sampled 0.70908030314024
[2019-03-26 17:12:07,618] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10635775], dtype=float32), 0.0853094]
[2019-03-26 17:12:07,619] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [21.77097360666667, 88.37160078833332, 1.0, 2.0, 0.3368326408957586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 534533.1536234573, 534533.1536234573, 169714.0196077414]
[2019-03-26 17:12:07,620] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 17:12:07,626] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [7.9927895e-17 1.0000000e+00 7.1826303e-20 2.6013592e-18 5.5089138e-30], sampled 0.123128095514349
[2019-03-26 17:12:09,148] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10635775], dtype=float32), 0.0853094]
[2019-03-26 17:12:09,149] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [22.50346348, 89.68682939, 1.0, 2.0, 0.3918977161540571, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 597046.4138392122, 597046.4138392122, 174593.4915347784]
[2019-03-26 17:12:09,149] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 17:12:09,151] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [8.185018e-17 1.000000e+00 7.261339e-20 2.931377e-18 6.537806e-30], sampled 0.43212197623447446
[2019-03-26 17:12:20,367] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8662.6924 2779103732.2345 920.0000
[2019-03-26 17:12:20,423] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8525.2655 2839528478.8932 1053.0000
[2019-03-26 17:12:20,496] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8273.8434 2924935072.0423 1272.0000
[2019-03-26 17:12:20,621] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7962.9165 3156393132.8536 1529.0000
[2019-03-26 17:12:20,702] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8046.4109 3000673819.8386 1594.0000
[2019-03-26 17:12:21,718] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1525000, evaluation results [1525000.0, 7962.916495852489, 3156393132.853628, 1529.0, 8273.843431424766, 2924935072.0422554, 1272.0, 8662.692416145293, 2779103732.234519, 920.0, 8046.410940345636, 3000673819.83864, 1594.0, 8525.265496904969, 2839528478.893239, 1053.0]
[2019-03-26 17:12:23,386] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.1278134e-16 1.0000000e+00 6.0291696e-20 4.8163625e-20 1.0450289e-30], sum to 1.0000
[2019-03-26 17:12:23,394] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2248
[2019-03-26 17:12:23,399] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.85, 93.0, 1.0, 2.0, 0.3826004951318505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 576206.3941894145, 576206.3941894138, 172534.4013985867], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1456200.0000, 
sim time next is 1456800.0000, 
raw observation next is [22.8, 93.33333333333334, 1.0, 2.0, 0.3817276113525269, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 575046.238524547, 575046.2385245475, 172435.9016830741], 
processed observation next is [0.0, 0.8695652173913043, 0.2796208530805688, 0.9333333333333335, 1.0, 1.0, 0.2550935076536469, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1597350662568186, 0.15973506625681877, 0.257367017437424], 
reward next is 0.7426, 
noisyNet noise sample is [array([-1.6355883], dtype=float32), -0.570058]. 
=============================================
[2019-03-26 17:12:38,008] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.9244354e-15 1.0000000e+00 2.3152684e-18 2.3127121e-15 1.1070860e-28], sum to 1.0000
[2019-03-26 17:12:38,017] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5725
[2019-03-26 17:12:38,026] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.7, 94.0, 1.0, 2.0, 0.5106239030525441, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 713522.5556837571, 713522.5556837571, 185277.5712869275], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1724400.0000, 
sim time next is 1725000.0000, 
raw observation next is [25.63333333333333, 94.00000000000001, 1.0, 2.0, 0.5088553574614962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 711050.4436148852, 711050.4436148852, 184995.3250477609], 
processed observation next is [1.0, 1.0, 0.4139020537124801, 0.9400000000000002, 1.0, 1.0, 0.4082594668210798, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19751401211524588, 0.19751401211524588, 0.2761124254444193], 
reward next is 0.7239, 
noisyNet noise sample is [array([-0.9711672], dtype=float32), -0.9926883]. 
=============================================
[2019-03-26 17:12:38,041] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[74.32727]
 [74.29479]
 [74.28431]
 [74.27399]
 [74.26638]], R is [[74.34458923]
 [74.32460785]
 [74.30483246]
 [74.28528595]
 [74.26604462]].
[2019-03-26 17:12:38,664] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.2913685e-12 9.9999797e-01 2.4001649e-12 2.0731941e-06 1.8331589e-19], sum to 1.0000
[2019-03-26 17:12:38,670] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2236
[2019-03-26 17:12:38,677] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 80.5, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.114549839296375, 6.9112, 168.9117128303902, 1598116.03899458, 1453853.726425372, 311349.7530214663], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1693800.0000, 
sim time next is 1694400.0000, 
raw observation next is [28.06666666666666, 80.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 8.386813787104678, 6.9112, 168.9043810159993, 2501239.868569289, 1454441.80858501, 310714.8921621171], 
processed observation next is [1.0, 0.6086956521739131, 0.5292259083728275, 0.8, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.14756137871046784, 0.0, 0.8293978355487647, 0.694788852380358, 0.4040116134958361, 0.46375357039121956], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4628361], dtype=float32), 0.7855935]. 
=============================================
[2019-03-26 17:12:40,168] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.5614098e-17 1.0000000e+00 2.2743346e-19 1.0565278e-17 5.3330944e-29], sum to 1.0000
[2019-03-26 17:12:40,176] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1336
[2019-03-26 17:12:40,182] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.46666666666667, 74.33333333333334, 1.0, 2.0, 0.5686707074686894, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 794664.8538357958, 794664.8538357958, 195055.0817631767], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2130600.0000, 
sim time next is 2131200.0000, 
raw observation next is [30.5, 74.0, 1.0, 2.0, 0.566709085033073, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 791922.645571247, 791922.645571247, 194708.4652772188], 
processed observation next is [0.0, 0.6956521739130435, 0.6445497630331753, 0.74, 1.0, 1.0, 0.47796275305189523, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2199785126586797, 0.2199785126586797, 0.29060964966749075], 
reward next is 0.7094, 
noisyNet noise sample is [array([0.3028357], dtype=float32), 0.43603623]. 
=============================================
[2019-03-26 17:12:41,177] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.20548113e-10 9.99098778e-01 2.89757579e-10 9.01263847e-04
 1.27948975e-17], sum to 1.0000
[2019-03-26 17:12:41,186] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4499
[2019-03-26 17:12:41,197] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1883447.904994338 W.
[2019-03-26 17:12:41,202] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.0, 85.16666666666667, 1.0, 2.0, 0.7059449421525699, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.979014917556444, 6.9112, 168.9125530686267, 1883447.904994338, 1835337.783379829, 386895.4531970315], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1869000.0000, 
sim time next is 1869600.0000, 
raw observation next is [27.0, 85.33333333333334, 1.0, 2.0, 0.3780472222625633, 1.0, 1.0, 0.3780472222625633, 1.0, 2.0, 0.6456688523212274, 6.9112, 6.9112, 170.5573041426782, 1585436.898262054, 1585436.898262054, 339634.6584045538], 
processed observation next is [1.0, 0.6521739130434783, 0.4786729857819906, 0.8533333333333334, 1.0, 1.0, 0.25065930393079916, 1.0, 0.5, 0.25065930393079916, 1.0, 1.0, 0.5678888442941797, 0.0, 0.0, 0.8375144448122397, 0.4403991384061261, 0.4403991384061261, 0.5069174006038116], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3572812], dtype=float32), 0.87894344]. 
=============================================
[2019-03-26 17:12:42,824] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0332935e-10 9.8064661e-01 1.3735076e-10 1.9353345e-02 5.4442682e-17], sum to 1.0000
[2019-03-26 17:12:42,834] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2499
[2019-03-26 17:12:42,843] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2069641.587120257 W.
[2019-03-26 17:12:42,848] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.76666666666667, 82.16666666666667, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.759425021523597, 6.9112, 168.9082642205966, 2069641.587120257, 1467898.279693335, 313553.2597379858], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1957800.0000, 
sim time next is 1958400.0000, 
raw observation next is [25.6, 83.0, 1.0, 2.0, 0.56371702660531, 0.0, 2.0, 0.0, 1.0, 1.0, 0.948685502626656, 6.9112, 6.9112, 168.9122658473262, 1601717.610734266, 1601717.610734266, 340302.4077997134], 
processed observation next is [1.0, 0.6956521739130435, 0.4123222748815167, 0.83, 1.0, 1.0, 0.4743578633798915, 0.0, 1.0, -0.20481927710843376, 1.0, 0.5, 0.9374213446666535, 0.0, 0.0, 0.8294365536802712, 0.4449215585372961, 0.4449215585372961, 0.5079140414921095], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3421799], dtype=float32), 1.0393816]. 
=============================================
[2019-03-26 17:12:44,643] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.3242061e-16 1.0000000e+00 6.6952611e-18 1.8869037e-15 1.0576999e-27], sum to 1.0000
[2019-03-26 17:12:44,650] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5582
[2019-03-26 17:12:44,655] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 84.5, 1.0, 2.0, 0.3927133440211353, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 618773.9956941775, 618773.9956941782, 176834.4018436307], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1789800.0000, 
sim time next is 1790400.0000, 
raw observation next is [22.26666666666667, 85.0, 1.0, 2.0, 0.3156928407504398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 497527.7290635515, 497527.7290635522, 166804.4611558323], 
processed observation next is [1.0, 0.7391304347826086, 0.2543443917851502, 0.85, 1.0, 1.0, 0.17553354307281901, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13820214696209765, 0.13820214696209784, 0.24896188232213778], 
reward next is 0.7510, 
noisyNet noise sample is [array([0.3990934], dtype=float32), -0.1639214]. 
=============================================
[2019-03-26 17:12:55,343] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.7799203e-16 1.0000000e+00 2.8350912e-19 1.7173810e-18 1.2082578e-28], sum to 1.0000
[2019-03-26 17:12:55,355] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3319
[2019-03-26 17:12:55,361] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 82.33333333333334, 1.0, 2.0, 0.495270425329538, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 692061.3174084985, 692061.3174084985, 182858.6997948849], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2637600.0000, 
sim time next is 2638200.0000, 
raw observation next is [27.0, 83.16666666666666, 1.0, 2.0, 0.499595863403963, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 698107.4123252076, 698107.4123252076, 183533.1453478362], 
processed observation next is [0.0, 0.5217391304347826, 0.4786729857819906, 0.8316666666666666, 1.0, 1.0, 0.39710344988429275, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.193918725645891, 0.193918725645891, 0.2739300676833376], 
reward next is 0.7261, 
noisyNet noise sample is [array([0.35609576], dtype=float32), -0.8156726]. 
=============================================
[2019-03-26 17:12:57,062] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.1715569e-16 1.0000000e+00 7.1179123e-18 6.0563389e-15 1.7848933e-27], sum to 1.0000
[2019-03-26 17:12:57,072] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3072
[2019-03-26 17:12:57,076] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 80.0, 1.0, 2.0, 0.5586144297159925, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 780606.9696201672, 780606.9696201679, 193289.1812310101], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2420400.0000, 
sim time next is 2421000.0000, 
raw observation next is [28.95, 80.0, 1.0, 2.0, 0.5566361447008397, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 777841.5048890228, 777841.5048890234, 192945.4512849399], 
processed observation next is [1.0, 0.0, 0.5710900473933649, 0.8, 1.0, 1.0, 0.4658266803624574, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2160670846913952, 0.21606708469139538, 0.2879782854999103], 
reward next is 0.7120, 
noisyNet noise sample is [array([0.20488179], dtype=float32), 0.551512]. 
=============================================
[2019-03-26 17:12:57,094] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[71.53015 ]
 [72.08473 ]
 [72.72    ]
 [73.571   ]
 [73.571526]], R is [[71.17919159]
 [71.1789093 ]
 [71.1781311 ]
 [71.17695618]
 [71.17549896]].
[2019-03-26 17:12:58,436] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.8923441e-17 1.0000000e+00 1.5310105e-19 8.9193128e-19 7.2328276e-30], sum to 1.0000
[2019-03-26 17:12:58,439] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4183
[2019-03-26 17:12:58,445] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.85, 92.0, 1.0, 2.0, 0.5068470436227975, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 708243.1851724104, 708243.1851724099, 184675.9932806488], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2028600.0000, 
sim time next is 2029200.0000, 
raw observation next is [25.96666666666667, 91.33333333333334, 1.0, 2.0, 0.5071619266429156, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 708683.3340249904, 708683.3340249899, 184726.0234999185], 
processed observation next is [0.0, 0.4782608695652174, 0.42969984202211703, 0.9133333333333334, 1.0, 1.0, 0.4062191887264043, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19685648167360845, 0.1968564816736083, 0.27571048283569927], 
reward next is 0.7243, 
noisyNet noise sample is [array([0.10593728], dtype=float32), -0.09876891]. 
=============================================
[2019-03-26 17:13:05,487] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.1829982e-16 1.0000000e+00 9.8976251e-20 2.2238300e-18 2.6561550e-29], sum to 1.0000
[2019-03-26 17:13:05,496] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6746
[2019-03-26 17:13:05,500] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.68333333333333, 90.66666666666667, 1.0, 2.0, 0.5344547091604308, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 746834.3436235257, 746834.3436235257, 189170.4358686113], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2152200.0000, 
sim time next is 2152800.0000, 
raw observation next is [26.6, 91.0, 1.0, 2.0, 0.5327190006761872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 744408.0558479098, 744408.0558479098, 188881.2250719339], 
processed observation next is [0.0, 0.9565217391304348, 0.4597156398104266, 0.91, 1.0, 1.0, 0.43701084418817726, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20678001551330827, 0.20678001551330827, 0.281912276226767], 
reward next is 0.7181, 
noisyNet noise sample is [array([-0.57398677], dtype=float32), -0.48869336]. 
=============================================
[2019-03-26 17:13:10,499] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.3443873e-16 1.0000000e+00 2.9267607e-19 3.8744321e-18 5.9823597e-29], sum to 1.0000
[2019-03-26 17:13:10,500] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4056
[2019-03-26 17:13:10,509] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333334, 85.66666666666666, 1.0, 2.0, 0.490508351975817, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 685404.9337410438, 685404.9337410444, 182122.4945417789], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2648400.0000, 
sim time next is 2649000.0000, 
raw observation next is [26.16666666666667, 87.33333333333334, 1.0, 2.0, 0.4936624669961582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 689813.7229251548, 689813.7229251548, 182609.2640349944], 
processed observation next is [0.0, 0.6521739130434783, 0.4391785150078992, 0.8733333333333334, 1.0, 1.0, 0.38995477951344365, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19161492303476524, 0.19161492303476524, 0.2725511403507379], 
reward next is 0.7274, 
noisyNet noise sample is [array([2.1238372], dtype=float32), 0.7933024]. 
=============================================
[2019-03-26 17:13:10,548] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[73.646194]
 [73.61268 ]
 [73.57259 ]
 [73.533455]
 [73.4717  ]], R is [[73.66703033]
 [73.65853119]
 [73.65054321]
 [73.64303589]
 [73.63597107]].
[2019-03-26 17:13:12,594] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.1415517e-16 1.0000000e+00 5.6149450e-18 6.1959213e-14 3.0946726e-27], sum to 1.0000
[2019-03-26 17:13:12,604] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6514
[2019-03-26 17:13:12,610] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.03333333333333, 77.33333333333334, 1.0, 2.0, 0.5760035941345235, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 804915.7691199516, 804915.7691199511, 196360.841515998], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2319600.0000, 
sim time next is 2320200.0000, 
raw observation next is [29.95, 77.5, 1.0, 2.0, 0.5752929894162296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 803922.383998383, 803922.383998383, 196233.4834917669], 
processed observation next is [1.0, 0.8695652173913043, 0.6184834123222749, 0.775, 1.0, 1.0, 0.48830480652557784, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22331177333288416, 0.22331177333288416, 0.2928857962563685], 
reward next is 0.7071, 
noisyNet noise sample is [array([2.0300047], dtype=float32), -1.0623046]. 
=============================================
[2019-03-26 17:13:12,664] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.0329840e-15 1.0000000e+00 5.9266578e-16 7.8687534e-13 1.6877732e-24], sum to 1.0000
[2019-03-26 17:13:12,676] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0748
[2019-03-26 17:13:12,683] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1973130.374738424 W.
[2019-03-26 17:13:12,691] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.2, 72.0, 1.0, 2.0, 0.7700302087710705, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 6.977795691441997, 6.9112, 168.9119928164059, 1973130.374738424, 1925885.368729716, 401561.4073274726], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2277000.0000, 
sim time next is 2277600.0000, 
raw observation next is [29.4, 71.33333333333333, 1.0, 2.0, 0.5879174094820527, 1.0, 1.0, 0.5879174094820527, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 1643765.198028998, 1643765.198028998, 329828.9386650969], 
processed observation next is [1.0, 0.34782608695652173, 0.5924170616113744, 0.7133333333333333, 1.0, 1.0, 0.503514951183196, 1.0, 0.5, 0.503514951183196, 0.0, 0.5, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.4566014438969439, 0.4566014438969439, 0.4922819980076073], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7108622], dtype=float32), 1.116027]. 
=============================================
[2019-03-26 17:13:13,714] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.5186987e-09 1.8928945e-01 6.7459140e-09 8.1071049e-01 1.7393566e-14], sum to 1.0000
[2019-03-26 17:13:13,721] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1510
[2019-03-26 17:13:13,730] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2009599.610468738 W.
[2019-03-26 17:13:13,736] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.1, 62.0, 1.0, 2.0, 0.4790940106804905, 1.0, 1.0, 0.4790940106804905, 1.0, 2.0, 0.8315393421782091, 6.911199999999999, 6.9112, 170.5573041426782, 2009599.610468738, 2009599.610468739, 400906.0032783092], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2286000.0000, 
sim time next is 2286600.0000, 
raw observation next is [32.08333333333334, 62.16666666666667, 1.0, 2.0, 0.5425360016895312, 1.0, 2.0, 0.5425360016895312, 1.0, 2.0, 0.9422056155372678, 6.9112, 6.9112, 170.5573041426782, 2275985.407959663, 2275985.407959663, 445806.4578776205], 
processed observation next is [1.0, 0.4782608695652174, 0.7195892575039499, 0.6216666666666667, 1.0, 1.0, 0.44883855625244723, 1.0, 1.0, 0.44883855625244723, 1.0, 1.0, 0.9295190433381314, 0.0, 0.0, 0.8375144448122397, 0.6322181688776841, 0.6322181688776841, 0.6653827729516724], 
reward next is 0.3346, 
noisyNet noise sample is [array([-0.36761874], dtype=float32), -0.5776797]. 
=============================================
[2019-03-26 17:13:16,468] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-26 17:13:16,470] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 17:13:16,472] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 17:13:16,472] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:13:16,473] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 17:13:16,475] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 17:13:16,476] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:13:16,477] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:13:16,477] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 17:13:16,477] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:13:16,481] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:13:16,512] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run63
[2019-03-26 17:13:16,512] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run63
[2019-03-26 17:13:16,555] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run63
[2019-03-26 17:13:16,582] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run63
[2019-03-26 17:13:16,585] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run63
[2019-03-26 17:13:35,129] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10279103], dtype=float32), 0.08280471]
[2019-03-26 17:13:35,130] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.25, 74.16666666666667, 1.0, 2.0, 0.8864470430408756, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.96947532228635, 6.9112, 168.9125625845395, 2136066.283203454, 2094723.86030758, 431538.2155954812]
[2019-03-26 17:13:35,131] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:13:35,134] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [8.4586793e-10 9.9735945e-01 1.2717154e-09 2.6405086e-03 7.2246266e-17], sampled 0.37198434661835256
[2019-03-26 17:13:35,136] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2136066.283203454 W.
[2019-03-26 17:13:37,153] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10279103], dtype=float32), 0.08280471]
[2019-03-26 17:13:37,155] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [20.6, 98.0, 1.0, 2.0, 0.3148380840668547, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 497111.9423132369, 497111.9423132376, 166794.2627271379]
[2019-03-26 17:13:37,157] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:13:37,160] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.1537602e-16 1.0000000e+00 1.2240226e-19 4.6737378e-20 2.6980452e-29], sampled 0.9698517065947276
[2019-03-26 17:13:39,255] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10279103], dtype=float32), 0.08280471]
[2019-03-26 17:13:39,259] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [20.16952559166667, 94.16636980833334, 1.0, 2.0, 0.3036165265489451, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 489143.5177479282, 489143.5177479275, 166312.5086500131]
[2019-03-26 17:13:39,260] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 17:13:39,262] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.2700388e-16 1.0000000e+00 1.0203048e-19 4.6853252e-19 1.3768181e-29], sampled 0.34477140312544563
[2019-03-26 17:13:47,641] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10279103], dtype=float32), 0.08280471]
[2019-03-26 17:13:47,643] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [23.5, 92.0, 1.0, 2.0, 0.4150928068441767, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 613755.167870822, 613755.1678708227, 175663.9607498194]
[2019-03-26 17:13:47,644] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:13:47,647] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.2575238e-16 1.0000000e+00 1.1232262e-19 7.5052868e-19 1.7746803e-29], sampled 0.22413017822651116
[2019-03-26 17:14:36,024] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10279103], dtype=float32), 0.08280471]
[2019-03-26 17:14:36,025] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.4, 76.0, 1.0, 2.0, 0.5567914516368947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 778058.6097731311, 778058.6097731318, 192971.8515375006]
[2019-03-26 17:14:36,026] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 17:14:36,027] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.4244028e-16 1.0000000e+00 4.4809790e-19 2.1555673e-17 9.7675403e-29], sampled 0.9478839377350238
[2019-03-26 17:14:42,753] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10279103], dtype=float32), 0.08280471]
[2019-03-26 17:14:42,754] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.727863995, 76.12316246, 1.0, 2.0, 0.5539482544672804, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 786644.3148131925, 786644.314813193, 194089.0842981675]
[2019-03-26 17:14:42,756] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 17:14:42,759] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [4.7930217e-16 1.0000000e+00 8.5338202e-19 1.1666936e-17 3.0261906e-28], sampled 0.38204926181694576
[2019-03-26 17:14:50,493] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10279103], dtype=float32), 0.08280471]
[2019-03-26 17:14:50,494] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.2, 70.5, 1.0, 2.0, 0.5075011301951279, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 709157.4787359153, 709157.4787359147, 184779.8942074112]
[2019-03-26 17:14:50,496] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:14:50,498] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.8777521e-14 1.0000000e+00 1.5164532e-15 4.6868126e-10 3.1013411e-25], sampled 0.5407347659114481
[2019-03-26 17:15:11,823] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8272.4731 2924802124.1248 1270.0000
[2019-03-26 17:15:12,030] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7969.3931 3155523478.3484 1510.0000
[2019-03-26 17:15:12,194] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8663.5504 2778739976.5983 922.0000
[2019-03-26 17:15:12,202] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8063.9579 2998838186.4710 1549.0000
[2019-03-26 17:15:12,267] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8519.4157 2839519032.3846 1057.0000
[2019-03-26 17:15:13,287] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1550000, evaluation results [1550000.0, 7969.393139434377, 3155523478.34839, 1510.0, 8272.473144898353, 2924802124.1247654, 1270.0, 8663.550441670908, 2778739976.5983, 922.0, 8063.957854729506, 2998838186.4710402, 1549.0, 8519.415703569626, 2839519032.3846292, 1057.0]
[2019-03-26 17:15:15,148] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.9995951e-16 1.0000000e+00 8.7595532e-19 1.3218519e-15 4.4818990e-28], sum to 1.0000
[2019-03-26 17:15:15,160] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5764
[2019-03-26 17:15:15,166] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.4, 89.0, 1.0, 2.0, 0.521605518401556, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 728873.0288200259, 728873.0288200252, 187049.960397948], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2584800.0000, 
sim time next is 2585400.0000, 
raw observation next is [26.3, 89.33333333333334, 1.0, 2.0, 0.5197959559566341, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 726343.5460024896, 726343.546002489, 186755.3305043713], 
processed observation next is [1.0, 0.9565217391304348, 0.4454976303317536, 0.8933333333333334, 1.0, 1.0, 0.4214409107911254, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20176209611180268, 0.2017620961118025, 0.27873929926025565], 
reward next is 0.7213, 
noisyNet noise sample is [array([1.8648005], dtype=float32), 0.23986465]. 
=============================================
[2019-03-26 17:15:22,237] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.5595903e-16 1.0000000e+00 7.3635437e-20 1.0404881e-19 1.0769813e-29], sum to 1.0000
[2019-03-26 17:15:22,245] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7709
[2019-03-26 17:15:22,251] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 94.0, 1.0, 2.0, 0.4404975202183125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 632708.5283133048, 632708.5283133048, 177012.2143808495], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2688600.0000, 
sim time next is 2689200.0000, 
raw observation next is [24.0, 94.0, 1.0, 2.0, 0.4399813768221698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 631967.518960236, 631967.5189602353, 176938.3436916701], 
processed observation next is [0.0, 0.13043478260869565, 0.3364928909952607, 0.94, 1.0, 1.0, 0.3252787672556263, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17554653304450998, 0.1755465330445098, 0.26408708013682103], 
reward next is 0.7359, 
noisyNet noise sample is [array([0.1901568], dtype=float32), -0.39116728]. 
=============================================
[2019-03-26 17:15:24,778] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.6221533e-17 1.0000000e+00 2.2440328e-20 7.3689669e-20 8.7024132e-31], sum to 1.0000
[2019-03-26 17:15:24,786] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5424
[2019-03-26 17:15:24,794] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.3960511450640312, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 590966.8437370453, 590966.8437370453, 173706.3800040062], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2674200.0000, 
sim time next is 2674800.0000, 
raw observation next is [23.0, 94.0, 1.0, 2.0, 0.3959781094822624, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 590857.7785036261, 590857.7785036255, 173696.3566230513], 
processed observation next is [0.0, 1.0, 0.28909952606635075, 0.94, 1.0, 1.0, 0.2722627825087499, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1641271606954517, 0.16412716069545155, 0.25924829346724076], 
reward next is 0.7408, 
noisyNet noise sample is [array([-1.1819767], dtype=float32), 0.47686943]. 
=============================================
[2019-03-26 17:15:29,398] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.3941098e-17 1.0000000e+00 5.8726780e-20 1.0771434e-18 8.8788997e-30], sum to 1.0000
[2019-03-26 17:15:29,403] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1602
[2019-03-26 17:15:29,409] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.23333333333333, 92.0, 1.0, 2.0, 0.4449993894872299, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 639556.9271264095, 639556.9271264095, 177708.6451254884], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2600400.0000, 
sim time next is 2601000.0000, 
raw observation next is [24.2, 92.0, 1.0, 2.0, 0.443301228954696, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 637989.3737035977, 637989.3737035977, 177573.5516215751], 
processed observation next is [0.0, 0.08695652173913043, 0.3459715639810427, 0.92, 1.0, 1.0, 0.3292785891020434, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17721927047322159, 0.17721927047322159, 0.2650351516739927], 
reward next is 0.7350, 
noisyNet noise sample is [array([-0.28132996], dtype=float32), -0.221399]. 
=============================================
[2019-03-26 17:15:29,425] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[75.56866 ]
 [75.2613  ]
 [75.1694  ]
 [74.864685]
 [74.859795]], R is [[75.57033539]
 [75.54940033]
 [75.52841187]
 [75.50730133]
 [75.48586273]].
[2019-03-26 17:15:35,044] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.3526996e-16 1.0000000e+00 5.7245981e-18 9.0611339e-16 3.1403145e-27], sum to 1.0000
[2019-03-26 17:15:35,052] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1624
[2019-03-26 17:15:35,058] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 94.0, 1.0, 2.0, 0.7506801962894162, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1049131.948596385, 1049131.948596384, 232164.0864793828], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3386400.0000, 
sim time next is 3387000.0000, 
raw observation next is [26.0, 94.0, 1.0, 2.0, 0.7356349309633216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1028094.881958236, 1028094.881958236, 228724.3100700208], 
processed observation next is [1.0, 0.17391304347826086, 0.4312796208530806, 0.94, 1.0, 1.0, 0.6814878686305079, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2855819116550656, 0.2855819116550656, 0.34137956726868773], 
reward next is 0.6586, 
noisyNet noise sample is [array([0.4546952], dtype=float32), 1.005401]. 
=============================================
[2019-03-26 17:15:35,070] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[71.52421]
 [71.18515]
 [70.95745]
 [70.3866 ]
 [70.22554]], R is [[71.64246368]
 [71.57952881]
 [71.50959778]
 [71.44520569]
 [71.35262299]].
[2019-03-26 17:15:47,470] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.1905031e-16 1.0000000e+00 5.9627733e-19 7.2452981e-18 4.0269691e-28], sum to 1.0000
[2019-03-26 17:15:47,478] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0847
[2019-03-26 17:15:47,482] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.5432639263750915, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 837069.2685101344, 837069.2685101344, 199991.506046124], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2970000.0000, 
sim time next is 2970600.0000, 
raw observation next is [22.0, 93.00000000000001, 1.0, 2.0, 0.540854919852412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 835031.0591947987, 835031.0591947987, 199714.5929616853], 
processed observation next is [1.0, 0.391304347826087, 0.2417061611374408, 0.9300000000000002, 1.0, 1.0, 0.4468131564486891, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2319530719985552, 0.2319530719985552, 0.2980814820323661], 
reward next is 0.7019, 
noisyNet noise sample is [array([0.786006], dtype=float32), -1.2290231]. 
=============================================
[2019-03-26 17:15:56,655] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.2026473e-16 1.0000000e+00 7.9685212e-18 2.5072873e-14 2.8566288e-27], sum to 1.0000
[2019-03-26 17:15:56,663] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1101
[2019-03-26 17:15:56,672] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666667, 96.0, 1.0, 2.0, 0.8303671613011229, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1197061.096569232, 1197061.096569233, 256670.0873613879], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3080400.0000, 
sim time next is 3081000.0000, 
raw observation next is [23.83333333333333, 95.0, 1.0, 2.0, 0.8422351893929869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1212111.288152422, 1212111.288152422, 259527.3534516696], 
processed observation next is [1.0, 0.6521739130434783, 0.32859399684044216, 0.95, 1.0, 1.0, 0.8099219149313095, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.33669758004233946, 0.33669758004233946, 0.38735425888308894], 
reward next is 0.6126, 
noisyNet noise sample is [array([1.1844399], dtype=float32), -1.131069]. 
=============================================
[2019-03-26 17:15:56,688] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[70.52488]
 [70.4503 ]
 [70.3568 ]
 [70.24373]
 [70.06582]], R is [[70.48964691]
 [70.40166473]
 [70.32089996]
 [70.24845123]
 [70.17758942]].
[2019-03-26 17:16:04,965] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0370541e-16 1.0000000e+00 2.7087414e-20 9.4316757e-19 7.4709102e-30], sum to 1.0000
[2019-03-26 17:16:04,976] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7103
[2019-03-26 17:16:04,981] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 0.5380746063124562, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 751894.4923981369, 751894.4923981369, 189776.4799464616], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3363600.0000, 
sim time next is 3364200.0000, 
raw observation next is [27.0, 89.0, 1.0, 2.0, 0.538254196697463, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 752145.5371931671, 752145.5371931671, 189806.637194862], 
processed observation next is [0.0, 0.9565217391304348, 0.4786729857819906, 0.89, 1.0, 1.0, 0.4436797550571843, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20892931588699087, 0.20892931588699087, 0.2832934883505403], 
reward next is 0.7167, 
noisyNet noise sample is [array([-1.4947388], dtype=float32), -1.0260283]. 
=============================================
[2019-03-26 17:16:05,360] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.3334649e-15 1.0000000e+00 2.0390281e-18 3.7588459e-15 6.9374423e-27], sum to 1.0000
[2019-03-26 17:16:05,366] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2538
[2019-03-26 17:16:05,372] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.16666666666667, 93.16666666666667, 1.0, 2.0, 0.8525567548986385, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1191591.978612995, 1191591.978612995, 257219.8526596784], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3388200.0000, 
sim time next is 3388800.0000, 
raw observation next is [26.33333333333334, 92.33333333333334, 1.0, 2.0, 0.8219963233802569, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1148855.509134595, 1148855.509134595, 249381.2279087122], 
processed observation next is [1.0, 0.21739130434782608, 0.44707740916271754, 0.9233333333333335, 1.0, 1.0, 0.7855377390123577, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3191265303151653, 0.3191265303151653, 0.372210787923451], 
reward next is 0.6278, 
noisyNet noise sample is [array([-2.1065302], dtype=float32), -0.2129603]. 
=============================================
[2019-03-26 17:16:08,298] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-26 17:16:08,303] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 17:16:08,304] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:16:08,304] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 17:16:08,306] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:16:08,307] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 17:16:08,308] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 17:16:08,308] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:16:08,311] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 17:16:08,311] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:16:08,314] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:16:08,329] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run64
[2019-03-26 17:16:08,350] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run64
[2019-03-26 17:16:08,371] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run64
[2019-03-26 17:16:08,394] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run64
[2019-03-26 17:16:08,412] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run64
[2019-03-26 17:16:43,101] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10436259], dtype=float32), 0.08390706]
[2019-03-26 17:16:43,102] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [33.91002449, 58.98682787, 1.0, 2.0, 0.6779054315841608, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005973883546901, 6.9112, 168.9123523515159, 1844211.125023447, 1776975.510655585, 379929.0748719594]
[2019-03-26 17:16:43,103] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 17:16:43,104] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [6.7860843e-13 1.0000000e+00 2.4913985e-14 1.2194631e-10 3.6307958e-22], sampled 0.05799982234977752
[2019-03-26 17:16:43,106] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1844211.125023447 W.
[2019-03-26 17:17:19,210] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10436259], dtype=float32), 0.08390706]
[2019-03-26 17:17:19,210] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [36.8, 47.5, 1.0, 2.0, 0.9168499071960453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.9129565104129, 1281506.74254158, 1281506.742541579, 274618.9866131613]
[2019-03-26 17:17:19,211] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:17:19,216] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.1740760e-13 1.0000000e+00 3.2978781e-15 2.5105548e-11 2.3863251e-23], sampled 0.7192110459119228
[2019-03-26 17:17:23,288] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10436259], dtype=float32), 0.08390706]
[2019-03-26 17:17:23,290] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.95, 81.83333333333334, 1.0, 2.0, 0.6162607601723796, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 861194.5228886747, 861194.5228886747, 203813.7215667483]
[2019-03-26 17:17:23,290] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 17:17:23,293] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.9592264e-16 1.0000000e+00 2.1390025e-19 1.4346190e-18 4.6265845e-29], sampled 0.02400191097561788
[2019-03-26 17:17:30,914] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10436259], dtype=float32), 0.08390706]
[2019-03-26 17:17:30,917] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [28.48333333333333, 93.16666666666667, 1.0, 2.0, 0.624398987424128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 872571.9724307673, 872571.9724307667, 205378.9875982567]
[2019-03-26 17:17:30,917] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:17:30,919] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [9.6904421e-17 1.0000000e+00 1.2038053e-19 4.1384007e-18 1.7712987e-29], sampled 0.9270400487036882
[2019-03-26 17:17:37,487] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10436259], dtype=float32), 0.08390706]
[2019-03-26 17:17:37,488] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.707875495, 83.679168655, 1.0, 2.0, 0.5572820699011516, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 778744.4495004601, 778744.4495004601, 193055.7726812872]
[2019-03-26 17:17:37,490] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 17:17:37,492] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [7.5425200e-17 1.0000000e+00 1.6227174e-19 5.3832656e-17 2.0987724e-29], sampled 0.44005651005823243
[2019-03-26 17:17:40,735] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10436259], dtype=float32), 0.08390706]
[2019-03-26 17:17:40,736] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.9, 82.0, 1.0, 2.0, 0.5770585197256992, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 806390.4970202877, 806390.4970202877, 196549.0076223965]
[2019-03-26 17:17:40,738] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 17:17:40,741] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.8251760e-16 1.0000000e+00 1.8677648e-19 1.0464714e-18 3.8841625e-29], sampled 0.6748744697138701
[2019-03-26 17:17:46,366] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10436259], dtype=float32), 0.08390706]
[2019-03-26 17:17:46,368] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.0, 91.0, 1.0, 2.0, 0.76000262765768, 1.0, 1.0, 0.76000262765768, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 172.86236624, 2125349.377034471, 2125349.377034471, 401339.9985477381]
[2019-03-26 17:17:46,368] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:17:46,371] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [6.5595646e-15 1.0000000e+00 1.7560507e-17 1.6419114e-15 4.5768610e-26], sampled 0.2557150727444003
[2019-03-26 17:17:46,374] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2125349.377034471 W.
[2019-03-26 17:18:03,668] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7962.5316 3156175398.4785 1531.0000
[2019-03-26 17:18:03,692] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8270.6482 2925389713.6559 1276.0000
[2019-03-26 17:18:03,878] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8519.8631 2839079364.7176 1054.0000
[2019-03-26 17:18:03,955] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8051.8242 3000847127.0168 1593.0000
[2019-03-26 17:18:04,040] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8662.5920 2778712333.8475 919.0000
[2019-03-26 17:18:05,060] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1575000, evaluation results [1575000.0, 7962.531624799481, 3156175398.4784703, 1531.0, 8270.648210456748, 2925389713.655931, 1276.0, 8662.591970980078, 2778712333.847454, 919.0, 8051.824189202319, 3000847127.016788, 1593.0, 8519.86311521512, 2839079364.7175546, 1054.0]
[2019-03-26 17:18:06,314] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.3661279e-16 1.0000000e+00 2.0381495e-18 5.7224363e-18 5.8274191e-28], sum to 1.0000
[2019-03-26 17:18:06,323] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9989
[2019-03-26 17:18:06,328] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 67.0, 1.0, 2.0, 0.5736982499282367, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 801693.0319605313, 801693.0319605318, 195948.9383480781], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3328200.0000, 
sim time next is 3328800.0000, 
raw observation next is [32.0, 67.0, 1.0, 2.0, 0.573834901793472, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 801884.0630500738, 801884.0630500738, 195973.3259548839], 
processed observation next is [0.0, 0.5217391304347826, 0.7156398104265403, 0.67, 1.0, 1.0, 0.4865480744499662, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22274557306946494, 0.22274557306946494, 0.29249750142519987], 
reward next is 0.7075, 
noisyNet noise sample is [array([-0.7098285], dtype=float32), 1.5021818]. 
=============================================
[2019-03-26 17:18:11,399] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.8475534e-11 1.4417595e-03 7.9677681e-11 9.9855822e-01 6.2970286e-18], sum to 1.0000
[2019-03-26 17:18:11,408] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1220
[2019-03-26 17:18:11,416] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.0, 67.0, 1.0, 2.0, 1.013718591718708, 1.0, 2.0, 1.013718591718708, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2835725.854626317, 2835725.854626318, 537336.7411937848], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3412800.0000, 
sim time next is 3413400.0000, 
raw observation next is [33.0, 67.0, 1.0, 2.0, 1.035452086285541, 1.0, 2.0, 1.035452086285541, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2896592.537563067, 2896592.537563067, 550783.5231265726], 
processed observation next is [1.0, 0.5217391304347826, 0.7630331753554502, 0.67, 1.0, 1.0, 1.0427133569705314, 1.0, 1.0, 1.0427133569705314, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.8046090382119631, 0.8046090382119631, 0.8220649598904068], 
reward next is 0.1779, 
noisyNet noise sample is [array([0.7941207], dtype=float32), -0.44107822]. 
=============================================
[2019-03-26 17:18:12,674] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.5712201e-15 1.0000000e+00 6.4621211e-18 6.2126479e-16 1.9985674e-26], sum to 1.0000
[2019-03-26 17:18:12,682] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8053
[2019-03-26 17:18:12,688] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.00000000000001, 1.0, 2.0, 0.7126459838344051, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 995951.3542207689, 995951.3542207689, 223595.1156155694], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3467400.0000, 
sim time next is 3468000.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.6680389578119544, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 933583.8447510903, 933583.8447510909, 214094.3565840539], 
processed observation next is [1.0, 0.13043478260869565, 0.4786729857819906, 0.79, 1.0, 1.0, 0.6000469371228366, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.25932884576419174, 0.2593288457641919, 0.31954381579709534], 
reward next is 0.6805, 
noisyNet noise sample is [array([0.15736213], dtype=float32), 0.47929546]. 
=============================================
[2019-03-26 17:18:12,710] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[67.377785]
 [67.4002  ]
 [67.40778 ]
 [67.38482 ]
 [67.47428 ]], R is [[67.47929382]
 [67.47077942]
 [67.45862579]
 [67.44161987]
 [67.41665649]].
[2019-03-26 17:18:20,053] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.0467820e-16 1.0000000e+00 7.5789400e-19 3.2057391e-17 2.5439568e-28], sum to 1.0000
[2019-03-26 17:18:20,062] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4995
[2019-03-26 17:18:20,069] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.75, 90.5, 1.0, 2.0, 0.5781903139495733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 807972.6853141182, 807972.6853141176, 196752.6146647437], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3893400.0000, 
sim time next is 3894000.0000, 
raw observation next is [27.66666666666666, 91.0, 1.0, 2.0, 0.577627009638801, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 807185.2154711109, 807185.2154711109, 196651.3604342198], 
processed observation next is [0.0, 0.043478260869565216, 0.5102685624012636, 0.91, 1.0, 1.0, 0.4911168790828927, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22421811540864192, 0.22421811540864192, 0.2935094931854027], 
reward next is 0.7065, 
noisyNet noise sample is [array([1.2677362], dtype=float32), 2.6732323]. 
=============================================
[2019-03-26 17:18:20,084] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[71.179214]
 [71.15838 ]
 [71.05981 ]
 [71.021385]
 [70.826256]], R is [[71.21091461]
 [71.20514679]
 [71.19908142]
 [71.19272614]
 [71.1867981 ]].
[2019-03-26 17:18:22,260] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.8303314e-15 1.0000000e+00 1.7251026e-18 8.5211051e-18 1.8445531e-28], sum to 1.0000
[2019-03-26 17:18:22,268] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0531
[2019-03-26 17:18:22,273] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [34.16666666666667, 59.33333333333333, 1.0, 2.0, 0.6513293883865268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 910222.2297468415, 910222.2297468421, 210695.5985835136], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3931800.0000, 
sim time next is 3932400.0000, 
raw observation next is [34.33333333333334, 58.66666666666667, 1.0, 2.0, 0.6018250241588811, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 841013.2950912022, 841013.2950912022, 201086.6152731599], 
processed observation next is [0.0, 0.5217391304347826, 0.8262243285939973, 0.5866666666666667, 1.0, 1.0, 0.520271113444435, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23361480419200062, 0.23361480419200062, 0.3001292765271043], 
reward next is 0.6999, 
noisyNet noise sample is [array([0.06804229], dtype=float32), -0.46484885]. 
=============================================
[2019-03-26 17:18:24,455] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0280229e-15 1.0000000e+00 1.1766152e-18 4.4890933e-17 6.8749452e-29], sum to 1.0000
[2019-03-26 17:18:24,464] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9210
[2019-03-26 17:18:24,471] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 79.0, 1.0, 2.0, 0.6214420417559785, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 868438.0727718945, 868438.0727718945, 204809.1119490259], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3970800.0000, 
sim time next is 3971400.0000, 
raw observation next is [30.83333333333334, 79.83333333333334, 1.0, 2.0, 0.6345517343025823, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 886765.9427293071, 886765.9427293071, 207359.2051816386], 
processed observation next is [0.0, 1.0, 0.6603475513428123, 0.7983333333333335, 1.0, 1.0, 0.5597008847019064, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2463238729803631, 0.2463238729803631, 0.309491351017371], 
reward next is 0.6905, 
noisyNet noise sample is [array([-1.529969], dtype=float32), -0.14695509]. 
=============================================
[2019-03-26 17:18:29,429] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.17923673e-15 1.00000000e+00 1.19058537e-17 8.98050406e-13
 1.21527135e-26], sum to 1.0000
[2019-03-26 17:18:29,439] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7735
[2019-03-26 17:18:29,446] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 76.5, 1.0, 2.0, 0.5413980553911583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 756540.2662723038, 756540.2662723038, 190336.320302138], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3699000.0000, 
sim time next is 3699600.0000, 
raw observation next is [29.0, 75.66666666666666, 1.0, 2.0, 0.5359869445913245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 748976.2079533341, 748976.2079533335, 189426.4703816694], 
processed observation next is [1.0, 0.8260869565217391, 0.5734597156398105, 0.7566666666666666, 1.0, 1.0, 0.4409481260136439, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2080489466537039, 0.20804894665370374, 0.2827260751965215], 
reward next is 0.7173, 
noisyNet noise sample is [array([-0.20046018], dtype=float32), -1.2814218]. 
=============================================
[2019-03-26 17:18:46,360] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0052744e-15 1.0000000e+00 4.6052164e-18 1.2980917e-14 3.6154867e-27], sum to 1.0000
[2019-03-26 17:18:46,367] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3759
[2019-03-26 17:18:46,371] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 84.0, 1.0, 2.0, 0.5832246196768941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 815010.4062550204, 815010.4062550204, 197662.1721715487], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4142400.0000, 
sim time next is 4143000.0000, 
raw observation next is [29.0, 84.0, 1.0, 2.0, 0.5833665816437785, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 815208.863036261, 815208.8630362618, 197687.9080803803], 
processed observation next is [1.0, 0.9565217391304348, 0.5734597156398105, 0.84, 1.0, 1.0, 0.49803202607684155, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2264469063989614, 0.2264469063989616, 0.2950565792244482], 
reward next is 0.7049, 
noisyNet noise sample is [array([0.1935168], dtype=float32), -0.34346497]. 
=============================================
[2019-03-26 17:18:46,385] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[69.383385]
 [69.53807 ]
 [69.7897  ]
 [69.966705]
 [70.34627 ]], R is [[69.22366333]
 [69.23640442]
 [69.24920654]
 [69.26194   ]
 [69.2743988 ]].
[2019-03-26 17:18:50,302] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.87056787e-15 1.00000000e+00 2.73463781e-18 1.32324495e-14
 9.04944176e-27], sum to 1.0000
[2019-03-26 17:18:50,311] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1352
[2019-03-26 17:18:50,317] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 84.0, 1.0, 2.0, 0.5441111608541516, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 760332.8697530448, 760332.8697530441, 190796.0943649762], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4053600.0000, 
sim time next is 4054200.0000, 
raw observation next is [27.83333333333334, 84.83333333333333, 1.0, 2.0, 0.543206161525321, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 759067.7852456463, 759067.785245647, 190642.5440530445], 
processed observation next is [1.0, 0.9565217391304348, 0.5181674565560824, 0.8483333333333333, 1.0, 1.0, 0.44964597774135057, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21085216256823508, 0.21085216256823527, 0.2845411105269321], 
reward next is 0.7155, 
noisyNet noise sample is [array([-0.054005], dtype=float32), -1.4025575]. 
=============================================
[2019-03-26 17:18:59,844] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-26 17:18:59,845] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 17:18:59,845] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:18:59,846] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 17:18:59,847] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:18:59,848] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 17:18:59,849] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:18:59,851] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 17:18:59,852] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:18:59,853] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 17:18:59,856] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:18:59,880] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run65
[2019-03-26 17:18:59,905] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run65
[2019-03-26 17:18:59,906] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run65
[2019-03-26 17:18:59,946] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run65
[2019-03-26 17:18:59,967] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run65
[2019-03-26 17:19:20,066] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10708078], dtype=float32), 0.08177838]
[2019-03-26 17:19:20,068] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.1, 56.0, 1.0, 2.0, 0.2676408765101833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 440504.1069937837, 440504.1069937837, 162692.8170211527]
[2019-03-26 17:19:20,068] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:19:20,071] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.7210941e-16 1.0000000e+00 3.4130217e-19 1.0544858e-18 1.9531550e-28], sampled 0.7533196292880906
[2019-03-26 17:19:57,911] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10708078], dtype=float32), 0.08177838]
[2019-03-26 17:19:57,912] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [31.89671588166667, 64.889301605, 1.0, 2.0, 0.8186674255447296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1144200.399279934, 1144200.399279934, 248546.8148189228]
[2019-03-26 17:19:57,915] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 17:19:57,919] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [6.4818048e-16 1.0000000e+00 1.7238396e-18 9.6696527e-17 1.3175446e-27], sampled 0.5101203052033805
[2019-03-26 17:20:00,244] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10708078], dtype=float32), 0.08177838]
[2019-03-26 17:20:00,246] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [33.54994173, 62.56750566, 1.0, 2.0, 0.8154608203620296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1139716.322001414, 1139716.322001414, 247746.4168197952]
[2019-03-26 17:20:00,247] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 17:20:00,250] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.7860427e-14 1.0000000e+00 3.0866256e-16 5.0095154e-12 4.1445948e-25], sampled 0.04086212829199909
[2019-03-26 17:20:54,658] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8665.9660 2778642832.7460 912.0000
[2019-03-26 17:20:54,676] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8061.8735 2999609669.7840 1566.0000
[2019-03-26 17:20:54,904] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8523.5401 2839224379.8869 1052.0000
[2019-03-26 17:20:55,115] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7963.9770 3155585222.1420 1523.0000
[2019-03-26 17:20:55,119] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8272.7136 2924998145.5845 1268.0000
[2019-03-26 17:20:56,136] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1600000, evaluation results [1600000.0, 7963.976971520906, 3155585222.1420355, 1523.0, 8272.713581465723, 2924998145.5845027, 1268.0, 8665.965980602934, 2778642832.746013, 912.0, 8061.873463314915, 2999609669.783969, 1566.0, 8523.540137099135, 2839224379.8869395, 1052.0]
[2019-03-26 17:20:59,173] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.4272867e-12 1.0041270e-02 1.2714766e-11 9.8995870e-01 1.6662607e-18], sum to 1.0000
[2019-03-26 17:20:59,180] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9276
[2019-03-26 17:20:59,185] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.66666666666667, 64.33333333333333, 1.0, 2.0, 0.8839046953832204, 1.0, 2.0, 0.8839046953832204, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2472231.64746976, 2472231.64746976, 462797.0799732752], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4625400.0000, 
sim time next is 4626000.0000, 
raw observation next is [34.0, 63.0, 1.0, 2.0, 0.8916754616101077, 1.0, 2.0, 0.8916754616101077, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2493987.733149339, 2493987.733149339, 466980.9987846825], 
processed observation next is [1.0, 0.5652173913043478, 0.8104265402843602, 0.63, 1.0, 1.0, 0.8694885079639851, 1.0, 1.0, 0.8694885079639851, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6927743703192608, 0.6927743703192608, 0.6969865653502724], 
reward next is 0.3030, 
noisyNet noise sample is [array([1.1297598], dtype=float32), -0.007747197]. 
=============================================
[2019-03-26 17:20:59,205] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[57.83854 ]
 [57.954292]
 [57.608368]
 [56.97886 ]
 [56.080986]], R is [[57.43324661]
 [57.16817093]
 [56.93501282]
 [56.78188705]
 [56.59597397]].
[2019-03-26 17:20:59,331] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.5250611e-17 1.0000000e+00 1.8492044e-19 2.7616531e-18 7.5952538e-29], sum to 1.0000
[2019-03-26 17:20:59,339] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6820
[2019-03-26 17:20:59,349] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.5, 79.0, 1.0, 2.0, 0.5792908206771125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 809511.1376075802, 809511.1376075802, 196950.6193577511], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4473000.0000, 
sim time next is 4473600.0000, 
raw observation next is [29.33333333333334, 79.0, 1.0, 2.0, 0.5745304247726876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 802856.3628796691, 802856.3628796698, 196096.1862347673], 
processed observation next is [0.0, 0.782608695652174, 0.5892575039494474, 0.79, 1.0, 1.0, 0.48738605394299706, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22301565635546364, 0.22301565635546383, 0.2926808749772646], 
reward next is 0.7073, 
noisyNet noise sample is [array([0.6158975], dtype=float32), 0.13639772]. 
=============================================
[2019-03-26 17:21:03,492] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.0184773e-16 1.0000000e+00 2.4437588e-19 4.8526981e-18 3.3618361e-28], sum to 1.0000
[2019-03-26 17:21:03,498] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5983
[2019-03-26 17:21:03,503] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.5091322767022494, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 711437.5270628781, 711437.5270628781, 185038.7082868818], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4498800.0000, 
sim time next is 4499400.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.5085719292308827, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 710654.2619121685, 710654.261912169, 184949.4775477625], 
processed observation next is [0.0, 0.043478260869565216, 0.4312796208530806, 0.89, 1.0, 1.0, 0.4079179870251598, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19740396164226903, 0.19740396164226917, 0.27604399633994403], 
reward next is 0.7240, 
noisyNet noise sample is [array([1.234448], dtype=float32), 0.07723]. 
=============================================
[2019-03-26 17:21:04,010] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.4970453e-12 1.2523186e-07 2.2743436e-11 9.9999988e-01 1.4299544e-16], sum to 1.0000
[2019-03-26 17:21:04,019] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5808
[2019-03-26 17:21:04,026] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.66666666666666, 72.33333333333333, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 7.084177355942541, 6.9112, 170.5573041426782, 3033384.795719872, 2909474.079389261, 552760.9184520037], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4354800.0000, 
sim time next is 4355400.0000, 
raw observation next is [33.83333333333334, 71.66666666666667, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 7.548552924491952, 6.9112, 170.5573041426782, 3366423.388694102, 2909861.563021145, 550159.7043950927], 
processed observation next is [1.0, 0.391304347826087, 0.8025276461295423, 0.7166666666666667, 1.0, 1.0, 1.0481927710843375, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.2195121951219512, 0.06373529244919522, 0.0, 0.8375144448122397, 0.9351176079705839, 0.8082948786169847, 0.8211338871568548], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.35845083], dtype=float32), -1.045591]. 
=============================================
[2019-03-26 17:21:07,598] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.5251371e-16 1.0000000e+00 2.4155580e-17 7.2504595e-13 1.2855558e-28], sum to 1.0000
[2019-03-26 17:21:07,606] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3126
[2019-03-26 17:21:07,609] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.16666666666667, 63.0, 1.0, 2.0, 0.5300957246783313, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 740741.078191181, 740741.0781911802, 188445.7701651514], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4391400.0000, 
sim time next is 4392000.0000, 
raw observation next is [31.0, 63.0, 1.0, 2.0, 0.5247837973173619, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 733315.7759126496, 733315.7759126503, 187570.242284233], 
processed observation next is [1.0, 0.8695652173913043, 0.6682464454976303, 0.63, 1.0, 1.0, 0.42745035821368904, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20369882664240266, 0.20369882664240285, 0.27995558549885524], 
reward next is 0.7200, 
noisyNet noise sample is [array([-1.1482133], dtype=float32), -0.2541087]. 
=============================================
[2019-03-26 17:21:07,618] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[76.31423]
 [77.73889]
 [79.12881]
 [80.1497 ]
 [81.07219]], R is [[74.89295959]
 [74.86276245]
 [74.83174896]
 [74.80014801]
 [74.76786041]].
[2019-03-26 17:21:11,935] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.1990446e-17 1.0000000e+00 7.4338205e-20 1.1260153e-18 2.1758609e-29], sum to 1.0000
[2019-03-26 17:21:11,946] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5027
[2019-03-26 17:21:11,954] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333333, 84.83333333333333, 1.0, 2.0, 0.5183244166576846, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 724286.5706564924, 724286.5706564924, 186516.2963389615], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4489800.0000, 
sim time next is 4490400.0000, 
raw observation next is [26.66666666666667, 85.66666666666667, 1.0, 2.0, 0.5162255930472541, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 721352.7595897908, 721352.7595897908, 186176.7387330674], 
processed observation next is [0.0, 1.0, 0.4628751974723541, 0.8566666666666667, 1.0, 1.0, 0.41713926873163143, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2003757665527197, 0.2003757665527197, 0.2778757294523394], 
reward next is 0.7221, 
noisyNet noise sample is [array([1.3619134], dtype=float32), -1.3496764]. 
=============================================
[2019-03-26 17:21:13,828] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.9996052e-17 1.0000000e+00 1.2696833e-19 3.7649658e-19 8.3401275e-30], sum to 1.0000
[2019-03-26 17:21:13,839] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6848
[2019-03-26 17:21:13,848] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.5134090715666738, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 717415.7373815287, 717415.7373815293, 185723.4554471353], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4520400.0000, 
sim time next is 4521000.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.5134148259972892, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 717423.7810905465, 717423.7810905459, 185724.3795693072], 
processed observation next is [0.0, 0.30434782608695654, 0.4786729857819906, 0.84, 1.0, 1.0, 0.41375280240637247, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1992843836362629, 0.19928438363626275, 0.27720056652135405], 
reward next is 0.7228, 
noisyNet noise sample is [array([-0.27589962], dtype=float32), 0.641113]. 
=============================================
[2019-03-26 17:21:13,858] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[71.36522]
 [71.34857]
 [71.33294]
 [71.32189]
 [71.29397]], R is [[71.39073944]
 [71.39963531]
 [71.40853119]
 [71.41742706]
 [71.42630768]].
[2019-03-26 17:21:14,040] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.8129906e-16 1.0000000e+00 3.2775775e-20 1.1098523e-19 3.3792307e-29], sum to 1.0000
[2019-03-26 17:21:14,045] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0029
[2019-03-26 17:21:14,050] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 86.5, 1.0, 2.0, 0.5085835229625861, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 710670.4678615045, 710670.4678615045, 184951.6564859185], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4516200.0000, 
sim time next is 4516800.0000, 
raw observation next is [26.66666666666667, 85.66666666666667, 1.0, 2.0, 0.5096431343431829, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 712151.6148201709, 712151.6148201709, 185120.5779413317], 
processed observation next is [0.0, 0.2608695652173913, 0.4628751974723541, 0.8566666666666667, 1.0, 1.0, 0.4092085955941962, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19781989300560304, 0.19781989300560304, 0.2762993700616891], 
reward next is 0.7237, 
noisyNet noise sample is [array([-0.17195645], dtype=float32), -0.026369536]. 
=============================================
[2019-03-26 17:21:14,978] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.9218373e-16 1.0000000e+00 7.4115683e-19 1.7848608e-18 4.6339322e-29], sum to 1.0000
[2019-03-26 17:21:14,992] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5906
[2019-03-26 17:21:14,996] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [34.0, 50.0, 1.0, 2.0, 0.5248473823490418, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 733404.658236917, 733404.658236917, 187580.9054157611], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4543200.0000, 
sim time next is 4543800.0000, 
raw observation next is [34.0, 50.5, 1.0, 2.0, 0.5416952461503156, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 756955.7034645606, 756955.7034645611, 190385.9096379447], 
processed observation next is [0.0, 0.6086956521739131, 0.8104265402843602, 0.505, 1.0, 1.0, 0.4478255977714646, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21026547318460015, 0.21026547318460032, 0.2841580740864846], 
reward next is 0.7158, 
noisyNet noise sample is [array([-0.5103228], dtype=float32), 0.86161405]. 
=============================================
[2019-03-26 17:21:15,104] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.4155899e-14 1.0000000e+00 2.1930662e-16 7.4782560e-14 8.1253166e-25], sum to 1.0000
[2019-03-26 17:21:15,112] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6727
[2019-03-26 17:21:15,120] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1912115.408060752 W.
[2019-03-26 17:21:15,125] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.5, 77.0, 1.0, 2.0, 0.7264307407134263, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 6.997361067221316, 6.9112, 168.9117644768777, 1912115.408060752, 1850990.212907785, 390815.1469627995], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4696200.0000, 
sim time next is 4696800.0000, 
raw observation next is [29.66666666666667, 76.33333333333334, 1.0, 2.0, 0.8471060634789535, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.998922709020061, 6.9112, 168.9123650485908, 2081002.218370057, 2018768.927324056, 420079.0224891172], 
processed observation next is [1.0, 0.34782608695652173, 0.6050552922590839, 0.7633333333333334, 1.0, 1.0, 0.8157904379264499, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.008772270902006074, 0.0, 0.8294370408038949, 0.5780561717694602, 0.5607691464789044, 0.6269836156553988], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.00795923], dtype=float32), -0.16289574]. 
=============================================
[2019-03-26 17:21:15,922] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.5909645e-15 1.0000000e+00 3.8761915e-18 1.8333973e-15 1.3690638e-26], sum to 1.0000
[2019-03-26 17:21:15,929] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4423
[2019-03-26 17:21:15,936] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 84.0, 1.0, 2.0, 0.8087786723191052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1130372.149146386, 1130372.149146385, 246077.820539602], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4690800.0000, 
sim time next is 4691400.0000, 
raw observation next is [28.16666666666667, 83.16666666666667, 1.0, 2.0, 0.8018281900160361, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1120652.830650528, 1120652.830650527, 244360.9320847051], 
processed observation next is [1.0, 0.30434782608695654, 0.5339652448657191, 0.8316666666666667, 1.0, 1.0, 0.7612387831518507, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.31129245295848, 0.31129245295847974, 0.3647178090816494], 
reward next is 0.6353, 
noisyNet noise sample is [array([0.34132442], dtype=float32), -2.4633186]. 
=============================================
[2019-03-26 17:21:22,125] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.6209684e-17 1.0000000e+00 3.5966278e-19 8.6502472e-17 1.2064432e-28], sum to 1.0000
[2019-03-26 17:21:22,132] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0843
[2019-03-26 17:21:22,141] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.492324315942019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 687943.2670588401, 687943.2670588401, 182401.8646252258], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4665600.0000, 
sim time next is 4666200.0000, 
raw observation next is [25.33333333333334, 92.33333333333334, 1.0, 2.0, 0.4964022733737382, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 693643.4106462325, 693643.4106462318, 183034.0097531545], 
processed observation next is [1.0, 0.0, 0.3996840442338076, 0.9233333333333335, 1.0, 1.0, 0.3932557510526966, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19267872517950904, 0.19267872517950885, 0.2731850891838127], 
reward next is 0.7268, 
noisyNet noise sample is [array([-0.15362495], dtype=float32), -0.07853766]. 
=============================================
[2019-03-26 17:21:22,375] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.4722764e-16 1.0000000e+00 1.4231941e-18 1.2097734e-16 1.2598557e-26], sum to 1.0000
[2019-03-26 17:21:22,380] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1949
[2019-03-26 17:21:22,384] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 85.66666666666667, 1.0, 2.0, 0.5136318924589645, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 717727.2028932939, 717727.2028932932, 185759.8312043077], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4670400.0000, 
sim time next is 4671000.0000, 
raw observation next is [27.0, 86.5, 1.0, 2.0, 0.5172810214406194, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 722828.0743134439, 722828.0743134439, 186348.385325485], 
processed observation next is [1.0, 0.043478260869565216, 0.4786729857819906, 0.865, 1.0, 1.0, 0.41841086920556547, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20078557619817886, 0.20078557619817886, 0.27813191839624624], 
reward next is 0.7219, 
noisyNet noise sample is [array([-0.41236705], dtype=float32), -0.9520185]. 
=============================================
[2019-03-26 17:21:22,407] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[67.841484]
 [67.77826 ]
 [67.77549 ]
 [67.63104 ]
 [67.74254 ]], R is [[67.87553406]
 [67.91952515]
 [67.96392059]
 [68.00861359]
 [68.05334473]].
[2019-03-26 17:21:24,571] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.6690924e-16 1.0000000e+00 2.3504010e-18 5.7212639e-16 3.8153951e-27], sum to 1.0000
[2019-03-26 17:21:24,575] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4023
[2019-03-26 17:21:24,580] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.6804918828114739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 950994.5880500379, 950994.5880500379, 216689.0901414799], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4858200.0000, 
sim time next is 4858800.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.7017733064338769, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 980749.3349556434, 980749.3349556434, 221226.7558547518], 
processed observation next is [1.0, 0.21739130434782608, 0.4786729857819906, 0.84, 1.0, 1.0, 0.6406907306432252, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.27243037082101207, 0.27243037082101207, 0.3301891878429131], 
reward next is 0.6698, 
noisyNet noise sample is [array([1.6117764], dtype=float32), 0.6517962]. 
=============================================
[2019-03-26 17:21:35,539] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.1809269e-16 1.0000000e+00 3.3641865e-19 1.6229782e-18 2.5061698e-28], sum to 1.0000
[2019-03-26 17:21:35,550] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0949
[2019-03-26 17:21:35,557] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 86.5, 1.0, 2.0, 0.5146236257301708, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 719113.4775577422, 719113.4775577415, 185918.4154986019], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5099400.0000, 
sim time next is 5100000.0000, 
raw observation next is [26.33333333333334, 87.33333333333333, 1.0, 2.0, 0.5131314479582318, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 717027.6671699791, 717027.6671699791, 185678.4695288258], 
processed observation next is [0.0, 0.0, 0.44707740916271754, 0.8733333333333333, 1.0, 1.0, 0.41341138308220704, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19917435199166086, 0.19917435199166086, 0.27713204407287434], 
reward next is 0.7229, 
noisyNet noise sample is [array([-1.4785913], dtype=float32), 0.8477147]. 
=============================================
[2019-03-26 17:21:35,566] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[71.6717 ]
 [71.95311]
 [72.44923]
 [73.04613]
 [73.87469]], R is [[71.57793427]
 [71.58466339]
 [71.59094238]
 [71.59663391]
 [71.60227203]].
[2019-03-26 17:21:41,618] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.1744708e-13 1.0000000e+00 4.7450150e-15 5.8600017e-12 4.9693942e-23], sum to 1.0000
[2019-03-26 17:21:41,626] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2119
[2019-03-26 17:21:41,631] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 86.5, 1.0, 2.0, 0.5373240918244456, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9084363489052549, 6.911199999999999, 6.9112, 168.9129564226556, 1502221.859434403, 1502221.859434404, 324166.7424325305], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5193000.0000, 
sim time next is 5193600.0000, 
raw observation next is [26.33333333333334, 87.33333333333333, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.546640891294885, 6.9112, 168.9095570980267, 1904858.269240045, 1454063.703295549, 311348.3218831458], 
processed observation next is [1.0, 0.08695652173913043, 0.44707740916271754, 0.8733333333333333, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 0.0635440891294885, 0.0, 0.8294232524811399, 0.5291272970111236, 0.4039065842487636, 0.4646989878852922], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.0691556], dtype=float32), 0.79600024]. 
=============================================
[2019-03-26 17:21:43,039] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.7074129e-17 1.0000000e+00 4.0589100e-20 5.8606853e-19 4.1371939e-29], sum to 1.0000
[2019-03-26 17:21:43,050] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5333
[2019-03-26 17:21:43,056] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 87.33333333333333, 1.0, 2.0, 0.4878876570466119, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 681741.7675323692, 681741.7675323692, 181720.2063402289], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5020800.0000, 
sim time next is 5021400.0000, 
raw observation next is [26.0, 88.16666666666667, 1.0, 2.0, 0.491929910150616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 687391.9707137512, 687391.9707137519, 182341.4938957685], 
processed observation next is [0.0, 0.08695652173913043, 0.4312796208530806, 0.8816666666666667, 1.0, 1.0, 0.3878673616272482, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1909422140871531, 0.19094221408715328, 0.2721514834265202], 
reward next is 0.7278, 
noisyNet noise sample is [array([-0.34365407], dtype=float32), 0.56276476]. 
=============================================
[2019-03-26 17:21:45,456] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.2731426e-17 1.0000000e+00 1.2610383e-19 4.7475039e-19 2.1589939e-29], sum to 1.0000
[2019-03-26 17:21:45,465] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9439
[2019-03-26 17:21:45,472] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.5, 61.0, 1.0, 2.0, 0.520904719009403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 727893.4211147603, 727893.4211147596, 186936.6864803091], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5063400.0000, 
sim time next is 5064000.0000, 
raw observation next is [31.66666666666666, 60.33333333333333, 1.0, 2.0, 0.5212675674919582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 728400.6263068545, 728400.6263068538, 186995.8504322216], 
processed observation next is [0.0, 0.6086956521739131, 0.6998420221169034, 0.6033333333333333, 1.0, 1.0, 0.42321393673729907, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20233350730745958, 0.2023335073074594, 0.2790982842271964], 
reward next is 0.7209, 
noisyNet noise sample is [array([-2.111878], dtype=float32), -1.1990072]. 
=============================================
[2019-03-26 17:21:45,486] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[74.022995]
 [73.97954 ]
 [73.930466]
 [73.88602 ]
 [73.81209 ]], R is [[74.03694153]
 [74.01756287]
 [73.99800873]
 [73.97563171]
 [73.95648193]].
[2019-03-26 17:21:48,113] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.6145919e-17 1.0000000e+00 4.1155063e-20 2.5361283e-20 1.6755484e-29], sum to 1.0000
[2019-03-26 17:21:48,121] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8459
[2019-03-26 17:21:48,126] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 84.0, 1.0, 2.0, 0.482364311720772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 674146.5682088706, 674146.5682088699, 180894.5739038551], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5111400.0000, 
sim time next is 5112000.0000, 
raw observation next is [26.0, 84.0, 1.0, 2.0, 0.4835689770511917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 675829.8095865631, 675829.8095865624, 181077.0919183193], 
processed observation next is [0.0, 0.17391304347826086, 0.4312796208530806, 0.84, 1.0, 1.0, 0.37779394825444784, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1877305026629342, 0.187730502662934, 0.27026431629599895], 
reward next is 0.7297, 
noisyNet noise sample is [array([-0.02609538], dtype=float32), 0.73537666]. 
=============================================
[2019-03-26 17:21:48,136] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[72.68397]
 [72.81737]
 [72.93436]
 [72.97184]
 [73.03148]], R is [[72.60906982]
 [72.61299133]
 [72.61721039]
 [72.62119293]
 [72.62496185]].
[2019-03-26 17:21:50,999] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-26 17:21:50,999] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 17:21:51,001] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:21:51,001] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 17:21:51,003] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 17:21:51,003] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 17:21:51,004] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 17:21:51,005] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:21:51,004] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:21:51,005] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:21:51,005] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:21:51,038] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run66
[2019-03-26 17:21:51,061] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run66
[2019-03-26 17:21:51,084] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run66
[2019-03-26 17:21:51,105] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run66
[2019-03-26 17:21:51,130] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run66
[2019-03-26 17:22:11,123] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10496823], dtype=float32), 0.08428287]
[2019-03-26 17:22:11,126] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.85, 86.66666666666667, 1.0, 2.0, 0.3457964186680915, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 534249.9698801828, 534249.9698801828, 169392.7170558443]
[2019-03-26 17:22:11,127] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:22:11,130] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.4381060e-17 1.0000000e+00 2.2120842e-20 6.5737227e-21 5.1345589e-30], sampled 0.11241294358100862
[2019-03-26 17:22:44,233] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10496823], dtype=float32), 0.08428287]
[2019-03-26 17:22:44,234] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.249788385, 67.86413830999999, 1.0, 2.0, 0.5391429401636196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 753387.8897730595, 753387.8897730602, 189953.2738356068]
[2019-03-26 17:22:44,235] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 17:22:44,237] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.4041334e-15 1.0000000e+00 6.2241937e-18 1.2646635e-15 4.4863656e-27], sampled 0.8240486936430658
[2019-03-26 17:22:47,950] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10496823], dtype=float32), 0.08428287]
[2019-03-26 17:22:47,953] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [34.0, 60.0, 1.0, 2.0, 0.59795932202276, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 835609.0901588723, 835609.0901588729, 200366.724353474]
[2019-03-26 17:22:47,954] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:22:47,957] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.71938417e-17 1.00000000e+00 5.69638252e-20 7.49198574e-19
 1.15829196e-29], sampled 0.8780000709264392
[2019-03-26 17:23:03,734] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10496823], dtype=float32), 0.08428287]
[2019-03-26 17:23:03,735] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.5, 84.0, 1.0, 2.0, 0.5230875223035841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 730944.6409575349, 730944.6409575342, 187292.8553258931]
[2019-03-26 17:23:03,737] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:23:03,739] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [7.00964762e-17 1.00000000e+00 4.37983087e-20 4.82940644e-20
 1.17212435e-29], sampled 0.7783443028698052
[2019-03-26 17:23:19,652] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10496823], dtype=float32), 0.08428287]
[2019-03-26 17:23:19,655] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [32.63333333333333, 61.33333333333333, 1.0, 2.0, 0.5699360944633319, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 796433.778364877, 796433.778364877, 195278.4195141195]
[2019-03-26 17:23:19,656] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:23:19,658] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [4.8608923e-16 1.0000000e+00 2.5302074e-18 3.8933577e-15 3.9935130e-28], sampled 0.5768657123415474
[2019-03-26 17:23:23,382] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10496823], dtype=float32), 0.08428287]
[2019-03-26 17:23:23,386] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.40977096, 69.66635115666668, 1.0, 2.0, 0.5172644440958095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 722804.9019052088, 722804.9019052088, 186344.9703401204]
[2019-03-26 17:23:23,388] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 17:23:23,390] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [9.2082811e-17 1.0000000e+00 5.9540648e-20 6.7808208e-20 1.7508093e-29], sampled 0.20350031866242635
[2019-03-26 17:23:39,012] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10496823], dtype=float32), 0.08428287]
[2019-03-26 17:23:39,012] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.11492219333334, 94.96766904166667, 1.0, 2.0, 0.4237307337240955, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 621435.8715106205, 621435.8715106205, 176259.5950764687]
[2019-03-26 17:23:39,013] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 17:23:39,016] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [5.7640440e-17 1.0000000e+00 2.6687307e-20 9.2979891e-21 6.7241685e-30], sampled 0.8891379807152707
[2019-03-26 17:23:46,211] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8507.9684 2841302810.6646 1103.0000
[2019-03-26 17:23:46,227] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8263.9729 2926672041.2947 1313.0000
[2019-03-26 17:23:46,270] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7921.4448 3160707260.1248 1671.0000
[2019-03-26 17:23:46,351] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.9039 2779337463.3193 927.0000
[2019-03-26 17:23:46,456] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8020.4675 3004853251.5895 1703.0000
[2019-03-26 17:23:47,475] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1625000, evaluation results [1625000.0, 7921.444804560617, 3160707260.1248097, 1671.0, 8263.972949190653, 2926672041.2947187, 1313.0, 8661.903944848309, 2779337463.3192787, 927.0, 8020.46751802947, 3004853251.58948, 1703.0, 8507.968429066428, 2841302810.6646347, 1103.0]
[2019-03-26 17:23:50,685] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.9976920e-16 1.0000000e+00 1.6007263e-18 1.8061508e-15 2.6089298e-27], sum to 1.0000
[2019-03-26 17:23:50,700] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8861
[2019-03-26 17:23:50,704] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333333, 84.83333333333333, 1.0, 2.0, 0.8563915738401026, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1196954.806512113, 1196954.806512114, 258221.7377385523], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5205000.0000, 
sim time next is 5205600.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.8135634201034204, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1137063.029716143, 1137063.029716142, 247265.5454943389], 
processed observation next is [1.0, 0.2608695652173913, 0.4786729857819906, 0.84, 1.0, 1.0, 0.7753776145824343, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.31585084158781745, 0.31585084158781723, 0.3690530529766252], 
reward next is 0.6309, 
noisyNet noise sample is [array([0.22525012], dtype=float32), -0.5831319]. 
=============================================
[2019-03-26 17:23:55,445] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0006922e-12 1.5666696e-03 8.3524602e-12 9.9843329e-01 1.1405451e-18], sum to 1.0000
[2019-03-26 17:23:55,455] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6756
[2019-03-26 17:23:55,460] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [35.96666666666667, 48.33333333333333, 1.0, 2.0, 1.014128653735197, 1.0, 2.0, 1.014128653735197, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2836874.244180864, 2836874.244180865, 537579.9732563336], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5498400.0000, 
sim time next is 5499000.0000, 
raw observation next is [35.85, 48.5, 1.0, 2.0, 1.004340731796297, 1.0, 2.0, 1.004340731796297, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2809463.197298845, 2809463.197298845, 531611.8778305859], 
processed observation next is [1.0, 0.6521739130434783, 0.8981042654028437, 0.485, 1.0, 1.0, 1.005229797344936, 1.0, 1.0, 1.005229797344936, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7804064436941236, 0.7804064436941236, 0.7934505639262477], 
reward next is 0.2065, 
noisyNet noise sample is [array([0.58966243], dtype=float32), 0.7395418]. 
=============================================
[2019-03-26 17:23:55,472] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[56.021717]
 [56.244213]
 [56.604553]
 [56.957287]
 [57.36998 ]], R is [[55.65242386]
 [55.29354477]
 [54.92603683]
 [54.59077454]
 [54.25494766]].
[2019-03-26 17:24:15,737] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.6307561e-17 1.0000000e+00 2.8936106e-20 3.0590496e-20 4.7310435e-30], sum to 1.0000
[2019-03-26 17:24:15,748] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2652
[2019-03-26 17:24:15,755] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.43333333333333, 86.83333333333333, 1.0, 2.0, 0.5034418228043765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 703483.3211220966, 703483.3211220972, 184137.1717802832], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5637000.0000, 
sim time next is 5637600.0000, 
raw observation next is [26.6, 86.0, 1.0, 2.0, 0.5047848553754679, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 705360.6277993605, 705360.6277993611, 184349.2608425079], 
processed observation next is [0.0, 0.2608695652173913, 0.4597156398104266, 0.86, 1.0, 1.0, 0.40335524744032275, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1959335077220446, 0.19593350772204476, 0.27514815051120584], 
reward next is 0.7249, 
noisyNet noise sample is [array([1.4806916], dtype=float32), 0.18790759]. 
=============================================
[2019-03-26 17:24:16,627] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.8225120e-16 1.0000000e+00 2.0387646e-17 4.2558161e-14 1.5448328e-26], sum to 1.0000
[2019-03-26 17:24:16,633] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7484
[2019-03-26 17:24:16,642] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.91666666666667, 83.83333333333334, 1.0, 2.0, 0.8759053997930168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1224244.465030682, 1224244.465030681, 263396.2920625035], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5813400.0000, 
sim time next is 5814000.0000, 
raw observation next is [28.1, 83.0, 1.0, 2.0, 0.8977171774923044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1254748.588977918, 1254748.588977918, 269311.1353555602], 
processed observation next is [1.0, 0.30434782608695654, 0.5308056872037916, 0.83, 1.0, 1.0, 0.8767676837256679, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.34854127471608837, 0.34854127471608837, 0.4019569184411347], 
reward next is 0.5980, 
noisyNet noise sample is [array([-0.31375253], dtype=float32), 0.22900335]. 
=============================================
[2019-03-26 17:24:16,657] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[64.848076]
 [65.11918 ]
 [65.75722 ]
 [66.625984]
 [67.686676]], R is [[64.53366852]
 [64.49520111]
 [64.4495163 ]
 [64.3784256 ]
 [64.33984375]].
[2019-03-26 17:24:26,130] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.1491222e-11 6.3184276e-02 1.4216085e-10 9.3681574e-01 2.0991861e-18], sum to 1.0000
[2019-03-26 17:24:26,137] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0079
[2019-03-26 17:24:26,146] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1804787.687109447 W.
[2019-03-26 17:24:26,150] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.0, 70.5, 1.0, 2.0, 0.645461072847493, 1.0, 2.0, 0.645461072847493, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1804787.687109447, 1804787.687109447, 351649.8670848185], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6006600.0000, 
sim time next is 6007200.0000, 
raw observation next is [29.0, 71.66666666666666, 1.0, 2.0, 0.6375265986504379, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.971644749347219, 6.9112, 168.9125537867535, 1782597.915903581, 1739716.432607577, 372659.7535691142], 
processed observation next is [1.0, 0.5217391304347826, 0.5734597156398105, 0.7166666666666666, 1.0, 1.0, 0.5632850586149855, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.006044474934721933, 0.0, 0.8294379675946785, 0.49516608775099474, 0.4832545646132158, 0.5562085874165884], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9248379], dtype=float32), -0.6065893]. 
=============================================
[2019-03-26 17:24:29,001] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.4583874e-14 1.0000000e+00 6.1846005e-17 9.1599964e-11 5.5864639e-26], sum to 1.0000
[2019-03-26 17:24:29,011] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2422
[2019-03-26 17:24:29,021] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.2, 74.5, 1.0, 2.0, 0.5575777256265146, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 779157.7495378867, 779157.7495378867, 193109.7338343183], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5855400.0000, 
sim time next is 5856000.0000, 
raw observation next is [30.0, 75.66666666666667, 1.0, 2.0, 0.5579658161244295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 779700.265294291, 779700.265294291, 193177.157757118], 
processed observation next is [1.0, 0.782608695652174, 0.6208530805687204, 0.7566666666666667, 1.0, 1.0, 0.46742869412581867, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21658340702619194, 0.21658340702619194, 0.2883241160554], 
reward next is 0.7117, 
noisyNet noise sample is [array([-0.9989202], dtype=float32), -0.19389378]. 
=============================================
[2019-03-26 17:24:29,039] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[77.34112]
 [76.8296 ]
 [76.18942]
 [75.09764]
 [73.52973]], R is [[77.29490662]
 [77.23373413]
 [77.17350769]
 [77.1155777 ]
 [77.06069946]].
[2019-03-26 17:24:34,033] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.2103463e-17 1.0000000e+00 9.6179185e-19 3.8724562e-16 7.9403222e-28], sum to 1.0000
[2019-03-26 17:24:34,042] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6977
[2019-03-26 17:24:34,046] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.46666666666667, 88.66666666666667, 1.0, 2.0, 0.6773894206206341, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 946656.9320164567, 946656.9320164567, 216041.7802774507], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6160200.0000, 
sim time next is 6160800.0000, 
raw observation next is [27.53333333333333, 88.33333333333334, 1.0, 2.0, 0.7099680150497212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 992207.037051142, 992207.0370511414, 223012.8648631969], 
processed observation next is [1.0, 0.30434782608695654, 0.5039494470774091, 0.8833333333333334, 1.0, 1.0, 0.6505638735538809, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2756130658475394, 0.27561306584753925, 0.33285502218387597], 
reward next is 0.6671, 
noisyNet noise sample is [array([0.7417118], dtype=float32), -0.8864328]. 
=============================================
[2019-03-26 17:24:35,005] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.4668085e-16 1.0000000e+00 5.0038921e-19 1.1220031e-16 3.3810652e-27], sum to 1.0000
[2019-03-26 17:24:35,017] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4268
[2019-03-26 17:24:35,026] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.4, 91.0, 1.0, 2.0, 0.5240565623480476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 732299.2111800533, 732299.2111800539, 187451.1534132516], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5968800.0000, 
sim time next is 5969400.0000, 
raw observation next is [26.36666666666667, 91.16666666666667, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.974264896367111, 6.9112, 168.9602238291896, 1498538.21340181, 1453785.285576813, 311358.1659200625], 
processed observation next is [1.0, 0.08695652173913043, 0.4486571879936811, 0.9116666666666667, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.006306489636711099, 0.0, 0.8296720493264795, 0.41626061483383614, 0.4038292459935591, 0.4647136804777052], 
reward next is 0.2200, 
noisyNet noise sample is [array([0.06205406], dtype=float32), -0.29140526]. 
=============================================
[2019-03-26 17:24:37,116] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.6314026e-16 1.0000000e+00 5.0773264e-18 2.8680754e-17 3.6705733e-27], sum to 1.0000
[2019-03-26 17:24:37,124] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1351
[2019-03-26 17:24:37,130] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.3, 88.5, 1.0, 2.0, 0.6996532994182234, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 977785.1973600307, 977785.1973600313, 220771.1993436064], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5985000.0000, 
sim time next is 5985600.0000, 
raw observation next is [27.46666666666667, 88.0, 1.0, 2.0, 0.7525521493816683, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1051749.439195432, 1051749.439195433, 232598.4663221888], 
processed observation next is [1.0, 0.2608695652173913, 0.500789889415482, 0.88, 1.0, 1.0, 0.7018700594959858, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2921526219987311, 0.2921526219987314, 0.3471618900331176], 
reward next is 0.6528, 
noisyNet noise sample is [array([-0.37820864], dtype=float32), -0.7717318]. 
=============================================
[2019-03-26 17:24:41,071] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.0861890e-16 1.0000000e+00 1.1772388e-19 4.4757709e-18 6.7679459e-29], sum to 1.0000
[2019-03-26 17:24:41,082] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7495
[2019-03-26 17:24:41,088] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.48333333333333, 90.16666666666667, 1.0, 2.0, 0.5199750205467105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 726593.849781271, 726593.8497812704, 186785.2032186275], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6225000.0000, 
sim time next is 6225600.0000, 
raw observation next is [26.46666666666667, 90.33333333333334, 1.0, 2.0, 0.5199932660851658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 726619.3541415257, 726619.3541415257, 186788.186377479], 
processed observation next is [0.0, 0.043478260869565216, 0.45339652448657203, 0.9033333333333334, 1.0, 1.0, 0.42167863383754917, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20183870948375712, 0.20183870948375712, 0.2787883378768343], 
reward next is 0.7212, 
noisyNet noise sample is [array([1.1879325], dtype=float32), -0.42873988]. 
=============================================
[2019-03-26 17:24:42,607] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-26 17:24:42,610] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 17:24:42,611] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 17:24:42,612] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:24:42,612] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 17:24:42,614] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 17:24:42,615] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 17:24:42,616] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:24:42,617] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:24:42,618] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:24:42,613] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:24:42,651] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run67
[2019-03-26 17:24:42,652] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run67
[2019-03-26 17:24:42,696] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run67
[2019-03-26 17:24:42,697] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run67
[2019-03-26 17:24:42,742] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run67
[2019-03-26 17:24:49,978] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10617312], dtype=float32), 0.084448196]
[2019-03-26 17:24:49,979] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [20.53333333333333, 79.16666666666667, 1.0, 2.0, 0.2655559406353868, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 437259.9974286218, 437259.9974286218, 162471.7820859479]
[2019-03-26 17:24:49,982] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:24:49,985] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.0708256e-17 1.0000000e+00 1.8072420e-20 2.1037748e-21 6.4080767e-30], sampled 0.7908750186068848
[2019-03-26 17:25:01,408] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10617312], dtype=float32), 0.084448196]
[2019-03-26 17:25:01,409] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [24.21666666666667, 94.0, 1.0, 2.0, 0.4549157610484547, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 647362.5582651753, 647362.5582651753, 178341.5926338373]
[2019-03-26 17:25:01,410] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:25:01,415] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [7.1264197e-17 1.0000000e+00 4.8177406e-20 1.4608781e-19 3.1794864e-29], sampled 0.6006012888514964
[2019-03-26 17:25:34,852] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10617312], dtype=float32), 0.084448196]
[2019-03-26 17:25:34,853] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [30.16531554, 75.55216047333333, 1.0, 2.0, 0.570718025364062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 797526.8657916373, 797526.8657916366, 195417.7544504811]
[2019-03-26 17:25:34,857] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 17:25:34,863] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.1327237e-17 1.0000000e+00 3.6000852e-20 2.7254510e-19 1.0596292e-29], sampled 0.5845420414622866
[2019-03-26 17:25:59,518] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10617312], dtype=float32), 0.084448196]
[2019-03-26 17:25:59,523] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [32.23333333333333, 64.66666666666667, 1.0, 2.0, 0.7015693045775537, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005975377794347, 6.9112, 168.9123225553087, 1877324.811223999, 1810088.148649939, 384977.4343122047]
[2019-03-26 17:25:59,527] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 17:25:59,528] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0070121e-13 1.0000000e+00 1.8868821e-15 8.0612730e-13 2.5272683e-23], sampled 0.039653337755587215
[2019-03-26 17:25:59,530] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1877324.811223999 W.
[2019-03-26 17:26:35,135] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10617312], dtype=float32), 0.084448196]
[2019-03-26 17:26:35,136] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [25.88333333333333, 63.0, 1.0, 2.0, 0.3385084019717743, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 529951.431303781, 529951.4313037804, 169230.053784346]
[2019-03-26 17:26:35,138] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 17:26:35,140] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [5.7189699e-17 1.0000000e+00 3.8895477e-20 1.0334035e-19 1.2369149e-29], sampled 0.43829799839595407
[2019-03-26 17:26:37,347] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10617312], dtype=float32), 0.084448196]
[2019-03-26 17:26:37,349] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.33333333333334, 78.0, 1.0, 2.0, 0.7699835284884465, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.980923906490286, 6.9112, 168.9124853187984, 1973065.041119558, 1923600.640127637, 401456.1201745226]
[2019-03-26 17:26:37,352] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:26:37,355] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.4684811e-12 1.0000000e+00 2.1771239e-13 3.2826869e-10 1.6864894e-20], sampled 0.058094137676128255
[2019-03-26 17:26:37,358] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1973065.041119558 W.
[2019-03-26 17:26:37,742] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8010.5243 3005512893.2498 1719.0000
[2019-03-26 17:26:37,776] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8257.3568 2927247670.1913 1332.0000
[2019-03-26 17:26:37,887] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.5375 2779182079.4160 932.0000
[2019-03-26 17:26:37,929] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7912.5635 3161966615.0241 1684.0000
[2019-03-26 17:26:38,049] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8502.3498 2841424253.9896 1109.0000
[2019-03-26 17:26:39,068] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1650000, evaluation results [1650000.0, 7912.563475471133, 3161966615.0240655, 1684.0, 8257.356786993932, 2927247670.191273, 1332.0, 8660.537518905896, 2779182079.4160323, 932.0, 8010.5242810786585, 3005512893.249797, 1719.0, 8502.349817553584, 2841424253.989592, 1109.0]
[2019-03-26 17:26:42,113] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.7247440e-16 1.0000000e+00 2.2352949e-18 2.7961820e-16 1.1688393e-27], sum to 1.0000
[2019-03-26 17:26:42,122] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9755
[2019-03-26 17:26:42,128] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.58333333333334, 92.0, 1.0, 2.0, 0.8195761215711496, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1145471.112078917, 1145471.112078916, 248772.8191490404], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6149400.0000, 
sim time next is 6150000.0000, 
raw observation next is [26.56666666666667, 92.0, 1.0, 2.0, 0.7094215103613662, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 991442.9196514131, 991442.9196514137, 222892.1227399357], 
processed observation next is [1.0, 0.17391304347826086, 0.45813586097946307, 0.92, 1.0, 1.0, 0.6499054341703208, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.27540081101428143, 0.2754008110142816, 0.33267481005960553], 
reward next is 0.6673, 
noisyNet noise sample is [array([-0.26826176], dtype=float32), 0.056141734]. 
=============================================
[2019-03-26 17:26:42,144] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[69.28121 ]
 [68.89932 ]
 [67.93917 ]
 [66.942604]
 [65.96245 ]], R is [[69.86058044]
 [69.7906723 ]
 [69.76365662]
 [69.73439026]
 [69.70243073]].
[2019-03-26 17:26:43,550] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.7816479e-17 1.0000000e+00 1.8937712e-20 4.8144362e-19 1.7384043e-29], sum to 1.0000
[2019-03-26 17:26:43,557] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1352
[2019-03-26 17:26:43,563] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333333, 79.0, 1.0, 2.0, 0.3305920882210895, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 518028.4278068644, 518028.4278068644, 168301.0503767728], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6831600.0000, 
sim time next is 6832200.0000, 
raw observation next is [23.26666666666667, 79.5, 1.0, 2.0, 0.3305199017016391, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 517860.1433440708, 517860.1433440708, 168286.6078706445], 
processed observation next is [0.0, 0.043478260869565216, 0.3017377567140602, 0.795, 1.0, 1.0, 0.19339747192968565, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14385003981779745, 0.14385003981779745, 0.2511740415979769], 
reward next is 0.7488, 
noisyNet noise sample is [array([0.16188098], dtype=float32), -0.45104268]. 
=============================================
[2019-03-26 17:26:44,591] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.3518073e-10 3.5577368e-02 3.4143549e-10 9.6442264e-01 1.0262266e-16], sum to 1.0000
[2019-03-26 17:26:44,596] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0825
[2019-03-26 17:26:44,603] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.1, 71.33333333333334, 1.0, 2.0, 0.8046515287523972, 1.0, 2.0, 0.8046515287523972, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2250365.416823647, 2250365.416823647, 422140.4496979332], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6189000.0000, 
sim time next is 6189600.0000, 
raw observation next is [30.0, 71.66666666666667, 1.0, 2.0, 0.8251849485772756, 1.0, 2.0, 0.8251849485772756, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2307844.165386696, 2307844.165386696, 432315.9827557048], 
processed observation next is [1.0, 0.6521739130434783, 0.6208530805687204, 0.7166666666666667, 1.0, 1.0, 0.7893794561171995, 1.0, 1.0, 0.7893794561171995, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6410678237185267, 0.6410678237185267, 0.6452477354562758], 
reward next is 0.3548, 
noisyNet noise sample is [array([-1.7926863], dtype=float32), 1.0492268]. 
=============================================
[2019-03-26 17:26:44,748] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.2378809e-11 7.4676299e-01 4.6910875e-10 2.5323704e-01 2.1303497e-16], sum to 1.0000
[2019-03-26 17:26:44,753] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5668
[2019-03-26 17:26:44,761] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2283265.566959635 W.
[2019-03-26 17:26:44,767] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.8, 72.33333333333333, 1.0, 2.0, 0.9916148662942377, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.990161656767828, 6.9112, 168.9123384657598, 2283265.566959635, 2227247.65496574, 461327.2827214438], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6190800.0000, 
sim time next is 6191400.0000, 
raw observation next is [29.7, 72.66666666666667, 1.0, 2.0, 0.9457140189660735, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.989391692834617, 6.9112, 168.9124271797236, 2219021.262306608, 2163549.558094265, 447667.2902945516], 
processed observation next is [1.0, 0.6521739130434783, 0.6066350710900474, 0.7266666666666667, 1.0, 1.0, 0.9345952035735826, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.007819169283461668, 0.0, 0.8294373458962008, 0.6163947950851688, 0.600985988359518, 0.6681601347679874], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.9589379], dtype=float32), -1.3332325]. 
=============================================
[2019-03-26 17:27:00,231] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.7301723e-10 8.5156935e-01 3.3396477e-10 1.4843060e-01 4.2395200e-17], sum to 1.0000
[2019-03-26 17:27:00,240] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7415
[2019-03-26 17:27:00,254] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2127833.310935632 W.
[2019-03-26 17:27:00,258] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.0, 67.0, 1.0, 2.0, 0.760879919568624, 1.0, 2.0, 0.760879919568624, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2127833.310935632, 2127833.310935632, 401269.0543556123], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6453000.0000, 
sim time next is 6453600.0000, 
raw observation next is [30.0, 67.0, 1.0, 2.0, 0.8887831364243867, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.978741166354493, 6.9112, 168.9125543139502, 2139336.113935825, 2091420.200028646, 431921.6850374056], 
processed observation next is [1.0, 0.6956521739130435, 0.6208530805687204, 0.67, 1.0, 1.0, 0.8660037788245623, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.006754116635449314, 0.0, 0.8294379701834557, 0.5942600316488402, 0.5809500555635128, 0.6446592313991129], 
reward next is 0.0176, 
noisyNet noise sample is [array([0.49529254], dtype=float32), -0.6715537]. 
=============================================
[2019-03-26 17:27:06,518] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.2105221e-16 1.0000000e+00 8.1665416e-20 9.6192342e-20 1.7469933e-29], sum to 1.0000
[2019-03-26 17:27:06,527] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4321
[2019-03-26 17:27:06,531] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.63333333333333, 52.0, 1.0, 2.0, 0.4580598965596291, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 646346.3453054957, 646346.3453054951, 178099.7782756368], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6964800.0000, 
sim time next is 6965400.0000, 
raw observation next is [31.81666666666667, 52.0, 1.0, 2.0, 0.4655127809537518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 652273.3864311778, 652273.3864311778, 178603.0257078125], 
processed observation next is [0.0, 0.6086956521739131, 0.7069510268562403, 0.52, 1.0, 1.0, 0.35603949512500216, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1811870517864383, 0.1811870517864383, 0.2665716801609142], 
reward next is 0.7334, 
noisyNet noise sample is [array([-0.9927942], dtype=float32), 0.30387327]. 
=============================================
[2019-03-26 17:27:08,377] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.1742347e-17 1.0000000e+00 1.6950936e-20 1.5181511e-20 1.1066759e-29], sum to 1.0000
[2019-03-26 17:27:08,386] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9012
[2019-03-26 17:27:08,389] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.75, 68.0, 1.0, 2.0, 0.4358092757034699, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 629424.2024752607, 629424.2024752607, 176779.7439311932], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6942600.0000, 
sim time next is 6943200.0000, 
raw observation next is [27.9, 67.33333333333334, 1.0, 2.0, 0.4366181041360506, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 629821.7251098184, 629821.7251098191, 176798.1981584021], 
processed observation next is [0.0, 0.34782608695652173, 0.5213270142180094, 0.6733333333333335, 1.0, 1.0, 0.3212266314892176, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17495047919717177, 0.17495047919717197, 0.26387790769910763], 
reward next is 0.7361, 
noisyNet noise sample is [array([0.701248], dtype=float32), -2.0117552]. 
=============================================
[2019-03-26 17:27:20,029] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.4665873e-15 1.0000000e+00 3.6038555e-17 8.7145975e-14 8.8527074e-26], sum to 1.0000
[2019-03-26 17:27:20,037] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1866
[2019-03-26 17:27:20,046] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.4, 45.0, 1.0, 2.0, 0.9470836105389412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1487683.571324547, 1487683.571324547, 305814.7340321878], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6789600.0000, 
sim time next is 6790200.0000, 
raw observation next is [29.38333333333333, 45.33333333333334, 1.0, 2.0, 0.9564329756309038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1501416.535329425, 1501416.535329425, 308765.8662549229], 
processed observation next is [1.0, 0.6086956521739131, 0.5916271721958924, 0.4533333333333334, 1.0, 1.0, 0.94750960919386, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.41706014870261804, 0.41706014870261804, 0.46084457649988486], 
reward next is 0.5392, 
noisyNet noise sample is [array([1.8560207], dtype=float32), 0.13722968]. 
=============================================
[2019-03-26 17:27:20,063] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.8198858e-17 1.0000000e+00 2.8209250e-20 7.9735267e-21 2.0373597e-30], sum to 1.0000
[2019-03-26 17:27:20,074] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6945
[2019-03-26 17:27:20,079] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.95, 81.0, 1.0, 2.0, 0.3605851860763643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 551974.9941587888, 551974.9941587888, 170712.0752082941], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6849000.0000, 
sim time next is 6849600.0000, 
raw observation next is [24.06666666666667, 80.66666666666666, 1.0, 2.0, 0.3633083576297908, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 555019.5417307054, 555019.5417307054, 170936.3612040957], 
processed observation next is [0.0, 0.2608695652173913, 0.3396524486571882, 0.8066666666666665, 1.0, 1.0, 0.23290163569854314, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15417209492519596, 0.15417209492519596, 0.25512889731954586], 
reward next is 0.7449, 
noisyNet noise sample is [array([0.5922664], dtype=float32), -1.0060749]. 
=============================================
[2019-03-26 17:27:20,397] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.9426452e-16 1.0000000e+00 6.2033790e-19 8.2289727e-17 1.3590775e-27], sum to 1.0000
[2019-03-26 17:27:20,403] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5770
[2019-03-26 17:27:20,407] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.3, 85.66666666666667, 1.0, 2.0, 0.5846640484027835, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 833223.8228101212, 833223.8228101212, 200006.4113674151], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7017600.0000, 
sim time next is 7018200.0000, 
raw observation next is [25.45, 84.5, 1.0, 2.0, 0.5915815635832289, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 843603.8261608009, 843603.8261608009, 201364.6853125938], 
processed observation next is [1.0, 0.21739130434782608, 0.4052132701421801, 0.845, 1.0, 1.0, 0.507929594678589, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23433439615577803, 0.23433439615577803, 0.30054430643670715], 
reward next is 0.6995, 
noisyNet noise sample is [array([-0.16990638], dtype=float32), -0.0844248]. 
=============================================
[2019-03-26 17:27:23,975] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.2851407e-17 1.0000000e+00 2.2973185e-20 3.4103372e-21 1.4811212e-30], sum to 1.0000
[2019-03-26 17:27:23,985] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0629
[2019-03-26 17:27:23,990] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.06666666666667, 80.66666666666666, 1.0, 2.0, 0.3633083576297908, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 555019.5417307054, 555019.5417307054, 170936.3612040957], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6849600.0000, 
sim time next is 6850200.0000, 
raw observation next is [24.18333333333333, 80.33333333333334, 1.0, 2.0, 0.3659376522105902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 557897.4955679895, 557897.4955679895, 171147.5153622031], 
processed observation next is [0.0, 0.2608695652173913, 0.3451816745655607, 0.8033333333333335, 1.0, 1.0, 0.236069460494687, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15497152654666377, 0.15497152654666377, 0.2554440527794076], 
reward next is 0.7446, 
noisyNet noise sample is [array([0.96190774], dtype=float32), 1.0530878]. 
=============================================
[2019-03-26 17:27:28,653] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.1514951e-17 1.0000000e+00 3.1193482e-20 4.8649424e-21 5.0272086e-29], sum to 1.0000
[2019-03-26 17:27:28,665] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6506
[2019-03-26 17:27:28,671] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.03333333333333, 89.33333333333334, 1.0, 2.0, 0.4188181688535201, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 615101.9956789002, 615101.9956789007, 175677.209279143], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6925200.0000, 
sim time next is 6925800.0000, 
raw observation next is [23.96666666666667, 89.66666666666666, 1.0, 2.0, 0.4177167231459037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 613994.5689308227, 613994.5689308232, 175586.1054938332], 
processed observation next is [0.0, 0.13043478260869565, 0.33491311216429714, 0.8966666666666666, 1.0, 1.0, 0.2984538833083177, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17055404692522852, 0.1705540469252287, 0.2620688141699003], 
reward next is 0.7379, 
noisyNet noise sample is [array([-0.4276116], dtype=float32), -0.29478836]. 
=============================================
[2019-03-26 17:27:34,175] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-26 17:27:34,176] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0303112e-16 1.0000000e+00 3.7790093e-19 1.0645670e-16 1.1300157e-28], sum to 1.0000
[2019-03-26 17:27:34,178] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 17:27:34,180] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:27:34,180] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 17:27:34,181] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 17:27:34,181] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4660
[2019-03-26 17:27:34,181] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:27:34,182] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 17:27:34,181] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:27:34,186] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.65, 86.83333333333333, 1.0, 2.0, 0.4821435089750622, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 673712.7317680084, 673712.7317680084, 180845.0936523137], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7077000.0000, 
sim time next is 7077600.0000, 
raw observation next is [25.6, 87.0, 1.0, 2.0, 0.4808707903607484, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 671933.7636823797, 671933.7636823804, 180652.6696115833], 
processed observation next is [1.0, 0.9565217391304348, 0.4123222748815167, 0.87, 1.0, 1.0, 0.37454312091656433, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18664826768954992, 0.18664826768955012, 0.2696308501665422], 
reward next is 0.7304, 
noisyNet noise sample is [array([-0.06060571], dtype=float32), 0.9892906]. 
=============================================
[2019-03-26 17:27:34,187] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:27:34,185] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 17:27:34,189] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:27:34,206] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run68
[2019-03-26 17:27:34,230] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run68
[2019-03-26 17:27:34,253] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run68
[2019-03-26 17:27:34,273] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run68
[2019-03-26 17:27:34,274] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run68
[2019-03-26 17:27:43,642] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10738566], dtype=float32), 0.08675091]
[2019-03-26 17:27:43,645] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.83333333333334, 49.00000000000001, 1.0, 2.0, 0.45776880482743, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 727932.060205617, 727932.0602056177, 187278.0887165435]
[2019-03-26 17:27:43,648] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:27:43,650] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0777899e-16 1.0000000e+00 7.6518226e-20 7.7681126e-20 2.1729742e-29], sampled 0.8113757061453419
[2019-03-26 17:27:52,000] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10738566], dtype=float32), 0.08675091]
[2019-03-26 17:27:52,001] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [18.8, 81.0, 1.0, 2.0, 0.2205729260328078, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 367872.8447334683, 367872.8447334683, 157512.5187734932]
[2019-03-26 17:27:52,003] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:27:52,005] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [6.9451831e-17 1.0000000e+00 3.0288595e-20 4.4536571e-21 7.4173536e-30], sampled 0.4504191327475173
[2019-03-26 17:28:07,565] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10738566], dtype=float32), 0.08675091]
[2019-03-26 17:28:07,747] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.7, 70.5, 1.0, 2.0, 0.6570551105552532, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 969536.46575292, 969536.4657529207, 218461.8998360386]
[2019-03-26 17:28:07,750] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 17:28:07,753] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.3290097e-16 1.0000000e+00 5.2188091e-19 2.1701793e-17 1.8268784e-28], sampled 0.16988126624271116
[2019-03-26 17:28:38,516] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10738566], dtype=float32), 0.08675091]
[2019-03-26 17:28:38,517] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [34.98001128, 75.52843613, 1.0, 2.0, 0.7298888621541617, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1020060.541902823, 1020060.541902824, 227444.8322962233]
[2019-03-26 17:28:38,519] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 17:28:38,521] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [7.8875655e-17 1.0000000e+00 7.3486997e-20 2.4599116e-19 1.4616400e-29], sampled 0.5839075933534714
[2019-03-26 17:29:28,874] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8269.3299 2925720706.5019 1277.0000
[2019-03-26 17:29:29,311] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.2555 2779186661.7215 930.0000
[2019-03-26 17:29:29,342] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7946.5449 3158683571.5585 1586.0000
[2019-03-26 17:29:29,413] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8514.6163 2840171780.9245 1078.0000
[2019-03-26 17:29:29,470] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8031.7183 3002294716.5975 1640.0000
[2019-03-26 17:29:30,485] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 1675000, evaluation results [1675000.0, 7946.544936596281, 3158683571.558498, 1586.0, 8269.329896132926, 2925720706.5019417, 1277.0, 8661.255501092748, 2779186661.721488, 930.0, 8031.718299542734, 3002294716.5974703, 1640.0, 8514.616333040854, 2840171780.9244943, 1078.0]
[2019-03-26 17:29:33,704] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.7698854e-16 1.0000000e+00 6.8871526e-21 1.8599011e-19 2.3535720e-30], sum to 1.0000
[2019-03-26 17:29:33,713] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0566
[2019-03-26 17:29:33,722] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666667, 79.0, 1.0, 2.0, 0.4158893333616966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 606903.4914427524, 606903.4914427524, 174784.5962774617], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7496400.0000, 
sim time next is 7497000.0000, 
raw observation next is [25.55, 79.5, 1.0, 2.0, 0.4140619188921128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 605155.6039935349, 605155.6039935349, 174647.3863554103], 
processed observation next is [0.0, 0.782608695652174, 0.40995260663507116, 0.795, 1.0, 1.0, 0.29405050468929256, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16809877888709304, 0.16809877888709304, 0.2606677408289706], 
reward next is 0.7393, 
noisyNet noise sample is [array([-0.59635127], dtype=float32), 0.1379763]. 
=============================================
[2019-03-26 17:29:33,736] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[76.48223]
 [76.44633]
 [76.3922 ]
 [76.34119]
 [76.31311]], R is [[76.49568939]
 [76.46986389]
 [76.44408417]
 [76.41841888]
 [76.39302063]].
[2019-03-26 17:29:38,034] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.1606099e-16 1.0000000e+00 5.7474830e-19 4.9126593e-16 3.3606948e-28], sum to 1.0000
[2019-03-26 17:29:38,044] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3763
[2019-03-26 17:29:38,048] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.86666666666667, 84.0, 1.0, 2.0, 0.4725233401623374, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 663947.7914001683, 663947.7914001676, 179878.1040407239], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7162800.0000, 
sim time next is 7163400.0000, 
raw observation next is [25.83333333333333, 84.0, 1.0, 2.0, 0.4714607753006186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 663420.109635108, 663420.1096351086, 179843.814024077], 
processed observation next is [1.0, 0.9130434782608695, 0.42338072669826204, 0.84, 1.0, 1.0, 0.3632057533742392, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18428336378753002, 0.18428336378753016, 0.2684236030210104], 
reward next is 0.7316, 
noisyNet noise sample is [array([0.01725589], dtype=float32), -0.509518]. 
=============================================
[2019-03-26 17:29:38,673] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.2981343e-17 1.0000000e+00 3.5118900e-20 2.1299146e-20 1.4540925e-30], sum to 1.0000
[2019-03-26 17:29:38,681] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5287
[2019-03-26 17:29:38,686] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.23333333333333, 67.0, 1.0, 2.0, 0.4388319086265688, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 626804.18747406, 626804.18747406, 176327.478970654], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7579200.0000, 
sim time next is 7579800.0000, 
raw observation next is [28.1, 68.0, 1.0, 2.0, 0.4437078962263412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 632638.4604049121, 632638.4604049115, 176878.8515653623], 
processed observation next is [0.0, 0.7391304347826086, 0.5308056872037916, 0.68, 1.0, 1.0, 0.32976854967029057, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17573290566803115, 0.175732905668031, 0.2639982859184512], 
reward next is 0.7360, 
noisyNet noise sample is [array([-0.08387229], dtype=float32), 0.33801073]. 
=============================================
[2019-03-26 17:29:41,109] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.8596884e-17 1.0000000e+00 1.4461626e-19 5.1008746e-18 4.0086823e-29], sum to 1.0000
[2019-03-26 17:29:41,116] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9295
[2019-03-26 17:29:41,123] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.03333333333333, 94.66666666666667, 1.0, 2.0, 0.3187621316488384, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 502701.3248446704, 502701.3248446711, 167200.2811768486], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7428000.0000, 
sim time next is 7428600.0000, 
raw observation next is [21.05, 94.5, 1.0, 2.0, 0.3186843401584374, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 502615.6106929396, 502615.6106929396, 167194.6153053548], 
processed observation next is [1.0, 1.0, 0.1966824644549764, 0.945, 1.0, 1.0, 0.17913775922703298, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13961544741470544, 0.13961544741470544, 0.24954420194829072], 
reward next is 0.7505, 
noisyNet noise sample is [array([0.43333432], dtype=float32), 0.79861575]. 
=============================================
[2019-03-26 17:29:44,532] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.7360694e-17 1.0000000e+00 1.3345047e-20 2.7134057e-20 2.1080388e-30], sum to 1.0000
[2019-03-26 17:29:44,540] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6319
[2019-03-26 17:29:44,549] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 77.0, 1.0, 2.0, 0.4157413201553971, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 606491.3773013739, 606491.3773013739, 174739.69708899], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7486200.0000, 
sim time next is 7486800.0000, 
raw observation next is [26.06666666666667, 76.66666666666667, 1.0, 2.0, 0.4157555384071969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 606176.3761989558, 606176.3761989564, 174699.6892515032], 
processed observation next is [0.0, 0.6521739130434783, 0.4344391785150081, 0.7666666666666667, 1.0, 1.0, 0.2960910101291529, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16838232672193218, 0.16838232672193232, 0.26074580485298987], 
reward next is 0.7393, 
noisyNet noise sample is [array([-2.833413], dtype=float32), 0.4297621]. 
=============================================
[2019-03-26 17:29:46,651] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:29:46,652] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:29:46,729] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run9
[2019-03-26 17:29:47,610] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.7556751e-10 2.7411746e-02 1.2857541e-09 9.7258830e-01 9.4254577e-17], sum to 1.0000
[2019-03-26 17:29:47,615] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2143
[2019-03-26 17:29:47,619] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.55, 62.66666666666666, 1.0, 2.0, 0.5165641327964545, 1.0, 2.0, 0.5165641327964545, 1.0, 1.0, 0.8933742742686412, 6.911199999999999, 6.9112, 170.5573041426782, 2166930.116288518, 2166930.116288519, 426092.0579053045], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7733400.0000, 
sim time next is 7734000.0000, 
raw observation next is [31.6, 62.33333333333334, 1.0, 2.0, 0.7025182417623156, 1.0, 2.0, 0.7025182417623156, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 1964472.730617785, 1964472.730617786, 375203.498062948], 
processed observation next is [1.0, 0.5217391304347826, 0.6966824644549764, 0.6233333333333334, 1.0, 1.0, 0.6415882430871271, 1.0, 1.0, 0.6415882430871271, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5456868696160514, 0.5456868696160517, 0.5600052209894746], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.2418895], dtype=float32), -0.342444]. 
=============================================
[2019-03-26 17:29:47,628] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[59.13251 ]
 [62.60243 ]
 [62.177643]
 [62.112206]
 [62.829235]], R is [[59.02722549]
 [58.80099487]
 [58.56674576]
 [57.9810791 ]
 [57.40126801]].
[2019-03-26 17:29:47,737] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.5633212e-16 1.0000000e+00 2.4662173e-18 3.4333345e-15 2.2749762e-27], sum to 1.0000
[2019-03-26 17:29:47,740] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.73923674e-16 1.00000000e+00 1.52182290e-18 2.17244985e-16
 1.31634885e-27], sum to 1.0000
[2019-03-26 17:29:47,744] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1323
[2019-03-26 17:29:47,747] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0786
[2019-03-26 17:29:47,749] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.58333333333334, 59.5, 1.0, 2.0, 0.5314612537988196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 810713.4058482694, 810713.4058482688, 196925.4549290281], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7305000.0000, 
sim time next is 7305600.0000, 
raw observation next is [27.66666666666667, 59.00000000000001, 1.0, 2.0, 0.8192553128984903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1250146.897308022, 1250146.897308022, 262814.2048696524], 
processed observation next is [1.0, 0.5652173913043478, 0.5102685624012641, 0.5900000000000001, 1.0, 1.0, 0.782235316745169, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3472630270300061, 0.3472630270300061, 0.3922600072681379], 
reward next is 0.6077, 
noisyNet noise sample is [array([-0.9461607], dtype=float32), -0.63515157]. 
=============================================
[2019-03-26 17:29:47,751] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.53333333333333, 73.66666666666666, 1.0, 2.0, 0.3868699793266774, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 583089.1592438482, 583089.1592438476, 173164.1113373199], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7332000.0000, 
sim time next is 7332600.0000, 
raw observation next is [25.46666666666667, 73.83333333333334, 1.0, 2.0, 0.3854389143278537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 581655.8441599511, 581655.8441599518, 173056.399844698], 
processed observation next is [1.0, 0.8695652173913043, 0.40600315955766203, 0.7383333333333334, 1.0, 1.0, 0.2595649570215105, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16157106782220865, 0.16157106782220884, 0.2582931340965642], 
reward next is 0.7417, 
noisyNet noise sample is [array([0.1506343], dtype=float32), -0.15648994]. 
=============================================
[2019-03-26 17:29:56,843] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.1742266e-16 1.0000000e+00 4.9502168e-20 1.0500332e-20 6.8874625e-30], sum to 1.0000
[2019-03-26 17:29:56,851] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7041
[2019-03-26 17:29:56,856] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 90.0, 1.0, 2.0, 0.3711948784039869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 561825.6157539217, 561825.6157539217, 171359.5274785451], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7536000.0000, 
sim time next is 7536600.0000, 
raw observation next is [23.15, 90.0, 1.0, 2.0, 0.3728689970565986, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 563456.4493623809, 563456.4493623809, 171472.3764390005], 
processed observation next is [0.0, 0.21739130434782608, 0.2962085308056872, 0.9, 1.0, 1.0, 0.2444204783814441, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15651568037843913, 0.15651568037843913, 0.2559289200582097], 
reward next is 0.7441, 
noisyNet noise sample is [array([-0.18296352], dtype=float32), -0.09866353]. 
=============================================
[2019-03-26 17:30:00,304] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.9615122e-10 7.1210301e-01 3.7818323e-10 2.8789705e-01 8.2250895e-19], sum to 1.0000
[2019-03-26 17:30:00,314] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8476
[2019-03-26 17:30:00,319] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.7, 61.66666666666667, 1.0, 2.0, 0.52923817421294, 1.0, 2.0, 0.52923817421294, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1479589.987743812, 1479589.987743812, 309586.3043435595], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7735200.0000, 
sim time next is 7735800.0000, 
raw observation next is [31.75, 61.33333333333334, 1.0, 2.0, 0.4995870955611795, 1.0, 2.0, 0.4995870955611795, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1396640.527221937, 1396640.527221937, 300124.8959542867], 
processed observation next is [1.0, 0.5217391304347826, 0.7037914691943128, 0.6133333333333334, 1.0, 1.0, 0.39709288621828853, 1.0, 1.0, 0.39709288621828853, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.3879557020060936, 0.3879557020060936, 0.4479476059019204], 
reward next is 0.5521, 
noisyNet noise sample is [array([0.6976854], dtype=float32), -1.2356352]. 
=============================================
[2019-03-26 17:30:01,195] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.0311079e-16 1.0000000e+00 6.8301267e-18 1.3128810e-16 1.3165297e-27], sum to 1.0000
[2019-03-26 17:30:01,206] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9193
[2019-03-26 17:30:01,213] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.4, 85.0, 1.0, 2.0, 0.6652724666991984, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 929715.9836599164, 929715.9836599157, 213527.6294061075], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7718400.0000, 
sim time next is 7719000.0000, 
raw observation next is [27.6, 83.83333333333334, 1.0, 2.0, 0.8698121618601413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1215723.129822778, 1215723.129822777, 261768.3282773621], 
processed observation next is [1.0, 0.34782608695652173, 0.5071090047393366, 0.8383333333333334, 1.0, 1.0, 0.8431471829640257, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.33770086939521615, 0.3377008693952158, 0.3906989974288987], 
reward next is 0.6093, 
noisyNet noise sample is [array([0.31261918], dtype=float32), -1.9296466]. 
=============================================
[2019-03-26 17:30:01,235] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[70.56124 ]
 [70.48817 ]
 [70.5778  ]
 [70.6273  ]
 [70.626816]], R is [[70.1178894 ]
 [70.09801483]
 [70.06768799]
 [70.04623413]
 [70.04197693]].
[2019-03-26 17:30:01,573] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:30:01,574] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:30:01,657] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run9
[2019-03-26 17:30:04,211] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:30:04,212] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:30:04,279] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run9
[2019-03-26 17:30:05,026] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.8908066e-10 6.8728268e-01 1.3157960e-09 3.1271732e-01 2.6768352e-17], sum to 1.0000
[2019-03-26 17:30:05,034] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8462
[2019-03-26 17:30:05,038] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.3, 68.0, 1.0, 2.0, 0.7318625059532811, 1.0, 2.0, 0.7318625059532811, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2046607.351827896, 2046607.351827896, 388060.2428263344], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7826400.0000, 
sim time next is 7827000.0000, 
raw observation next is [30.41666666666666, 68.33333333333334, 1.0, 2.0, 0.7841102901878586, 1.0, 2.0, 0.7841102901878586, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2192864.535972496, 2192864.535972496, 412206.9695511632], 
processed observation next is [1.0, 0.6086956521739131, 0.6406003159557659, 0.6833333333333335, 1.0, 1.0, 0.7398919158889863, 1.0, 1.0, 0.7398919158889863, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6091290377701378, 0.6091290377701378, 0.6152342829121838], 
reward next is 0.3848, 
noisyNet noise sample is [array([0.03368969], dtype=float32), -0.12715143]. 
=============================================
[2019-03-26 17:30:05,046] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[57.680187]
 [57.856575]
 [57.15784 ]
 [57.262383]
 [62.357788]], R is [[57.4372139 ]
 [57.28364944]
 [57.12849045]
 [56.5572052 ]
 [55.99163437]].
[2019-03-26 17:30:12,042] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:30:12,042] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:30:12,130] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run9
[2019-03-26 17:30:13,122] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:30:13,123] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:30:13,176] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run9
[2019-03-26 17:30:14,648] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:30:14,648] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:30:14,714] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run9
[2019-03-26 17:30:15,332] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:30:15,334] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:30:15,386] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run9
[2019-03-26 17:30:15,507] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.8259534e-10 9.9999928e-01 1.0116810e-11 7.7322517e-07 1.4865519e-18], sum to 1.0000
[2019-03-26 17:30:15,512] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6015
[2019-03-26 17:30:15,516] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1903945.367866781 W.
[2019-03-26 17:30:15,519] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.1, 79.0, 1.0, 2.0, 0.72059248970238, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.982409161729024, 6.9112, 168.9124780601019, 1903945.367866781, 1853427.280800207, 390024.8739870846], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7894800.0000, 
sim time next is 7895400.0000, 
raw observation next is [28.21666666666667, 78.50000000000001, 1.0, 2.0, 0.6952596099043646, 1.0, 1.0, 0.6952596099043646, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1944156.785099297, 1944156.785099297, 372097.9528120738], 
processed observation next is [1.0, 0.391304347826087, 0.5363349131121644, 0.7850000000000001, 1.0, 1.0, 0.6328429034992344, 1.0, 0.5, 0.6328429034992344, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5400435514164714, 0.5400435514164714, 0.5553700788239908], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8413654], dtype=float32), 0.52351505]. 
=============================================
[2019-03-26 17:30:19,034] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.0690597e-10 1.5892336e-01 1.1165890e-09 8.4107661e-01 8.5819843e-17], sum to 1.0000
[2019-03-26 17:30:19,042] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9900
[2019-03-26 17:30:19,050] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.1, 70.5, 1.0, 2.0, 0.7541210148720651, 1.0, 1.0, 0.6976505469502952, 1.0, 1.0, 1.03, 7.004524264663246, 6.9112, 170.5573041426782, 2927466.669134465, 2860614.702167808, 538991.0462094304], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7911000.0000, 
sim time next is 7911600.0000, 
raw observation next is [30.13333333333333, 70.33333333333333, 1.0, 2.0, 0.7636785198019754, 1.0, 2.0, 0.7636785198019754, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2135667.518387401, 2135667.518387402, 402574.503442088], 
processed observation next is [1.0, 0.5652173913043478, 0.6271721958925749, 0.7033333333333333, 1.0, 1.0, 0.715275325062621, 1.0, 1.0, 0.715275325062621, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5932409773298336, 0.5932409773298338, 0.600857467824012], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.33124247], dtype=float32), 1.3194346]. 
=============================================
[2019-03-26 17:30:19,223] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:30:19,224] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:30:19,282] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run9
[2019-03-26 17:30:20,078] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:30:20,078] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:30:20,132] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run9
[2019-03-26 17:30:21,117] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:30:21,118] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:30:21,178] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run9
[2019-03-26 17:30:21,589] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:30:21,590] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:30:21,652] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run9
[2019-03-26 17:30:21,672] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:30:21,674] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:30:21,740] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run9
[2019-03-26 17:30:21,758] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:30:21,760] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:30:21,814] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run9
[2019-03-26 17:30:22,308] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:30:22,308] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:30:22,339] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run9
[2019-03-26 17:30:22,375] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:30:22,376] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:30:22,397] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run9
[2019-03-26 17:30:22,585] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:30:22,585] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:30:22,612] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run9
[2019-03-26 17:30:23,055] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-26 17:30:23,056] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 17:30:23,057] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:30:23,058] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 17:30:23,059] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:30:23,059] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 17:30:23,060] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 17:30:23,060] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:30:23,060] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:30:23,060] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 17:30:23,061] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:30:23,072] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run69
[2019-03-26 17:30:23,089] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run69
[2019-03-26 17:30:23,108] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run69
[2019-03-26 17:30:23,131] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run69
[2019-03-26 17:30:23,153] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run69
[2019-03-26 17:30:24,943] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10609243], dtype=float32), 0.08917105]
[2019-03-26 17:30:24,944] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.4, 67.0, 1.0, 2.0, 0.8248474346396195, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1152842.501462744, 1152842.501462744, 250098.6165118122]
[2019-03-26 17:30:24,946] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:30:24,948] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [4.0571073e-16 1.0000000e+00 1.8937874e-18 6.5565094e-16 4.9266106e-28], sampled 0.6495959518318348
[2019-03-26 17:30:36,440] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10609243], dtype=float32), 0.08917105]
[2019-03-26 17:30:36,443] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [21.011275895, 93.29395661999999, 1.0, 2.0, 0.2884955067243473, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 460921.8324569882, 460921.8324569876, 164307.2679470447]
[2019-03-26 17:30:36,443] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 17:30:36,446] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.8136429e-17 1.0000000e+00 1.6255728e-20 3.9535582e-20 1.2359096e-30], sampled 0.12831506784815583
[2019-03-26 17:30:52,028] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10609243], dtype=float32), 0.08917105]
[2019-03-26 17:30:52,029] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.1, 90.16666666666667, 1.0, 2.0, 0.4314341509215794, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 629817.8765954756, 629817.8765954762, 176997.8566789002]
[2019-03-26 17:30:52,030] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:30:52,033] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [6.3561650e-17 1.0000000e+00 4.5104915e-20 4.6584124e-20 5.4830007e-30], sampled 0.22286518742443517
[2019-03-26 17:31:12,293] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10609243], dtype=float32), 0.08917105]
[2019-03-26 17:31:12,294] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [24.16192822, 92.23303944, 1.0, 2.0, 0.463875694468414, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 665604.6473220198, 665604.6473220198, 180359.0974910136]
[2019-03-26 17:31:12,296] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 17:31:12,298] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.5460669e-16 1.0000000e+00 2.4633483e-19 3.1683290e-18 4.5627164e-29], sampled 0.5113818990550828
[2019-03-26 17:31:15,080] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10609243], dtype=float32), 0.08917105]
[2019-03-26 17:31:15,082] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.15719484666667, 68.63272514333333, 1.0, 2.0, 0.4586350042130738, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 654722.1281823785, 654722.1281823792, 179150.7869105692]
[2019-03-26 17:31:15,085] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 17:31:15,089] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.1593030e-16 1.0000000e+00 2.2065818e-19 1.3482045e-17 2.6959053e-29], sampled 0.7911044495961422
[2019-03-26 17:31:28,092] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10609243], dtype=float32), 0.08917105]
[2019-03-26 17:31:28,093] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.8, 70.0, 1.0, 2.0, 0.5592698464574971, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 781523.1849330212, 781523.1849330212, 193403.5116760856]
[2019-03-26 17:31:28,094] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:31:28,098] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.8085077e-16 1.0000000e+00 3.6583567e-19 1.2276572e-17 6.3143900e-29], sampled 0.6962576947471705
[2019-03-26 17:31:32,018] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10609243], dtype=float32), 0.08917105]
[2019-03-26 17:31:32,022] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [30.28542296, 65.12834553, 1.0, 2.0, 0.5073637002162941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 708965.3766608866, 708965.376660886, 184758.2689369346]
[2019-03-26 17:31:32,023] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 17:31:32,026] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [5.0641781e-16 1.0000000e+00 5.1066764e-18 5.5557043e-14 3.5703655e-28], sampled 0.8084285934974442
[2019-03-26 17:32:17,999] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8662.1933 2779033461.8836 919.0000
[2019-03-26 17:32:18,366] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8287.8513 2923832053.6933 1234.0000
[2019-03-26 17:32:18,393] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8078.0113 2997707576.8484 1521.0000
[2019-03-26 17:32:18,504] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8525.7877 2838720714.4259 1039.0000
[2019-03-26 17:32:18,526] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7975.1491 3153819984.5926 1469.0000
[2019-03-26 17:32:19,544] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 1700000, evaluation results [1700000.0, 7975.14910233181, 3153819984.592607, 1469.0, 8287.851291271185, 2923832053.693254, 1234.0, 8662.193321916395, 2779033461.8836484, 919.0, 8078.011299819513, 2997707576.848401, 1521.0, 8525.787728313806, 2838720714.425897, 1039.0]
[2019-03-26 17:32:30,764] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.1421538e-16 1.0000000e+00 5.5481742e-18 1.8946069e-15 1.6072476e-27], sum to 1.0000
[2019-03-26 17:32:30,773] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1425
[2019-03-26 17:32:30,779] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.96666666666667, 66.0, 1.0, 2.0, 0.2559756984143901, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 418568.5634198869, 418568.5634198862, 161487.9069930623], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 582000.0000, 
sim time next is 582600.0000, 
raw observation next is [22.83333333333333, 66.5, 1.0, 2.0, 0.2553916522124396, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 417912.0570407765, 417912.0570407765, 161435.166928166], 
processed observation next is [1.0, 0.7391304347826086, 0.2812006319115322, 0.665, 1.0, 1.0, 0.10288150868968625, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1160866825113268, 0.1160866825113268, 0.24094801034054628], 
reward next is 0.7591, 
noisyNet noise sample is [array([-0.2360784], dtype=float32), 0.33009169]. 
=============================================
[2019-03-26 17:32:35,539] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0033391e-16 1.0000000e+00 5.8387022e-20 2.8803166e-21 1.9883581e-30], sum to 1.0000
[2019-03-26 17:32:35,548] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8855
[2019-03-26 17:32:35,554] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.46666666666667, 95.33333333333334, 1.0, 2.0, 0.2668480080711604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 433630.2012884766, 433630.2012884766, 162505.1355426611], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 274800.0000, 
sim time next is 275400.0000, 
raw observation next is [19.4, 95.5, 1.0, 2.0, 0.2650526154486161, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 431053.1406491161, 431053.1406491161, 162334.7419220064], 
processed observation next is [0.0, 0.17391304347826086, 0.11848341232227487, 0.955, 1.0, 1.0, 0.11452122343206755, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.11973698351364336, 0.11973698351364336, 0.24229065958508417], 
reward next is 0.7577, 
noisyNet noise sample is [array([-0.67726785], dtype=float32), 0.5033048]. 
=============================================
[2019-03-26 17:32:37,953] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.8436343e-18 1.0000000e+00 4.3278114e-21 8.1165353e-21 3.0168037e-31], sum to 1.0000
[2019-03-26 17:32:37,961] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1845
[2019-03-26 17:32:37,966] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.13333333333333, 77.66666666666667, 1.0, 2.0, 0.3094962625492548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 489258.1009426742, 489258.1009426742, 166226.0873306207], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 315600.0000, 
sim time next is 316200.0000, 
raw observation next is [23.06666666666667, 77.83333333333333, 1.0, 2.0, 0.3080996017122549, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 487513.7142572048, 487513.7142572048, 166108.3679744664], 
processed observation next is [0.0, 0.6521739130434783, 0.29225908372827825, 0.7783333333333333, 1.0, 1.0, 0.16638506230392158, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1354204761825569, 0.1354204761825569, 0.247922937275323], 
reward next is 0.7521, 
noisyNet noise sample is [array([-1.4266503], dtype=float32), 0.29101464]. 
=============================================
[2019-03-26 17:32:41,109] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.2019441e-16 1.0000000e+00 4.6307752e-19 3.6634001e-18 1.7566697e-29], sum to 1.0000
[2019-03-26 17:32:41,118] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7912
[2019-03-26 17:32:41,128] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.75, 83.33333333333333, 1.0, 2.0, 0.2860399072619095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 466092.7313237328, 466092.7313237321, 164613.132883018], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 371400.0000, 
sim time next is 372000.0000, 
raw observation next is [20.8, 82.66666666666667, 1.0, 2.0, 0.2668630131458348, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 435066.5850133558, 435066.5850133558, 162563.8464363459], 
processed observation next is [1.0, 0.30434782608695654, 0.1848341232227489, 0.8266666666666667, 1.0, 1.0, 0.11670242547690943, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.12085182917037662, 0.12085182917037662, 0.24263260662141178], 
reward next is 0.7574, 
noisyNet noise sample is [array([1.3970548], dtype=float32), 1.1218544]. 
=============================================
[2019-03-26 17:32:41,146] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[73.64903 ]
 [73.682396]
 [73.64414 ]
 [73.63377 ]
 [73.62237 ]], R is [[73.67749023]
 [73.69503021]
 [73.71697998]
 [73.73866272]
 [73.76008606]].
[2019-03-26 17:32:44,650] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.0794290e-16 1.0000000e+00 7.9908909e-19 7.1445715e-18 4.0717963e-28], sum to 1.0000
[2019-03-26 17:32:44,657] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0640
[2019-03-26 17:32:44,663] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333334, 62.33333333333334, 1.0, 2.0, 0.5348901116764662, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 877201.9130404252, 877201.9130404245, 202335.4223483047], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 642000.0000, 
sim time next is 642600.0000, 
raw observation next is [23.5, 61.5, 1.0, 2.0, 0.5755322113276665, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 943539.055656543, 943539.055656543, 210440.7834478318], 
processed observation next is [1.0, 0.43478260869565216, 0.31279620853080575, 0.615, 1.0, 1.0, 0.48859302569598373, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2620941821268175, 0.2620941821268175, 0.3140907215639281], 
reward next is 0.6859, 
noisyNet noise sample is [array([-0.3986732], dtype=float32), 0.33346277]. 
=============================================
[2019-03-26 17:32:46,581] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.3516550e-17 1.0000000e+00 2.6470449e-19 4.6413908e-17 1.4854343e-28], sum to 1.0000
[2019-03-26 17:32:46,589] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2496
[2019-03-26 17:32:46,597] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.45, 71.5, 1.0, 2.0, 0.2442429345325114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 402702.5802681952, 402702.5802681945, 160319.3379870274], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 675000.0000, 
sim time next is 675600.0000, 
raw observation next is [21.23333333333333, 72.66666666666667, 1.0, 2.0, 0.2432084654639678, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 401205.2548112692, 401205.2548112686, 160211.5489642061], 
processed observation next is [1.0, 0.8260869565217391, 0.2053712480252764, 0.7266666666666667, 1.0, 1.0, 0.08820297043851541, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11144590411424143, 0.11144590411424128, 0.23912171487194941], 
reward next is 0.7609, 
noisyNet noise sample is [array([0.11595068], dtype=float32), 1.4685643]. 
=============================================
[2019-03-26 17:32:51,654] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.6358081e-17 1.0000000e+00 6.8326217e-20 3.8240346e-20 1.7169849e-29], sum to 1.0000
[2019-03-26 17:32:51,668] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6642
[2019-03-26 17:32:51,672] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 80.0, 1.0, 2.0, 0.2321895276978192, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 384136.3550020184, 384136.3550020184, 159105.5177691892], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 543600.0000, 
sim time next is 544200.0000, 
raw observation next is [20.2, 79.16666666666667, 1.0, 2.0, 0.2379483029790189, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 393328.7558126719, 393328.7558126719, 159667.2780906805], 
processed observation next is [1.0, 0.30434782608695654, 0.15639810426540288, 0.7916666666666667, 1.0, 1.0, 0.08186542527592637, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1092579877257422, 0.1092579877257422, 0.23830937028459778], 
reward next is 0.7617, 
noisyNet noise sample is [array([-0.34583592], dtype=float32), -1.5438473]. 
=============================================
[2019-03-26 17:32:54,075] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.9957553e-16 1.0000000e+00 4.4218020e-19 3.0628374e-17 7.5157635e-29], sum to 1.0000
[2019-03-26 17:32:54,083] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0263
[2019-03-26 17:32:54,089] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 71.0, 1.0, 2.0, 0.2496570161819618, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 411226.8252311549, 411226.8252311542, 160859.4074592386], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 588000.0000, 
sim time next is 588600.0000, 
raw observation next is [21.45, 71.5, 1.0, 2.0, 0.2478202630018402, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 408548.6347422035, 408548.634742204, 160668.6997043289], 
processed observation next is [1.0, 0.8260869565217391, 0.2156398104265403, 0.715, 1.0, 1.0, 0.0937593530142653, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11348573187283431, 0.11348573187283444, 0.23980402940944612], 
reward next is 0.7602, 
noisyNet noise sample is [array([-0.35582167], dtype=float32), 0.5499701]. 
=============================================
[2019-03-26 17:32:57,023] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.7519940e-17 1.0000000e+00 1.0996831e-19 5.4047216e-19 1.8480103e-29], sum to 1.0000
[2019-03-26 17:32:57,036] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8228
[2019-03-26 17:32:57,042] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 68.16666666666667, 1.0, 2.0, 0.4488592894162586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 738340.9935510228, 738340.9935510228, 187039.087585057], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 637800.0000, 
sim time next is 638400.0000, 
raw observation next is [22.33333333333334, 67.33333333333334, 1.0, 2.0, 0.4307439058912286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 708198.5681105608, 708198.5681105608, 184139.3985399752], 
processed observation next is [1.0, 0.391304347826087, 0.2575039494470777, 0.6733333333333335, 1.0, 1.0, 0.31414928420629945, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19672182447515577, 0.19672182447515577, 0.27483492319399283], 
reward next is 0.7252, 
noisyNet noise sample is [array([-0.07956342], dtype=float32), 0.5701778]. 
=============================================
[2019-03-26 17:32:59,585] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.59041216e-17 1.00000000e+00 1.59792440e-20 9.72277907e-22
 1.06258765e-30], sum to 1.0000
[2019-03-26 17:32:59,592] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2809
[2019-03-26 17:32:59,596] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 79.0, 1.0, 2.0, 0.2938409864394043, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 469050.3185091248, 469050.3185091242, 164864.1524690835], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 901800.0000, 
sim time next is 902400.0000, 
raw observation next is [22.5, 79.0, 1.0, 2.0, 0.2939403222194549, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 469208.8858034216, 469208.8858034223, 164875.2402231568], 
processed observation next is [0.0, 0.43478260869565216, 0.2654028436018958, 0.79, 1.0, 1.0, 0.14932568942102997, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13033580161206157, 0.13033580161206176, 0.2460824480942639], 
reward next is 0.7539, 
noisyNet noise sample is [array([0.8347169], dtype=float32), 1.2218984]. 
=============================================
[2019-03-26 17:33:04,008] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.3055866e-16 1.0000000e+00 1.2172993e-18 2.1487050e-16 5.9078383e-29], sum to 1.0000
[2019-03-26 17:33:04,014] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8348
[2019-03-26 17:33:04,017] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666667, 80.0, 1.0, 2.0, 0.2553848248439695, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 419233.0722709419, 419233.0722709419, 161446.3840239161], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 764400.0000, 
sim time next is 765000.0000, 
raw observation next is [20.6, 80.5, 1.0, 2.0, 0.2554862561026551, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 419403.3804272165, 419403.3804272165, 161456.5559875444], 
processed observation next is [1.0, 0.8695652173913043, 0.17535545023696694, 0.805, 1.0, 1.0, 0.10299548928030731, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.11650093900756014, 0.11650093900756014, 0.24097993430976775], 
reward next is 0.7590, 
noisyNet noise sample is [array([0.0789538], dtype=float32), 0.8003837]. 
=============================================
[2019-03-26 17:33:04,035] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[75.44099 ]
 [75.359566]
 [75.30484 ]
 [75.208115]
 [75.18743 ]], R is [[75.5621109 ]
 [75.56552124]
 [75.56900024]
 [75.5725708 ]
 [75.57628632]].
[2019-03-26 17:33:05,422] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.3845742e-17 1.0000000e+00 1.5605691e-20 8.8327606e-21 2.8818847e-31], sum to 1.0000
[2019-03-26 17:33:05,424] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.0982638e-18 1.0000000e+00 2.2271557e-20 2.0723136e-20 6.4493255e-30], sum to 1.0000
[2019-03-26 17:33:05,432] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8741
[2019-03-26 17:33:05,432] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9188
[2019-03-26 17:33:05,438] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 92.0, 1.0, 2.0, 0.2594014098224554, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 424576.881604003, 424576.881604003, 161841.3151887065], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 786000.0000, 
sim time next is 786600.0000, 
raw observation next is [19.4, 92.0, 1.0, 2.0, 0.2590417686379294, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 423988.3716942275, 423988.3716942275, 161804.8166700756], 
processed observation next is [0.0, 0.08695652173913043, 0.11848341232227487, 0.92, 1.0, 1.0, 0.10727923932280647, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.11777454769284097, 0.11777454769284097, 0.24149972637324718], 
reward next is 0.7585, 
noisyNet noise sample is [array([-0.5818078], dtype=float32), 0.5725751]. 
=============================================
[2019-03-26 17:33:05,440] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 73.0, 1.0, 2.0, 0.2874972932357521, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 461288.1406071365, 461288.1406071359, 164353.5380346968], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 810000.0000, 
sim time next is 810600.0000, 
raw observation next is [23.28333333333334, 72.0, 1.0, 2.0, 0.2879159252798174, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 461782.0591718462, 461782.0591718456, 164385.9963950096], 
processed observation next is [0.0, 0.391304347826087, 0.30252764612954214, 0.72, 1.0, 1.0, 0.14206737985520168, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12827279421440171, 0.12827279421440155, 0.24535223342538745], 
reward next is 0.7546, 
noisyNet noise sample is [array([-0.5673087], dtype=float32), 0.14736146]. 
=============================================
[2019-03-26 17:33:10,474] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.8305486e-17 1.0000000e+00 3.5310882e-19 4.0895317e-18 6.3009157e-29], sum to 1.0000
[2019-03-26 17:33:10,482] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9799
[2019-03-26 17:33:10,486] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.53333333333333, 91.66666666666667, 1.0, 2.0, 0.5137428404186826, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 730800.3274593552, 730800.3274593552, 187428.4019170274], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1311600.0000, 
sim time next is 1312200.0000, 
raw observation next is [24.55, 91.5, 1.0, 2.0, 0.5153362958853872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 733246.0981006918, 733246.0981006911, 187712.6272447009], 
processed observation next is [1.0, 0.17391304347826086, 0.3625592417061612, 0.915, 1.0, 1.0, 0.4160678263679364, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2036794716946366, 0.2036794716946364, 0.2801681003652252], 
reward next is 0.7198, 
noisyNet noise sample is [array([-0.6487706], dtype=float32), -0.8380838]. 
=============================================
[2019-03-26 17:33:14,089] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.2262456e-17 1.0000000e+00 7.6668956e-21 3.0579762e-20 6.0000885e-31], sum to 1.0000
[2019-03-26 17:33:14,096] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1309
[2019-03-26 17:33:14,105] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.6, 87.66666666666667, 1.0, 2.0, 0.3384132657816531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 524183.5858627975, 524183.585862798, 168622.8294463988], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 937200.0000, 
sim time next is 937800.0000, 
raw observation next is [22.55, 88.0, 1.0, 2.0, 0.3387289176552802, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 524766.1754814181, 524766.1754814174, 168672.0485317231], 
processed observation next is [0.0, 0.8695652173913043, 0.26777251184834133, 0.88, 1.0, 1.0, 0.2032878525967231, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14576838207817172, 0.14576838207817153, 0.2517493261667509], 
reward next is 0.7483, 
noisyNet noise sample is [array([0.78199524], dtype=float32), -0.91421163]. 
=============================================
[2019-03-26 17:33:14,141] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-26 17:33:14,143] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 17:33:14,144] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:33:14,144] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 17:33:14,147] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 17:33:14,149] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 17:33:14,149] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:33:14,150] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:33:14,152] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 17:33:14,150] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:33:14,154] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:33:14,174] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run70
[2019-03-26 17:33:14,199] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run70
[2019-03-26 17:33:14,220] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run70
[2019-03-26 17:33:14,221] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run70
[2019-03-26 17:33:14,221] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run70
[2019-03-26 17:33:16,417] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10502683], dtype=float32), 0.09007255]
[2019-03-26 17:33:16,418] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [22.6, 89.5, 1.0, 2.0, 0.3749607221845714, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 576695.3442161948, 576695.3442161955, 172909.6474559471]
[2019-03-26 17:33:16,420] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:33:16,422] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [7.2077832e-17 1.0000000e+00 5.9664563e-20 7.3559918e-20 7.0129715e-30], sampled 0.06391519498906117
[2019-03-26 17:33:24,946] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10502683], dtype=float32), 0.09007255]
[2019-03-26 17:33:24,947] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [22.83333333333334, 74.33333333333334, 1.0, 2.0, 0.2888285054821289, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 464148.1805930112, 464148.1805930112, 164554.1967273912]
[2019-03-26 17:33:24,949] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 17:33:24,953] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [8.2556040e-17 1.0000000e+00 4.7030688e-20 1.8799156e-20 6.9901093e-30], sampled 0.7042156435644266
[2019-03-26 17:33:51,933] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10502683], dtype=float32), 0.09007255]
[2019-03-26 17:33:51,935] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.53333333333333, 79.33333333333334, 1.0, 2.0, 0.96750183150506, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1352349.444594403, 1352349.444594403, 289178.2416293738]
[2019-03-26 17:33:51,936] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:33:51,939] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [7.1388343e-15 1.0000000e+00 1.0348331e-16 1.0521445e-12 2.2782341e-26], sampled 0.7867495314363573
[2019-03-26 17:34:02,220] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10502683], dtype=float32), 0.09007255]
[2019-03-26 17:34:02,220] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [34.28333333333333, 57.16666666666667, 1.0, 2.0, 0.9134992136372413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1276820.568317785, 1276820.568317785, 273682.0519136427]
[2019-03-26 17:34:02,221] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:34:02,223] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.3839895e-15 1.0000000e+00 8.5195782e-18 6.5009245e-15 3.4405244e-27], sampled 0.457345490518144
[2019-03-26 17:34:03,380] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10502683], dtype=float32), 0.09007255]
[2019-03-26 17:34:03,382] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.75, 69.5, 1.0, 2.0, 0.6671317403914989, 1.0, 1.0, 0.6671317403914989, 0.0, 1.0, 0.0, 6.9112, 6.9112, 172.86236624, 1865412.603012479, 1865412.603012479, 360859.2460612094]
[2019-03-26 17:34:03,383] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:34:03,385] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [8.1431512e-10 7.3643947e-01 2.0441249e-09 2.6356050e-01 8.2705323e-18], sampled 0.3395142653008415
[2019-03-26 17:34:03,388] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1865412.603012479 W.
[2019-03-26 17:34:16,560] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10502683], dtype=float32), 0.09007255]
[2019-03-26 17:34:16,560] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [35.83333333333333, 49.33333333333333, 1.0, 2.0, 0.6636829361955878, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 927493.6502745332, 927493.6502745325, 213204.8680854585]
[2019-03-26 17:34:16,561] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:34:16,565] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [8.1792122e-17 1.0000000e+00 1.7810578e-19 1.8636386e-17 1.4878892e-29], sampled 0.048743436394906636
[2019-03-26 17:34:20,900] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10502683], dtype=float32), 0.09007255]
[2019-03-26 17:34:20,901] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.43333333333334, 71.0, 1.0, 2.0, 0.6797987922112149, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.995620707814966, 6.9112, 168.9123876843767, 1846860.532463419, 1786969.778489888, 380728.5614764906]
[2019-03-26 17:34:20,904] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:34:20,907] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0891217e-09 8.1909984e-01 3.0813350e-09 1.8090019e-01 7.5892241e-18], sampled 0.37259968327607973
[2019-03-26 17:34:20,908] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1846860.532463419 W.
[2019-03-26 17:35:02,616] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10502683], dtype=float32), 0.09007255]
[2019-03-26 17:35:02,617] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.63333333333334, 83.66666666666667, 1.0, 2.0, 0.5565833941968609, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9626167096534762, 6.911200000000001, 6.9112, 168.9126991045387, 1556105.453856885, 1556105.453856885, 339728.3101093352]
[2019-03-26 17:35:02,618] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 17:35:02,620] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.8387554e-15 1.0000000e+00 7.5451354e-18 5.6035031e-16 4.7631938e-27], sampled 0.32380535875459204
[2019-03-26 17:35:04,823] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7973.7485 3154683170.1940 1494.0000
[2019-03-26 17:35:05,514] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8662.9234 2778731954.5167 918.0000
[2019-03-26 17:35:05,634] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8278.6208 2923948962.2471 1244.0000
[2019-03-26 17:35:05,734] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8063.6105 2999302667.6638 1553.0000
[2019-03-26 17:35:05,784] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8520.4567 2839132192.3768 1054.0000
[2019-03-26 17:35:06,800] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 1725000, evaluation results [1725000.0, 7973.7485399740735, 3154683170.19404, 1494.0, 8278.620789258131, 2923948962.2471094, 1244.0, 8662.923368898702, 2778731954.5166855, 918.0, 8063.61051843734, 2999302667.663849, 1553.0, 8520.456683748096, 2839132192.376757, 1054.0]
[2019-03-26 17:35:10,178] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.29622987e-16 1.00000000e+00 1.00301995e-19 7.42328270e-19
 1.26225418e-29], sum to 1.0000
[2019-03-26 17:35:10,189] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1646
[2019-03-26 17:35:10,198] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.55, 95.0, 1.0, 2.0, 0.2985181058265153, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 475780.7580911931, 475780.7580911931, 165327.4756442262], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1061400.0000, 
sim time next is 1062000.0000, 
raw observation next is [20.6, 95.0, 1.0, 2.0, 0.3003555778695772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 478186.0030671549, 478186.0030671549, 165490.4903227347], 
processed observation next is [1.0, 0.30434782608695654, 0.17535545023696694, 0.95, 1.0, 1.0, 0.1570549130958761, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13282944529643192, 0.13282944529643192, 0.24700073182497714], 
reward next is 0.7530, 
noisyNet noise sample is [array([-0.12388979], dtype=float32), 0.51491874]. 
=============================================
[2019-03-26 17:35:10,219] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[73.21982 ]
 [73.22263 ]
 [73.22742 ]
 [73.223625]
 [73.22418 ]], R is [[73.29418945]
 [73.31449127]
 [73.33481598]
 [73.35515594]
 [73.37535095]].
[2019-03-26 17:35:16,460] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.1035621e-16 1.0000000e+00 1.3766427e-17 1.4390171e-15 3.5505782e-27], sum to 1.0000
[2019-03-26 17:35:16,468] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7696
[2019-03-26 17:35:16,473] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.1, 71.0, 1.0, 2.0, 0.3490872568899471, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 539398.1730298485, 539398.1730298485, 169814.6973556046], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1194000.0000, 
sim time next is 1194600.0000, 
raw observation next is [24.95, 72.0, 1.0, 2.0, 0.3499966945628205, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 540667.404520237, 540667.4045202364, 169915.0372686255], 
processed observation next is [1.0, 0.8260869565217391, 0.3815165876777251, 0.72, 1.0, 1.0, 0.21686348742508493, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15018539014451027, 0.15018539014451013, 0.2536045332367545], 
reward next is 0.7464, 
noisyNet noise sample is [array([1.6850854], dtype=float32), -0.9838881]. 
=============================================
[2019-03-26 17:35:23,441] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0409581e-16 1.0000000e+00 7.0315444e-20 2.2561182e-20 5.3265245e-30], sum to 1.0000
[2019-03-26 17:35:23,452] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0408
[2019-03-26 17:35:23,462] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.01666666666667, 95.5, 1.0, 2.0, 0.3215504480514403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 506198.4007645856, 506198.4007645856, 167445.299654477], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1403400.0000, 
sim time next is 1404000.0000, 
raw observation next is [21.1, 95.0, 1.0, 2.0, 0.3225379551858542, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 507450.764792115, 507450.7647921143, 167533.8054971398], 
processed observation next is [0.0, 0.2608695652173913, 0.1990521327014219, 0.95, 1.0, 1.0, 0.18378066889861952, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1409585457755875, 0.1409585457755873, 0.2500504559658803], 
reward next is 0.7499, 
noisyNet noise sample is [array([-0.39195946], dtype=float32), 0.9072831]. 
=============================================
[2019-03-26 17:35:23,473] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[75.77484]
 [75.7656 ]
 [75.75052]
 [75.73086]
 [75.71087]], R is [[75.79781342]
 [75.78991699]
 [75.78231812]
 [75.77508545]
 [75.76815796]].
[2019-03-26 17:35:23,770] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.7951390e-16 1.0000000e+00 4.6828954e-19 4.3018633e-17 9.4613927e-29], sum to 1.0000
[2019-03-26 17:35:23,785] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7804
[2019-03-26 17:35:23,789] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.65, 90.50000000000001, 1.0, 2.0, 0.3960540149804686, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 606811.435791724, 606811.4357917234, 175548.456382218], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1231800.0000, 
sim time next is 1232400.0000, 
raw observation next is [22.8, 90.0, 1.0, 2.0, 0.3946336613856963, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 603071.9388037825, 603071.9388037825, 175178.1188802123], 
processed observation next is [1.0, 0.2608695652173913, 0.2796208530805688, 0.9, 1.0, 1.0, 0.2706429655249353, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16751998300105067, 0.16751998300105067, 0.26145987892569], 
reward next is 0.7385, 
noisyNet noise sample is [array([-0.6273115], dtype=float32), -0.8933111]. 
=============================================
[2019-03-26 17:35:34,525] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.2749846e-16 1.0000000e+00 7.6271390e-20 3.2402823e-20 2.2795694e-29], sum to 1.0000
[2019-03-26 17:35:34,539] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4636
[2019-03-26 17:35:34,545] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.91666666666667, 89.16666666666667, 1.0, 2.0, 0.3533220127885744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 539921.864594008, 539921.864594008, 169674.4484729247], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1494600.0000, 
sim time next is 1495200.0000, 
raw observation next is [23.13333333333333, 88.33333333333334, 1.0, 2.0, 0.357434373157981, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 544417.1301215849, 544417.1301215843, 169990.0831217124], 
processed observation next is [0.0, 0.30434782608695654, 0.29541864139020524, 0.8833333333333334, 1.0, 1.0, 0.22582454597347107, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15122698058932912, 0.15122698058932896, 0.2537165419727051], 
reward next is 0.7463, 
noisyNet noise sample is [array([0.7075837], dtype=float32), 1.3347566]. 
=============================================
[2019-03-26 17:35:40,455] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.7783760e-17 1.0000000e+00 1.9694658e-20 1.6239187e-19 2.6698460e-31], sum to 1.0000
[2019-03-26 17:35:40,457] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6625
[2019-03-26 17:35:40,465] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.4, 58.33333333333333, 1.0, 2.0, 0.3491524393875517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 537979.8451074867, 537979.845107486, 169654.2106731027], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1528800.0000, 
sim time next is 1529400.0000, 
raw observation next is [27.25, 58.66666666666667, 1.0, 2.0, 0.346292124444137, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 534723.2371210987, 534723.2371210987, 169422.5073354292], 
processed observation next is [0.0, 0.6956521739130435, 0.490521327014218, 0.5866666666666667, 1.0, 1.0, 0.21240014993269515, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1485342325336385, 0.1485342325336385, 0.2528694139334764], 
reward next is 0.7471, 
noisyNet noise sample is [array([1.0843287], dtype=float32), 0.09749689]. 
=============================================
[2019-03-26 17:35:52,387] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.2207649e-16 1.0000000e+00 2.1956256e-18 6.7565053e-14 3.5422293e-28], sum to 1.0000
[2019-03-26 17:35:52,397] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5811
[2019-03-26 17:35:52,401] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.93333333333333, 84.66666666666666, 1.0, 2.0, 0.5090827636249359, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 711368.3166479467, 711368.3166479474, 185031.53148485], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1712400.0000, 
sim time next is 1713000.0000, 
raw observation next is [26.81666666666667, 85.33333333333334, 1.0, 2.0, 0.5083002362419704, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 710274.4841059294, 710274.4841059294, 184906.9153788787], 
processed observation next is [1.0, 0.8260869565217391, 0.46998420221169057, 0.8533333333333334, 1.0, 1.0, 0.4075906460746631, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19729846780720262, 0.19729846780720262, 0.27598047071474435], 
reward next is 0.7240, 
noisyNet noise sample is [array([0.37867558], dtype=float32), 0.5689361]. 
=============================================
[2019-03-26 17:35:52,412] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[74.74008 ]
 [75.46483 ]
 [76.32965 ]
 [76.867905]
 [77.54255 ]], R is [[73.94450378]
 [73.92889404]
 [73.91362762]
 [73.89875793]
 [73.88428497]].
[2019-03-26 17:36:01,960] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-26 17:36:01,961] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 17:36:01,962] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:36:01,963] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 17:36:01,964] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 17:36:01,965] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:36:01,965] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 17:36:01,966] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:36:01,967] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 17:36:01,967] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:36:01,969] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:36:01,994] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run71
[2019-03-26 17:36:02,017] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run71
[2019-03-26 17:36:02,017] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run71
[2019-03-26 17:36:02,067] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run71
[2019-03-26 17:36:02,068] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run71
[2019-03-26 17:36:26,697] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10570703], dtype=float32), 0.088146426]
[2019-03-26 17:36:26,699] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [28.45, 68.0, 1.0, 2.0, 0.6521856588653252, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 916582.9749567442, 916582.9749567448, 211543.2642658466]
[2019-03-26 17:36:26,700] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:36:26,703] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.2772640e-16 1.0000000e+00 3.2467180e-19 4.0838105e-18 1.2814626e-28], sampled 0.8212852882835959
[2019-03-26 17:36:33,554] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10570703], dtype=float32), 0.088146426]
[2019-03-26 17:36:33,556] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.881378575, 85.71961974, 1.0, 2.0, 0.6201456165008118, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 866625.6360486294, 866625.6360486294, 204559.6037906611]
[2019-03-26 17:36:33,557] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 17:36:33,560] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.601192e-16 1.000000e+00 3.373735e-19 3.252473e-17 8.847900e-29], sampled 0.8988129551762887
[2019-03-26 17:37:16,530] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10570703], dtype=float32), 0.088146426]
[2019-03-26 17:37:16,531] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [33.42954752666667, 66.36734795833334, 1.0, 2.0, 0.6111894863394712, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 854104.814189582, 854104.814189582, 202850.4564203924]
[2019-03-26 17:37:16,532] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 17:37:16,537] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.3243590e-16 1.0000000e+00 2.8038577e-19 1.8317445e-18 8.3230007e-29], sampled 0.0034114651977118493
[2019-03-26 17:37:19,824] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10570703], dtype=float32), 0.088146426]
[2019-03-26 17:37:19,827] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.2, 87.0, 1.0, 2.0, 0.6803475333278061, 1.0, 1.0, 0.6607638061781657, 1.0, 1.0, 1.03, 7.005096182628445, 6.9112, 170.5573041426782, 2772511.527075974, 2705249.87200671, 515193.8932437238]
[2019-03-26 17:37:19,828] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:37:19,831] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.2157129e-13 1.0000000e+00 1.3093156e-15 1.0831378e-12 1.3767593e-23], sampled 0.36306062950418916
[2019-03-26 17:37:19,831] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2772511.527075974 W.
[2019-03-26 17:37:36,387] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10570703], dtype=float32), 0.088146426]
[2019-03-26 17:37:36,388] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.1, 65.0, 1.0, 2.0, 0.5447839041937217, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 761273.2881962361, 761273.2881962368, 190909.9057459063]
[2019-03-26 17:37:36,389] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:37:36,391] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [4.0483416e-16 1.0000000e+00 1.2399690e-18 2.4365673e-16 4.4116054e-28], sampled 0.7921198382083562
[2019-03-26 17:37:47,621] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10570703], dtype=float32), 0.088146426]
[2019-03-26 17:37:47,622] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [21.63333333333333, 89.66666666666667, 1.0, 2.0, 0.3310579444283711, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 522246.5324323068, 522246.5324323062, 168702.9998408542]
[2019-03-26 17:37:47,623] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:37:47,628] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.3990480e-16 1.0000000e+00 9.3429701e-20 1.0509554e-19 3.4871905e-29], sampled 0.2719410993935638
[2019-03-26 17:37:56,639] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8299.7346 2922800130.7890 1203.0000
[2019-03-26 17:37:56,839] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8095.6839 2995096981.1216 1458.0000
[2019-03-26 17:37:56,881] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8669.9071 2777987701.8929 906.0000
[2019-03-26 17:37:57,064] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8535.0982 2837889037.7127 1014.0000
[2019-03-26 17:37:57,068] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 8002.9884 3151432018.9374 1411.0000
[2019-03-26 17:37:58,085] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1750000, evaluation results [1750000.0, 8002.988364042677, 3151432018.9373884, 1411.0, 8299.734591566175, 2922800130.788952, 1203.0, 8669.907064751489, 2777987701.892937, 906.0, 8095.683945802091, 2995096981.121632, 1458.0, 8535.098183949623, 2837889037.7126584, 1014.0]
[2019-03-26 17:38:01,439] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.8718268e-14 1.0000000e+00 1.0942747e-15 1.2747156e-12 1.2428728e-24], sum to 1.0000
[2019-03-26 17:38:01,447] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7857
[2019-03-26 17:38:01,458] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1686734.859267304 W.
[2019-03-26 17:38:01,462] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.3, 79.33333333333334, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.204879867323831, 6.9112, 168.9109805457709, 1686734.859267304, 1478390.69097118, 315270.6597340959], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1939200.0000, 
sim time next is 1939800.0000, 
raw observation next is [26.35, 79.16666666666667, 1.0, 2.0, 0.5522005903389777, 1.0, 1.0, 0.5522005903389777, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1543832.197639485, 1543832.197639485, 317254.2278620806], 
processed observation next is [1.0, 0.43478260869565216, 0.4478672985781992, 0.7916666666666667, 1.0, 1.0, 0.46048263896262376, 1.0, 0.5, 0.46048263896262376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.4288422771220791, 0.4288422771220791, 0.4735137729284785], 
reward next is 0.5265, 
noisyNet noise sample is [array([1.5981914], dtype=float32), -0.77598345]. 
=============================================
[2019-03-26 17:38:01,559] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.2198832e-15 1.0000000e+00 8.3818733e-16 1.0103775e-12 3.7867055e-24], sum to 1.0000
[2019-03-26 17:38:01,568] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9638
[2019-03-26 17:38:01,575] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.1, 80.0, 1.0, 2.0, 0.9555895829597093, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 168.9129564536985, 1348010.459809329, 1348010.459809328, 287571.9116682726], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1936800.0000, 
sim time next is 1937400.0000, 
raw observation next is [26.15, 79.83333333333334, 1.0, 2.0, 0.9056315403245663, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129565104168, 1290499.347349971, 1290499.347349971, 275152.1756881311], 
processed observation next is [1.0, 0.43478260869565216, 0.43838862559241704, 0.7983333333333335, 1.0, 1.0, 0.8863030606320076, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.829439945152233, 0.3584720409305475, 0.3584720409305475, 0.4106748890867628], 
reward next is 0.5893, 
noisyNet noise sample is [array([1.2594364], dtype=float32), -0.88793075]. 
=============================================
[2019-03-26 17:38:01,779] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.0923312e-10 9.8854619e-01 1.4608278e-09 1.1453783e-02 2.2707687e-15], sum to 1.0000
[2019-03-26 17:38:01,788] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7743
[2019-03-26 17:38:01,801] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1765255.492189592 W.
[2019-03-26 17:38:01,807] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.8, 77.0, 1.0, 2.0, 0.4208896565580444, 1.0, 2.0, 0.4208896565580444, 1.0, 2.0, 0.706148321616556, 6.9112, 6.9112, 170.5573041426782, 1765255.492189592, 1765255.492189592, 360966.5217422853], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1944000.0000, 
sim time next is 1944600.0000, 
raw observation next is [26.86666666666667, 76.66666666666667, 1.0, 2.0, 0.5684572877050935, 1.0, 2.0, 0.5684572877050935, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1589316.070940047, 1589316.070940047, 322880.3958074359], 
processed observation next is [1.0, 0.5217391304347826, 0.4723538704581361, 0.7666666666666667, 1.0, 1.0, 0.480069021331438, 1.0, 1.0, 0.480069021331438, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.4414766863722353, 0.4414766863722353, 0.48191103851856104], 
reward next is 0.5181, 
noisyNet noise sample is [array([-0.15718485], dtype=float32), 0.59209216]. 
=============================================
[2019-03-26 17:38:12,191] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.1560401e-15 1.0000000e+00 1.0980117e-17 1.7332121e-15 9.1289804e-27], sum to 1.0000
[2019-03-26 17:38:12,201] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0542
[2019-03-26 17:38:12,204] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.71666666666667, 96.16666666666667, 1.0, 2.0, 0.5331504626619314, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 745011.1813455194, 745011.1813455194, 188950.06243114], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2178600.0000, 
sim time next is 2179200.0000, 
raw observation next is [24.93333333333334, 95.33333333333334, 1.0, 2.0, 0.5530980050185144, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 772895.5214171896, 772895.5214171902, 192329.2531387658], 
processed observation next is [1.0, 0.21739130434782608, 0.3807266982622437, 0.9533333333333335, 1.0, 1.0, 0.4615638614680896, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2146932003936638, 0.21469320039366394, 0.2870585867742773], 
reward next is 0.7129, 
noisyNet noise sample is [array([-0.26884922], dtype=float32), 1.5035385]. 
=============================================
[2019-03-26 17:38:13,394] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.1782933e-17 1.0000000e+00 1.1026025e-19 2.8843234e-18 1.4840977e-28], sum to 1.0000
[2019-03-26 17:38:13,402] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8651
[2019-03-26 17:38:13,408] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.06666666666666, 75.66666666666666, 1.0, 2.0, 0.5661459106881557, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 791135.3693099535, 791135.3693099535, 194608.8102520434], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2137200.0000, 
sim time next is 2137800.0000, 
raw observation next is [29.88333333333333, 76.33333333333334, 1.0, 2.0, 0.5653684545235572, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 790048.5438035389, 790048.5438035389, 194471.7247832766], 
processed observation next is [0.0, 0.7391304347826086, 0.6153238546603473, 0.7633333333333334, 1.0, 1.0, 0.4763475355705508, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21945792883431636, 0.21945792883431636, 0.2902563056466815], 
reward next is 0.7097, 
noisyNet noise sample is [array([0.05542516], dtype=float32), 0.24741745]. 
=============================================
[2019-03-26 17:38:16,824] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.3034356e-11 9.9995589e-01 6.8917982e-11 4.4152930e-05 5.8031260e-17], sum to 1.0000
[2019-03-26 17:38:16,832] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3014
[2019-03-26 17:38:16,840] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2043423.308323411 W.
[2019-03-26 17:38:16,844] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.55, 68.5, 1.0, 2.0, 0.4871499890392367, 1.0, 1.0, 0.4871499890392367, 1.0, 2.0, 0.8423067116113523, 6.911199999999999, 6.9112, 170.5573041426782, 2043423.308323411, 2043423.308323412, 405723.2525804515], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2365800.0000, 
sim time next is 2366400.0000, 
raw observation next is [30.7, 68.0, 1.0, 2.0, 0.8406837556392208, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.993870708488317, 6.9112, 168.9124644157759, 2072013.429417077, 2013364.154372886, 418594.5292409575], 
processed observation next is [1.0, 0.391304347826087, 0.6540284360189573, 0.68, 1.0, 1.0, 0.8080527176376154, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.008267070848831715, 0.0, 0.8294375287422643, 0.575559285949188, 0.559267820659135, 0.6247679540909814], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.26659188], dtype=float32), -3.0620003]. 
=============================================
[2019-03-26 17:38:22,093] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.7015381e-10 7.1154326e-01 2.5219729e-10 2.8845671e-01 6.5746453e-18], sum to 1.0000
[2019-03-26 17:38:22,106] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1848
[2019-03-26 17:38:22,114] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2015290.030745253 W.
[2019-03-26 17:38:22,120] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.86666666666667, 64.33333333333334, 1.0, 2.0, 0.8001547740872302, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.000150076649222, 6.9112, 168.9124281478365, 2015290.030745253, 1952185.982336076, 408096.487252294], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2294400.0000, 
sim time next is 2295000.0000, 
raw observation next is [31.85, 64.5, 1.0, 2.0, 0.7501990835030152, 1.0, 1.0, 0.7501990835030152, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2097934.645607864, 2097934.645607864, 396357.2050061058], 
processed observation next is [1.0, 0.5652173913043478, 0.7085308056872038, 0.645, 1.0, 1.0, 0.6990350403650786, 1.0, 0.5, 0.6990350403650786, 0.0, 0.5, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5827596237799623, 0.5827596237799623, 0.5915779179195609], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.19882853], dtype=float32), -0.2853852]. 
=============================================
[2019-03-26 17:38:22,142] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[59.984486]
 [61.695797]
 [61.18627 ]
 [61.396984]
 [61.409412]], R is [[58.74599457]
 [58.158535  ]
 [58.06877136]
 [57.9364624 ]
 [57.77806854]].
[2019-03-26 17:38:29,034] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.2569071e-16 1.0000000e+00 5.5699745e-18 2.2384470e-15 3.8613563e-27], sum to 1.0000
[2019-03-26 17:38:29,044] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4546
[2019-03-26 17:38:29,054] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 80.0, 1.0, 2.0, 0.5586144297159925, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 780606.9696201672, 780606.9696201679, 193289.1812310101], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2420400.0000, 
sim time next is 2421000.0000, 
raw observation next is [28.95, 80.0, 1.0, 2.0, 0.5566361447008397, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 777841.5048890228, 777841.5048890234, 192945.4512849399], 
processed observation next is [1.0, 0.0, 0.5710900473933649, 0.8, 1.0, 1.0, 0.4658266803624574, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2160670846913952, 0.21606708469139538, 0.2879782854999103], 
reward next is 0.7120, 
noisyNet noise sample is [array([-0.02908631], dtype=float32), 0.40417212]. 
=============================================
[2019-03-26 17:38:29,072] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[70.98656]
 [71.4776 ]
 [72.09441]
 [72.95756]
 [72.95516]], R is [[70.72740936]
 [70.73164368]
 [70.73534393]
 [70.73860168]
 [70.74153137]].
[2019-03-26 17:38:31,384] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.1065005e-14 1.0000000e+00 4.4766464e-16 2.3568998e-12 2.5243174e-25], sum to 1.0000
[2019-03-26 17:38:31,394] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1739
[2019-03-26 17:38:31,402] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1991375.086080634 W.
[2019-03-26 17:38:31,408] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.35, 86.5, 1.0, 2.0, 0.7121299032552998, 1.0, 1.0, 0.7121299032552998, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1991375.086080634, 1991375.086080634, 379358.7367608983], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2449800.0000, 
sim time next is 2450400.0000, 
raw observation next is [27.23333333333333, 86.66666666666667, 1.0, 2.0, 0.7407619720645322, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.986858527610512, 6.9112, 168.9125110512642, 1932170.754170318, 1878496.13226956, 394440.0873943556], 
processed observation next is [1.0, 0.34782608695652173, 0.4897314375987361, 0.8666666666666667, 1.0, 1.0, 0.6876650265837737, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.007565852761051239, 0.0, 0.8294377577438616, 0.5367140983806439, 0.5218044811859889, 0.5887165483497845], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.9428956], dtype=float32), -0.44218156]. 
=============================================
[2019-03-26 17:38:36,085] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.7360009e-16 1.0000000e+00 1.0836469e-18 2.6452116e-16 3.7952448e-28], sum to 1.0000
[2019-03-26 17:38:36,094] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6942
[2019-03-26 17:38:36,100] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666666, 99.0, 1.0, 2.0, 0.3441424890590314, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 533493.0394974338, 533493.0394974338, 169382.653889772], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2915400.0000, 
sim time next is 2916000.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.3444608833846927, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 534749.1700828595, 534749.1700828589, 169505.0779180692], 
processed observation next is [1.0, 0.782608695652174, 0.19431279620853087, 1.0, 1.0, 1.0, 0.21019383540324424, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14854143613412762, 0.14854143613412746, 0.25299265360905854], 
reward next is 0.7470, 
noisyNet noise sample is [array([0.49860036], dtype=float32), 0.6036488]. 
=============================================
[2019-03-26 17:38:36,118] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[71.959236]
 [71.931694]
 [71.78213 ]
 [71.5491  ]
 [71.21075 ]], R is [[72.08435822]
 [72.11071014]
 [72.13677216]
 [72.16247559]
 [72.18719482]].
[2019-03-26 17:38:38,917] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.7739980e-16 1.0000000e+00 4.2665765e-18 2.0405535e-14 4.5861388e-27], sum to 1.0000
[2019-03-26 17:38:38,929] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5462
[2019-03-26 17:38:38,936] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.43333333333334, 85.66666666666667, 1.0, 2.0, 0.5364686463239524, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 749649.5647398575, 749649.5647398575, 189507.0929359912], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2578800.0000, 
sim time next is 2579400.0000, 
raw observation next is [27.35, 86.0, 1.0, 2.0, 0.5349974238189689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 747592.9870983448, 747592.9870983455, 189261.0103431962], 
processed observation next is [1.0, 0.8695652173913043, 0.4952606635071091, 0.86, 1.0, 1.0, 0.43975593231201066, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2076647186384291, 0.2076647186384293, 0.2824791199152182], 
reward next is 0.7175, 
noisyNet noise sample is [array([-0.31661725], dtype=float32), -0.6882155]. 
=============================================
[2019-03-26 17:38:41,183] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.2403386e-17 1.0000000e+00 5.0061614e-20 5.8632795e-19 6.0103316e-30], sum to 1.0000
[2019-03-26 17:38:41,191] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6157
[2019-03-26 17:38:41,197] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.16666666666667, 92.0, 1.0, 2.0, 0.4417324161473611, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 636596.4127780722, 636596.4127780729, 177456.4061942771], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2601600.0000, 
sim time next is 2602200.0000, 
raw observation next is [24.13333333333333, 92.0, 1.0, 2.0, 0.4399230405821846, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 634846.1989082854, 634846.1989082847, 177304.0313787904], 
processed observation next is [0.0, 0.08695652173913043, 0.3428120063191152, 0.92, 1.0, 1.0, 0.32520848262913815, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1763461663634126, 0.1763461663634124, 0.26463288265491103], 
reward next is 0.7354, 
noisyNet noise sample is [array([0.836377], dtype=float32), 0.53206205]. 
=============================================
[2019-03-26 17:38:52,954] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-26 17:38:52,957] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 17:38:52,958] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:38:52,958] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 17:38:52,959] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 17:38:52,960] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:38:52,960] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:38:52,960] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 17:38:52,960] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 17:38:52,961] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:38:52,962] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:38:52,977] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run72
[2019-03-26 17:38:53,002] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run72
[2019-03-26 17:38:53,003] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run72
[2019-03-26 17:38:53,046] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run72
[2019-03-26 17:38:53,047] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run72
[2019-03-26 17:38:56,769] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.1070888], dtype=float32), 0.089405835]
[2019-03-26 17:38:56,771] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [25.78333333333333, 52.5, 1.0, 2.0, 0.2749239036003482, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 447230.4961486622, 447230.4961486622, 163375.3787385239]
[2019-03-26 17:38:56,772] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 17:38:56,774] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [4.8471136e-17 1.0000000e+00 1.9734819e-20 3.5746574e-21 4.0463980e-30], sampled 0.18458638371005764
[2019-03-26 17:39:12,545] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.1070888], dtype=float32), 0.089405835]
[2019-03-26 17:39:12,547] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [24.40863832, 88.5110726, 1.0, 2.0, 0.4199684743861631, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 612580.2586331117, 612580.2586331123, 175316.4070249602]
[2019-03-26 17:39:12,549] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 17:39:12,552] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [5.911323e-17 1.000000e+00 4.288110e-20 3.930206e-20 8.756330e-30], sampled 0.14647729078943394
[2019-03-26 17:39:56,988] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.1070888], dtype=float32), 0.089405835]
[2019-03-26 17:39:56,988] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [32.79845017666667, 75.36328876666667, 1.0, 2.0, 0.6744080282935979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 942488.5644969211, 942488.5644969217, 215427.9357357194]
[2019-03-26 17:39:56,993] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 17:39:56,996] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [5.7160033e-17 1.0000000e+00 6.4330185e-20 4.9856766e-19 1.3077389e-29], sampled 0.7521910383160657
[2019-03-26 17:40:17,907] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.1070888], dtype=float32), 0.089405835]
[2019-03-26 17:40:17,909] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [26.43333333333333, 95.16666666666667, 1.0, 2.0, 0.5677952509392752, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9737782304156393, 6.911199999999999, 6.9112, 168.9129299568905, 1587475.196282614, 1587475.196282614, 344789.9345001557]
[2019-03-26 17:40:17,913] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:40:17,915] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.9337918e-11 9.9999976e-01 5.5230716e-12 2.3162282e-07 1.6079529e-19], sampled 0.18015721421986897
[2019-03-26 17:40:36,383] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.1070888], dtype=float32), 0.089405835]
[2019-03-26 17:40:36,385] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.55, 80.83333333333333, 1.0, 2.0, 0.5898913491701059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 824330.2500601214, 824330.2500601214, 198877.3478471597]
[2019-03-26 17:40:36,386] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 17:40:36,389] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [5.4067890e-17 1.0000000e+00 1.3755285e-19 2.4688448e-17 2.2356491e-29], sampled 0.5875104440930152
[2019-03-26 17:40:39,583] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.1070888], dtype=float32), 0.089405835]
[2019-03-26 17:40:39,585] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [33.1, 67.0, 1.0, 2.0, 0.6033144521488355, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.931349437045384, 6.9112, 168.9127808970668, 1686860.777418248, 1672566.088149894, 365201.0353717346]
[2019-03-26 17:40:39,586] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 17:40:39,588] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.3179033e-13 1.0000000e+00 3.3194482e-15 3.0826548e-12 2.5433421e-23], sampled 0.8756480867355579
[2019-03-26 17:40:39,589] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1686860.777418248 W.
[2019-03-26 17:40:47,724] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8662.4452 2778941300.7239 925.0000
[2019-03-26 17:40:47,822] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8515.5992 2839672280.1717 1064.0000
[2019-03-26 17:40:47,831] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8048.9144 3000727374.7469 1595.0000
[2019-03-26 17:40:47,891] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8276.6970 2924536508.0825 1269.0000
[2019-03-26 17:40:48,018] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7951.8331 3157448389.8690 1567.0000
[2019-03-26 17:40:49,036] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1775000, evaluation results [1775000.0, 7951.833069155373, 3157448389.8690314, 1567.0, 8276.69699040959, 2924536508.082547, 1269.0, 8662.445158924134, 2778941300.7239428, 925.0, 8048.914417276287, 3000727374.7468505, 1595.0, 8515.599196463605, 2839672280.171651, 1064.0]
[2019-03-26 17:41:11,102] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.0931390e-17 1.0000000e+00 1.2156188e-19 7.5680191e-19 6.2201001e-29], sum to 1.0000
[2019-03-26 17:41:11,110] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3446
[2019-03-26 17:41:11,116] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.0, 63.0, 1.0, 2.0, 0.5819015969336226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 813160.8786120126, 813160.8786120126, 197423.2344444387], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3247800.0000, 
sim time next is 3248400.0000, 
raw observation next is [33.0, 63.00000000000001, 1.0, 2.0, 0.5794404456166239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 809720.305816154, 809720.305816154, 196978.9719834855], 
processed observation next is [0.0, 0.6086956521739131, 0.7630331753554502, 0.6300000000000001, 1.0, 1.0, 0.49330174170677576, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22492230717115388, 0.22492230717115388, 0.2939984656469933], 
reward next is 0.7060, 
noisyNet noise sample is [array([0.2861941], dtype=float32), -1.4805171]. 
=============================================
[2019-03-26 17:41:15,106] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.5889946e-16 1.0000000e+00 1.5103832e-18 4.6144709e-16 1.0019642e-27], sum to 1.0000
[2019-03-26 17:41:15,114] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2494
[2019-03-26 17:41:15,119] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333334, 82.33333333333334, 1.0, 2.0, 0.6271433952662702, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 876408.7521644707, 876408.7521644714, 205901.485104607], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3645600.0000, 
sim time next is 3646200.0000, 
raw observation next is [26.16666666666667, 83.16666666666666, 1.0, 2.0, 0.6155744053851062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 860234.9869399042, 860234.9869399042, 203673.6704587517], 
processed observation next is [1.0, 0.17391304347826086, 0.4391785150078992, 0.8316666666666666, 1.0, 1.0, 0.5368366329941039, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23895416303886227, 0.23895416303886227, 0.30399055292351], 
reward next is 0.6960, 
noisyNet noise sample is [array([-0.26709956], dtype=float32), -0.93867373]. 
=============================================
[2019-03-26 17:41:24,780] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.1757152e-15 1.0000000e+00 3.7286089e-17 9.5734737e-13 2.5007097e-26], sum to 1.0000
[2019-03-26 17:41:24,789] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8624
[2019-03-26 17:41:24,792] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.16666666666667, 78.16666666666667, 1.0, 2.0, 0.516028016286732, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 721076.5801110404, 721076.5801110397, 186145.6822240083], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3441000.0000, 
sim time next is 3441600.0000, 
raw observation next is [28.0, 79.0, 1.0, 2.0, 0.5166829660210659, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 721992.0912784077, 721992.0912784083, 186251.3456363576], 
processed observation next is [1.0, 0.8695652173913043, 0.5260663507109005, 0.79, 1.0, 1.0, 0.41769032050730825, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2005533586884466, 0.20055335868844676, 0.2779870830393397], 
reward next is 0.7220, 
noisyNet noise sample is [array([2.044781], dtype=float32), -0.38541415]. 
=============================================
[2019-03-26 17:41:25,230] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.0791207e-15 1.0000000e+00 1.5832915e-17 1.0891934e-12 1.7072048e-25], sum to 1.0000
[2019-03-26 17:41:25,240] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0040
[2019-03-26 17:41:25,248] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 74.0, 1.0, 2.0, 0.525114077381621, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 733777.4579177726, 733777.457917772, 187624.4689086815], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3614400.0000, 
sim time next is 3615000.0000, 
raw observation next is [29.0, 74.0, 1.0, 2.0, 0.5239995308192782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 732219.4897511872, 732219.4897511872, 187441.802578741], 
processed observation next is [1.0, 0.8695652173913043, 0.5734597156398105, 0.74, 1.0, 1.0, 0.42650545881840746, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2033943027086631, 0.2033943027086631, 0.27976388444588207], 
reward next is 0.7202, 
noisyNet noise sample is [array([-0.11260923], dtype=float32), 0.06724185]. 
=============================================
[2019-03-26 17:41:25,261] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[72.1686 ]
 [73.12922]
 [74.05905]
 [75.11761]
 [76.00943]], R is [[71.27941132]
 [71.28658295]
 [71.29305267]
 [71.29884338]
 [71.30390167]].
[2019-03-26 17:41:44,267] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-26 17:41:44,269] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 17:41:44,270] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 17:41:44,271] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:41:44,273] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 17:41:44,274] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:41:44,275] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:41:44,276] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 17:41:44,278] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 17:41:44,279] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:41:44,280] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:41:44,303] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run73
[2019-03-26 17:41:44,328] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run73
[2019-03-26 17:41:44,328] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run73
[2019-03-26 17:41:44,366] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run73
[2019-03-26 17:41:44,390] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run73
[2019-03-26 17:41:58,134] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10407934], dtype=float32), 0.08662342]
[2019-03-26 17:41:58,135] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.26666666666667, 67.83333333333333, 1.0, 2.0, 0.3399833128043724, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 529826.0585912851, 529826.0585912851, 169161.9976557063]
[2019-03-26 17:41:58,137] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:41:58,142] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.1295859e-16 1.0000000e+00 2.0798700e-19 1.2363362e-19 7.5155913e-29], sampled 0.6755917431571409
[2019-03-26 17:42:07,239] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10407934], dtype=float32), 0.08662342]
[2019-03-26 17:42:07,239] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [23.6, 75.5, 1.0, 2.0, 0.328702060633624, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 517935.096880372, 517935.0968803726, 168356.3720372412]
[2019-03-26 17:42:07,240] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:42:07,245] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.4001853e-16 1.0000000e+00 1.4493271e-19 2.6958163e-19 4.3239159e-29], sampled 0.680195431524227
[2019-03-26 17:42:26,387] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10407934], dtype=float32), 0.08662342]
[2019-03-26 17:42:26,387] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [19.7391906, 93.57142738833332, 1.0, 2.0, 0.2782995260018405, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 450748.0064400854, 450748.0064400854, 163639.5830302942]
[2019-03-26 17:42:26,388] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 17:42:26,392] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.5857102e-16 1.0000000e+00 3.1643174e-19 3.0418642e-19 1.3341582e-28], sampled 0.33946537932293674
[2019-03-26 17:43:04,568] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10407934], dtype=float32), 0.08662342]
[2019-03-26 17:43:04,571] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [35.55, 58.0, 1.0, 2.0, 0.5575932704266554, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9683551118187897, 6.9112, 6.9112, 168.9124875159034, 1558930.958113612, 1558930.958113612, 341184.1572935207]
[2019-03-26 17:43:04,572] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:43:04,577] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.7699336e-14 1.0000000e+00 9.3664702e-16 1.6380915e-12 5.3334945e-24], sampled 0.823533024227962
[2019-03-26 17:43:13,736] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10407934], dtype=float32), 0.08662342]
[2019-03-26 17:43:13,738] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.46666666666667, 58.66666666666667, 1.0, 2.0, 0.5176820273673558, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 723388.614960856, 723388.6149608567, 186412.3542216883]
[2019-03-26 17:43:13,739] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:43:13,742] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.5265989e-15 1.0000000e+00 8.4432228e-18 2.7546710e-15 9.4003154e-27], sampled 0.4472804826528578
[2019-03-26 17:43:17,921] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10407934], dtype=float32), 0.08662342]
[2019-03-26 17:43:17,923] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.9, 83.0, 1.0, 2.0, 0.6621592672346645, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.986653147386289, 6.9112, 168.9124463973196, 1822177.537695591, 1768648.63969933, 377376.1223427093]
[2019-03-26 17:43:17,924] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:43:17,929] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.0383381e-10 9.9999893e-01 7.2850871e-11 1.0777870e-06 9.0179421e-18], sampled 0.452529785538909
[2019-03-26 17:43:17,930] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1822177.537695591 W.
[2019-03-26 17:43:38,420] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8673.8051 2777826684.8760 892.0000
[2019-03-26 17:43:38,713] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 8033.3548 3149109150.7627 1326.0000
[2019-03-26 17:43:38,759] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8553.5442 2836173555.1777 963.0000
[2019-03-26 17:43:38,813] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8144.1815 2989833111.3955 1319.0000
[2019-03-26 17:43:38,825] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8316.9492 2921041096.2836 1150.0000
[2019-03-26 17:43:39,841] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1800000, evaluation results [1800000.0, 8033.3548073282345, 3149109150.762725, 1326.0, 8316.949224251228, 2921041096.2835608, 1150.0, 8673.805125365177, 2777826684.875993, 892.0, 8144.181477073863, 2989833111.3955374, 1319.0, 8553.544154346971, 2836173555.1777186, 963.0]
[2019-03-26 17:43:55,605] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.6102694e-12 9.5492776e-04 2.2745483e-11 9.9904507e-01 7.0617774e-19], sum to 1.0000
[2019-03-26 17:43:55,615] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6408
[2019-03-26 17:43:55,624] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 3 has been changed to 4 for the demand 4028045.820356483 W.
[2019-03-26 17:43:55,628] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [34.0, 69.0, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 8.471092104515531, 6.9112, 170.5573041426782, 4028045.820356483, 2910631.653538089, 543986.3403756422], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4109400.0000, 
sim time next is 4110000.0000, 
raw observation next is [34.0, 68.33333333333333, 1.0, 2.0, 0.9982947856865573, 1.0, 2.0, 0.8197374323575413, 1.0, 1.0, 1.03, 7.005121264219274, 6.9112, 170.5573041426782, 3440470.788795503, 3373191.166762475, 632124.0626432088], 
processed observation next is [1.0, 0.5652173913043478, 0.8104265402843602, 0.6833333333333332, 1.0, 1.0, 0.997945524923563, 1.0, 1.0, 0.7828161835633027, 1.0, 0.5, 1.0365853658536586, 0.009392126421927393, 0.0, 0.8375144448122397, 0.955686330220973, 0.9369975463229097, 0.9434687502137444], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.37656236], dtype=float32), -0.9661697]. 
=============================================
[2019-03-26 17:43:55,646] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[55.987415]
 [57.46923 ]
 [58.961082]
 [59.533573]
 [59.533897]], R is [[51.2375679 ]
 [50.72519302]
 [50.21794128]
 [50.03554916]
 [49.91973877]].
[2019-03-26 17:43:58,380] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4381188e-10 9.9997199e-01 5.1710053e-11 2.8062441e-05 3.6052535e-17], sum to 1.0000
[2019-03-26 17:43:58,390] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1530
[2019-03-26 17:43:58,402] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2193328.626334824 W.
[2019-03-26 17:43:58,406] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.66666666666666, 79.83333333333334, 1.0, 2.0, 0.5228507112548245, 1.0, 1.0, 0.5228507112548245, 1.0, 2.0, 0.9080187760772082, 6.9112, 6.9112, 170.5573041426782, 2193328.626334824, 2193328.626334824, 431307.9563790648], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4092600.0000, 
sim time next is 4093200.0000, 
raw observation next is [30.0, 79.0, 1.0, 2.0, 0.8989579996413095, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 7.005987666205088, 6.9112, 168.912393144653, 2153577.992743984, 2086332.584278933, 433757.7118806065], 
processed observation next is [1.0, 0.391304347826087, 0.6208530805687204, 0.79, 1.0, 1.0, 0.8782626501702524, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.009478766620508772, 0.0, 0.8294371787684228, 0.5982161090955511, 0.5795368289663703, 0.6473995699710544], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5297574], dtype=float32), 0.5442939]. 
=============================================
[2019-03-26 17:44:00,667] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.4626347e-14 3.3029730e-05 2.3085624e-12 9.9996698e-01 4.6332525e-20], sum to 1.0000
[2019-03-26 17:44:00,680] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6186
[2019-03-26 17:44:00,686] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [36.0, 53.0, 1.0, 2.0, 0.7795454745903402, 1.0, 2.0, 0.7795454745903402, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2180085.454833686, 2180085.454833686, 410047.8563550899], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4192800.0000, 
sim time next is 4193400.0000, 
raw observation next is [36.0, 53.0, 1.0, 2.0, 0.7660937125387983, 1.0, 2.0, 0.7660937125387983, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2142428.487537094, 2142428.487537093, 403714.0934990218], 
processed observation next is [1.0, 0.5217391304347826, 0.9052132701421801, 0.53, 1.0, 1.0, 0.7181851958298775, 1.0, 1.0, 0.7181851958298775, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5951190243158594, 0.5951190243158592, 0.6025583485060027], 
reward next is 0.3974, 
noisyNet noise sample is [array([0.42441112], dtype=float32), 0.98250383]. 
=============================================
[2019-03-26 17:44:03,982] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.6289335e-15 1.0000000e+00 6.2478666e-17 9.9295348e-14 2.4433320e-25], sum to 1.0000
[2019-03-26 17:44:03,988] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9993
[2019-03-26 17:44:03,993] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.7957369330861369, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1112135.096893048, 1112135.096893047, 242863.5803199192], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4847400.0000, 
sim time next is 4848000.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.7863176796647563, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1098963.780301931, 1098963.780301931, 240576.5413430417], 
processed observation next is [1.0, 0.08695652173913043, 0.4786729857819906, 0.79, 1.0, 1.0, 0.7425514212828389, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.30526771675053643, 0.30526771675053643, 0.359069464691107], 
reward next is 0.6409, 
noisyNet noise sample is [array([-0.46736073], dtype=float32), -1.099843]. 
=============================================
[2019-03-26 17:44:04,011] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[65.94875 ]
 [66.041245]
 [66.33572 ]
 [67.33285 ]
 [67.24975 ]], R is [[65.83036804]
 [65.80958557]
 [65.74604797]
 [65.65115356]
 [65.72412109]].
[2019-03-26 17:44:04,740] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.3929158e-09 9.9674380e-01 4.9960787e-09 3.2562129e-03 5.6388660e-15], sum to 1.0000
[2019-03-26 17:44:04,748] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4863
[2019-03-26 17:44:04,761] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1961995.174771455 W.
[2019-03-26 17:44:04,765] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.66666666666666, 82.33333333333334, 1.0, 2.0, 0.4677553663889408, 1.0, 2.0, 0.4677553663889408, 1.0, 2.0, 0.8123363823541379, 6.911200000000001, 6.9112, 170.5573041426782, 1961995.174771455, 1961995.174771454, 393566.3285042875], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4261200.0000, 
sim time next is 4261800.0000, 
raw observation next is [30.83333333333334, 83.16666666666666, 1.0, 2.0, 0.7261405580301321, 1.0, 2.0, 0.7261405580301321, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2030591.120332105, 2030591.120332105, 385534.313457825], 
processed observation next is [1.0, 0.30434782608695654, 0.6603475513428123, 0.8316666666666666, 1.0, 1.0, 0.6700488650965447, 1.0, 1.0, 0.6700488650965447, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5640530889811403, 0.5640530889811403, 0.575424348444515], 
reward next is 0.4246, 
noisyNet noise sample is [array([-0.13236517], dtype=float32), -0.08205782]. 
=============================================
[2019-03-26 17:44:10,350] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.3437600e-12 1.1677602e-05 3.3785325e-11 9.9998832e-01 5.6819764e-18], sum to 1.0000
[2019-03-26 17:44:10,362] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2896
[2019-03-26 17:44:10,369] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [34.0, 71.0, 1.0, 2.0, 0.8807667309107523, 1.0, 2.0, 0.7609734049696387, 1.0, 1.0, 1.03, 7.005111989775698, 6.9112, 170.5573041426782, 3193520.433873883, 3126247.455502049, 584508.1345444643], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4269600.0000, 
sim time next is 4270200.0000, 
raw observation next is [34.33333333333334, 69.16666666666667, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 7.372152659411595, 6.9112, 170.5573041426782, 3239913.49947314, 2909714.359181253, 551187.8125831645], 
processed observation next is [1.0, 0.43478260869565216, 0.8262243285939973, 0.6916666666666668, 1.0, 1.0, 1.0481927710843375, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.2195121951219512, 0.046095265941159536, 0.0, 0.8375144448122397, 0.8999759720758722, 0.8082539886614591, 0.8226683769897978], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.4584912], dtype=float32), -1.7837912]. 
=============================================
[2019-03-26 17:44:12,141] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.3163077e-11 5.8245747e-03 1.1231978e-10 9.9417549e-01 1.1358415e-18], sum to 1.0000
[2019-03-26 17:44:12,173] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9842
[2019-03-26 17:44:12,182] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 70.0, 1.0, 2.0, 0.8493053740553682, 1.0, 2.0, 0.8493053740553682, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2375367.316562211, 2375367.316562212, 444590.244777713], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4726800.0000, 
sim time next is 4727400.0000, 
raw observation next is [30.83333333333334, 70.0, 1.0, 2.0, 0.3842806879640291, 1.0, 2.0, 0.3842806879640291, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1074129.641498486, 1074129.641498486, 268246.0980864416], 
processed observation next is [1.0, 0.7391304347826086, 0.6603475513428123, 0.7, 1.0, 1.0, 0.2581695035711194, 1.0, 1.0, 0.2581695035711194, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.29836934486069056, 0.29836934486069056, 0.4003673105767785], 
reward next is 0.5996, 
noisyNet noise sample is [array([0.60633016], dtype=float32), 1.3226794]. 
=============================================
[2019-03-26 17:44:17,482] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.021655e-17 1.000000e+00 4.284973e-19 9.340271e-18 2.205544e-29], sum to 1.0000
[2019-03-26 17:44:17,498] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5084
[2019-03-26 17:44:17,506] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.66666666666667, 80.66666666666667, 1.0, 2.0, 0.5586200852771847, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 780614.8755969654, 780614.8755969654, 193289.581452214], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4476000.0000, 
sim time next is 4476600.0000, 
raw observation next is [28.5, 81.5, 1.0, 2.0, 0.5577636451529746, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 779417.6483492494, 779417.64834925, 193140.5940172905], 
processed observation next is [0.0, 0.8260869565217391, 0.5497630331753555, 0.815, 1.0, 1.0, 0.4671851146421381, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21650490231923594, 0.2165049023192361, 0.2882695433093888], 
reward next is 0.7117, 
noisyNet noise sample is [array([-1.7450833], dtype=float32), 1.4097742]. 
=============================================
[2019-03-26 17:44:23,841] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.46532751e-15 1.00000000e+00 1.02010345e-17 7.68541713e-17
 2.34822167e-27], sum to 1.0000
[2019-03-26 17:44:23,851] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4210
[2019-03-26 17:44:23,855] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.5157352250759678, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 720667.3067852287, 720667.3067852287, 186097.8166697838], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5188200.0000, 
sim time next is 5188800.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.5156102579911713, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 720492.6236715536, 720492.623671553, 186077.6642661265], 
processed observation next is [1.0, 0.043478260869565216, 0.4786729857819906, 0.84, 1.0, 1.0, 0.4163979011941823, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20013683990876488, 0.2001368399087647, 0.27772785711362163], 
reward next is 0.7223, 
noisyNet noise sample is [array([-0.10029165], dtype=float32), -0.0065676593]. 
=============================================
[2019-03-26 17:44:31,376] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.3854246e-15 1.0000000e+00 1.2374692e-18 1.4445328e-16 5.4880941e-27], sum to 1.0000
[2019-03-26 17:44:31,390] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8986
[2019-03-26 17:44:31,396] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 84.0, 1.0, 2.0, 0.4792585827153151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 669680.2722406677, 669680.2722406677, 180409.6123663083], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5014800.0000, 
sim time next is 5015400.0000, 
raw observation next is [26.0, 84.0, 1.0, 2.0, 0.4780269629038127, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 668042.163974603, 668042.1639746025, 180235.2955815805], 
processed observation next is [0.0, 0.043478260869565216, 0.4312796208530806, 0.84, 1.0, 1.0, 0.371116822775678, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18556726777072308, 0.1855672677707229, 0.2690079038531052], 
reward next is 0.7310, 
noisyNet noise sample is [array([0.00811937], dtype=float32), 0.87380207]. 
=============================================
[2019-03-26 17:44:32,003] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.3344820e-16 1.0000000e+00 9.0644687e-20 2.7667449e-19 4.5997653e-29], sum to 1.0000
[2019-03-26 17:44:32,012] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0658
[2019-03-26 17:44:32,017] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 59.0, 1.0, 2.0, 0.5230332995882274, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 730868.8459204002, 730868.8459204008, 187284.1077407033], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5065200.0000, 
sim time next is 5065800.0000, 
raw observation next is [31.83333333333334, 59.66666666666667, 1.0, 2.0, 0.5228005374421864, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 730543.4802124075, 730543.4802124068, 187246.0124310103], 
processed observation next is [0.0, 0.6521739130434783, 0.7077409162717223, 0.5966666666666667, 1.0, 1.0, 0.42506088848456186, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20292874450344653, 0.20292874450344633, 0.27947166034479154], 
reward next is 0.7205, 
noisyNet noise sample is [array([1.4572737], dtype=float32), 0.09508772]. 
=============================================
[2019-03-26 17:44:32,822] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.7238147e-17 1.0000000e+00 1.1787306e-19 8.1172513e-20 3.4332840e-29], sum to 1.0000
[2019-03-26 17:44:32,827] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5150
[2019-03-26 17:44:32,832] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.83333333333334, 84.0, 1.0, 2.0, 0.5314590615979516, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 742646.8333928303, 742646.8333928296, 188672.5042758357], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5039400.0000, 
sim time next is 5040000.0000, 
raw observation next is [28.0, 84.0, 1.0, 2.0, 0.5364795520307343, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 749664.8095138671, 749664.8095138664, 189509.7604375454], 
processed observation next is [0.0, 0.34782608695652173, 0.5260663507109005, 0.84, 1.0, 1.0, 0.4415416289526919, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2082402248649631, 0.2082402248649629, 0.2828503887127543], 
reward next is 0.7171, 
noisyNet noise sample is [array([0.72139007], dtype=float32), 0.8588024]. 
=============================================
[2019-03-26 17:44:32,854] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[71.54497]
 [71.54153]
 [71.53899]
 [71.54074]
 [71.54271]], R is [[71.57806396]
 [71.58068085]
 [71.58436584]
 [71.58898163]
 [71.59460449]].
[2019-03-26 17:44:35,040] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-26 17:44:35,042] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 17:44:35,042] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 17:44:35,043] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:44:35,043] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:44:35,044] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 17:44:35,044] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 17:44:35,046] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 17:44:35,047] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:44:35,047] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:44:35,048] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:44:35,085] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run74
[2019-03-26 17:44:35,110] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run74
[2019-03-26 17:44:35,111] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run74
[2019-03-26 17:44:35,112] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run74
[2019-03-26 17:44:35,140] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run74
[2019-03-26 17:44:38,421] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10474118], dtype=float32), 0.08759864]
[2019-03-26 17:44:38,424] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [20.03333333333333, 96.0, 1.0, 2.0, 0.293820680113893, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 471937.8987883507, 471937.8987883501, 165093.0315112215]
[2019-03-26 17:44:38,424] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:44:38,429] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.1664672e-16 1.0000000e+00 1.0027904e-19 8.9630008e-20 5.0861962e-29], sampled 0.5793489528436084
[2019-03-26 17:44:38,440] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10474118], dtype=float32), 0.08759864]
[2019-03-26 17:44:38,441] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [20.0, 96.0, 1.0, 2.0, 0.2933728789546386, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 471529.6977802881, 471529.6977802888, 165065.6030079018]
[2019-03-26 17:44:38,442] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:44:38,445] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.1147208e-16 1.0000000e+00 7.6891595e-20 5.5945637e-20 3.8323264e-29], sampled 0.79943464103206
[2019-03-26 17:45:08,019] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10474118], dtype=float32), 0.08759864]
[2019-03-26 17:45:08,021] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.18726503, 91.16617653, 1.0, 2.0, 0.4905585478775396, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 685475.0969073345, 685475.0969073351, 182129.3426688122]
[2019-03-26 17:45:08,022] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 17:45:08,024] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.9157442e-16 1.0000000e+00 9.1050893e-19 1.5626385e-17 3.1231458e-28], sampled 0.36402139744953577
[2019-03-26 17:45:08,195] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10474118], dtype=float32), 0.08759864]
[2019-03-26 17:45:08,196] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [23.2, 92.5, 1.0, 2.0, 0.3910568938364687, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 583415.1138354276, 583415.1138354283, 173013.5327274509]
[2019-03-26 17:45:08,197] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 17:45:08,198] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.3171096e-16 1.0000000e+00 1.4016207e-19 5.8027760e-20 4.4655984e-29], sampled 0.07753413115293839
[2019-03-26 17:46:03,410] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10474118], dtype=float32), 0.08759864]
[2019-03-26 17:46:03,411] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [32.7, 62.0, 1.0, 2.0, 0.7413257800093648, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1036052.071859843, 1036052.071859843, 230021.0976230785]
[2019-03-26 17:46:03,414] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:46:03,418] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.2225971e-15 1.0000000e+00 8.3664033e-18 9.5989153e-15 2.4272950e-27], sampled 0.5389184916148224
[2019-03-26 17:46:04,263] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10474118], dtype=float32), 0.08759864]
[2019-03-26 17:46:04,264] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.070769285, 82.12451557, 1.0, 2.0, 0.4886772933045702, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 689078.714557734, 689078.714557734, 182641.9740474836]
[2019-03-26 17:46:04,265] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 17:46:04,268] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.2374705e-16 1.0000000e+00 3.1660198e-19 8.5133404e-18 8.3448095e-29], sampled 0.07633628511832002
[2019-03-26 17:46:22,260] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10474118], dtype=float32), 0.08759864]
[2019-03-26 17:46:22,262] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [27.63333333333333, 87.33333333333334, 1.0, 2.0, 0.5584756416161369, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 780412.9560898108, 780412.9560898115, 193264.4161601071]
[2019-03-26 17:46:22,263] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 17:46:22,266] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [9.6265910e-17 1.0000000e+00 1.8108591e-19 3.7327766e-18 5.6284887e-29], sampled 0.8615509039726723
[2019-03-26 17:46:28,981] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7993.4240 3153917512.5640 1460.0000
[2019-03-26 17:46:29,187] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8293.7651 2922925941.9874 1220.0000
[2019-03-26 17:46:29,547] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8076.3049 2997009990.7265 1504.0000
[2019-03-26 17:46:29,781] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8534.0447 2837808854.4997 1013.0000
[2019-03-26 17:46:29,846] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8665.3829 2778358866.1600 911.0000
[2019-03-26 17:46:30,863] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1825000, evaluation results [1825000.0, 7993.4240212569875, 3153917512.5640073, 1460.0, 8293.765111788554, 2922925941.9874496, 1220.0, 8665.382919314568, 2778358866.1600356, 911.0, 8076.304907465991, 2997009990.726531, 1504.0, 8534.044718215137, 2837808854.499699, 1013.0]
[2019-03-26 17:46:30,975] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.5485071e-17 1.0000000e+00 4.6227113e-18 1.3868063e-15 2.5343990e-26], sum to 1.0000
[2019-03-26 17:46:30,984] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5885
[2019-03-26 17:46:30,990] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.5, 84.0, 1.0, 2.0, 0.6866836397159045, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 959651.5431896322, 959651.5431896322, 217996.7302538599], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4865400.0000, 
sim time next is 4866000.0000, 
raw observation next is [27.66666666666666, 82.33333333333334, 1.0, 2.0, 0.6701306356375218, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 936508.2514518601, 936508.2514518608, 214529.4205903352], 
processed observation next is [1.0, 0.30434782608695654, 0.5102685624012636, 0.8233333333333335, 1.0, 1.0, 0.6025670308885805, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.26014118095885, 0.2601411809588502, 0.3201931650602018], 
reward next is 0.6798, 
noisyNet noise sample is [array([0.35337263], dtype=float32), -1.2073866]. 
=============================================
[2019-03-26 17:46:31,012] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[67.16341 ]
 [67.07979 ]
 [66.999695]
 [66.92036 ]
 [66.79246 ]], R is [[67.28311157]
 [67.28491211]
 [67.28530884]
 [67.27854156]
 [67.28044891]].
[2019-03-26 17:46:33,174] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.6129428e-10 1.4594586e-01 4.3757781e-10 8.5405415e-01 1.1452368e-17], sum to 1.0000
[2019-03-26 17:46:33,182] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4613
[2019-03-26 17:46:33,188] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 70.0, 1.0, 2.0, 0.8493053740553682, 1.0, 2.0, 0.8493053740553682, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2375367.316562211, 2375367.316562212, 444590.2447777138], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4726800.0000, 
sim time next is 4727400.0000, 
raw observation next is [30.83333333333334, 70.0, 1.0, 2.0, 0.3842806879640291, 1.0, 2.0, 0.3842806879640291, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1074129.641498486, 1074129.641498486, 268246.0980864419], 
processed observation next is [1.0, 0.7391304347826086, 0.6603475513428123, 0.7, 1.0, 1.0, 0.2581695035711194, 1.0, 1.0, 0.2581695035711194, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.29836934486069056, 0.29836934486069056, 0.400367310576779], 
reward next is 0.5996, 
noisyNet noise sample is [array([0.092567], dtype=float32), 2.6978483]. 
=============================================
[2019-03-26 17:46:39,342] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1575139e-15 1.0000000e+00 6.8085836e-19 1.7737852e-16 1.6692979e-27], sum to 1.0000
[2019-03-26 17:46:39,347] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7710
[2019-03-26 17:46:39,353] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.91666666666667, 74.5, 1.0, 2.0, 0.4919079443026316, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 687361.2670865305, 687361.2670865298, 182337.7432771303], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4831800.0000, 
sim time next is 4832400.0000, 
raw observation next is [27.83333333333334, 75.0, 1.0, 2.0, 0.4930706138307717, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 688986.4353290875, 688986.435329087, 182517.2528753647], 
processed observation next is [1.0, 0.9565217391304348, 0.5181674565560824, 0.75, 1.0, 1.0, 0.38924170341056835, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19138512092474655, 0.19138512092474638, 0.2724138102617384], 
reward next is 0.7276, 
noisyNet noise sample is [array([1.17865], dtype=float32), -0.35530424]. 
=============================================
[2019-03-26 17:46:48,574] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.9578427e-17 1.0000000e+00 7.4609804e-20 3.1793692e-19 8.8823937e-29], sum to 1.0000
[2019-03-26 17:46:48,582] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3895
[2019-03-26 17:46:48,591] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.16666666666666, 79.0, 1.0, 2.0, 0.5006537658082684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 699586.1529506514, 699586.1529506508, 183697.824478063], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5179800.0000, 
sim time next is 5180400.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.4951180188941846, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 691848.2844061784, 691848.2844061791, 182833.909537162], 
processed observation next is [0.0, 1.0, 0.4786729857819906, 0.79, 1.0, 1.0, 0.3917084564990176, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19218007900171621, 0.1921800790017164, 0.2728864321450179], 
reward next is 0.7271, 
noisyNet noise sample is [array([-0.5465022], dtype=float32), -0.75557375]. 
=============================================
[2019-03-26 17:46:50,414] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.4407787e-17 1.0000000e+00 7.2311541e-20 1.2161243e-19 2.8123166e-29], sum to 1.0000
[2019-03-26 17:46:50,416] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7961
[2019-03-26 17:46:50,422] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.45, 87.0, 1.0, 2.0, 0.5122068554158608, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 715735.2463210775, 715735.2463210775, 185530.3552951152], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5707800.0000, 
sim time next is 5708400.0000, 
raw observation next is [26.43333333333333, 87.0, 1.0, 2.0, 0.5113840476243214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 714585.1043146537, 714585.1043146544, 185398.5746482973], 
processed observation next is [0.0, 0.043478260869565216, 0.4518167456556081, 0.87, 1.0, 1.0, 0.411306081475086, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19849586230962601, 0.1984958623096262, 0.27671429051984675], 
reward next is 0.7233, 
noisyNet noise sample is [array([1.7574328], dtype=float32), 0.11738245]. 
=============================================
[2019-03-26 17:46:53,080] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.6953713e-12 9.3595457e-04 1.2568053e-11 9.9906403e-01 3.3375034e-19], sum to 1.0000
[2019-03-26 17:46:53,092] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3951
[2019-03-26 17:46:53,096] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.0, 67.0, 1.0, 2.0, 0.9067220020914892, 1.0, 2.0, 0.9067220020914892, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2536115.135091062, 2536115.135091063, 475174.8765017462], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5239200.0000, 
sim time next is 5239800.0000, 
raw observation next is [32.0, 67.0, 1.0, 2.0, 0.9025497505779693, 1.0, 2.0, 0.9025497505779693, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2524433.495836941, 2524433.495836941, 472887.3587438244], 
processed observation next is [1.0, 0.6521739130434783, 0.7156398104265403, 0.67, 1.0, 1.0, 0.8825900609373124, 1.0, 1.0, 0.8825900609373124, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7012315266213726, 0.7012315266213726, 0.7058020279758573], 
reward next is 0.2942, 
noisyNet noise sample is [array([-1.343668], dtype=float32), 0.9315821]. 
=============================================
[2019-03-26 17:46:53,630] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.6541033e-17 1.0000000e+00 5.9719209e-20 1.6073339e-19 3.0552570e-29], sum to 1.0000
[2019-03-26 17:46:53,639] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8995
[2019-03-26 17:46:53,644] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.16666666666667, 62.33333333333333, 1.0, 2.0, 0.5346691542317358, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 747134.109469819, 747134.109469819, 189205.5921577475], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5062200.0000, 
sim time next is 5062800.0000, 
raw observation next is [31.33333333333334, 61.66666666666667, 1.0, 2.0, 0.5224315252581876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 730027.658095248, 730027.6580952486, 187185.5399929009], 
processed observation next is [0.0, 0.6086956521739131, 0.6840442338072673, 0.6166666666666667, 1.0, 1.0, 0.42461629549179225, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20278546058201335, 0.2027854605820135, 0.279381402974479], 
reward next is 0.7206, 
noisyNet noise sample is [array([1.0968299], dtype=float32), 1.3882935]. 
=============================================
[2019-03-26 17:47:00,401] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.4285455e-15 1.0000000e+00 3.2339911e-16 1.2156643e-13 2.6962810e-25], sum to 1.0000
[2019-03-26 17:47:00,410] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7440
[2019-03-26 17:47:00,415] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.8712444868087609, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1217726.216471143, 1217726.216471143, 262147.7242955074], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5197200.0000, 
sim time next is 5197800.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.8397750199891579, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1173717.47252946, 1173717.47252946, 253905.8636983483], 
processed observation next is [1.0, 0.13043478260869565, 0.4312796208530806, 0.89, 1.0, 1.0, 0.806957855408624, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3260326312581833, 0.3260326312581833, 0.37896397566917656], 
reward next is 0.6210, 
noisyNet noise sample is [array([1.6890229], dtype=float32), -0.53231645]. 
=============================================
[2019-03-26 17:47:00,563] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.8425549e-16 1.0000000e+00 2.2593845e-18 4.3069063e-16 7.4086265e-27], sum to 1.0000
[2019-03-26 17:47:00,574] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3602
[2019-03-26 17:47:00,583] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.15, 93.0, 1.0, 2.0, 0.5257780160128267, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 734705.5451753035, 734705.545175304, 187733.5330950924], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5880600.0000, 
sim time next is 5881200.0000, 
raw observation next is [26.1, 93.33333333333334, 1.0, 2.0, 0.5254404552102758, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 734233.6853797704, 734233.6853797697, 187678.0905028576], 
processed observation next is [1.0, 0.043478260869565216, 0.4360189573459717, 0.9333333333333335, 1.0, 1.0, 0.4282415123015371, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20395380149438067, 0.20395380149438047, 0.28011655298933974], 
reward next is 0.7199, 
noisyNet noise sample is [array([0.8206385], dtype=float32), 0.3785293]. 
=============================================
[2019-03-26 17:47:02,637] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.5779150e-16 1.0000000e+00 1.9469611e-18 5.8580566e-16 1.0455243e-28], sum to 1.0000
[2019-03-26 17:47:02,645] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9291
[2019-03-26 17:47:02,651] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.76666666666667, 90.0, 1.0, 2.0, 0.5384643945517558, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 752439.3674601886, 752439.367460188, 189841.7069438901], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5611200.0000, 
sim time next is 5611800.0000, 
raw observation next is [26.68333333333333, 90.0, 1.0, 2.0, 0.5361237086903345, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 749167.3864504865, 749167.3864504859, 189449.0325888569], 
processed observation next is [1.0, 0.9565217391304348, 0.4636650868878356, 0.9, 1.0, 1.0, 0.4411129020365476, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2081020517918018, 0.20810205179180163, 0.2827597501326222], 
reward next is 0.7172, 
noisyNet noise sample is [array([0.2596711], dtype=float32), -0.44781563]. 
=============================================
[2019-03-26 17:47:03,574] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.3211193e-16 1.0000000e+00 8.8535201e-18 4.1849060e-15 1.9905631e-26], sum to 1.0000
[2019-03-26 17:47:03,584] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4367
[2019-03-26 17:47:03,593] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.56666666666667, 80.33333333333334, 1.0, 2.0, 0.5446155168730131, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 761037.9018531352, 761037.9018531352, 190881.7070866035], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5260800.0000, 
sim time next is 5261400.0000, 
raw observation next is [28.55, 80.5, 1.0, 2.0, 0.5446991173061282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 761154.7657538848, 761154.7657538854, 190895.9316898881], 
processed observation next is [1.0, 0.9130434782608695, 0.552132701421801, 0.805, 1.0, 1.0, 0.4514447196459376, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2114318793760791, 0.21143187937607927, 0.2849193010296837], 
reward next is 0.7151, 
noisyNet noise sample is [array([1.18519], dtype=float32), 1.2584738]. 
=============================================
[2019-03-26 17:47:06,760] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.2928312e-13 1.0000000e+00 2.9229189e-14 1.5913484e-09 1.0503331e-21], sum to 1.0000
[2019-03-26 17:47:06,773] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6405
[2019-03-26 17:47:06,777] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 77.0, 1.0, 2.0, 0.5899445632698629, 1.0, 1.0, 0.5899445632698629, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1649437.302838394, 1649437.302838394, 330582.0083941699], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5383200.0000, 
sim time next is 5383800.0000, 
raw observation next is [31.2, 76.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.624350948009438, 6.9112, 168.9090163657366, 1960023.499864045, 1454101.474240065, 311356.2945852533], 
processed observation next is [1.0, 0.30434782608695654, 0.6777251184834123, 0.76, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.07131509480094378, 0.0, 0.8294205972380471, 0.5444509721844569, 0.4039170761777959, 0.46471088744067657], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.8823184], dtype=float32), -1.1496937]. 
=============================================
[2019-03-26 17:47:07,457] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.8403223e-09 8.4998077e-01 2.9119624e-08 1.5001921e-01 9.7069044e-15], sum to 1.0000
[2019-03-26 17:47:07,464] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9189
[2019-03-26 17:47:07,471] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.15, 77.0, 1.0, 2.0, 0.8993130558720883, 1.0, 1.0, 0.8993130558720883, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2515371.341757172, 2515371.341757172, 471119.7270721841], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5995800.0000, 
sim time next is 5996400.0000, 
raw observation next is [30.3, 76.33333333333334, 1.0, 2.0, 0.858703575677508, 1.0, 2.0, 0.858703575677508, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2401677.79832252, 2401677.79832252, 449466.3433962109], 
processed observation next is [1.0, 0.391304347826087, 0.6350710900473934, 0.7633333333333334, 1.0, 1.0, 0.8297633441897686, 1.0, 1.0, 0.8297633441897686, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6671327217562556, 0.6671327217562556, 0.6708452886510611], 
reward next is 0.3292, 
noisyNet noise sample is [array([1.456169], dtype=float32), 0.52448094]. 
=============================================
[2019-03-26 17:47:17,360] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.7703444e-16 1.0000000e+00 1.4064310e-18 7.6232783e-18 1.6586215e-27], sum to 1.0000
[2019-03-26 17:47:17,373] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2906
[2019-03-26 17:47:17,376] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 87.0, 1.0, 2.0, 0.5174428119056992, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 723054.2308655551, 723054.2308655551, 186373.5141258332], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5704200.0000, 
sim time next is 5704800.0000, 
raw observation next is [26.5, 87.0, 1.0, 2.0, 0.5194312625950179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 725833.7629470523, 725833.7629470523, 186695.802563423], 
processed observation next is [0.0, 0.0, 0.4549763033175356, 0.87, 1.0, 1.0, 0.42100152119881673, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2016204897075145, 0.2016204897075145, 0.27865045158719853], 
reward next is 0.7213, 
noisyNet noise sample is [array([0.11296447], dtype=float32), -0.2569779]. 
=============================================
[2019-03-26 17:47:19,674] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.30487783e-13 9.99996543e-01 1.05988284e-13 3.50455571e-06
 3.90814914e-23], sum to 1.0000
[2019-03-26 17:47:19,686] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2404
[2019-03-26 17:47:19,692] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.66666666666667, 62.0, 1.0, 2.0, 0.5511377745273186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 770155.3151498293, 770155.3151498287, 191997.6754617111], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5509200.0000, 
sim time next is 5509800.0000, 
raw observation next is [32.40000000000001, 63.5, 1.0, 2.0, 0.5530221974118666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 772789.5498299884, 772789.5498299884, 192321.982932189], 
processed observation next is [1.0, 0.782608695652174, 0.7345971563981049, 0.635, 1.0, 1.0, 0.46147252700224894, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21466376384166344, 0.21466376384166344, 0.2870477357196851], 
reward next is 0.7130, 
noisyNet noise sample is [array([-1.3908967], dtype=float32), 0.5501961]. 
=============================================
[2019-03-26 17:47:26,269] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-26 17:47:26,272] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 17:47:26,273] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:47:26,273] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 17:47:26,274] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:47:26,274] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 17:47:26,275] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 17:47:26,277] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 17:47:26,277] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:47:26,278] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:47:26,278] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:47:26,303] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run75
[2019-03-26 17:47:26,327] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run75
[2019-03-26 17:47:26,328] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run75
[2019-03-26 17:47:26,375] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run75
[2019-03-26 17:47:26,376] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run75
[2019-03-26 17:47:44,159] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10520081], dtype=float32), 0.08811143]
[2019-03-26 17:47:44,160] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [19.5, 77.33333333333334, 1.0, 2.0, 0.2235181863748544, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 372346.6628217089, 372346.6628217083, 157911.1346128634]
[2019-03-26 17:47:44,162] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:47:44,165] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [5.1714501e-17 1.0000000e+00 2.5696870e-20 1.4875945e-21 8.8582629e-30], sampled 0.7862629886057085
[2019-03-26 17:47:53,355] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10520081], dtype=float32), 0.08811143]
[2019-03-26 17:47:53,356] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.08887148, 92.138088585, 1.0, 2.0, 0.879646782363571, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1229476.786806233, 1229476.786806233, 264404.5433422429]
[2019-03-26 17:47:53,359] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 17:47:53,361] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.4263735e-16 1.0000000e+00 6.0714550e-19 7.4762586e-18 4.2346442e-28], sampled 0.7440259934805952
[2019-03-26 17:47:58,335] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10520081], dtype=float32), 0.08811143]
[2019-03-26 17:47:58,337] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [25.06666666666667, 82.66666666666667, 1.0, 2.0, 0.5976184203859426, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 872975.5013713333, 872975.5013713333, 205121.1212157501]
[2019-03-26 17:47:58,338] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 17:47:58,340] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.2393372e-16 1.0000000e+00 9.2705854e-19 1.7916012e-17 5.7927996e-28], sampled 0.931084660333521
[2019-03-26 17:48:26,893] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10520081], dtype=float32), 0.08811143]
[2019-03-26 17:48:26,896] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [35.20766330666666, 72.64765927333333, 1.0, 2.0, 0.7334375200326421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1025022.38343965, 1025022.383439649, 228243.1130378239]
[2019-03-26 17:48:26,897] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 17:48:26,899] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [6.7435078e-16 1.0000000e+00 3.0155467e-18 1.1997459e-15 9.8279059e-28], sampled 0.9481336898557333
[2019-03-26 17:48:32,684] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10520081], dtype=float32), 0.08811143]
[2019-03-26 17:48:32,686] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [32.66666666666667, 68.33333333333334, 1.0, 2.0, 0.7880828708238224, 1.0, 2.0, 0.7880828708238224, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2203985.794997171, 2203985.794997171, 414123.1348684142]
[2019-03-26 17:48:32,687] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:48:32,690] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.1143665e-10 2.3731744e-01 8.9964003e-10 7.6268256e-01 1.5468901e-17], sampled 0.11210619028495683
[2019-03-26 17:48:32,694] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2203985.794997171 W.
[2019-03-26 17:48:38,929] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10520081], dtype=float32), 0.08811143]
[2019-03-26 17:48:38,932] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [30.53333333333333, 77.0, 1.0, 2.0, 0.6103433715861836, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 852921.9390455625, 852921.9390455618, 202687.8265202271]
[2019-03-26 17:48:38,933] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 17:48:38,938] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [7.4340019e-17 1.0000000e+00 1.2480500e-19 1.3963487e-18 3.3623601e-29], sampled 0.5899138318654449
[2019-03-26 17:48:56,955] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10520081], dtype=float32), 0.08811143]
[2019-03-26 17:48:56,959] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.3, 79.0, 1.0, 2.0, 0.5735879736497628, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 801538.8723801395, 801538.8723801395, 195927.8243539541]
[2019-03-26 17:48:56,959] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 17:48:56,964] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [9.4768382e-17 1.0000000e+00 1.1806477e-19 1.7409283e-19 4.1013665e-29], sampled 0.9327011990125968
[2019-03-26 17:49:20,125] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8287.8077 2923733685.8127 1231.0000
[2019-03-26 17:49:20,219] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8072.1394 2998083579.0114 1522.0000
[2019-03-26 17:49:20,527] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8667.3364 2778444235.0769 911.0000
[2019-03-26 17:49:20,577] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7974.8471 3154559044.5027 1486.0000
[2019-03-26 17:49:20,713] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8526.4335 2838197505.0702 1029.0000
[2019-03-26 17:49:21,728] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1850000, evaluation results [1850000.0, 7974.847134084995, 3154559044.50267, 1486.0, 8287.807723339913, 2923733685.8126745, 1231.0, 8667.336416867638, 2778444235.076926, 911.0, 8072.139354346046, 2998083579.0113945, 1522.0, 8526.433542939214, 2838197505.070187, 1029.0]
[2019-03-26 17:49:22,345] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.0010471e-16 1.0000000e+00 5.8838283e-18 3.0850483e-16 1.7349288e-26], sum to 1.0000
[2019-03-26 17:49:22,354] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8767
[2019-03-26 17:49:22,358] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.1, 93.0, 1.0, 2.0, 0.7299022786947874, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1020079.30127493, 1020079.30127493, 227431.2087076436], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6064200.0000, 
sim time next is 6064800.0000, 
raw observation next is [26.1, 93.0, 1.0, 2.0, 0.7133067839727418, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 996875.2823695963, 996875.2823695963, 223742.9300283698], 
processed observation next is [1.0, 0.17391304347826086, 0.4360189573459717, 0.93, 1.0, 1.0, 0.6545864867141468, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2769098006582212, 0.2769098006582212, 0.333944671684134], 
reward next is 0.6661, 
noisyNet noise sample is [array([-0.4402571], dtype=float32), -0.68840533]. 
=============================================
[2019-03-26 17:49:28,152] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.9109528e-17 1.0000000e+00 6.8972258e-20 1.0230915e-19 8.2171908e-29], sum to 1.0000
[2019-03-26 17:49:28,161] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7777
[2019-03-26 17:49:28,164] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.36666666666667, 88.0, 1.0, 2.0, 0.5112322650033273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 714372.9387784209, 714372.9387784209, 185374.4662645817], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5722800.0000, 
sim time next is 5723400.0000, 
raw observation next is [26.53333333333333, 87.0, 1.0, 2.0, 0.5118142065993034, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 715186.3914972004, 715186.3914972009, 185467.6518458023], 
processed observation next is [0.0, 0.21739130434782608, 0.45655608214849913, 0.87, 1.0, 1.0, 0.41182434530036555, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1986628865270001, 0.19866288652700026, 0.2768173908146303], 
reward next is 0.7232, 
noisyNet noise sample is [array([-1.5178977], dtype=float32), -0.21882308]. 
=============================================
[2019-03-26 17:49:39,965] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.2731978e-14 9.9999881e-01 3.8043411e-14 1.1847405e-06 6.2947288e-23], sum to 1.0000
[2019-03-26 17:49:39,972] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8487
[2019-03-26 17:49:39,977] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 79.66666666666666, 1.0, 2.0, 0.5614878417888134, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 784623.7543877551, 784623.7543877556, 193792.8122678471], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5938800.0000, 
sim time next is 5939400.0000, 
raw observation next is [29.9, 79.83333333333334, 1.0, 2.0, 0.5642787740667699, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 788525.2539859136, 788525.2539859136, 194281.7116579368], 
processed observation next is [1.0, 0.7391304347826086, 0.6161137440758293, 0.7983333333333335, 1.0, 1.0, 0.4750346675503251, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2190347927738649, 0.2190347927738649, 0.28997270396706987], 
reward next is 0.7100, 
noisyNet noise sample is [array([0.31971878], dtype=float32), 1.713514]. 
=============================================
[2019-03-26 17:49:49,111] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.4787484e-17 1.0000000e+00 2.5334209e-20 4.2100824e-20 1.0810480e-29], sum to 1.0000
[2019-03-26 17:49:49,118] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8548
[2019-03-26 17:49:49,122] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.6, 63.0, 1.0, 2.0, 0.5102283636509687, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 712969.6614769972, 712969.6614769972, 185214.2027767767], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6278400.0000, 
sim time next is 6279000.0000, 
raw observation next is [30.56666666666667, 63.0, 1.0, 2.0, 0.5107832639923038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 713745.3142059032, 713745.3142059025, 185302.7683196795], 
processed observation next is [0.0, 0.6956521739130435, 0.6477093206951029, 0.63, 1.0, 1.0, 0.41058224577385993, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19826258727941756, 0.19826258727941737, 0.2765712959995217], 
reward next is 0.7234, 
noisyNet noise sample is [array([0.01399902], dtype=float32), -0.0779781]. 
=============================================
[2019-03-26 17:49:49,140] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[73.7181 ]
 [73.68265]
 [73.67474]
 [73.66732]
 [73.65703]], R is [[73.73988342]
 [73.72605133]
 [73.71235657]
 [73.69889832]
 [73.68590546]].
[2019-03-26 17:49:58,174] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.9702792e-18 1.0000000e+00 3.1242188e-20 3.0581878e-19 7.4501103e-29], sum to 1.0000
[2019-03-26 17:49:58,182] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9548
[2019-03-26 17:49:58,188] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.8, 64.0, 1.0, 2.0, 0.5226111962812262, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 730278.8104418882, 730278.8104418882, 187214.7367163221], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6267600.0000, 
sim time next is 6268200.0000, 
raw observation next is [30.81666666666667, 63.66666666666667, 1.0, 2.0, 0.5217021483770581, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 729008.1024506357, 729008.1024506363, 187066.2768385472], 
processed observation next is [0.0, 0.5652173913043478, 0.6595576619273303, 0.6366666666666667, 1.0, 1.0, 0.4237375281651302, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20250225068073216, 0.20250225068073233, 0.2792033982664884], 
reward next is 0.7208, 
noisyNet noise sample is [array([0.530192], dtype=float32), 1.2863275]. 
=============================================
[2019-03-26 17:49:59,808] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.6502215e-10 2.0375720e-01 2.1495872e-09 7.9624277e-01 5.7179707e-17], sum to 1.0000
[2019-03-26 17:49:59,816] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5527
[2019-03-26 17:49:59,821] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.0, 68.0, 1.0, 2.0, 0.5324324354074921, 1.0, 2.0, 0.5324324354074921, 1.0, 1.0, 0.9142757526354003, 6.911199999999999, 6.9112, 170.5573041426782, 2233562.1990114, 2233562.1990114, 436277.6145839756], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6445200.0000, 
sim time next is 6445800.0000, 
raw observation next is [30.0, 68.0, 1.0, 2.0, 0.8063560535096215, 1.0, 2.0, 0.8063560535096215, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2255136.75471102, 2255136.75471102, 422971.058701303], 
processed observation next is [1.0, 0.6086956521739131, 0.6208530805687204, 0.68, 1.0, 1.0, 0.7666940403730379, 1.0, 1.0, 0.7666940403730379, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6264268763086166, 0.6264268763086166, 0.631300087613885], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.8673135], dtype=float32), -0.26063788]. 
=============================================
[2019-03-26 17:50:02,862] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.1641837e-17 1.0000000e+00 5.7513403e-20 1.3771508e-19 1.8005521e-29], sum to 1.0000
[2019-03-26 17:50:02,873] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8977
[2019-03-26 17:50:02,877] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.56666666666667, 82.0, 1.0, 2.0, 0.5252533749782115, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 733972.1751306232, 733972.1751306232, 187646.9582171834], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6381600.0000, 
sim time next is 6382200.0000, 
raw observation next is [27.53333333333333, 82.0, 1.0, 2.0, 0.5247844716849677, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 733316.7185772388, 733316.7185772388, 187569.9571318318], 
processed observation next is [0.0, 0.8695652173913043, 0.5039494470774091, 0.82, 1.0, 1.0, 0.4274511707047803, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20369908849367746, 0.20369908849367746, 0.2799551598982564], 
reward next is 0.7200, 
noisyNet noise sample is [array([-0.40572935], dtype=float32), -0.28041112]. 
=============================================
[2019-03-26 17:50:13,202] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.9655947e-16 1.0000000e+00 1.6487754e-18 5.4754941e-16 4.8340341e-27], sum to 1.0000
[2019-03-26 17:50:13,212] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6766
[2019-03-26 17:50:13,217] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.16666666666667, 92.66666666666667, 1.0, 2.0, 0.7344736857797572, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1026471.186321585, 1026471.186321584, 228461.5663768529], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6498600.0000, 
sim time next is 6499200.0000, 
raw observation next is [26.23333333333333, 92.33333333333334, 1.0, 2.0, 0.6725292212962413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 939861.7605912875, 939861.7605912869, 215026.8114320446], 
processed observation next is [1.0, 0.21739130434782608, 0.44233807266982617, 0.9233333333333335, 1.0, 1.0, 0.6054568931280015, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.26107271127535764, 0.26107271127535747, 0.3209355394508128], 
reward next is 0.6791, 
noisyNet noise sample is [array([0.12992829], dtype=float32), -0.09361018]. 
=============================================
[2019-03-26 17:50:13,697] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.7219678e-14 1.0000000e+00 1.8414227e-15 5.4937782e-13 6.9168413e-24], sum to 1.0000
[2019-03-26 17:50:13,705] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5566
[2019-03-26 17:50:13,714] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1881337.682108045 W.
[2019-03-26 17:50:13,721] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.85, 81.5, 1.0, 2.0, 0.7044369502719927, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 6.981704534241862, 6.9112, 168.9119509521337, 1881337.682108045, 1831319.636703034, 386487.0394128693], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6510600.0000, 
sim time next is 6511200.0000, 
raw observation next is [28.06666666666667, 79.66666666666667, 1.0, 2.0, 0.4442952111030102, 1.0, 1.0, 0.4442952111030102, 1.0, 2.0, 0.759555647671235, 6.9112, 6.9112, 170.5573041426782, 1863506.212364019, 1863506.212364019, 376845.9860253154], 
processed observation next is [1.0, 0.34782608695652173, 0.529225908372828, 0.7966666666666667, 1.0, 1.0, 0.3304761579554339, 1.0, 0.5, 0.3304761579554339, 1.0, 1.0, 0.7067751800868718, 0.0, 0.0, 0.8375144448122397, 0.5176406145455608, 0.5176406145455608, 0.5624566955601723], 
reward next is 0.4375, 
noisyNet noise sample is [array([-0.02447514], dtype=float32), 0.45110863]. 
=============================================
[2019-03-26 17:50:14,573] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.1167265e-14 1.0000000e+00 9.5797375e-17 3.4079618e-11 9.2676180e-26], sum to 1.0000
[2019-03-26 17:50:14,582] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7022
[2019-03-26 17:50:14,587] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.83333333333334, 69.0, 1.0, 2.0, 0.4826671817542217, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 674444.7068110128, 674444.7068110134, 180925.1786570862], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6547200.0000, 
sim time next is 6547800.0000, 
raw observation next is [28.71666666666667, 69.5, 1.0, 2.0, 0.4836530697608024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 675822.7546329242, 675822.7546329242, 181074.6124154043], 
processed observation next is [1.0, 0.782608695652174, 0.5600315955766194, 0.695, 1.0, 1.0, 0.37789526477205115, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18772854295359007, 0.18772854295359007, 0.27026061554537956], 
reward next is 0.7297, 
noisyNet noise sample is [array([-0.6874377], dtype=float32), -1.3683457]. 
=============================================
[2019-03-26 17:50:16,680] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-26 17:50:16,681] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 17:50:16,681] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:50:16,685] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 17:50:16,686] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 17:50:16,686] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:50:16,687] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:50:16,687] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 17:50:16,687] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:50:16,690] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 17:50:16,692] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:50:16,715] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run76
[2019-03-26 17:50:16,751] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run76
[2019-03-26 17:50:16,752] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run76
[2019-03-26 17:50:16,798] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run76
[2019-03-26 17:50:16,822] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run76
[2019-03-26 17:51:04,813] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10625768], dtype=float32), 0.08930975]
[2019-03-26 17:51:04,816] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [24.81171218166667, 91.641498945, 1.0, 2.0, 0.6362158227340776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 897350.8941347363, 897350.8941347363, 208762.6014572277]
[2019-03-26 17:51:04,821] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 17:51:04,823] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.6024875e-16 1.0000000e+00 2.0861871e-19 6.7983064e-19 1.3025368e-28], sampled 0.13135021834636196
[2019-03-26 17:51:16,813] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10625768], dtype=float32), 0.08930975]
[2019-03-26 17:51:16,814] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [32.33333333333334, 76.33333333333334, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 8.887141847638247, 6.9112, 168.9017865891732, 3686680.17503232, 2284971.72033019, 470845.7817357886]
[2019-03-26 17:51:16,815] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:51:16,818] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [8.8459128e-13 1.0000000e+00 4.8919534e-14 8.0303125e-11 1.3842598e-21], sampled 0.8291662533456504
[2019-03-26 17:51:16,819] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 0, 1] for the demand 3686680.17503232 W.
[2019-03-26 17:52:10,758] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8664.0032 2778714880.2683 921.0000
[2019-03-26 17:52:11,020] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8284.8670 2923790166.7021 1245.0000
[2019-03-26 17:52:11,117] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7964.1478 3155382156.4041 1517.0000
[2019-03-26 17:52:11,180] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8524.5368 2839332127.0134 1048.0000
[2019-03-26 17:52:11,214] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8062.8595 2998799224.0895 1544.0000
[2019-03-26 17:52:12,231] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1875000, evaluation results [1875000.0, 7964.147792653324, 3155382156.4041142, 1517.0, 8284.86701778607, 2923790166.702129, 1245.0, 8664.003244355192, 2778714880.268322, 921.0, 8062.859526220903, 2998799224.0894823, 1544.0, 8524.536754842986, 2839332127.013364, 1048.0]
[2019-03-26 17:52:13,995] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.7617713e-11 6.6697309e-03 3.1440542e-10 9.9333030e-01 5.7151033e-17], sum to 1.0000
[2019-03-26 17:52:14,002] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7084
[2019-03-26 17:52:14,007] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.08333333333334, 62.5, 1.0, 2.0, 0.8082621732147469, 1.0, 2.0, 0.8082621732147469, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2260472.422558457, 2260472.422558457, 423907.3094397347], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6619800.0000, 
sim time next is 6620400.0000, 
raw observation next is [31.0, 63.0, 1.0, 2.0, 0.756399977174609, 1.0, 2.0, 0.756399977174609, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2115292.590083741, 2115292.590083741, 399198.4468471328], 
processed observation next is [1.0, 0.6521739130434783, 0.6682464454976303, 0.63, 1.0, 1.0, 0.7065059965959145, 1.0, 1.0, 0.7065059965959145, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5875812750232614, 0.5875812750232614, 0.5958185773837803], 
reward next is 0.4042, 
noisyNet noise sample is [array([-1.295504], dtype=float32), -0.66272545]. 
=============================================
[2019-03-26 17:52:15,187] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.4346084e-15 1.0000000e+00 3.7127709e-16 9.5669486e-11 3.8156006e-26], sum to 1.0000
[2019-03-26 17:52:15,195] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4900
[2019-03-26 17:52:15,201] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.26666666666667, 85.0, 1.0, 2.0, 0.518071380718566, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 723932.8674980478, 723932.8674980478, 186476.4307150955], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6632400.0000, 
sim time next is 6633000.0000, 
raw observation next is [27.25, 85.0, 1.0, 2.0, 0.5196585907159637, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 726151.5313130427, 726151.5313130427, 186733.8434060956], 
processed observation next is [1.0, 0.782608695652174, 0.490521327014218, 0.85, 1.0, 1.0, 0.421275410501161, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20170875869806743, 0.20170875869806743, 0.2787072289643218], 
reward next is 0.7213, 
noisyNet noise sample is [array([-0.3029613], dtype=float32), 0.78291225]. 
=============================================
[2019-03-26 17:52:15,218] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[74.93895]
 [73.98511]
 [72.67   ]
 [70.50792]
 [68.01522]], R is [[75.37260437]
 [75.34056091]
 [75.30930328]
 [75.27961731]
 [75.25144958]].
[2019-03-26 17:52:21,724] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.1589789e-16 1.0000000e+00 6.3933896e-19 1.8114215e-16 8.7787479e-28], sum to 1.0000
[2019-03-26 17:52:21,734] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4378
[2019-03-26 17:52:21,741] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.23333333333333, 69.33333333333334, 1.0, 2.0, 0.3848427439331689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 579613.0163836644, 579613.0163836639, 172839.5019586726], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6729600.0000, 
sim time next is 6730200.0000, 
raw observation next is [26.1, 69.5, 1.0, 2.0, 0.3806444809760919, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 575123.0264484802, 575123.0264484802, 172494.4721721456], 
processed observation next is [1.0, 0.9130434782608695, 0.4360189573459717, 0.695, 1.0, 1.0, 0.25378853129649626, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15975639623568894, 0.15975639623568894, 0.25745443607782925], 
reward next is 0.7425, 
noisyNet noise sample is [array([0.23693727], dtype=float32), -1.3631818]. 
=============================================
[2019-03-26 17:52:23,180] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0406727e-15 1.0000000e+00 1.5098820e-18 7.6585548e-16 3.5825232e-27], sum to 1.0000
[2019-03-26 17:52:23,184] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8789
[2019-03-26 17:52:23,190] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.25, 54.5, 1.0, 2.0, 0.322858277554824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 508053.5868684333, 508053.5868684333, 167581.9541114929], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6808200.0000, 
sim time next is 6808800.0000, 
raw observation next is [27.1, 55.00000000000001, 1.0, 2.0, 0.3225041806554598, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 508029.8917311263, 508029.8917311269, 167591.8918616561], 
processed observation next is [1.0, 0.8260869565217391, 0.4834123222748816, 0.55, 1.0, 1.0, 0.1837399766933251, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1411194143697573, 0.14111941436975747, 0.25013715203232256], 
reward next is 0.7499, 
noisyNet noise sample is [array([1.3689823], dtype=float32), 0.2310233]. 
=============================================
[2019-03-26 17:52:27,181] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.2300378e-16 1.0000000e+00 2.0424924e-18 8.3482080e-16 1.4874593e-27], sum to 1.0000
[2019-03-26 17:52:27,187] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1895
[2019-03-26 17:52:27,197] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.15, 59.5, 1.0, 2.0, 0.3197452436669642, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 504924.4537710003, 504924.453771001, 167382.0851305817], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6813000.0000, 
sim time next is 6813600.0000, 
raw observation next is [26.03333333333333, 60.33333333333333, 1.0, 2.0, 0.3230952826349026, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 509817.3087269706, 509817.3087269706, 167745.9518597321], 
processed observation next is [1.0, 0.8695652173913043, 0.4328593996840442, 0.6033333333333333, 1.0, 1.0, 0.1844521477528947, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14161591909082516, 0.14161591909082516, 0.25036709232795834], 
reward next is 0.7496, 
noisyNet noise sample is [array([0.7321574], dtype=float32), -1.154972]. 
=============================================
[2019-03-26 17:52:32,610] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.7299536e-17 1.0000000e+00 4.7927924e-20 3.6701526e-20 7.2954527e-30], sum to 1.0000
[2019-03-26 17:52:32,618] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8392
[2019-03-26 17:52:32,623] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.66666666666667, 53.66666666666667, 1.0, 2.0, 0.4729709186584572, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 660891.6254807549, 660891.6254807543, 179469.7601195881], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6966600.0000, 
sim time next is 6967200.0000, 
raw observation next is [31.33333333333334, 55.33333333333334, 1.0, 2.0, 0.4751808813675474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 663980.6151790711, 663980.6151790704, 179798.9960230589], 
processed observation next is [0.0, 0.6521739130434783, 0.6840442338072673, 0.5533333333333335, 1.0, 1.0, 0.36768780887656316, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1844390597719642, 0.184439059771964, 0.26835671048217746], 
reward next is 0.7316, 
noisyNet noise sample is [array([-1.1840895], dtype=float32), 0.37227476]. 
=============================================
[2019-03-26 17:52:33,427] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.6525096e-16 1.0000000e+00 7.1471031e-19 6.3855471e-17 7.5053998e-27], sum to 1.0000
[2019-03-26 17:52:33,433] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2785
[2019-03-26 17:52:33,437] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.93333333333333, 73.33333333333334, 1.0, 2.0, 0.3574353477227357, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 549117.5728930659, 549117.5728930659, 170529.9301087906], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7348800.0000, 
sim time next is 7349400.0000, 
raw observation next is [24.95, 73.0, 1.0, 2.0, 0.3558436563160816, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 547202.70411356, 547202.70411356, 170385.2903284315], 
processed observation next is [1.0, 0.043478260869565216, 0.3815165876777251, 0.73, 1.0, 1.0, 0.22390801965792964, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15200075114265557, 0.15200075114265557, 0.2543064034752709], 
reward next is 0.7457, 
noisyNet noise sample is [array([0.60066366], dtype=float32), 1.0505002]. 
=============================================
[2019-03-26 17:52:34,055] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.1697241e-16 1.0000000e+00 7.4052980e-18 8.5760297e-16 6.7910732e-27], sum to 1.0000
[2019-03-26 17:52:34,065] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1333
[2019-03-26 17:52:34,071] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.65, 76.0, 1.0, 2.0, 0.5917320944556285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 846554.1892061256, 846554.1892061256, 201742.0874032477], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7023000.0000, 
sim time next is 7023600.0000, 
raw observation next is [26.8, 75.0, 1.0, 2.0, 0.6364402611088918, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 910828.0310405577, 910828.031040557, 210518.0316832197], 
processed observation next is [1.0, 0.30434782608695654, 0.4691943127962086, 0.75, 1.0, 1.0, 0.5619762182034841, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2530077864001549, 0.2530077864001547, 0.31420601743764137], 
reward next is 0.6858, 
noisyNet noise sample is [array([-0.91184], dtype=float32), -1.2898196]. 
=============================================
[2019-03-26 17:52:37,594] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.8537513e-18 1.0000000e+00 2.6207693e-20 1.3600891e-19 3.2876017e-31], sum to 1.0000
[2019-03-26 17:52:37,602] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7132
[2019-03-26 17:52:37,614] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.45, 77.0, 1.0, 2.0, 0.446562342492944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 640099.1347765512, 640099.1347765506, 177719.6724194971], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6996600.0000, 
sim time next is 6997200.0000, 
raw observation next is [26.4, 77.33333333333334, 1.0, 2.0, 0.447679540859505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 641649.3312446683, 641649.3312446683, 177875.1561538553], 
processed observation next is [0.0, 1.0, 0.45023696682464454, 0.7733333333333334, 1.0, 1.0, 0.3345536636861506, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1782359253457412, 0.1782359253457412, 0.2654853076923213], 
reward next is 0.7345, 
noisyNet noise sample is [array([0.8810285], dtype=float32), 0.39190984]. 
=============================================
[2019-03-26 17:52:40,020] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.79391776e-16 1.00000000e+00 1.12317164e-17 1.22441260e-15
 6.52787252e-27], sum to 1.0000
[2019-03-26 17:52:40,033] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6842
[2019-03-26 17:52:40,042] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 77.0, 1.0, 2.0, 0.5928815583752316, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 847976.1421943277, 847976.1421943277, 201930.7281508207], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7022400.0000, 
sim time next is 7023000.0000, 
raw observation next is [26.65, 76.0, 1.0, 2.0, 0.5917320944556285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 846554.1892061256, 846554.1892061256, 201742.0874032477], 
processed observation next is [1.0, 0.2608695652173913, 0.462085308056872, 0.76, 1.0, 1.0, 0.508110957175456, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.235153941446146, 0.235153941446146, 0.3011075931391757], 
reward next is 0.6989, 
noisyNet noise sample is [array([0.4094876], dtype=float32), 0.4705519]. 
=============================================
[2019-03-26 17:52:40,057] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[68.5912  ]
 [68.70328 ]
 [68.83498 ]
 [69.017166]
 [69.322205]], R is [[68.55118561]
 [68.56428528]
 [68.57589722]
 [68.59083557]
 [68.59792328]].
[2019-03-26 17:52:42,435] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.59770555e-10 3.89630228e-01 4.02749084e-10 6.10369802e-01
 1.18269564e-17], sum to 1.0000
[2019-03-26 17:52:42,447] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6932
[2019-03-26 17:52:42,461] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.26666666666667, 71.83333333333334, 1.0, 2.0, 0.3184776164483656, 1.0, 2.0, 0.3184776164483656, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 890122.5672233509, 890122.5672233509, 253535.3526545081], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7060200.0000, 
sim time next is 7060800.0000, 
raw observation next is [28.13333333333333, 72.66666666666667, 1.0, 2.0, 0.2266303183940492, 1.0, 2.0, 0.2266303183940492, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 633340.028410076, 633340.028410076, 237274.5982320681], 
processed observation next is [1.0, 0.7391304347826086, 0.532385466034755, 0.7266666666666667, 1.0, 1.0, 0.06822929926993879, 1.0, 1.0, 0.06822929926993879, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.17592778566946557, 0.17592778566946557, 0.3541411913911464], 
reward next is 0.6459, 
noisyNet noise sample is [array([1.0616385], dtype=float32), 1.323082]. 
=============================================
[2019-03-26 17:52:46,700] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.4664955e-11 1.0000000e+00 1.6508132e-12 2.7764132e-08 1.2906278e-19], sum to 1.0000
[2019-03-26 17:52:46,707] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4295
[2019-03-26 17:52:46,717] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1963393.01571818 W.
[2019-03-26 17:52:46,724] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.0, 84.0, 1.0, 2.0, 0.7630723550850621, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.005979178642951, 6.9112, 168.912393212874, 1963393.01571818, 1896153.628574589, 398912.485964965], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7203600.0000, 
sim time next is 7204200.0000, 
raw observation next is [29.0, 83.16666666666667, 1.0, 2.0, 0.8589903713142947, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005985212810473, 6.9112, 168.9123160035796, 2097635.929710222, 2030392.292471644, 422922.7305369521], 
processed observation next is [1.0, 0.391304347826087, 0.5734597156398105, 0.8316666666666667, 1.0, 1.0, 0.8301088811015599, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.009478521281047314, 0.0, 0.8294367999704371, 0.5826766471417283, 0.5639978590199011, 0.6312279560253016], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2777846], dtype=float32), 0.3849202]. 
=============================================
[2019-03-26 17:52:51,474] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.6193718e-10 7.4632205e-02 1.7777310e-09 9.2536777e-01 1.6252725e-16], sum to 1.0000
[2019-03-26 17:52:51,485] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6578
[2019-03-26 17:52:51,491] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.2, 64.0, 1.0, 2.0, 0.62122097863242, 1.0, 2.0, 0.62122097863242, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1736954.500913103, 1736954.500913103, 342215.3829706985], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7657200.0000, 
sim time next is 7657800.0000, 
raw observation next is [30.08333333333334, 64.83333333333334, 1.0, 2.0, 0.5783166449839502, 1.0, 2.0, 0.5783166449839502, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1616902.058099235, 1616902.058099235, 326374.649059137], 
processed observation next is [1.0, 0.6521739130434783, 0.6248025276461299, 0.6483333333333334, 1.0, 1.0, 0.4919477650409038, 1.0, 1.0, 0.4919477650409038, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.4491394605831208, 0.4491394605831208, 0.4871263418793089], 
reward next is 0.5129, 
noisyNet noise sample is [array([-0.86202806], dtype=float32), 0.38129976]. 
=============================================
[2019-03-26 17:52:52,695] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.4549560e-17 1.0000000e+00 1.7301756e-20 3.3298139e-20 6.4278863e-29], sum to 1.0000
[2019-03-26 17:52:52,705] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5247
[2019-03-26 17:52:52,712] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.1, 81.0, 1.0, 2.0, 0.4017569457259792, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 592685.9122017049, 592685.9122017055, 173657.7022912811], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7479000.0000, 
sim time next is 7479600.0000, 
raw observation next is [25.2, 80.66666666666666, 1.0, 2.0, 0.4036288715111631, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 594362.9525237568, 594362.9525237568, 173779.8462242809], 
processed observation next is [0.0, 0.5652173913043478, 0.3933649289099526, 0.8066666666666665, 1.0, 1.0, 0.2814805680857387, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.165100820145488, 0.165100820145488, 0.25937290481235953], 
reward next is 0.7406, 
noisyNet noise sample is [array([-0.01828225], dtype=float32), -1.2497821]. 
=============================================
[2019-03-26 17:52:54,441] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:52:54,442] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:52:54,514] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run10
[2019-03-26 17:52:55,182] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.3692531e-17 1.0000000e+00 1.4636289e-18 3.7164249e-17 2.3760286e-27], sum to 1.0000
[2019-03-26 17:52:55,190] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6012
[2019-03-26 17:52:55,193] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.3, 93.0, 1.0, 2.0, 0.7074684945793798, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1114112.989064285, 1114112.989064286, 237691.992370086], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7383600.0000, 
sim time next is 7384200.0000, 
raw observation next is [21.28333333333333, 93.0, 1.0, 2.0, 0.6395973424484709, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1006985.689436953, 1006985.689436953, 221741.7633299674], 
processed observation next is [1.0, 0.4782608695652174, 0.20774091627172192, 0.93, 1.0, 1.0, 0.5657799306608082, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.27971824706582027, 0.27971824706582027, 0.33095785571636926], 
reward next is 0.6690, 
noisyNet noise sample is [array([1.0107299], dtype=float32), -0.5935389]. 
=============================================
[2019-03-26 17:53:00,945] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.8924412e-17 1.0000000e+00 4.5829373e-20 1.7144935e-19 9.3594034e-30], sum to 1.0000
[2019-03-26 17:53:00,953] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4366
[2019-03-26 17:53:00,961] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.33333333333334, 62.0, 1.0, 2.0, 0.4513166777827046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 638710.9203464325, 638710.9203464318, 177365.3130854174], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7573200.0000, 
sim time next is 7573800.0000, 
raw observation next is [29.16666666666667, 62.0, 1.0, 2.0, 0.4445139563660606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 633156.6034245412, 633156.6034245412, 176913.5538732694], 
processed observation next is [0.0, 0.6521739130434783, 0.581358609794629, 0.62, 1.0, 1.0, 0.33073970646513323, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17587683428459477, 0.17587683428459477, 0.2640500804078648], 
reward next is 0.7359, 
noisyNet noise sample is [array([0.57611763], dtype=float32), -0.2958901]. 
=============================================
[2019-03-26 17:53:02,332] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.5387063e-16 1.0000000e+00 3.6518455e-19 2.4182028e-18 3.3977295e-28], sum to 1.0000
[2019-03-26 17:53:02,341] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4842
[2019-03-26 17:53:02,348] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.91666666666666, 91.00000000000001, 1.0, 2.0, 0.4676925561097179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 708839.6244483565, 708839.6244483565, 185466.9295031413], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 112200.0000, 
sim time next is 112800.0000, 
raw observation next is [22.93333333333333, 91.0, 1.0, 2.0, 0.4666124415444929, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 706773.0203536035, 706773.020353603, 185245.6791247776], 
processed observation next is [1.0, 0.30434782608695654, 0.28593996840442326, 0.91, 1.0, 1.0, 0.35736438740300347, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1963258389871121, 0.19632583898711192, 0.27648608824593673], 
reward next is 0.7235, 
noisyNet noise sample is [array([0.65047646], dtype=float32), -0.41396567]. 
=============================================
[2019-03-26 17:53:06,013] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.6783190e-09 1.8430799e-01 4.4660498e-10 8.1569207e-01 1.6225370e-16], sum to 1.0000
[2019-03-26 17:53:06,025] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4534
[2019-03-26 17:53:06,029] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.61666666666667, 68.16666666666666, 1.0, 2.0, 0.746254922266112, 1.0, 2.0, 0.746254922266112, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2086894.039544481, 2086894.039544481, 394547.1789090253], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7660200.0000, 
sim time next is 7660800.0000, 
raw observation next is [29.5, 69.0, 1.0, 2.0, 0.7403915644765992, 1.0, 2.0, 0.7403915644765992, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2070481.375312207, 2070481.375312207, 391888.2347337119], 
processed observation next is [1.0, 0.6956521739130435, 0.5971563981042655, 0.69, 1.0, 1.0, 0.6872187523814447, 1.0, 1.0, 0.6872187523814447, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.575133715364502, 0.575133715364502, 0.584907813035391], 
reward next is 0.4151, 
noisyNet noise sample is [array([-1.6866846], dtype=float32), -0.267731]. 
=============================================
[2019-03-26 17:53:06,745] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.1835196e-16 1.0000000e+00 9.5408195e-18 7.5252271e-15 1.4501514e-26], sum to 1.0000
[2019-03-26 17:53:06,756] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6933
[2019-03-26 17:53:06,760] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.6, 87.0, 1.0, 2.0, 0.5981795680841518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 835916.9907559324, 835916.9907559331, 200400.9850089962], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7884000.0000, 
sim time next is 7884600.0000, 
raw observation next is [26.66666666666667, 86.5, 1.0, 2.0, 0.6033662351347145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 843167.8971018008, 843167.8971018002, 201368.0948255169], 
processed observation next is [1.0, 0.2608695652173913, 0.4628751974723541, 0.865, 1.0, 1.0, 0.5221279941382103, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2342133047505002, 0.23421330475050006, 0.3005493952619655], 
reward next is 0.6995, 
noisyNet noise sample is [array([0.31030634], dtype=float32), -0.34715548]. 
=============================================
[2019-03-26 17:53:06,839] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.4978525e-17 1.0000000e+00 1.6700172e-20 3.0591546e-20 6.4750827e-31], sum to 1.0000
[2019-03-26 17:53:06,847] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9226
[2019-03-26 17:53:06,855] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.9, 78.0, 1.0, 2.0, 0.4192212272567798, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 609932.050515837, 609932.050515837, 175017.344579115], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7495200.0000, 
sim time next is 7495800.0000, 
raw observation next is [25.78333333333333, 78.5, 1.0, 2.0, 0.4177501772966061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 608701.117699015, 608701.117699015, 174927.5002061765], 
processed observation next is [0.0, 0.782608695652174, 0.4210110584518167, 0.785, 1.0, 1.0, 0.2984941895139832, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16908364380528193, 0.16908364380528193, 0.2610858212032485], 
reward next is 0.7389, 
noisyNet noise sample is [array([1.2252322], dtype=float32), 0.980264]. 
=============================================
[2019-03-26 17:53:07,339] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-26 17:53:07,340] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 17:53:07,341] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:53:07,342] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 17:53:07,343] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 17:53:07,343] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 17:53:07,344] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:53:07,346] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 17:53:07,346] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:53:07,346] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:53:07,353] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:53:07,375] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run77
[2019-03-26 17:53:07,399] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run77
[2019-03-26 17:53:07,421] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run77
[2019-03-26 17:53:07,421] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run77
[2019-03-26 17:53:07,464] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run77
[2019-03-26 17:53:50,036] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10788066], dtype=float32), 0.091195256]
[2019-03-26 17:53:50,037] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.0, 88.0, 1.0, 2.0, 0.6031809713445242, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 947686.2622197444, 947686.2622197444, 213650.3070876373]
[2019-03-26 17:53:50,039] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:53:50,042] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.5602796e-17 1.0000000e+00 1.1868567e-19 2.3391210e-19 3.6595666e-29], sampled 0.326115133553458
[2019-03-26 17:54:11,873] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10788066], dtype=float32), 0.091195256]
[2019-03-26 17:54:11,874] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [24.79547488666667, 82.02962584666668, 1.0, 2.0, 0.4064789984467796, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 607826.9953981729, 607826.9953981729, 175294.5970965488]
[2019-03-26 17:54:11,875] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 17:54:11,879] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [5.7101846e-17 1.0000000e+00 5.2622468e-20 6.5092212e-20 9.9978311e-30], sampled 0.42221333317591225
[2019-03-26 17:54:18,458] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10788066], dtype=float32), 0.091195256]
[2019-03-26 17:54:18,459] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [34.86666666666667, 57.16666666666666, 1.0, 2.0, 0.6856844307682348, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005974389614755, 6.9112, 168.9123160672838, 1855096.437243459, 1787860.478297956, 381582.2131400533]
[2019-03-26 17:54:18,460] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:54:18,463] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [9.8961750e-10 9.9644250e-01 1.1026617e-09 3.5574494e-03 4.7452410e-17], sampled 0.28164618145938547
[2019-03-26 17:54:18,465] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1855096.437243459 W.
[2019-03-26 17:54:22,675] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10788066], dtype=float32), 0.091195256]
[2019-03-26 17:54:22,678] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.7, 79.5, 1.0, 2.0, 0.5479810284523111, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 765742.5145672448, 765742.5145672441, 191454.9592761847]
[2019-03-26 17:54:22,680] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:54:22,682] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.5013044e-16 1.0000000e+00 7.7310456e-19 1.6039307e-16 2.0111078e-28], sampled 0.008789994215455232
[2019-03-26 17:54:24,020] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10788066], dtype=float32), 0.091195256]
[2019-03-26 17:54:24,021] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [32.50576685, 61.04242279, 1.0, 2.0, 0.5747002269390811, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 803093.7363617774, 803093.7363617768, 196126.1885663427]
[2019-03-26 17:54:24,023] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 17:54:24,027] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [5.9903263e-15 1.0000000e+00 8.6105763e-17 1.1054583e-11 3.2825223e-26], sampled 0.8800178355447189
[2019-03-26 17:54:33,106] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10788066], dtype=float32), 0.091195256]
[2019-03-26 17:54:33,108] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.9, 94.0, 1.0, 2.0, 0.6603204725723009, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 922792.5823845468, 922792.5823845468, 212512.677932431]
[2019-03-26 17:54:33,110] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:54:33,114] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.0685741e-16 1.0000000e+00 5.1004443e-19 4.2582191e-18 1.8719360e-28], sampled 0.004733719623803645
[2019-03-26 17:54:52,022] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10788066], dtype=float32), 0.091195256]
[2019-03-26 17:54:52,025] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.91666666666666, 77.0, 1.0, 2.0, 0.6188979037045651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 963114.0137039186, 963114.0137039186, 216104.6805326202]
[2019-03-26 17:54:52,025] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:54:52,027] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.3023212e-16 1.0000000e+00 1.5127293e-19 1.9970579e-19 5.5753216e-29], sampled 0.37388829482453034
[2019-03-26 17:55:01,583] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8668.9406 2778199608.5034 906.0000
[2019-03-26 17:55:01,664] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8308.5003 2921640933.4259 1181.0000
[2019-03-26 17:55:01,696] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 8001.2628 3151262423.3444 1402.0000
[2019-03-26 17:55:01,741] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8106.8375 2994296251.6172 1429.0000
[2019-03-26 17:55:01,758] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8541.7035 2837028978.3371 993.0000
[2019-03-26 17:55:02,774] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1900000, evaluation results [1900000.0, 8001.26281253882, 3151262423.3444376, 1402.0, 8308.500279352964, 2921640933.4259014, 1181.0, 8668.940636195566, 2778199608.5033517, 906.0, 8106.837458813758, 2994296251.617248, 1429.0, 8541.703544419232, 2837028978.3370595, 993.0]
[2019-03-26 17:55:05,026] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:55:05,029] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:55:05,097] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run10
[2019-03-26 17:55:05,438] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.1944362e-10 2.7128619e-01 2.8775674e-10 7.2871381e-01 2.6936415e-17], sum to 1.0000
[2019-03-26 17:55:05,443] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1695
[2019-03-26 17:55:05,449] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2293661.7022813 W.
[2019-03-26 17:55:05,453] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.3, 64.0, 1.0, 2.0, 0.8201185643585631, 1.0, 2.0, 0.8201185643585631, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2293661.7022813, 2293661.702281299, 429781.354497897], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7731000.0000, 
sim time next is 7731600.0000, 
raw observation next is [31.36666666666667, 63.66666666666667, 1.0, 2.0, 0.8170998604844574, 1.0, 2.0, 0.8170998604844574, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2285211.441345512, 2285211.441345512, 428278.8320234593], 
processed observation next is [1.0, 0.4782608695652174, 0.6856240126382308, 0.6366666666666667, 1.0, 1.0, 0.7796383861258522, 1.0, 1.0, 0.7796383861258522, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6347809559293088, 0.6347809559293088, 0.6392221373484467], 
reward next is 0.3608, 
noisyNet noise sample is [array([-1.4701818], dtype=float32), 0.83716214]. 
=============================================
[2019-03-26 17:55:06,306] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.3677543e-11 8.3613652e-01 1.6642500e-10 1.6386354e-01 1.3072914e-18], sum to 1.0000
[2019-03-26 17:55:06,313] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4006
[2019-03-26 17:55:06,319] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.13333333333333, 64.16666666666667, 1.0, 2.0, 0.3490114693136311, 1.0, 2.0, 0.3490114693136311, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 975501.356314041, 975501.356314041, 260041.1799662495], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7751400.0000, 
sim time next is 7752000.0000, 
raw observation next is [29.96666666666667, 65.33333333333334, 1.0, 2.0, 0.4605356573126653, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 643510.3258140581, 643510.3258140587, 177646.0505531049], 
processed observation next is [1.0, 0.7391304347826086, 0.6192733017377569, 0.6533333333333334, 1.0, 1.0, 0.35004296061766904, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1787528682816828, 0.17875286828168296, 0.26514335903448494], 
reward next is 0.7349, 
noisyNet noise sample is [array([1.4679253], dtype=float32), -0.8391759]. 
=============================================
[2019-03-26 17:55:06,328] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[65.246994]
 [62.754917]
 [62.94419 ]
 [62.789383]
 [62.70203 ]], R is [[68.87674713]
 [68.79985809]
 [68.48561859]
 [68.16604614]
 [67.8524704 ]].
[2019-03-26 17:55:06,802] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:55:06,802] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:55:06,864] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run10
[2019-03-26 17:55:06,981] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0063640e-15 1.0000000e+00 2.3526797e-18 2.3828053e-15 1.4124894e-27], sum to 1.0000
[2019-03-26 17:55:06,986] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3574
[2019-03-26 17:55:06,991] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.4, 90.66666666666667, 1.0, 2.0, 0.5228763296238115, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 730649.426023216, 730649.426023216, 187257.9797993716], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7773000.0000, 
sim time next is 7773600.0000, 
raw observation next is [26.4, 90.33333333333334, 1.0, 2.0, 0.520622383934911, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 727498.761189787, 727498.761189787, 186890.3243605811], 
processed observation next is [1.0, 1.0, 0.45023696682464454, 0.9033333333333334, 1.0, 1.0, 0.42243660715049514, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20208298921938525, 0.20208298921938525, 0.278940782627733], 
reward next is 0.7211, 
noisyNet noise sample is [array([-1.3101263], dtype=float32), -0.5915988]. 
=============================================
[2019-03-26 17:55:07,227] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.0935826e-10 3.2528794e-01 5.2536389e-09 6.7471200e-01 2.7742039e-16], sum to 1.0000
[2019-03-26 17:55:07,236] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1469
[2019-03-26 17:55:07,241] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2105433.657544455 W.
[2019-03-26 17:55:07,245] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.06666666666667, 71.33333333333334, 1.0, 2.0, 0.7528780176193752, 1.0, 2.0, 0.7528780176193752, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2105433.657544455, 2105433.657544455, 397581.9659338489], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7816800.0000, 
sim time next is 7817400.0000, 
raw observation next is [30.3, 71.0, 1.0, 2.0, 0.5127068432034336, 1.0, 2.0, 0.5127068432034336, 1.0, 1.0, 0.8901068700613786, 6.911200000000001, 6.9112, 170.5573041426782, 2150732.96323883, 2150732.96323883, 423989.233451165], 
processed observation next is [1.0, 0.4782608695652174, 0.6350710900473934, 0.71, 1.0, 1.0, 0.41289981108847423, 1.0, 1.0, 0.41289981108847423, 1.0, 0.5, 0.86598398787973, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5974258231218973, 0.5974258231218973, 0.6328197514196493], 
reward next is 0.3672, 
noisyNet noise sample is [array([0.3811369], dtype=float32), -0.44824883]. 
=============================================
[2019-03-26 17:55:07,692] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.3343009e-17 1.0000000e+00 7.0968930e-20 4.1245927e-19 1.2132354e-30], sum to 1.0000
[2019-03-26 17:55:07,698] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3370
[2019-03-26 17:55:07,701] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.6, 89.0, 1.0, 2.0, 0.484058537974898, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 676389.5077499435, 676389.5077499435, 181136.0137621213], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7594200.0000, 
sim time next is 7594800.0000, 
raw observation next is [25.53333333333333, 89.33333333333334, 1.0, 2.0, 0.4829224890743254, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 674801.5683662131, 674801.5683662125, 180963.5920637619], 
processed observation next is [0.0, 0.9130434782608695, 0.4091627172195892, 0.8933333333333334, 1.0, 1.0, 0.3770150470775005, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18744488010172586, 0.1874448801017257, 0.27009491352800286], 
reward next is 0.7299, 
noisyNet noise sample is [array([-0.3876979], dtype=float32), 2.348405]. 
=============================================
[2019-03-26 17:55:12,063] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.1410286e-15 1.0000000e+00 9.9080231e-18 1.4928126e-14 2.8595847e-26], sum to 1.0000
[2019-03-26 17:55:12,073] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4104
[2019-03-26 17:55:12,077] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333333, 87.66666666666667, 1.0, 2.0, 0.5225463123681657, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 730188.1127435089, 730188.1127435095, 187204.1012011808], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7766400.0000, 
sim time next is 7767000.0000, 
raw observation next is [26.8, 88.0, 1.0, 2.0, 0.523318483537868, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 731267.4893892081, 731267.4893892087, 187330.321357835], 
processed observation next is [1.0, 0.9130434782608695, 0.4691943127962086, 0.88, 1.0, 1.0, 0.4256849199251422, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20312985816366894, 0.2031298581636691, 0.27959749456393285], 
reward next is 0.7204, 
noisyNet noise sample is [array([-2.02833], dtype=float32), 0.69701326]. 
=============================================
[2019-03-26 17:55:12,096] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[71.61405 ]
 [70.69865 ]
 [70.12198 ]
 [69.693405]
 [69.45061 ]], R is [[72.23342133]
 [72.23167419]
 [72.23007202]
 [72.22862244]
 [72.22731018]].
[2019-03-26 17:55:12,896] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.1641878e-15 1.0000000e+00 3.5537788e-18 9.4882376e-16 9.6834086e-27], sum to 1.0000
[2019-03-26 17:55:12,905] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5017
[2019-03-26 17:55:12,911] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.9, 94.0, 1.0, 2.0, 0.7523565089805304, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1126767.662118722, 1126767.662118722, 242529.6785571532], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 122400.0000, 
sim time next is 123000.0000, 
raw observation next is [22.88333333333333, 94.16666666666667, 1.0, 2.0, 0.7717516638050138, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1155141.158100615, 1155141.158100615, 247338.3886303107], 
processed observation next is [1.0, 0.43478260869565216, 0.28357030015797774, 0.9416666666666668, 1.0, 1.0, 0.7250020045843539, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3208725439168375, 0.3208725439168375, 0.3691617740750906], 
reward next is 0.6308, 
noisyNet noise sample is [array([-0.35612264], dtype=float32), 0.3012803]. 
=============================================
[2019-03-26 17:55:12,923] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[69.45602]
 [69.43644]
 [69.26504]
 [69.09772]
 [69.11983]], R is [[69.39672089]
 [69.34076691]
 [69.31171417]
 [69.27681732]
 [69.2128067 ]].
[2019-03-26 17:55:14,546] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.4734271e-09 9.8281962e-01 4.1451442e-09 1.7180413e-02 6.8196190e-16], sum to 1.0000
[2019-03-26 17:55:14,557] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5103
[2019-03-26 17:55:14,565] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1932457.809792741 W.
[2019-03-26 17:55:14,571] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.93333333333333, 75.33333333333334, 1.0, 2.0, 0.7409670954362029, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.985175809160479, 6.9112, 168.912515579892, 1932457.809792741, 1879976.961719852, 394543.4818136215], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7899000.0000, 
sim time next is 7899600.0000, 
raw observation next is [29.06666666666667, 74.66666666666667, 1.0, 2.0, 0.6769702247935123, 1.0, 1.0, 0.6769702247935123, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1892968.935957212, 1892968.935957212, 364419.1979558659], 
processed observation next is [1.0, 0.43478260869565216, 0.5766192733017379, 0.7466666666666667, 1.0, 1.0, 0.6108074997512196, 1.0, 0.5, 0.6108074997512196, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5258247044325589, 0.5258247044325589, 0.5439092506803969], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.10259993], dtype=float32), 0.8984217]. 
=============================================
[2019-03-26 17:55:14,774] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:55:14,775] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:55:14,852] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run10
[2019-03-26 17:55:15,124] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0687179e-15 1.0000000e+00 2.0230522e-18 6.0280485e-18 2.6899281e-28], sum to 1.0000
[2019-03-26 17:55:15,134] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6339
[2019-03-26 17:55:15,139] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.7, 86.0, 1.0, 2.0, 0.2442807504006924, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 402025.3453116264, 402025.3453116264, 160343.6647814425], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 432000.0000, 
sim time next is 432600.0000, 
raw observation next is [19.68333333333333, 85.83333333333334, 1.0, 2.0, 0.2435470947532007, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 400939.6576215969, 400939.6576215975, 160270.3409328334], 
processed observation next is [1.0, 0.0, 0.13191153238546593, 0.8583333333333334, 1.0, 1.0, 0.08861095753397673, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11137212711711024, 0.11137212711711042, 0.23920946407885582], 
reward next is 0.7608, 
noisyNet noise sample is [array([1.9038054], dtype=float32), -0.613604]. 
=============================================
[2019-03-26 17:55:15,687] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:55:15,688] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:55:15,741] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run10
[2019-03-26 17:55:17,054] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.3239462e-15 1.0000000e+00 4.2021123e-18 5.0404750e-15 8.6093829e-27], sum to 1.0000
[2019-03-26 17:55:17,062] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4848
[2019-03-26 17:55:17,072] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.4, 88.33333333333334, 1.0, 2.0, 0.5117471010429623, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 715092.5896172201, 715092.5896172201, 185457.0375287665], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7777200.0000, 
sim time next is 7777800.0000, 
raw observation next is [26.4, 88.0, 1.0, 2.0, 0.5101332702930573, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 712836.7378048967, 712836.737804896, 185198.9423960287], 
processed observation next is [1.0, 0.0, 0.45023696682464454, 0.88, 1.0, 1.0, 0.4097991208350088, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19801020494580462, 0.19801020494580443, 0.2764163319343712], 
reward next is 0.7236, 
noisyNet noise sample is [array([0.23370104], dtype=float32), -1.923138]. 
=============================================
[2019-03-26 17:55:17,156] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.8351123e-16 1.0000000e+00 3.6593217e-18 1.7228102e-15 7.4204494e-27], sum to 1.0000
[2019-03-26 17:55:17,162] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9874
[2019-03-26 17:55:17,169] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.01666666666667, 92.66666666666667, 1.0, 2.0, 0.9778363665412079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1366804.093822836, 1366804.093822837, 292244.4060780596], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7870200.0000, 
sim time next is 7870800.0000, 
raw observation next is [26.03333333333333, 92.33333333333334, 1.0, 2.0, 0.8849227226535293, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1236855.230653404, 1236855.230653404, 265822.6574180614], 
processed observation next is [1.0, 0.08695652173913043, 0.4328593996840442, 0.9233333333333335, 1.0, 1.0, 0.8613526778958185, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3435708974037233, 0.3435708974037233, 0.3967502349523304], 
reward next is 0.6032, 
noisyNet noise sample is [array([2.0725875], dtype=float32), -0.080349416]. 
=============================================
[2019-03-26 17:55:17,436] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:55:17,438] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:55:17,500] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run10
[2019-03-26 17:55:17,681] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:55:17,682] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:55:17,764] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run10
[2019-03-26 17:55:21,550] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.0663276e-15 1.0000000e+00 7.4485323e-18 2.7635121e-15 1.0222140e-26], sum to 1.0000
[2019-03-26 17:55:21,561] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6030
[2019-03-26 17:55:21,565] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666667, 86.5, 1.0, 2.0, 0.6033662351347145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 843167.8971018008, 843167.8971018002, 201368.0948255169], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7884600.0000, 
sim time next is 7885200.0000, 
raw observation next is [26.73333333333334, 86.0, 1.0, 2.0, 0.6243938726880052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 872564.8218607658, 872564.8218607658, 205370.5781021543], 
processed observation next is [1.0, 0.2608695652173913, 0.4660347551342816, 0.86, 1.0, 1.0, 0.547462497214464, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.24237911718354604, 0.24237911718354604, 0.3065232508987378], 
reward next is 0.6935, 
noisyNet noise sample is [array([1.0120497], dtype=float32), 1.5587652]. 
=============================================
[2019-03-26 17:55:22,193] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:55:22,195] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:55:22,266] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run10
[2019-03-26 17:55:23,811] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:55:23,812] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:55:23,874] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run10
[2019-03-26 17:55:25,437] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:55:25,438] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:55:25,535] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run10
[2019-03-26 17:55:25,757] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:55:25,758] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:55:25,826] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run10
[2019-03-26 17:55:26,294] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:55:26,295] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:55:26,350] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run10
[2019-03-26 17:55:26,634] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:55:26,634] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:55:26,670] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:55:26,671] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:55:26,702] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run10
[2019-03-26 17:55:26,748] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run10
[2019-03-26 17:55:26,916] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:55:26,916] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:55:26,958] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:55:26,958] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:55:26,964] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run10
[2019-03-26 17:55:27,026] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run10
[2019-03-26 17:55:28,084] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.7068819e-17 1.0000000e+00 7.1997994e-21 1.9231452e-21 8.9518456e-31], sum to 1.0000
[2019-03-26 17:55:28,087] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0443
[2019-03-26 17:55:28,091] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.03333333333333, 83.33333333333334, 1.0, 2.0, 0.2963295790978868, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 471918.240543293, 471918.2405432923, 165048.3676505503], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 289200.0000, 
sim time next is 289800.0000, 
raw observation next is [22.1, 83.0, 1.0, 2.0, 0.2966076757588989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 472137.6107390649, 472137.6107390655, 165060.0192987906], 
processed observation next is [0.0, 0.34782608695652173, 0.24644549763033188, 0.83, 1.0, 1.0, 0.15253936838421553, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13114933631640693, 0.13114933631640707, 0.24635823775938898], 
reward next is 0.7536, 
noisyNet noise sample is [array([-1.0204252], dtype=float32), 0.009796616]. 
=============================================
[2019-03-26 17:55:29,935] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.6725006e-16 1.0000000e+00 2.5829066e-19 1.5363244e-17 4.1286507e-28], sum to 1.0000
[2019-03-26 17:55:29,944] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5852
[2019-03-26 17:55:29,948] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 73.5, 1.0, 2.0, 0.2395569635656393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 395710.2236278414, 395710.2236278414, 159836.5058957534], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 502200.0000, 
sim time next is 502800.0000, 
raw observation next is [20.76666666666667, 75.0, 1.0, 2.0, 0.2397413199632716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 396109.0358317908, 396109.0358317908, 159848.4993827649], 
processed observation next is [1.0, 0.8260869565217391, 0.18325434439178534, 0.75, 1.0, 1.0, 0.08402568670273687, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.110030287731053, 0.110030287731053, 0.23857984982502223], 
reward next is 0.7614, 
noisyNet noise sample is [array([1.0569094], dtype=float32), -0.36761376]. 
=============================================
[2019-03-26 17:55:35,957] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.9331981e-15 1.0000000e+00 3.9838276e-17 2.7227510e-14 2.0340245e-26], sum to 1.0000
[2019-03-26 17:55:35,964] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0847
[2019-03-26 17:55:35,971] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.75, 96.0, 1.0, 2.0, 0.9123297797886507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1360691.385182906, 1360691.385182906, 285705.5645954492], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 138600.0000, 
sim time next is 139200.0000, 
raw observation next is [22.73333333333333, 96.0, 1.0, 2.0, 0.8486763137904157, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1266470.075735952, 1266470.075735952, 267414.8147117951], 
processed observation next is [1.0, 0.6086956521739131, 0.27646129541864134, 0.96, 1.0, 1.0, 0.8176823057715852, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3517972432599867, 0.3517972432599867, 0.3991265891220822], 
reward next is 0.6009, 
noisyNet noise sample is [array([1.6943103], dtype=float32), -0.26766744]. 
=============================================
[2019-03-26 17:55:40,318] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.1882765e-16 1.0000000e+00 3.2911604e-19 1.3294562e-17 7.5369517e-29], sum to 1.0000
[2019-03-26 17:55:40,328] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9987
[2019-03-26 17:55:40,333] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333334, 62.33333333333334, 1.0, 2.0, 0.5348901116764662, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 877201.9130404252, 877201.9130404245, 202335.4223483047], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 642000.0000, 
sim time next is 642600.0000, 
raw observation next is [23.5, 61.5, 1.0, 2.0, 0.5755322113276665, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 943539.055656543, 943539.055656543, 210440.7834478318], 
processed observation next is [1.0, 0.43478260869565216, 0.31279620853080575, 0.615, 1.0, 1.0, 0.48859302569598373, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2620941821268175, 0.2620941821268175, 0.3140907215639281], 
reward next is 0.6859, 
noisyNet noise sample is [array([-1.2961444], dtype=float32), -0.8485234]. 
=============================================
[2019-03-26 17:55:55,223] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-26 17:55:55,224] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 17:55:55,226] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:55:55,227] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 17:55:55,229] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:55:55,229] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 17:55:55,231] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 17:55:55,231] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:55:55,231] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:55:55,233] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 17:55:55,235] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:55:55,254] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run78
[2019-03-26 17:55:55,278] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run78
[2019-03-26 17:55:55,299] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run78
[2019-03-26 17:55:55,318] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run78
[2019-03-26 17:55:55,338] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run78
[2019-03-26 17:55:59,235] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10963692], dtype=float32), 0.09425562]
[2019-03-26 17:55:59,237] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.2, 50.0, 1.0, 2.0, 0.2981118154218661, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 478330.3300668095, 478330.3300668095, 165540.443870175]
[2019-03-26 17:55:59,240] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:55:59,241] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.3208139e-17 1.0000000e+00 1.0161482e-20 1.9007978e-21 1.3718003e-30], sampled 0.8579922441234134
[2019-03-26 17:56:06,800] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10963692], dtype=float32), 0.09425562]
[2019-03-26 17:56:06,802] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.56980072333334, 53.73763392666666, 1.0, 2.0, 0.2906592776360186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 473633.4964234911, 473633.4964234911, 165128.7465596409]
[2019-03-26 17:56:06,803] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 17:56:06,805] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.5249144e-17 1.0000000e+00 2.0778625e-20 8.3923782e-21 3.8460178e-30], sampled 0.958654267657727
[2019-03-26 17:56:23,165] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10963692], dtype=float32), 0.09425562]
[2019-03-26 17:56:23,166] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [24.83333333333334, 88.33333333333334, 1.0, 2.0, 0.5811551411884145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 831988.1279475796, 831988.1279475796, 199836.1119890111]
[2019-03-26 17:56:23,169] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 17:56:23,171] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.0864828e-17 1.0000000e+00 2.6078048e-20 3.0407951e-20 4.1767880e-30], sampled 0.4957570258744798
[2019-03-26 17:56:44,771] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10963692], dtype=float32), 0.09425562]
[2019-03-26 17:56:44,771] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.0, 74.0, 1.0, 2.0, 0.8173905210953945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1142414.789522128, 1142414.789522127, 248221.2262875607]
[2019-03-26 17:56:44,772] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:56:44,776] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.0444277e-16 1.0000000e+00 5.6801107e-19 1.1807345e-17 2.0209748e-28], sampled 0.42434166509142746
[2019-03-26 17:56:49,525] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10963692], dtype=float32), 0.09425562]
[2019-03-26 17:56:49,527] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [33.0, 67.0, 1.0, 2.0, 0.6032944792888155, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 843067.5828412719, 843067.5828412719, 201362.446010146]
[2019-03-26 17:56:49,529] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:56:49,532] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.9604322e-17 1.0000000e+00 4.1587481e-20 1.1680462e-19 6.1358928e-30], sampled 0.6166148883116639
[2019-03-26 17:56:59,950] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10963692], dtype=float32), 0.09425562]
[2019-03-26 17:56:59,952] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [34.0, 53.0, 1.0, 2.0, 0.5403888823392552, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 755129.5640688089, 755129.5640688089, 190166.8481492438]
[2019-03-26 17:56:59,955] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:56:59,957] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.2131093e-17 1.0000000e+00 3.3261071e-20 1.8178633e-19 4.0764237e-30], sampled 0.4925134348965904
[2019-03-26 17:57:02,248] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10963692], dtype=float32), 0.09425562]
[2019-03-26 17:57:02,250] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [36.0, 55.0, 1.0, 2.0, 0.9464984641996865, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1322973.179600868, 1322973.179600868, 283055.339332652]
[2019-03-26 17:57:02,251] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:57:02,253] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.1330468e-15 1.0000000e+00 4.4674999e-17 8.1347169e-13 2.7247240e-26], sampled 0.4396668028748557
[2019-03-26 17:57:11,304] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10963692], dtype=float32), 0.09425562]
[2019-03-26 17:57:11,306] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [35.91666666666666, 53.83333333333333, 1.0, 2.0, 0.8412242279433211, 1.0, 2.0, 0.7412021534859232, 1.0, 2.0, 1.03, 7.005108870198267, 6.9112, 170.5573041426782, 3110444.568272883, 3043173.824581258, 569645.9682384728]
[2019-03-26 17:57:11,308] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:57:11,312] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.71652954e-16 5.88415219e-11 4.81648717e-14 1.00000000e+00
 1.06185555e-20], sampled 0.8852860306123607
[2019-03-26 17:57:14,764] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10963692], dtype=float32), 0.09425562]
[2019-03-26 17:57:14,765] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.8, 76.16666666666666, 1.0, 2.0, 0.8464076318118576, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.001234189824699, 6.9112, 168.9123478509329, 2080024.676254371, 2016151.553415756, 419805.7657521525]
[2019-03-26 17:57:14,765] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:57:14,770] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.37044163e-13 1.00000000e+00 9.30426221e-15 1.12235065e-11
 6.51646566e-23], sampled 0.565341934045113
[2019-03-26 17:57:14,771] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2080024.676254371 W.
[2019-03-26 17:57:32,947] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10963692], dtype=float32), 0.09425562]
[2019-03-26 17:57:32,949] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [32.06666666666667, 56.0, 1.0, 2.0, 0.5198910863057817, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 726476.5230726255, 726476.5230726255, 186770.6933305781]
[2019-03-26 17:57:32,950] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:57:32,953] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.7440035e-16 1.0000000e+00 1.1686172e-18 9.7164314e-16 2.2886148e-28], sampled 0.6756665191455831
[2019-03-26 17:57:37,501] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10963692], dtype=float32), 0.09425562]
[2019-03-26 17:57:37,503] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [32.0, 76.0, 1.0, 2.0, 0.9632359840905653, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.9129565042375, 1346382.970556789, 1346382.970556789, 287932.2575044983]
[2019-03-26 17:57:37,503] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:57:37,507] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [4.3668604e-16 1.0000000e+00 1.9783681e-18 3.7348033e-16 1.0534759e-27], sampled 0.5639862771172014
[2019-03-26 17:57:48,460] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8065.8795 2998391558.8243 1541.0000
[2019-03-26 17:57:48,771] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8528.3142 2839000113.3510 1041.0000
[2019-03-26 17:57:48,834] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8665.9946 2778576884.4950 916.0000
[2019-03-26 17:57:48,998] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7971.9541 3154823994.7496 1503.0000
[2019-03-26 17:57:49,012] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8282.0291 2923820858.4108 1232.0000
[2019-03-26 17:57:50,030] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 1925000, evaluation results [1925000.0, 7971.954057336285, 3154823994.7495832, 1503.0, 8282.029127651189, 2923820858.41079, 1232.0, 8665.99458850943, 2778576884.495042, 916.0, 8065.87954843103, 2998391558.8242955, 1541.0, 8528.314242827362, 2839000113.3509583, 1041.0]
[2019-03-26 17:57:56,563] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.9670420e-16 1.0000000e+00 1.3802703e-18 2.5579363e-16 7.6503614e-28], sum to 1.0000
[2019-03-26 17:57:56,573] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8792
[2019-03-26 17:57:56,579] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.7, 54.0, 1.0, 2.0, 0.6503903047182602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1067798.144919577, 1067798.144919577, 226868.7953992902], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 664800.0000, 
sim time next is 665400.0000, 
raw observation next is [24.7, 54.0, 1.0, 2.0, 0.6472894781032879, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1062697.434414753, 1062697.434414753, 226150.7762930955], 
processed observation next is [1.0, 0.6956521739130435, 0.3696682464454976, 0.54, 1.0, 1.0, 0.5750475639798649, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.29519373178187586, 0.29519373178187586, 0.337538472079247], 
reward next is 0.6625, 
noisyNet noise sample is [array([-0.288316], dtype=float32), -0.52121687]. 
=============================================
[2019-03-26 17:58:00,088] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.2506994e-17 1.0000000e+00 9.0551029e-20 7.7814328e-19 2.1993267e-29], sum to 1.0000
[2019-03-26 17:58:00,098] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4151
[2019-03-26 17:58:00,103] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 69.0, 1.0, 2.0, 0.4320835532460939, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 711115.6809246483, 711115.6809246477, 184346.6503951903], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 637200.0000, 
sim time next is 637800.0000, 
raw observation next is [22.16666666666667, 68.16666666666667, 1.0, 2.0, 0.4488592894162586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 738340.9935510228, 738340.9935510228, 187039.087585057], 
processed observation next is [1.0, 0.391304347826087, 0.24960505529225935, 0.6816666666666668, 1.0, 1.0, 0.3359750474894682, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20509472043083968, 0.20509472043083968, 0.27916281729112985], 
reward next is 0.7208, 
noisyNet noise sample is [array([1.1076679], dtype=float32), -1.6877899]. 
=============================================
[2019-03-26 17:58:04,443] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.1662340e-17 1.0000000e+00 6.9147145e-21 1.0738597e-21 5.8488569e-31], sum to 1.0000
[2019-03-26 17:58:04,452] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7054
[2019-03-26 17:58:04,460] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.45, 75.5, 1.0, 2.0, 0.3105343506142487, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 490927.7073007232, 490927.7073007232, 166349.4056229615], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 840600.0000, 
sim time next is 841200.0000, 
raw observation next is [23.3, 76.33333333333334, 1.0, 2.0, 0.3101469496316649, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 490613.1999019503, 490613.1999019509, 166332.5888356419], 
processed observation next is [0.0, 0.7391304347826086, 0.3033175355450238, 0.7633333333333334, 1.0, 1.0, 0.16885174654417456, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1362814444172084, 0.13628144441720857, 0.24825759527707744], 
reward next is 0.7517, 
noisyNet noise sample is [array([0.9592126], dtype=float32), 0.036229484]. 
=============================================
[2019-03-26 17:58:20,274] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.3056640e-16 1.0000000e+00 1.4816050e-18 6.9529271e-16 1.5601588e-27], sum to 1.0000
[2019-03-26 17:58:20,281] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9199
[2019-03-26 17:58:20,287] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.7, 98.0, 1.0, 2.0, 0.626724693742629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 960206.4200807251, 960206.4200807257, 216202.5402614928], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1011600.0000, 
sim time next is 1012200.0000, 
raw observation next is [21.7, 97.83333333333334, 1.0, 2.0, 0.4068980605363464, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 623561.2886847962, 623561.2886847956, 177085.8042402147], 
processed observation next is [1.0, 0.7391304347826086, 0.2274881516587678, 0.9783333333333334, 1.0, 1.0, 0.2854193500437909, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17321146907911006, 0.1732114690791099, 0.26430717050778313], 
reward next is 0.7357, 
noisyNet noise sample is [array([0.42186168], dtype=float32), -0.97417575]. 
=============================================
[2019-03-26 17:58:20,306] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.7600575e-17 1.0000000e+00 3.5839182e-19 9.8192672e-17 2.6166329e-28], sum to 1.0000
[2019-03-26 17:58:20,312] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3793
[2019-03-26 17:58:20,314] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.2, 78.0, 1.0, 2.0, 0.3582388996383469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 551037.1222666402, 551037.1222666402, 170710.5296477101], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1198800.0000, 
sim time next is 1199400.0000, 
raw observation next is [24.08333333333334, 78.66666666666667, 1.0, 2.0, 0.358055639261249, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 550841.4673749172, 550841.4673749172, 170696.5097147721], 
processed observation next is [1.0, 0.9130434782608695, 0.34044233807267016, 0.7866666666666667, 1.0, 1.0, 0.2265730593509024, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15301151871525479, 0.15301151871525479, 0.25477091002204794], 
reward next is 0.7452, 
noisyNet noise sample is [array([-0.78437525], dtype=float32), -2.252319]. 
=============================================
[2019-03-26 17:58:27,766] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.2789951e-15 1.0000000e+00 3.0337901e-17 8.6281473e-14 1.1960470e-26], sum to 1.0000
[2019-03-26 17:58:27,771] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3688
[2019-03-26 17:58:27,776] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666666, 67.5, 1.0, 2.0, 0.4232138857200688, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 653470.7032023642, 653470.7032023648, 179974.1591324478], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1098600.0000, 
sim time next is 1099200.0000, 
raw observation next is [25.53333333333333, 68.0, 1.0, 2.0, 0.3327323270616147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 514524.5463198539, 514524.5463198539, 167832.2459973225], 
processed observation next is [1.0, 0.7391304347826086, 0.4091627172195892, 0.68, 1.0, 1.0, 0.19606304465254784, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1429234850888483, 0.1429234850888483, 0.25049588954824253], 
reward next is 0.7495, 
noisyNet noise sample is [array([2.0210996], dtype=float32), -0.93665874]. 
=============================================
[2019-03-26 17:58:30,229] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.5488952e-16 1.0000000e+00 7.1144067e-19 5.3390885e-18 4.4528088e-28], sum to 1.0000
[2019-03-26 17:58:30,242] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6607
[2019-03-26 17:58:30,250] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 89.16666666666667, 1.0, 2.0, 0.3066885794240479, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 484786.7941328553, 484786.7941328558, 165898.6661183088], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1572600.0000, 
sim time next is 1573200.0000, 
raw observation next is [21.6, 89.0, 1.0, 2.0, 0.3058931738368764, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 483763.8062439788, 483763.8062439788, 165829.6271591172], 
processed observation next is [1.0, 0.21739130434782608, 0.22274881516587688, 0.89, 1.0, 1.0, 0.16372671546611617, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13437883506777187, 0.13437883506777187, 0.2475069062076376], 
reward next is 0.7525, 
noisyNet noise sample is [array([-1.4228626], dtype=float32), -1.879994]. 
=============================================
[2019-03-26 17:58:32,703] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0396570e-15 1.0000000e+00 7.4111518e-17 3.2594598e-13 1.8986263e-26], sum to 1.0000
[2019-03-26 17:58:32,711] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7212
[2019-03-26 17:58:32,717] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.6, 57.5, 1.0, 2.0, 0.8694337795922499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1338358.83683975, 1338358.836839749, 278471.2090432497], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1182600.0000, 
sim time next is 1183200.0000, 
raw observation next is [27.6, 57.33333333333334, 1.0, 2.0, 0.8756463434796307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1349039.152794541, 1349039.152794542, 280439.4418665444], 
processed observation next is [1.0, 0.6956521739130435, 0.5071090047393366, 0.5733333333333335, 1.0, 1.0, 0.8501763174453382, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.37473309799848364, 0.3747330979984839, 0.41856633114409614], 
reward next is 0.5814, 
noisyNet noise sample is [array([-1.065288], dtype=float32), 0.099311255]. 
=============================================
[2019-03-26 17:58:41,056] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.3377309e-16 1.0000000e+00 6.5988321e-18 2.2368507e-15 2.4812383e-27], sum to 1.0000
[2019-03-26 17:58:41,067] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7197
[2019-03-26 17:58:41,078] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 93.5, 1.0, 2.0, 0.3197966538423226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 506622.848828721, 506622.8488287205, 167539.9788568775], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1362600.0000, 
sim time next is 1363200.0000, 
raw observation next is [21.03333333333333, 93.66666666666667, 1.0, 2.0, 0.3188438018254088, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 504488.8921073263, 504488.8921073263, 167368.041642011], 
processed observation next is [1.0, 0.782608695652174, 0.19589257503949445, 0.9366666666666668, 1.0, 1.0, 0.17932988171735997, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14013580336314618, 0.14013580336314618, 0.2498030472268821], 
reward next is 0.7502, 
noisyNet noise sample is [array([0.8511718], dtype=float32), -0.7891348]. 
=============================================
[2019-03-26 17:58:42,813] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0942819e-17 1.0000000e+00 2.3695291e-20 2.3801193e-20 4.1120955e-30], sum to 1.0000
[2019-03-26 17:58:42,823] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0169
[2019-03-26 17:58:42,829] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 93.33333333333334, 1.0, 2.0, 0.3382249340770461, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 524194.9318888809, 524194.9318888815, 168632.8292670927], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1491600.0000, 
sim time next is 1492200.0000, 
raw observation next is [22.1, 92.5, 1.0, 2.0, 0.3419022963034121, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 528449.00397552, 528449.0039755206, 168930.2571604968], 
processed observation next is [0.0, 0.2608695652173913, 0.24644549763033188, 0.925, 1.0, 1.0, 0.20711120036555677, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14679138999320002, 0.14679138999320016, 0.252134712179846], 
reward next is 0.7479, 
noisyNet noise sample is [array([-1.2142547], dtype=float32), -1.1563033]. 
=============================================
[2019-03-26 17:58:45,561] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-26 17:58:45,562] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 17:58:45,564] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:58:45,565] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 17:58:45,565] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:58:45,567] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 17:58:45,568] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 17:58:45,568] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 17:58:45,569] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:58:45,569] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:58:45,570] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:58:45,605] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run79
[2019-03-26 17:58:45,629] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run79
[2019-03-26 17:58:45,653] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run79
[2019-03-26 17:58:45,674] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run79
[2019-03-26 17:58:45,695] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run79
[2019-03-26 17:58:57,092] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10967635], dtype=float32), 0.09277175]
[2019-03-26 17:58:57,094] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [19.52040783, 91.658075625, 1.0, 2.0, 0.2707605422955378, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 442732.9164565281, 442732.9164565281, 163008.9956127697]
[2019-03-26 17:58:57,094] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 17:58:57,096] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [7.4164689e-17 1.0000000e+00 3.5472468e-20 8.9341855e-21 1.0399510e-29], sampled 0.6213045271510278
[2019-03-26 17:58:58,407] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10967635], dtype=float32), 0.09277175]
[2019-03-26 17:58:58,409] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [21.52813789666667, 87.08030954333333, 1.0, 2.0, 0.3094607873305362, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 491688.9444515524, 491688.9444515524, 166451.3721838196]
[2019-03-26 17:58:58,411] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 17:58:58,414] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [4.9347074e-17 1.0000000e+00 2.3283121e-20 4.4139610e-21 5.4709662e-30], sampled 0.1981670543481926
[2019-03-26 17:59:01,670] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10967635], dtype=float32), 0.09277175]
[2019-03-26 17:59:01,672] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.74843176333333, 61.7927049, 1.0, 2.0, 0.3899165467133303, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 599536.1824344185, 599536.1824344179, 174937.4503389472]
[2019-03-26 17:59:01,674] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 17:59:01,675] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.1595374e-16 1.0000000e+00 1.1930575e-19 3.4271251e-19 3.8427788e-29], sampled 0.08457004681811153
[2019-03-26 17:59:13,516] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10967635], dtype=float32), 0.09277175]
[2019-03-26 17:59:13,518] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [24.55, 96.83333333333334, 1.0, 2.0, 0.5637536282232145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 787791.14109876, 787791.14109876, 194182.0596976558]
[2019-03-26 17:59:13,520] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:59:13,522] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.3254056e-16 1.0000000e+00 4.1068044e-19 3.5998143e-18 1.6765211e-28], sampled 0.37715645861769753
[2019-03-26 17:59:27,860] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10967635], dtype=float32), 0.09277175]
[2019-03-26 17:59:27,861] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.16666666666667, 94.0, 1.0, 2.0, 0.498595926225157, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 696709.6976388592, 696709.6976388586, 183376.0837626854]
[2019-03-26 17:59:27,862] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:59:27,864] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [6.2217753e-17 1.0000000e+00 8.8325958e-20 2.2187120e-18 1.8879848e-29], sampled 0.6866774385157054
[2019-03-26 17:59:47,735] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10967635], dtype=float32), 0.09277175]
[2019-03-26 17:59:47,737] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [37.71666666666666, 45.33333333333333, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.05872709834223, 6.9112, 168.9118834515642, 2388434.28858922, 2283774.152416473, 475752.9348535587]
[2019-03-26 17:59:47,738] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 17:59:47,740] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.0570293e-09 3.4884357e-01 9.1175041e-09 6.5115649e-01 9.3562158e-16], sampled 0.8468545916181118
[2019-03-26 18:00:01,441] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10967635], dtype=float32), 0.09277175]
[2019-03-26 18:00:01,442] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.68333333333333, 75.33333333333334, 1.0, 2.0, 0.5025670287475932, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8727927274784554, 6.911199999999999, 6.9112, 168.9128793330219, 1404985.621356815, 1404985.621356816, 309586.6958862802]
[2019-03-26 18:00:01,443] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 18:00:01,446] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [7.5951095e-10 9.4801152e-01 5.1765703e-10 5.1988475e-02 4.1090730e-17], sampled 0.6464603307118879
[2019-03-26 18:00:35,861] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8138.3771 2991578517.2899 1361.0000
[2019-03-26 18:00:35,932] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8547.4148 2836006794.7283 971.0000
[2019-03-26 18:00:36,017] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8314.5919 2920553510.4468 1145.0000
[2019-03-26 18:00:36,025] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 8029.8697 3148621724.7705 1335.0000
[2019-03-26 18:00:36,059] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8672.1601 2777941914.8297 893.0000
[2019-03-26 18:00:37,075] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 1950000, evaluation results [1950000.0, 8029.869699570514, 3148621724.770463, 1335.0, 8314.591872994537, 2920553510.446847, 1145.0, 8672.160107145699, 2777941914.8297453, 893.0, 8138.377121212083, 2991578517.28988, 1361.0, 8547.414793885468, 2836006794.7282763, 971.0]
[2019-03-26 18:00:43,987] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0554251e-15 1.0000000e+00 1.1610987e-18 9.5935971e-17 2.7458296e-28], sum to 1.0000
[2019-03-26 18:00:43,998] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0680
[2019-03-26 18:00:44,007] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.4, 93.0, 1.0, 2.0, 0.3272048030727237, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 514163.28648065, 514163.28648065, 168034.7519484025], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1803600.0000, 
sim time next is 1804200.0000, 
raw observation next is [21.4, 93.16666666666667, 1.0, 2.0, 0.3280013532986883, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 515005.1491886139, 515005.1491886139, 168090.5317381071], 
processed observation next is [1.0, 0.9130434782608695, 0.21327014218009477, 0.9316666666666668, 1.0, 1.0, 0.19036307626347987, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1430569858857261, 0.1430569858857261, 0.2508813906538912], 
reward next is 0.7491, 
noisyNet noise sample is [array([1.5487167], dtype=float32), 0.63782126]. 
=============================================
[2019-03-26 18:00:48,775] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.8945440e-16 1.0000000e+00 3.4408422e-18 1.3630889e-15 1.4642979e-27], sum to 1.0000
[2019-03-26 18:00:48,785] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6716
[2019-03-26 18:00:48,792] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.53333333333333, 94.0, 1.0, 2.0, 0.5277877554670948, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 740526.6961008434, 740526.6961008434, 188449.1569334539], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1737600.0000, 
sim time next is 1738200.0000, 
raw observation next is [24.51666666666667, 94.0, 1.0, 2.0, 0.5168699173348718, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 725773.0075960452, 725773.0075960445, 186732.0838326232], 
processed observation next is [1.0, 0.08695652173913043, 0.36097946287519767, 0.94, 1.0, 1.0, 0.4179155630540623, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20160361322112366, 0.20160361322112347, 0.2787046027352585], 
reward next is 0.7213, 
noisyNet noise sample is [array([-0.08726139], dtype=float32), -0.14696294]. 
=============================================
[2019-03-26 18:00:51,215] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.7555405e-16 1.0000000e+00 5.6821916e-19 1.4471195e-16 5.5738781e-28], sum to 1.0000
[2019-03-26 18:00:51,225] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8703
[2019-03-26 18:00:51,233] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 98.0, 1.0, 2.0, 0.4200944851691179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 613363.8565777503, 613363.8565777509, 175408.5805615911], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1638000.0000, 
sim time next is 1638600.0000, 
raw observation next is [23.1, 98.0, 1.0, 2.0, 0.4204909772655581, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 613788.3591621993, 613788.3591621986, 175444.6769027057], 
processed observation next is [1.0, 1.0, 0.2938388625592418, 0.98, 1.0, 1.0, 0.30179635815127487, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17049676643394426, 0.17049676643394407, 0.26185772672045626], 
reward next is 0.7381, 
noisyNet noise sample is [array([-1.0995419], dtype=float32), 0.57745904]. 
=============================================
[2019-03-26 18:00:54,643] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.6244664e-16 1.0000000e+00 8.3900135e-20 1.4122804e-18 6.4735086e-29], sum to 1.0000
[2019-03-26 18:00:54,654] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8526
[2019-03-26 18:00:54,658] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 76.16666666666667, 1.0, 2.0, 0.5627679389941809, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 786413.2258867561, 786413.2258867561, 194015.3221651925], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2121000.0000, 
sim time next is 2121600.0000, 
raw observation next is [30.0, 76.33333333333334, 1.0, 2.0, 0.5635677638004177, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 787531.3172691067, 787531.3172691074, 194155.6260370398], 
processed observation next is [0.0, 0.5652173913043478, 0.6208530805687204, 0.7633333333333334, 1.0, 1.0, 0.47417802867520203, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21875869924141855, 0.21875869924141875, 0.2897845164731937], 
reward next is 0.7102, 
noisyNet noise sample is [array([0.907576], dtype=float32), -0.9568067]. 
=============================================
[2019-03-26 18:00:55,322] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.4616383e-15 1.0000000e+00 8.9996734e-17 3.3234743e-13 1.7199646e-25], sum to 1.0000
[2019-03-26 18:00:55,331] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6278
[2019-03-26 18:00:55,337] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.7, 85.16666666666667, 1.0, 2.0, 0.7531453279333653, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1052578.862651041, 1052578.862651041, 232735.2849056105], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2445000.0000, 
sim time next is 2445600.0000, 
raw observation next is [27.7, 85.33333333333334, 1.0, 2.0, 0.7423467209443687, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1037479.601694007, 1037479.601694007, 230251.8085865166], 
processed observation next is [1.0, 0.30434782608695654, 0.5118483412322274, 0.8533333333333334, 1.0, 1.0, 0.6895743625835767, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2881887782483353, 0.2881887782483353, 0.34365941580077103], 
reward next is 0.6563, 
noisyNet noise sample is [array([0.09536161], dtype=float32), -1.3775375]. 
=============================================
[2019-03-26 18:01:03,466] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.37721476e-14 1.00000000e+00 2.96001143e-16 2.46383296e-11
 1.66404883e-24], sum to 1.0000
[2019-03-26 18:01:03,474] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0563
[2019-03-26 18:01:03,479] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.9, 83.66666666666666, 1.0, 2.0, 1.0333137698404, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1444402.279950556, 1444402.279950556, 309238.4309818231], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1863600.0000, 
sim time next is 1864200.0000, 
raw observation next is [27.0, 83.33333333333334, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.152305130557446, 6.9112, 168.9115474263927, 1624918.922166852, 1453872.071248269, 311348.3894367213], 
processed observation next is [1.0, 0.5652173913043478, 0.4786729857819906, 0.8333333333333335, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.024110513055744586, 0.0, 0.8294330259045931, 0.45136636726857, 0.40385335312451914, 0.4646990887115243], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.02915807], dtype=float32), -0.17691213]. 
=============================================
[2019-03-26 18:01:05,390] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.2443199e-16 1.0000000e+00 3.6068656e-18 2.6608783e-16 7.0715424e-28], sum to 1.0000
[2019-03-26 18:01:05,398] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9238
[2019-03-26 18:01:05,403] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.55, 94.5, 1.0, 2.0, 0.4325988030863935, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 630478.0488462491, 630478.0488462498, 177035.4536174381], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1917000.0000, 
sim time next is 1917600.0000, 
raw observation next is [23.5, 94.33333333333334, 1.0, 2.0, 0.4259573929352983, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 622513.4018254412, 622513.4018254412, 176304.953978988], 
processed observation next is [1.0, 0.17391304347826086, 0.31279620853080575, 0.9433333333333335, 1.0, 1.0, 0.30838240112686544, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1729203893959559, 0.1729203893959559, 0.26314172235669847], 
reward next is 0.7369, 
noisyNet noise sample is [array([0.5220056], dtype=float32), 1.5481038]. 
=============================================
[2019-03-26 18:01:07,187] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.7367388e-16 1.0000000e+00 1.8955727e-18 6.2694017e-17 4.4417838e-27], sum to 1.0000
[2019-03-26 18:01:07,197] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0371
[2019-03-26 18:01:07,206] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 94.33333333333334, 1.0, 2.0, 0.4259573929352983, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 622513.4018254412, 622513.4018254412, 176304.953978988], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1917600.0000, 
sim time next is 1918200.0000, 
raw observation next is [23.45, 94.16666666666667, 1.0, 2.0, 0.4203535402130014, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 615999.7236060007, 615999.7236060014, 175724.8899134576], 
processed observation next is [1.0, 0.17391304347826086, 0.3104265402843602, 0.9416666666666668, 1.0, 1.0, 0.30163077134096555, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1711110343350002, 0.17111103433500038, 0.2622759550947128], 
reward next is 0.7377, 
noisyNet noise sample is [array([-1.3714978], dtype=float32), -1.3719138]. 
=============================================
[2019-03-26 18:01:15,962] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.4601857e-11 6.1877426e-02 1.4305462e-10 9.3812263e-01 5.6571201e-18], sum to 1.0000
[2019-03-26 18:01:15,977] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0228
[2019-03-26 18:01:15,986] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2018165.059078146 W.
[2019-03-26 18:01:15,989] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.7, 84.0, 1.0, 2.0, 0.7217011729431894, 1.0, 2.0, 0.7217011729431894, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2018165.059078146, 2018165.059078146, 383550.7306948595], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2476800.0000, 
sim time next is 2477400.0000, 
raw observation next is [27.81666666666666, 83.66666666666667, 1.0, 2.0, 0.9239498209853588, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.988424033973335, 6.9112, 168.9124973004794, 2188560.151788165, 2133774.913181943, 441433.5803061265], 
processed observation next is [1.0, 0.6956521739130435, 0.5173775671406, 0.8366666666666667, 1.0, 1.0, 0.9083732782956131, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.007722403397333455, 0.0, 0.829437690221213, 0.6079333754967124, 0.5927152536616508, 0.658856090009144], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3595421], dtype=float32), -0.51270735]. 
=============================================
[2019-03-26 18:01:16,282] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.9939856e-16 1.0000000e+00 1.5861010e-19 9.5021728e-18 2.6744562e-29], sum to 1.0000
[2019-03-26 18:01:16,285] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.2092473e-16 1.0000000e+00 8.7078461e-19 1.8868543e-14 2.9483199e-27], sum to 1.0000
[2019-03-26 18:01:16,292] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2192
[2019-03-26 18:01:16,296] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 93.0, 1.0, 2.0, 0.5209833541982788, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 728003.3407383447, 728003.3407383454, 186948.9830338373], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2157600.0000, 
sim time next is 2158200.0000, 
raw observation next is [25.95, 93.0, 1.0, 2.0, 0.5198918164369748, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 726477.5436797593, 726477.5436797593, 186771.2839850073], 
processed observation next is [0.0, 1.0, 0.42890995260663506, 0.93, 1.0, 1.0, 0.4215564053457527, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.201799317688822, 0.201799317688822, 0.27876311042538404], 
reward next is 0.7212, 
noisyNet noise sample is [array([0.5294867], dtype=float32), 0.9830439]. 
=============================================
[2019-03-26 18:01:16,296] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0371
[2019-03-26 18:01:16,303] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.5, 78.66666666666667, 1.0, 2.0, 0.5676985508345127, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 793305.8473093299, 793305.8473093299, 194882.5793136188], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2323200.0000, 
sim time next is 2323800.0000, 
raw observation next is [29.4, 79.0, 1.0, 2.0, 0.5655846257790007, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 790350.7349213045, 790350.7349213045, 194509.6589926694], 
processed observation next is [1.0, 0.9130434782608695, 0.5924170616113744, 0.79, 1.0, 1.0, 0.4766079828662659, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21954187081147347, 0.21954187081147347, 0.29031292386965585], 
reward next is 0.7097, 
noisyNet noise sample is [array([-0.8242114], dtype=float32), 0.7761702]. 
=============================================
[2019-03-26 18:01:29,918] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.21883975e-14 1.00000000e+00 2.59267223e-17 3.18989796e-14
 8.38352559e-26], sum to 1.0000
[2019-03-26 18:01:29,930] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7408
[2019-03-26 18:01:29,935] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.95, 81.0, 1.0, 2.0, 0.5278805504544675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 737644.5803271668, 737644.5803271674, 188079.6796327491], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2338200.0000, 
sim time next is 2338800.0000, 
raw observation next is [27.9, 81.0, 1.0, 2.0, 0.5258523360577524, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 734809.4335724213, 734809.4335724219, 187745.7522814385], 
processed observation next is [1.0, 0.043478260869565216, 0.5213270142180094, 0.81, 1.0, 1.0, 0.4287377542864486, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2041137315478948, 0.20411373154789497, 0.2802175407185649], 
reward next is 0.7198, 
noisyNet noise sample is [array([0.86849564], dtype=float32), -0.36873528]. 
=============================================
[2019-03-26 18:01:31,487] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.4914781e-15 1.0000000e+00 1.3271209e-16 2.1424675e-13 2.1098220e-25], sum to 1.0000
[2019-03-26 18:01:31,496] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8343
[2019-03-26 18:01:31,502] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.36666666666667, 72.5, 1.0, 2.0, 0.8230301068088046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1150301.149550287, 1150301.149550286, 249641.8106628332], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2361000.0000, 
sim time next is 2361600.0000, 
raw observation next is [29.5, 72.0, 1.0, 2.0, 0.855149821951676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1195218.267409612, 1195218.267409612, 257897.9041275255], 
processed observation next is [1.0, 0.34782608695652173, 0.5971563981042655, 0.72, 1.0, 1.0, 0.8254817131947904, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3320050742804478, 0.3320050742804478, 0.38492224496645594], 
reward next is 0.6151, 
noisyNet noise sample is [array([1.1693186], dtype=float32), 0.20964342]. 
=============================================
[2019-03-26 18:01:32,604] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-26 18:01:32,606] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 18:01:32,608] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 18:01:32,608] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:01:32,609] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 18:01:32,610] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 18:01:32,611] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 18:01:32,612] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:01:32,613] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:01:32,615] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:01:32,609] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:01:32,643] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run80
[2019-03-26 18:01:32,666] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run80
[2019-03-26 18:01:32,667] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run80
[2019-03-26 18:01:32,713] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run80
[2019-03-26 18:01:32,714] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run80
[2019-03-26 18:01:54,451] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10885241], dtype=float32), 0.0913153]
[2019-03-26 18:01:54,452] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [22.85, 81.66666666666666, 1.0, 2.0, 0.3301117675513057, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 518870.0966742033, 518870.0966742039, 168402.8215058543]
[2019-03-26 18:01:54,454] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 18:01:54,459] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [6.4771544e-17 1.0000000e+00 3.1970999e-20 7.9164876e-21 1.4002615e-29], sampled 0.3194355448877856
[2019-03-26 18:01:58,646] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10885241], dtype=float32), 0.0913153]
[2019-03-26 18:01:58,647] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [21.72162129666667, 95.57338667333333, 1.0, 2.0, 0.3556906077715093, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 549717.6624235968, 549717.6624235975, 170671.2895525019]
[2019-03-26 18:01:58,649] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:01:58,652] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.5416264e-16 1.0000000e+00 1.9127068e-19 9.5755989e-19 1.1660374e-28], sampled 0.29477440374255426
[2019-03-26 18:02:27,154] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10885241], dtype=float32), 0.0913153]
[2019-03-26 18:02:27,154] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.2, 71.0, 1.0, 2.0, 0.5541754523891513, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 774401.6881422515, 774401.6881422515, 192518.9909985608]
[2019-03-26 18:02:27,156] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 18:02:27,158] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.3909651e-16 1.0000000e+00 4.2069377e-19 9.5578677e-18 5.7564308e-28], sampled 0.2646885706587916
[2019-03-26 18:02:33,311] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10885241], dtype=float32), 0.0913153]
[2019-03-26 18:02:33,312] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [30.43903948, 79.53613287, 1.0, 2.0, 0.6590544236781771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 921022.5219949716, 921022.5219949721, 212260.8908900346]
[2019-03-26 18:02:33,314] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:02:33,317] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.5501121e-16 1.0000000e+00 3.8386374e-19 8.2967724e-17 2.0632025e-28], sampled 0.4426535700985381
[2019-03-26 18:02:45,824] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10885241], dtype=float32), 0.0913153]
[2019-03-26 18:02:45,825] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [33.88333333333333, 58.66666666666667, 1.0, 2.0, 0.6271201283150794, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 876376.2240812539, 876376.2240812533, 205904.750756233]
[2019-03-26 18:02:45,826] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 18:02:45,829] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.1787074e-16 1.0000000e+00 3.1246257e-19 3.7213743e-18 1.8720502e-28], sampled 0.008332011264698624
[2019-03-26 18:02:51,678] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10885241], dtype=float32), 0.0913153]
[2019-03-26 18:02:51,680] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.8, 82.0, 1.0, 2.0, 1.007630450325946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1408477.416688641, 1408477.416688641, 301261.517850252]
[2019-03-26 18:02:51,682] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 18:02:51,684] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.5963200e-15 1.0000000e+00 7.2116029e-18 5.6235036e-16 1.2868672e-26], sampled 0.31715447286612897
[2019-03-26 18:03:09,743] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10885241], dtype=float32), 0.0913153]
[2019-03-26 18:03:09,745] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [34.63333333333334, 50.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.341261899215445, 6.9112, 168.9101943471941, 1759059.616740136, 1453963.893033359, 311351.27217473]
[2019-03-26 18:03:09,746] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 18:03:09,749] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.6324691e-15 1.0000000e+00 1.5205935e-17 5.3652710e-15 3.1046776e-26], sampled 0.3680578128947817
[2019-03-26 18:03:09,751] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1759059.616740136 W.
[2019-03-26 18:03:14,434] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10885241], dtype=float32), 0.0913153]
[2019-03-26 18:03:14,435] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.0, 81.0, 1.0, 2.0, 0.537309990994946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 765116.9800715566, 765116.9800715559, 191474.8870578634]
[2019-03-26 18:03:14,436] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 18:03:14,439] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.5425655e-16 1.0000000e+00 3.5754383e-19 1.5010323e-18 2.8127901e-28], sampled 0.4065172051451371
[2019-03-26 18:03:15,451] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10885241], dtype=float32), 0.0913153]
[2019-03-26 18:03:15,453] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [22.64473701, 95.94471845, 1.0, 2.0, 0.3998878934239565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 599030.5344483143, 599030.5344483149, 174513.2181067945]
[2019-03-26 18:03:15,454] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:03:15,456] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [8.0255419e-17 1.0000000e+00 7.7729438e-20 5.1181025e-19 3.4179945e-29], sampled 0.6027696043546268
[2019-03-26 18:03:25,578] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8551.6628 2835639599.3472 969.0000
[2019-03-26 18:03:26,202] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8679.4893 2777300831.7287 884.0000
[2019-03-26 18:03:26,309] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8318.9329 2920871339.3275 1145.0000
[2019-03-26 18:03:26,311] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 8027.4150 3147868327.8257 1325.0000
[2019-03-26 18:03:26,467] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8143.0429 2991370588.8747 1354.0000
[2019-03-26 18:03:27,484] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1975000, evaluation results [1975000.0, 8027.414958814775, 3147868327.8257484, 1325.0, 8318.932925286641, 2920871339.3274655, 1145.0, 8679.489291201138, 2777300831.728718, 884.0, 8143.042866005777, 2991370588.8747206, 1354.0, 8551.662762507594, 2835639599.3472257, 969.0]
[2019-03-26 18:03:28,972] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.0252228e-10 5.3849579e-03 3.9233508e-10 9.9461502e-01 3.6360795e-17], sum to 1.0000
[2019-03-26 18:03:28,983] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5481
[2019-03-26 18:03:28,988] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.3, 64.0, 1.0, 2.0, 0.8738566233478515, 1.0, 2.0, 0.8738566233478515, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2444100.270730732, 2444100.270730732, 457430.8286580808], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2374200.0000, 
sim time next is 2374800.0000, 
raw observation next is [32.33333333333334, 64.0, 1.0, 2.0, 0.8743331273040499, 1.0, 2.0, 0.8743331273040499, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2445434.314568075, 2445434.314568074, 457683.7532726572], 
processed observation next is [1.0, 0.4782608695652174, 0.7314375987361774, 0.64, 1.0, 1.0, 0.8485941292819879, 1.0, 1.0, 0.8485941292819879, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.679287309602243, 0.6792873096022428, 0.6831100795114287], 
reward next is 0.3169, 
noisyNet noise sample is [array([0.7910478], dtype=float32), 0.10302793]. 
=============================================
[2019-03-26 18:03:29,727] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.6533545e-12 3.4201436e-02 9.7488042e-12 9.6579862e-01 6.6793754e-19], sum to 1.0000
[2019-03-26 18:03:29,739] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0921
[2019-03-26 18:03:29,742] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.06666666666667, 60.83333333333333, 1.0, 2.0, 0.3969563528064545, 1.0, 2.0, 0.3969563528064545, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1109578.605206887, 1109578.605206887, 271371.7390708911], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2394600.0000, 
sim time next is 2395200.0000, 
raw observation next is [32.93333333333334, 61.66666666666667, 1.0, 2.0, 0.2656599325242986, 1.0, 2.0, 0.2656599325242986, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 742449.7542786436, 742449.7542786436, 243596.6780878715], 
processed observation next is [1.0, 0.7391304347826086, 0.7598736176935231, 0.6166666666666667, 1.0, 1.0, 0.11525293075216697, 1.0, 1.0, 0.11525293075216697, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.2062360428551788, 0.2062360428551788, 0.36357713147443504], 
reward next is 0.6364, 
noisyNet noise sample is [array([0.89459115], dtype=float32), -0.6372741]. 
=============================================
[2019-03-26 18:03:31,001] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.6682705e-16 1.0000000e+00 3.0044761e-19 2.4424845e-17 1.3301140e-27], sum to 1.0000
[2019-03-26 18:03:31,011] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8418
[2019-03-26 18:03:31,017] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 92.33333333333334, 1.0, 2.0, 0.5761807441617123, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 884800.8871292019, 884800.8871292025, 206028.3130815259], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3140400.0000, 
sim time next is 3141000.0000, 
raw observation next is [22.5, 91.5, 1.0, 2.0, 0.6531035362529316, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1000958.272467623, 1000958.272467623, 221994.5514946665], 
processed observation next is [1.0, 0.34782608695652173, 0.2654028436018958, 0.915, 1.0, 1.0, 0.582052453316785, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2780439645743397, 0.2780439645743397, 0.3313351514845769], 
reward next is 0.6687, 
noisyNet noise sample is [array([-0.55434036], dtype=float32), -0.43634763]. 
=============================================
[2019-03-26 18:03:31,030] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[70.20453 ]
 [70.60131 ]
 [70.585915]
 [70.486534]
 [70.48801 ]], R is [[69.74545288]
 [69.74049377]
 [69.78067017]
 [69.82439423]
 [69.86323547]].
[2019-03-26 18:03:32,928] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.5049139e-16 1.0000000e+00 2.3105292e-19 4.5235034e-19 4.2759542e-29], sum to 1.0000
[2019-03-26 18:03:32,935] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8707
[2019-03-26 18:03:32,942] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.16666666666667, 89.0, 1.0, 2.0, 0.4750088158621437, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 666012.16823512, 666012.16823512, 180066.1552623873], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2656200.0000, 
sim time next is 2656800.0000, 
raw observation next is [25.0, 89.0, 1.0, 2.0, 0.4657907796082175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 657914.0540058315, 657914.0540058315, 179319.7866438999], 
processed observation next is [0.0, 0.782608695652174, 0.38388625592417064, 0.89, 1.0, 1.0, 0.35637443326291274, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18275390389050875, 0.18275390389050875, 0.26764147260283566], 
reward next is 0.7324, 
noisyNet noise sample is [array([1.4024719], dtype=float32), 0.08210672]. 
=============================================
[2019-03-26 18:03:51,133] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.5900738e-16 1.0000000e+00 2.0617172e-19 8.9695723e-19 1.9595422e-29], sum to 1.0000
[2019-03-26 18:03:51,145] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6320
[2019-03-26 18:03:51,151] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 96.0, 1.0, 2.0, 0.337116271885331, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 520451.6342583667, 520451.6342583673, 168272.3744305947], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2776800.0000, 
sim time next is 2777400.0000, 
raw observation next is [21.5, 97.0, 1.0, 2.0, 0.3334609077491934, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 515505.4628424659, 515505.4628424659, 167904.5039443714], 
processed observation next is [1.0, 0.13043478260869565, 0.21800947867298584, 0.97, 1.0, 1.0, 0.19694085270987158, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14319596190068498, 0.14319596190068498, 0.2506037372304051], 
reward next is 0.7494, 
noisyNet noise sample is [array([-1.1411238], dtype=float32), 1.1213466]. 
=============================================
[2019-03-26 18:03:53,710] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.9335501e-16 1.0000000e+00 8.8023572e-20 5.0315726e-18 2.4656687e-28], sum to 1.0000
[2019-03-26 18:03:53,719] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3761
[2019-03-26 18:03:53,728] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.3039678834542239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 484051.0362989192, 484051.0362989186, 165912.9389391483], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3010800.0000, 
sim time next is 3011400.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.3041065107829917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 484272.064722271, 484272.064722271, 165928.8890831842], 
processed observation next is [1.0, 0.8695652173913043, 0.1469194312796209, 1.0, 1.0, 1.0, 0.16157410937709846, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13452001797840862, 0.13452001797840862, 0.24765505833311077], 
reward next is 0.7523, 
noisyNet noise sample is [array([0.13856445], dtype=float32), 0.54447794]. 
=============================================
[2019-03-26 18:03:56,985] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.4472328e-16 1.0000000e+00 2.3074464e-19 2.5003860e-18 6.5585204e-28], sum to 1.0000
[2019-03-26 18:03:56,992] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2882
[2019-03-26 18:03:56,999] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.3482396457427301, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 536454.1334988913, 536454.1334988913, 169525.7583088381], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2875200.0000, 
sim time next is 2875800.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.3474840441343431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 535290.2104987665, 535290.2104987672, 169430.6731444829], 
processed observation next is [1.0, 0.2608695652173913, 0.2417061611374408, 0.94, 1.0, 1.0, 0.21383619775222057, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14869172513854625, 0.14869172513854645, 0.2528816017081834], 
reward next is 0.7471, 
noisyNet noise sample is [array([-0.6969126], dtype=float32), 1.2507755]. 
=============================================
[2019-03-26 18:03:57,024] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.0057012e-16 1.0000000e+00 3.1316900e-19 9.6134848e-18 7.6624784e-29], sum to 1.0000
[2019-03-26 18:03:57,033] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6097
[2019-03-26 18:03:57,038] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 97.0, 1.0, 2.0, 0.3926630830326238, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 588240.3927870096, 588240.3927870103, 173526.4117950871], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3119400.0000, 
sim time next is 3120000.0000, 
raw observation next is [22.33333333333334, 98.0, 1.0, 2.0, 0.3857961973768184, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 578874.8120788713, 578874.8120788713, 172707.3047827693], 
processed observation next is [1.0, 0.08695652173913043, 0.2575039494470777, 0.98, 1.0, 1.0, 0.25999541852628727, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16079855891079758, 0.16079855891079758, 0.25777209669070045], 
reward next is 0.7422, 
noisyNet noise sample is [array([-1.0042982], dtype=float32), 1.1040057]. 
=============================================
[2019-03-26 18:03:57,053] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[72.3297 ]
 [72.23486]
 [71.9998 ]
 [72.16783]
 [72.08601]], R is [[72.36631775]
 [72.38365936]
 [72.39699554]
 [72.39260101]
 [72.41031647]].
[2019-03-26 18:03:58,980] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.5562893e-17 1.0000000e+00 1.5194496e-19 2.5079408e-19 3.7809799e-29], sum to 1.0000
[2019-03-26 18:03:58,993] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8263
[2019-03-26 18:03:59,000] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.00000000000001, 1.0, 2.0, 0.3578061486825639, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 551189.273692111, 551189.273692111, 170746.0739588929], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2877000.0000, 
sim time next is 2877600.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.3449059683428146, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 531314.878465243, 531314.8784652436, 169107.2311510369], 
processed observation next is [1.0, 0.30434782608695654, 0.2417061611374408, 0.94, 1.0, 1.0, 0.2107300823407405, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1475874662403453, 0.14758746624034544, 0.25239885246423416], 
reward next is 0.7476, 
noisyNet noise sample is [array([-0.28359598], dtype=float32), -0.6776553]. 
=============================================
[2019-03-26 18:04:01,286] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.3930419e-16 1.0000000e+00 3.9575609e-18 1.0679232e-15 9.8265992e-27], sum to 1.0000
[2019-03-26 18:04:01,293] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0846
[2019-03-26 18:04:01,297] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 91.5, 1.0, 2.0, 0.691377519829407, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1058189.701077414, 1058189.701077414, 230590.0933971494], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2907000.0000, 
sim time next is 2907600.0000, 
raw observation next is [22.33333333333334, 92.33333333333334, 1.0, 2.0, 0.6938240014645728, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1063880.020833004, 1063880.020833004, 231383.7439126078], 
processed observation next is [1.0, 0.6521739130434783, 0.2575039494470777, 0.9233333333333335, 1.0, 1.0, 0.6311132547765937, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2955222280091678, 0.2955222280091678, 0.34534887151135496], 
reward next is 0.6547, 
noisyNet noise sample is [array([-1.3096068], dtype=float32), 1.103806]. 
=============================================
[2019-03-26 18:04:12,075] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.9949889e-17 1.0000000e+00 1.4022456e-20 9.2854772e-21 6.6143672e-30], sum to 1.0000
[2019-03-26 18:04:12,078] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8458
[2019-03-26 18:04:12,085] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 74.0, 1.0, 2.0, 0.4830576255237365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 674990.4584296432, 674990.4584296439, 180984.4103177766], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3229200.0000, 
sim time next is 3229800.0000, 
raw observation next is [28.16666666666667, 74.83333333333334, 1.0, 2.0, 0.4896412377836521, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 684192.8937446977, 684192.8937446977, 181989.5898148881], 
processed observation next is [0.0, 0.391304347826087, 0.5339652448657191, 0.7483333333333334, 1.0, 1.0, 0.38510992504054464, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19005358159574937, 0.19005358159574937, 0.27162625345505687], 
reward next is 0.7284, 
noisyNet noise sample is [array([-0.03607777], dtype=float32), -0.92116034]. 
=============================================
[2019-03-26 18:04:15,086] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0355761e-15 1.0000000e+00 1.2832497e-18 1.6831564e-17 2.7123301e-27], sum to 1.0000
[2019-03-26 18:04:15,100] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7703
[2019-03-26 18:04:15,105] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.16666666666667, 89.0, 1.0, 2.0, 0.6362739479298782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 965837.7640789308, 965837.7640789314, 217252.5311161857], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3143400.0000, 
sim time next is 3144000.0000, 
raw observation next is [23.33333333333334, 89.0, 1.0, 2.0, 0.6353656039245327, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 959454.6949367183, 959454.6949367183, 216482.4968872991], 
processed observation next is [1.0, 0.391304347826087, 0.3048973143759877, 0.89, 1.0, 1.0, 0.5606814505114851, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2665151930379773, 0.2665151930379773, 0.3231082043094016], 
reward next is 0.6769, 
noisyNet noise sample is [array([-1.2306615], dtype=float32), 1.651062]. 
=============================================
[2019-03-26 18:04:15,118] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[69.41632]
 [69.39273]
 [69.43683]
 [69.68505]
 [70.01253]], R is [[69.43549347]
 [69.41688538]
 [69.39093018]
 [69.35645294]
 [69.32636261]].
[2019-03-26 18:04:20,133] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.1597144e-16 1.0000000e+00 1.2098545e-19 4.3497771e-20 3.1991333e-30], sum to 1.0000
[2019-03-26 18:04:20,144] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7883
[2019-03-26 18:04:20,151] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.66666666666666, 77.33333333333333, 1.0, 2.0, 0.5156798263094226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 720589.8685582536, 720589.8685582536, 186090.4566880261], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3231600.0000, 
sim time next is 3232200.0000, 
raw observation next is [28.83333333333334, 78.16666666666667, 1.0, 2.0, 0.5251002316093973, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 733758.1036003145, 733758.1036003145, 187623.5510522571], 
processed observation next is [0.0, 0.391304347826087, 0.5655608214849924, 0.7816666666666667, 1.0, 1.0, 0.42783160434867146, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2038216954445318, 0.2038216954445318, 0.28003515082426433], 
reward next is 0.7200, 
noisyNet noise sample is [array([-0.89616007], dtype=float32), -0.1541609]. 
=============================================
[2019-03-26 18:04:23,003] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-26 18:04:23,006] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 18:04:23,007] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:04:23,007] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 18:04:23,009] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 18:04:23,011] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:04:23,011] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 18:04:23,012] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:04:23,008] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 18:04:23,015] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:04:23,021] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:04:23,915] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run81
[2019-03-26 18:04:23,978] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run81
[2019-03-26 18:04:23,984] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run81
[2019-03-26 18:04:24,359] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run81
[2019-03-26 18:04:24,800] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run81
[2019-03-26 18:04:27,357] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10872493], dtype=float32), 0.09127503]
[2019-03-26 18:04:27,358] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [21.35, 62.16666666666666, 1.0, 2.0, 0.2160700605558726, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 360555.9179635464, 360555.9179635458, 157043.8739761185]
[2019-03-26 18:04:27,359] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:04:27,362] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [9.8670292e-17 1.0000000e+00 7.3406024e-20 3.2513639e-20 5.7182148e-29], sampled 0.3849532668229224
[2019-03-26 18:05:08,052] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10872493], dtype=float32), 0.09127503]
[2019-03-26 18:05:08,054] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.0, 94.0, 1.0, 2.0, 0.3514967435835583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 541706.0223128739, 541706.0223128739, 169964.0671676623]
[2019-03-26 18:05:08,056] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 18:05:08,059] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.9262707e-17 1.0000000e+00 2.5142235e-20 6.9756771e-21 1.0257749e-29], sampled 0.867984726506539
[2019-03-26 18:05:38,847] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10872493], dtype=float32), 0.09127503]
[2019-03-26 18:05:38,848] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.8, 79.0, 1.0, 2.0, 0.5473916124312921, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 764918.5746976368, 764918.5746976368, 191354.3720096959]
[2019-03-26 18:05:38,849] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 18:05:38,854] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [4.4620859e-16 1.0000000e+00 1.0983505e-18 5.5225669e-16 1.0153115e-27], sampled 0.3007397096321678
[2019-03-26 18:05:50,456] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10872493], dtype=float32), 0.09127503]
[2019-03-26 18:05:50,459] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [30.32145488666666, 81.24459294, 1.0, 2.0, 0.9206367574255109, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129010385984, 1286802.936869151, 1286802.936869151, 275683.1466502074]
[2019-03-26 18:05:50,459] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 18:05:50,462] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.702258e-14 1.000000e+00 5.763607e-16 7.116522e-12 8.967458e-25], sampled 0.27163488926400203
[2019-03-26 18:05:58,450] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10872493], dtype=float32), 0.09127503]
[2019-03-26 18:05:58,451] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.55, 76.5, 1.0, 2.0, 0.6802466394553881, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.980116111180164, 6.9112, 168.9124908916374, 1847487.211778976, 1798595.885370548, 381348.0193864296]
[2019-03-26 18:05:58,453] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 18:05:58,455] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [8.5288367e-11 9.9999928e-01 2.9166728e-11 7.1696769e-07 2.1590953e-18], sampled 0.7895629170988961
[2019-03-26 18:05:58,457] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1847487.211778976 W.
[2019-03-26 18:06:05,785] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10872493], dtype=float32), 0.09127503]
[2019-03-26 18:06:05,786] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [24.0, 95.0, 1.0, 2.0, 0.5141674473029951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 734205.7616544202, 734205.7616544209, 187852.6115572024]
[2019-03-26 18:06:05,787] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 18:06:05,793] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.3282453e-16 1.0000000e+00 1.8098024e-19 2.4681172e-19 1.1978859e-28], sampled 0.9121940900182657
[2019-03-26 18:06:17,172] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8313.7064 2921150112.9012 1179.0000
[2019-03-26 18:06:17,764] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8108.7952 2993862693.2063 1412.0000
[2019-03-26 18:06:17,797] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 8018.1480 3150448522.0244 1393.0000
[2019-03-26 18:06:17,995] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8545.8944 2836908962.4174 986.0000
[2019-03-26 18:06:18,295] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8667.3858 2778018309.6279 900.0000
[2019-03-26 18:06:19,313] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 2000000, evaluation results [2000000.0, 8018.147975572845, 3150448522.0243673, 1393.0, 8313.706444816902, 2921150112.901227, 1179.0, 8667.385819697203, 2778018309.627869, 900.0, 8108.7952127859635, 2993862693.20625, 1412.0, 8545.894445490736, 2836908962.417436, 986.0]
[2019-03-26 18:06:20,354] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.7954130e-16 1.0000000e+00 6.2227156e-20 3.2287948e-20 2.4973598e-29], sum to 1.0000
[2019-03-26 18:06:20,363] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7057
[2019-03-26 18:06:20,368] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.480609474195439, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 671568.5041160118, 671568.5041160111, 180613.7178263492], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3310200.0000, 
sim time next is 3310800.0000, 
raw observation next is [27.33333333333333, 77.33333333333333, 1.0, 2.0, 0.4831848330666783, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 675168.2657133715, 675168.2657133715, 181003.4236145625], 
processed observation next is [0.0, 0.30434782608695654, 0.494470774091627, 0.7733333333333333, 1.0, 1.0, 0.3773311241767209, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1875467404759365, 0.1875467404759365, 0.2701543636038246], 
reward next is 0.7298, 
noisyNet noise sample is [array([-1.0025512], dtype=float32), 0.80448544]. 
=============================================
[2019-03-26 18:06:24,235] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.1665518e-16 1.0000000e+00 3.2196105e-18 9.2686150e-17 2.6640437e-26], sum to 1.0000
[2019-03-26 18:06:24,244] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1948
[2019-03-26 18:06:24,250] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.8, 90.33333333333334, 1.0, 2.0, 0.5372417824557576, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 750730.3100555604, 750730.310055561, 189636.7238444064], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3372000.0000, 
sim time next is 3372600.0000, 
raw observation next is [26.75, 90.66666666666667, 1.0, 2.0, 0.5371298264495912, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 750573.8098263108, 750573.8098263108, 189617.9473488054], 
processed observation next is [1.0, 0.0, 0.4668246445497631, 0.9066666666666667, 1.0, 1.0, 0.44232509210794113, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.208492724951753, 0.208492724951753, 0.28301186171463494], 
reward next is 0.7170, 
noisyNet noise sample is [array([0.16767643], dtype=float32), -0.13181144]. 
=============================================
[2019-03-26 18:06:27,358] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.9244235e-16 1.0000000e+00 7.9461799e-18 4.0178484e-16 3.1429990e-27], sum to 1.0000
[2019-03-26 18:06:27,365] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5383
[2019-03-26 18:06:27,370] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.5087901389756155, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 710959.2798855759, 710959.2798855753, 184984.8540444339], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3456600.0000, 
sim time next is 3457200.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.5085543023491554, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 710629.6227059133, 710629.6227059127, 184947.3115575033], 
processed observation next is [1.0, 0.0, 0.4786729857819906, 0.84, 1.0, 1.0, 0.4078967498182595, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19739711741830923, 0.19739711741830906, 0.27604076351866164], 
reward next is 0.7240, 
noisyNet noise sample is [array([2.0028439], dtype=float32), 2.5945024]. 
=============================================
[2019-03-26 18:06:31,226] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.5381148e-16 1.0000000e+00 2.3909977e-17 1.4792742e-12 5.1584031e-26], sum to 1.0000
[2019-03-26 18:06:31,234] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7036
[2019-03-26 18:06:31,239] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 77.33333333333334, 1.0, 2.0, 0.5458690742630228, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 762790.2339132758, 762790.2339132765, 191094.7013062788], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3698400.0000, 
sim time next is 3699000.0000, 
raw observation next is [29.0, 76.5, 1.0, 2.0, 0.5413980553911583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 756540.2662723038, 756540.2662723038, 190336.320302138], 
processed observation next is [1.0, 0.8260869565217391, 0.5734597156398105, 0.765, 1.0, 1.0, 0.4474675366158533, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2101500739645288, 0.2101500739645288, 0.28408406015244475], 
reward next is 0.7159, 
noisyNet noise sample is [array([0.5909865], dtype=float32), -0.8370834]. 
=============================================
[2019-03-26 18:06:31,259] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[71.05532 ]
 [71.79855 ]
 [72.396805]
 [73.021416]
 [73.45238 ]], R is [[70.32701111]
 [70.33852386]
 [70.34924316]
 [70.35927582]
 [70.36878967]].
[2019-03-26 18:06:32,422] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.9776037e-16 1.0000000e+00 9.2700911e-19 5.6920275e-16 4.1117884e-27], sum to 1.0000
[2019-03-26 18:06:32,433] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7396
[2019-03-26 18:06:32,438] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 79.0, 1.0, 2.0, 0.519240429844908, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 725567.0093477033, 725567.0093477033, 186665.4998872212], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3540600.0000, 
sim time next is 3541200.0000, 
raw observation next is [28.0, 79.0, 1.0, 2.0, 0.5192310005660238, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 725553.8287288164, 725553.828728817, 186663.9693649771], 
processed observation next is [1.0, 1.0, 0.5260663507109005, 0.79, 1.0, 1.0, 0.42076024164581177, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20154273020244898, 0.20154273020244917, 0.27860293935071206], 
reward next is 0.7214, 
noisyNet noise sample is [array([-0.6706796], dtype=float32), -1.072979]. 
=============================================
[2019-03-26 18:06:45,771] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.0997781e-17 1.0000000e+00 5.2475330e-20 1.9371957e-19 4.6368322e-29], sum to 1.0000
[2019-03-26 18:06:45,778] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5369
[2019-03-26 18:06:45,783] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 75.0, 1.0, 2.0, 0.632968016525192, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 884551.8256887555, 884551.8256887548, 207049.2942383701], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4444200.0000, 
sim time next is 4444800.0000, 
raw observation next is [32.0, 75.0, 1.0, 2.0, 0.632362869431495, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 883705.8008596677, 883705.8008596677, 206930.7413228846], 
processed observation next is [0.0, 0.43478260869565216, 0.7156398104265403, 0.75, 1.0, 1.0, 0.5570636981102349, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.24547383357212993, 0.24547383357212993, 0.3088518527207233], 
reward next is 0.6911, 
noisyNet noise sample is [array([0.15379946], dtype=float32), -0.36576188]. 
=============================================
[2019-03-26 18:06:47,293] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.5441278e-17 1.0000000e+00 1.1816795e-19 3.9261789e-18 2.8714406e-29], sum to 1.0000
[2019-03-26 18:06:47,304] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7186
[2019-03-26 18:06:47,312] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.33333333333334, 82.33333333333334, 1.0, 2.0, 0.6210960742048425, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 867954.4007017325, 867954.4007017325, 204742.1950792598], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3973200.0000, 
sim time next is 3973800.0000, 
raw observation next is [30.16666666666666, 83.16666666666666, 1.0, 2.0, 0.6205568352776938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 867200.5304170754, 867200.5304170754, 204638.3574451312], 
processed observation next is [0.0, 1.0, 0.6287519747235385, 0.8316666666666666, 1.0, 1.0, 0.5428395605755346, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2408890362269654, 0.2408890362269654, 0.30543038424646446], 
reward next is 0.6946, 
noisyNet noise sample is [array([2.0271113], dtype=float32), 0.4009573]. 
=============================================
[2019-03-26 18:06:47,412] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.1394073e-14 9.6837596e-08 1.2963115e-12 9.9999988e-01 1.5524412e-19], sum to 1.0000
[2019-03-26 18:06:47,421] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7914
[2019-03-26 18:06:47,429] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.33333333333334, 63.16666666666666, 1.0, 2.0, 0.9167757733306382, 1.0, 2.0, 0.9167757733306382, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2564264.54083844, 2564264.54083844, 480732.6421234999], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4032600.0000, 
sim time next is 4033200.0000, 
raw observation next is [32.66666666666667, 66.33333333333334, 1.0, 2.0, 0.9321738894127911, 1.0, 2.0, 0.9321738894127911, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2607378.728369007, 2607378.728369007, 489354.0994067359], 
processed observation next is [1.0, 0.6956521739130435, 0.7472353870458138, 0.6633333333333334, 1.0, 1.0, 0.9182817944732423, 1.0, 1.0, 0.9182817944732423, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7242718689913908, 0.7242718689913908, 0.7303792528458745], 
reward next is 0.2696, 
noisyNet noise sample is [array([-1.111136], dtype=float32), -2.149821]. 
=============================================
[2019-03-26 18:06:49,046] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.7960018e-14 4.8013586e-08 1.5507718e-12 1.0000000e+00 8.0624517e-18], sum to 1.0000
[2019-03-26 18:06:49,057] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7502
[2019-03-26 18:06:49,065] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [36.0, 56.33333333333333, 1.0, 2.0, 0.8996370565638383, 1.0, 2.0, 0.7704085677961819, 1.0, 2.0, 1.03, 7.005113478635004, 6.9112, 170.5573041426782, 3233167.536345979, 3165893.49144366, 591804.3675951877], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4197000.0000, 
sim time next is 4197600.0000, 
raw observation next is [36.0, 57.0, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 7.87214610953406, 6.9112, 170.5573041426782, 3598496.423350702, 2910131.636302901, 548140.9154395369], 
processed observation next is [1.0, 0.6086956521739131, 0.9052132701421801, 0.57, 1.0, 1.0, 1.0481927710843375, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.2195121951219512, 0.09609461095340599, 0.0, 0.8375144448122397, 0.9995823398196395, 0.808369898973028, 0.8181207693127417], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0320303], dtype=float32), -1.3797499]. 
=============================================
[2019-03-26 18:06:50,255] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1896559e-15 1.0000000e+00 1.5543375e-19 3.6218925e-19 4.4698788e-28], sum to 1.0000
[2019-03-26 18:06:50,264] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3181
[2019-03-26 18:06:50,273] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 0.5348235321367516, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 747349.9094147426, 747349.9094147426, 189232.2036326701], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3813600.0000, 
sim time next is 3814200.0000, 
raw observation next is [27.0, 89.0, 1.0, 2.0, 0.5348095010040107, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 747330.2957404146, 747330.2957404152, 189229.8614114463], 
processed observation next is [0.0, 0.13043478260869565, 0.4786729857819906, 0.89, 1.0, 1.0, 0.43952951928194056, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20759174881678186, 0.207591748816782, 0.2824326289723079], 
reward next is 0.7176, 
noisyNet noise sample is [array([-0.07994729], dtype=float32), 0.51704615]. 
=============================================
[2019-03-26 18:06:50,275] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.7541755e-18 1.0000000e+00 3.1366980e-20 2.2654926e-20 3.0298856e-29], sum to 1.0000
[2019-03-26 18:06:50,287] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0770
[2019-03-26 18:06:50,294] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.5134148259972892, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 717423.7810905465, 717423.7810905459, 185724.3795693072], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4521000.0000, 
sim time next is 4521600.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.5131814695597957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 717097.5887832848, 717097.5887832848, 185686.9122256765], 
processed observation next is [0.0, 0.34782608695652173, 0.4786729857819906, 0.84, 1.0, 1.0, 0.413471650072043, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19919377466202354, 0.19919377466202354, 0.27714464511295], 
reward next is 0.7229, 
noisyNet noise sample is [array([-0.46292567], dtype=float32), -0.5350292]. 
=============================================
[2019-03-26 18:07:01,526] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.4459137e-13 9.9999654e-01 3.3420928e-14 3.5092783e-06 3.5184294e-23], sum to 1.0000
[2019-03-26 18:07:01,534] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2627
[2019-03-26 18:07:01,541] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.66666666666666, 76.33333333333333, 1.0, 2.0, 0.6211045600646814, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 867966.2641625409, 867966.2641625409, 204744.6780789671], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4128000.0000, 
sim time next is 4128600.0000, 
raw observation next is [31.33333333333334, 77.66666666666667, 1.0, 2.0, 0.6193364997335836, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 865494.4710205401, 865494.4710205394, 204404.552864512], 
processed observation next is [1.0, 0.782608695652174, 0.6840442338072673, 0.7766666666666667, 1.0, 1.0, 0.5413692767874502, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.24041513083903893, 0.24041513083903873, 0.3050814221858388], 
reward next is 0.6949, 
noisyNet noise sample is [array([0.53737193], dtype=float32), -0.9280458]. 
=============================================
[2019-03-26 18:07:01,860] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.6571206e-11 1.8551067e-03 6.1390981e-10 9.9814487e-01 2.6992391e-16], sum to 1.0000
[2019-03-26 18:07:01,868] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3192
[2019-03-26 18:07:01,876] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.0, 70.0, 1.0, 2.0, 0.8944098594307669, 1.0, 2.0, 0.8944098594307669, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2501643.412355355, 2501643.412355355, 468444.6793009068], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4012200.0000, 
sim time next is 4012800.0000, 
raw observation next is [30.33333333333333, 68.66666666666667, 1.0, 2.0, 0.9041927738088437, 1.0, 2.0, 0.9041927738088437, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2529033.685978529, 2529033.68597853, 473778.2478681711], 
processed observation next is [1.0, 0.43478260869565216, 0.6366508688783569, 0.6866666666666668, 1.0, 1.0, 0.8845696069986069, 1.0, 1.0, 0.8845696069986069, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.7025093572162581, 0.7025093572162583, 0.7071317132360763], 
reward next is 0.2929, 
noisyNet noise sample is [array([-1.3908159], dtype=float32), -0.7170759]. 
=============================================
[2019-03-26 18:07:02,300] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.1221044e-16 1.0000000e+00 2.1331704e-17 4.7645910e-13 7.0899706e-26], sum to 1.0000
[2019-03-26 18:07:02,310] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7754
[2019-03-26 18:07:02,317] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 84.0, 1.0, 2.0, 0.5449808257091711, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 761548.5621678563, 761548.5621678557, 190943.7741778573], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4046400.0000, 
sim time next is 4047000.0000, 
raw observation next is [28.0, 84.0, 1.0, 2.0, 0.5452465447021885, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 761920.0073329152, 761920.0073329152, 190988.9409948862], 
processed observation next is [1.0, 0.8695652173913043, 0.5260663507109005, 0.84, 1.0, 1.0, 0.4521042707255283, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21164444648136532, 0.21164444648136532, 0.28505812088788984], 
reward next is 0.7149, 
noisyNet noise sample is [array([-0.9523891], dtype=float32), 0.9002293]. 
=============================================
[2019-03-26 18:07:02,331] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[68.02506 ]
 [68.398766]
 [68.92726 ]
 [69.6498  ]
 [70.192505]], R is [[67.8343277 ]
 [67.87099457]
 [67.90693665]
 [67.94216156]
 [67.97668457]].
[2019-03-26 18:07:09,430] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.1645653e-15 1.0000000e+00 7.5334052e-17 5.2249180e-14 1.6781360e-25], sum to 1.0000
[2019-03-26 18:07:09,436] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0504
[2019-03-26 18:07:09,439] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 89.0, 1.0, 2.0, 0.8809010652799849, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1231230.906649581, 1231230.906649581, 264740.7812458202], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4168200.0000, 
sim time next is 4168800.0000, 
raw observation next is [28.0, 89.0, 1.0, 2.0, 0.8841526440840171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1235778.266542298, 1235778.266542298, 265618.3853730501], 
processed observation next is [1.0, 0.2608695652173913, 0.5260663507109005, 0.89, 1.0, 1.0, 0.860424872390382, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3432717407061939, 0.3432717407061939, 0.39644535130305986], 
reward next is 0.6036, 
noisyNet noise sample is [array([1.8826181], dtype=float32), 1.0587074]. 
=============================================
[2019-03-26 18:07:13,606] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.1144741e-16 1.0000000e+00 1.2535896e-19 5.8144118e-19 2.2460950e-29], sum to 1.0000
[2019-03-26 18:07:13,614] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2020
[2019-03-26 18:07:13,622] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 75.0, 1.0, 2.0, 0.5976065777655433, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 835115.9593134685, 835115.9593134685, 200301.1169543692], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4469400.0000, 
sim time next is 4470000.0000, 
raw observation next is [30.66666666666667, 76.33333333333333, 1.0, 2.0, 0.5949407814006721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 831389.2259173662, 831389.2259173656, 199807.3334906885], 
processed observation next is [0.0, 0.7391304347826086, 0.6524486571879939, 0.7633333333333333, 1.0, 1.0, 0.5119768450610507, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.23094145164371283, 0.2309414516437127, 0.29821990073237087], 
reward next is 0.7018, 
noisyNet noise sample is [array([-0.6340754], dtype=float32), -0.12501475]. 
=============================================
[2019-03-26 18:07:13,637] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[72.17967 ]
 [72.09917 ]
 [72.024025]
 [72.0653  ]
 [72.00736 ]], R is [[72.23525238]
 [72.21394348]
 [72.19024658]
 [72.15530396]
 [72.13237   ]].
[2019-03-26 18:07:14,895] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-26 18:07:14,897] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 18:07:14,898] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 18:07:14,900] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:07:14,900] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 18:07:14,900] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:07:14,901] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:07:14,903] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 18:07:14,902] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 18:07:14,905] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:07:14,905] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:07:14,932] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run82
[2019-03-26 18:07:14,957] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run82
[2019-03-26 18:07:14,983] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run82
[2019-03-26 18:07:15,010] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run82
[2019-03-26 18:07:15,041] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run82
[2019-03-26 18:07:57,865] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10781904], dtype=float32), 0.09052062]
[2019-03-26 18:07:57,867] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [20.69759827, 89.54875623999999, 1.0, 2.0, 0.2938682787592155, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 474367.6053224611, 474367.6053224604, 165260.6956882935]
[2019-03-26 18:07:57,868] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 18:07:57,872] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.4350169e-17 1.0000000e+00 3.7928577e-20 6.6303882e-21 1.6629659e-29], sampled 0.04151410243353282
[2019-03-26 18:08:09,039] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10781904], dtype=float32), 0.09052062]
[2019-03-26 18:08:09,042] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [32.91817371, 71.44641317, 1.0, 2.0, 0.9966866131092025, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005993183235223, 6.9112, 168.9123159291829, 2290364.351954128, 2223115.060272972, 462308.4038642545]
[2019-03-26 18:08:09,044] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:08:09,048] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [5.4626434e-12 1.0000000e+00 4.5617178e-13 3.9281872e-10 1.8941685e-20], sampled 0.10127477115147376
[2019-03-26 18:08:09,048] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2290364.351954128 W.
[2019-03-26 18:08:31,968] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10781904], dtype=float32), 0.09052062]
[2019-03-26 18:08:31,969] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [35.93333333333333, 51.0, 1.0, 2.0, 0.640484569211076, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.004600892697583, 6.9112, 168.9123233466096, 1790875.723938429, 1724614.164428005, 372281.9597996734]
[2019-03-26 18:08:31,972] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 18:08:31,976] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.7212285e-11 9.9999928e-01 1.4221453e-11 6.7440618e-07 6.1321556e-19], sampled 0.8130058007328126
[2019-03-26 18:08:31,976] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1790875.723938429 W.
[2019-03-26 18:08:59,411] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10781904], dtype=float32), 0.09052062]
[2019-03-26 18:08:59,412] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [19.99158975666667, 90.02442838666667, 1.0, 2.0, 0.2771390737467306, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 451401.9978324311, 451401.9978324304, 163635.3490073146]
[2019-03-26 18:08:59,413] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:08:59,415] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [6.9743608e-17 1.0000000e+00 6.3422290e-20 1.5040515e-20 3.3050333e-29], sampled 0.7343899411276229
[2019-03-26 18:09:02,858] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10781904], dtype=float32), 0.09052062]
[2019-03-26 18:09:02,859] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.16666666666667, 71.66666666666667, 1.0, 2.0, 0.4468265360497495, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 644166.7003819195, 644166.7003819195, 178223.7449444766]
[2019-03-26 18:09:02,860] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 18:09:02,864] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.2168826e-16 1.0000000e+00 1.1615987e-19 8.8010479e-20 1.0384095e-28], sampled 0.32900362862894206
[2019-03-26 18:09:08,911] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8092.9084 2994836422.5936 1448.0000
[2019-03-26 18:09:08,951] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8669.8204 2778032554.6110 906.0000
[2019-03-26 18:09:09,023] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8299.9603 2922692110.6062 1203.0000
[2019-03-26 18:09:09,035] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7992.0367 3152107308.0394 1443.0000
[2019-03-26 18:09:09,042] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8539.3880 2836951135.2370 991.0000
[2019-03-26 18:09:10,060] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 2025000, evaluation results [2025000.0, 7992.036689163494, 3152107308.0394344, 1443.0, 8299.96029098108, 2922692110.606205, 1203.0, 8669.820443638291, 2778032554.610993, 906.0, 8092.9083855212975, 2994836422.5935745, 1448.0, 8539.388043102352, 2836951135.2370043, 991.0]
[2019-03-26 18:09:14,578] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.9658874e-18 5.3523338e-14 3.9378824e-16 1.0000000e+00 9.4767777e-22], sum to 1.0000
[2019-03-26 18:09:14,588] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8949
[2019-03-26 18:09:14,596] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 3 has been changed to 4 for the demand 3326758.3274409 W.
[2019-03-26 18:09:14,604] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [37.16666666666667, 47.5, 1.0, 2.0, 0.9441798953029356, 1.0, 2.0, 0.7926799871657305, 1.0, 1.0, 1.03, 7.005116993417568, 6.9112, 170.5573041426782, 3326758.3274409, 3259481.764756858, 609556.2790613951], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4294200.0000, 
sim time next is 4294800.0000, 
raw observation next is [37.0, 48.0, 1.0, 2.0, 0.7898540999611776, 1.0, 2.0, 0.7155170894948515, 1.0, 2.0, 1.03, 7.00510481813808, 6.9112, 170.5573041426782, 3002527.991848526, 2935260.150812441, 551211.2357016603], 
processed observation next is [1.0, 0.7391304347826086, 0.95260663507109, 0.48, 1.0, 1.0, 0.7468121686279249, 1.0, 1.0, 0.6572495054154837, 1.0, 1.0, 1.0365853658536586, 0.009390481813808017, 0.0, 0.8375144448122397, 0.8340355532912572, 0.8153500418923447, 0.8227033368681497], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.99902976], dtype=float32), -0.87202996]. 
=============================================
[2019-03-26 18:09:23,821] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.8726609e-17 1.0000000e+00 5.0968630e-20 3.6827606e-20 1.0556637e-28], sum to 1.0000
[2019-03-26 18:09:23,828] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8634
[2019-03-26 18:09:23,832] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.33333333333334, 65.0, 1.0, 2.0, 0.546577589218973, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 763780.6593100135, 763780.6593100135, 191215.6663663194], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4537200.0000, 
sim time next is 4537800.0000, 
raw observation next is [31.5, 64.5, 1.0, 2.0, 0.5468455069623703, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 764155.178867518, 764155.178867518, 191261.5018438103], 
processed observation next is [0.0, 0.5217391304347826, 0.6919431279620853, 0.645, 1.0, 1.0, 0.45403073127996424, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21226532746319943, 0.21226532746319943, 0.28546492812509], 
reward next is 0.7145, 
noisyNet noise sample is [array([1.6183822], dtype=float32), -1.6267654]. 
=============================================
[2019-03-26 18:09:27,592] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.6958086e-17 1.0000000e+00 1.3565295e-19 3.7171426e-20 5.0440743e-29], sum to 1.0000
[2019-03-26 18:09:27,597] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.6205434e-17 1.0000000e+00 1.4036318e-20 2.9032631e-20 4.0874658e-29], sum to 1.0000
[2019-03-26 18:09:27,603] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6898
[2019-03-26 18:09:27,609] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.33333333333334, 62.66666666666667, 1.0, 2.0, 0.5290955894582405, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 739343.0305724948, 739343.0305724948, 188280.6058050734], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4555200.0000, 
sim time next is 4555800.0000, 
raw observation next is [31.0, 64.5, 1.0, 2.0, 0.5295354357464656, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 739957.8732625517, 739957.8732625517, 188353.3893941975], 
processed observation next is [0.0, 0.7391304347826086, 0.6682464454976303, 0.645, 1.0, 1.0, 0.4331752237909223, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20554385368404215, 0.20554385368404215, 0.2811244617823843], 
reward next is 0.7189, 
noisyNet noise sample is [array([-1.3394573], dtype=float32), -0.9964596]. 
=============================================
[2019-03-26 18:09:27,610] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9971
[2019-03-26 18:09:27,617] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 79.0, 1.0, 2.0, 0.5150205109398079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 719668.2561756148, 719668.2561756148, 185983.1662604543], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4528800.0000, 
sim time next is 4529400.0000, 
raw observation next is [28.16666666666667, 79.00000000000001, 1.0, 2.0, 0.520589465356836, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 727452.7462166852, 727452.7462166859, 186885.1744092829], 
processed observation next is [0.0, 0.43478260869565216, 0.5339652448657191, 0.7900000000000001, 1.0, 1.0, 0.42239694621305546, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20207020728241254, 0.20207020728241273, 0.27893309613325806], 
reward next is 0.7211, 
noisyNet noise sample is [array([-0.41639376], dtype=float32), -0.12352759]. 
=============================================
[2019-03-26 18:09:31,126] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.9868457e-17 1.0000000e+00 7.9795858e-20 9.1762519e-20 5.6991137e-30], sum to 1.0000
[2019-03-26 18:09:31,135] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2166
[2019-03-26 18:09:31,138] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.33333333333334, 72.66666666666666, 1.0, 2.0, 0.529589629599696, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 740033.6286030613, 740033.6286030613, 188361.9485519146], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4560000.0000, 
sim time next is 4560600.0000, 
raw observation next is [29.16666666666667, 73.33333333333334, 1.0, 2.0, 0.5285019838757005, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 738513.2547740127, 738513.2547740127, 188182.1144252415], 
processed observation next is [0.0, 0.782608695652174, 0.581358609794629, 0.7333333333333334, 1.0, 1.0, 0.4319301010550608, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20514257077055909, 0.20514257077055909, 0.28086882750036046], 
reward next is 0.7191, 
noisyNet noise sample is [array([-0.8685391], dtype=float32), -0.22535175]. 
=============================================
[2019-03-26 18:09:47,605] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.1261024e-17 1.0000000e+00 6.4415637e-20 1.8903933e-20 2.0087683e-29], sum to 1.0000
[2019-03-26 18:09:47,613] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7723
[2019-03-26 18:09:47,618] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333333, 82.33333333333333, 1.0, 2.0, 0.5122393071937514, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 715780.6082808475, 715780.6082808468, 185535.990862769], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5123400.0000, 
sim time next is 5124000.0000, 
raw observation next is [27.66666666666667, 80.66666666666667, 1.0, 2.0, 0.5150709156731073, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 719738.71351649, 719738.71351649, 185991.1029217095], 
processed observation next is [0.0, 0.30434782608695654, 0.5102685624012641, 0.8066666666666668, 1.0, 1.0, 0.41574809117241834, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1999274204212472, 0.1999274204212472, 0.27759866107717834], 
reward next is 0.7224, 
noisyNet noise sample is [array([-0.8400505], dtype=float32), 0.95470023]. 
=============================================
[2019-03-26 18:09:47,629] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[72.27586 ]
 [72.261055]
 [72.23921 ]
 [72.24459 ]
 [72.24564 ]], R is [[72.27019501]
 [72.27057648]
 [72.27193451]
 [72.27455139]
 [72.27837372]].
[2019-03-26 18:09:53,285] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.4812173e-15 1.0000000e+00 5.4026834e-18 1.5705457e-16 1.7696255e-27], sum to 1.0000
[2019-03-26 18:09:53,296] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7676
[2019-03-26 18:09:53,302] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.6599435366153074, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 922265.5886796128, 922265.5886796123, 212434.3622953894], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4944600.0000, 
sim time next is 4945200.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.8223806614057153, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1149392.966333013, 1149392.966333013, 249476.1266131804], 
processed observation next is [1.0, 0.21739130434782608, 0.4312796208530806, 0.89, 1.0, 1.0, 0.7860007968743558, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3192758239813925, 0.3192758239813925, 0.37235242778086625], 
reward next is 0.6276, 
noisyNet noise sample is [array([-1.0854605], dtype=float32), 0.3072441]. 
=============================================
[2019-03-26 18:09:57,617] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.8994040e-18 1.0000000e+00 1.4269328e-20 1.2083180e-20 2.4450881e-30], sum to 1.0000
[2019-03-26 18:09:57,627] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1236
[2019-03-26 18:09:57,631] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.83333333333334, 63.0, 1.0, 2.0, 0.5419154270068041, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 757263.4901138083, 757263.4901138083, 190424.636971973], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5058600.0000, 
sim time next is 5059200.0000, 
raw observation next is [31.66666666666667, 63.00000000000001, 1.0, 2.0, 0.54020022425649, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 754865.843032267, 754865.843032267, 190134.738375304], 
processed observation next is [0.0, 0.5652173913043478, 0.6998420221169038, 0.6300000000000001, 1.0, 1.0, 0.44602436657408423, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20968495639785192, 0.20968495639785192, 0.2837831916049314], 
reward next is 0.7162, 
noisyNet noise sample is [array([-0.82367516], dtype=float32), -0.32925594]. 
=============================================
[2019-03-26 18:09:59,097] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.1100686e-17 1.0000000e+00 8.1271348e-20 7.7438219e-20 2.6669375e-29], sum to 1.0000
[2019-03-26 18:09:59,110] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5601
[2019-03-26 18:09:59,116] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 79.00000000000001, 1.0, 2.0, 0.5225655432050414, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 730214.9944851904, 730214.9944851898, 187206.8633915978], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5083800.0000, 
sim time next is 5084400.0000, 
raw observation next is [28.0, 79.0, 1.0, 2.0, 0.5224280315099159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 730022.7743752343, 730022.7743752343, 187184.4101223437], 
processed observation next is [0.0, 0.8695652173913043, 0.5260663507109005, 0.79, 1.0, 1.0, 0.4246120861565252, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20278410399312063, 0.20278410399312063, 0.279379716600513], 
reward next is 0.7206, 
noisyNet noise sample is [array([-0.08698095], dtype=float32), 0.5938262]. 
=============================================
[2019-03-26 18:10:01,052] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.8043912e-13 1.0000000e+00 5.0529910e-14 1.0065931e-10 1.8342520e-21], sum to 1.0000
[2019-03-26 18:10:01,058] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7721
[2019-03-26 18:10:01,064] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.4, 91.66666666666667, 1.0, 2.0, 0.38191040072035, 1.0, 1.0, 0.38191040072035, 1.0, 1.0, 0.6550735350478396, 6.911200000000001, 6.9112, 170.5573041426782, 1601650.222895215, 1601650.222895214, 342013.6594625384], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5800800.0000, 
sim time next is 5801400.0000, 
raw observation next is [26.35, 92.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.12849485154089, 6.9112, 168.9115555435132, 1608015.670463704, 1453860.502645156, 311349.838190387], 
processed observation next is [1.0, 0.13043478260869565, 0.4478672985781992, 0.92, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 0.021729485154089012, 0.0, 0.8294330657633708, 0.4466710195732511, 0.40385013962365446, 0.46470125103042836], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8316927], dtype=float32), -0.15923218]. 
=============================================
[2019-03-26 18:10:03,509] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.3459486e-17 1.0000000e+00 1.0394090e-19 6.3844902e-20 6.1376516e-29], sum to 1.0000
[2019-03-26 18:10:03,512] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7755
[2019-03-26 18:10:03,518] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.5064369021369601, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 707669.8826862844, 707669.882686285, 184610.3440527181], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5103600.0000, 
sim time next is 5104200.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.5059225387264951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 706950.8975243263, 706950.8975243256, 184528.8429603633], 
processed observation next is [0.0, 0.043478260869565216, 0.4312796208530806, 0.89, 1.0, 1.0, 0.4047259502728856, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19637524931231287, 0.19637524931231268, 0.2754161835229303], 
reward next is 0.7246, 
noisyNet noise sample is [array([0.00165272], dtype=float32), -0.69333255]. 
=============================================
[2019-03-26 18:10:05,692] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-26 18:10:05,694] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 18:10:05,695] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:10:05,695] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 18:10:05,696] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 18:10:05,698] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 18:10:05,698] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 18:10:05,697] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:10:05,699] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:10:05,699] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:10:05,698] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:10:05,734] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run83
[2019-03-26 18:10:05,757] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run83
[2019-03-26 18:10:05,758] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run83
[2019-03-26 18:10:05,780] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run83
[2019-03-26 18:10:05,829] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run83
[2019-03-26 18:10:18,659] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10895289], dtype=float32), 0.0917468]
[2019-03-26 18:10:18,661] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.48704073, 64.85321464, 1.0, 2.0, 0.2987973264672557, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 472517.5829657869, 472517.5829657862, 165022.1363707868]
[2019-03-26 18:10:18,662] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:10:18,665] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.5851530e-17 1.0000000e+00 6.1253266e-21 1.8635487e-22 2.0193005e-30], sampled 0.9130268258092328
[2019-03-26 18:10:39,864] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10895289], dtype=float32), 0.0917468]
[2019-03-26 18:10:39,868] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [33.29333242, 70.50474581333333, 1.0, 2.0, 0.6564129994368355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 917329.5616216676, 917329.5616216669, 211726.999034602]
[2019-03-26 18:10:39,869] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:10:39,873] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.5398110e-15 1.0000000e+00 1.1836026e-17 6.2351383e-14 2.9099498e-27], sampled 0.742927743182125
[2019-03-26 18:11:01,808] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10895289], dtype=float32), 0.0917468]
[2019-03-26 18:11:01,808] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [30.3, 70.5, 1.0, 2.0, 0.5585107086459004, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 780461.9767031505, 780461.9767031505, 193270.3468410093]
[2019-03-26 18:11:01,809] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:11:01,813] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.3655375e-17 1.0000000e+00 4.3374986e-20 1.7581268e-19 1.3797415e-29], sampled 0.5866671289564374
[2019-03-26 18:11:19,861] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10895289], dtype=float32), 0.0917468]
[2019-03-26 18:11:19,863] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [30.10524231, 60.77554976, 1.0, 2.0, 0.5045813625361564, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 705076.1829090016, 705076.1829090009, 184315.4232727447]
[2019-03-26 18:11:19,865] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:11:19,870] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.5948896e-17 1.0000000e+00 3.9266542e-20 6.3505331e-20 1.4447436e-29], sampled 0.3340576380781173
[2019-03-26 18:11:29,773] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10895289], dtype=float32), 0.0917468]
[2019-03-26 18:11:29,774] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.93493314333333, 94.80684572833334, 1.0, 2.0, 0.9664750515783013, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1350913.324580779, 1350913.324580779, 288879.7046040775]
[2019-03-26 18:11:29,776] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 18:11:29,779] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.2388976e-15 1.0000000e+00 8.5286176e-18 1.7243026e-15 5.2973331e-27], sampled 0.9314846894673277
[2019-03-26 18:11:59,242] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8282.4949 2923828822.4618 1245.0000
[2019-03-26 18:11:59,534] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8663.5182 2778896941.6138 917.0000
[2019-03-26 18:11:59,539] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7965.2767 3155481633.5907 1526.0000
[2019-03-26 18:11:59,750] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8063.0533 2999736249.9174 1570.0000
[2019-03-26 18:11:59,821] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8525.7414 2839257081.9563 1049.0000
[2019-03-26 18:12:00,838] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 2050000, evaluation results [2050000.0, 7965.276673306677, 3155481633.5906525, 1526.0, 8282.494878415304, 2923828822.461772, 1245.0, 8663.518172209706, 2778896941.613845, 917.0, 8063.0532925221805, 2999736249.917427, 1570.0, 8525.741352933963, 2839257081.9562902, 1049.0]
[2019-03-26 18:12:02,820] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.22821468e-18 1.83481946e-13 3.09207196e-15 1.00000000e+00
 1.01572965e-20], sum to 1.0000
[2019-03-26 18:12:02,827] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6177
[2019-03-26 18:12:02,840] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 3 has been changed to 4 for the demand 4061485.940421187 W.
[2019-03-26 18:12:02,845] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [36.9, 54.0, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 8.517719621167226, 6.9112, 170.5573041426782, 4061485.940421187, 2910670.586739073, 543636.3715910243], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5407200.0000, 
sim time next is 5407800.0000, 
raw observation next is [37.08333333333334, 54.0, 1.0, 2.0, 0.9314604738746934, 1.0, 2.0, 0.7863202764516093, 1.0, 1.0, 1.03, 7.005115989700826, 6.9112, 170.5573041426782, 3300032.312229517, 3232756.468548606, 604412.7243020408], 
processed observation next is [1.0, 0.6086956521739131, 0.9565560821484996, 0.54, 1.0, 1.0, 0.9174222576803536, 1.0, 1.0, 0.7425545499416979, 1.0, 0.5, 1.0365853658536586, 0.009391598970082616, 0.0, 0.8375144448122397, 0.9166756422859769, 0.8979879079301684, 0.9021085437343892], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.5235975], dtype=float32), 0.50575745]. 
=============================================
[2019-03-26 18:12:12,064] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.2971106e-09 6.7665718e-02 9.9116679e-09 9.3233430e-01 8.4802016e-15], sum to 1.0000
[2019-03-26 18:12:12,073] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1556
[2019-03-26 18:12:12,079] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.3, 68.0, 1.0, 2.0, 0.8471334917580841, 1.0, 2.0, 0.8471334917580841, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2369287.160880099, 2369287.1608801, 443471.080303486], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5565600.0000, 
sim time next is 5566200.0000, 
raw observation next is [31.5, 67.0, 1.0, 2.0, 0.7615594857760521, 1.0, 2.0, 0.7615594857760521, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2129735.63619161, 2129735.63619161, 401594.2332633058], 
processed observation next is [1.0, 0.43478260869565216, 0.6919431279620853, 0.67, 1.0, 1.0, 0.7127222720193399, 1.0, 1.0, 0.7127222720193399, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5915932322754471, 0.5915932322754471, 0.599394378004934], 
reward next is 0.4006, 
noisyNet noise sample is [array([-0.4935509], dtype=float32), -0.48056683]. 
=============================================
[2019-03-26 18:12:17,861] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.1569268e-15 1.0000000e+00 7.0670784e-17 8.1627625e-15 2.6865378e-25], sum to 1.0000
[2019-03-26 18:12:17,875] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5899
[2019-03-26 18:12:17,880] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.4, 84.33333333333334, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.162334949921681, 6.9112, 168.9114930119914, 1632039.177974247, 1453876.944751443, 311352.3946409515], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5901600.0000, 
sim time next is 5902200.0000, 
raw observation next is [28.6, 83.5, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.629502893913581, 6.9112, 168.9087034292206, 1963679.944062809, 1454103.98004513, 311352.6526017103], 
processed observation next is [1.0, 0.30434782608695654, 0.5545023696682465, 0.835, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.07183028939135809, 0.0, 0.8294190605764906, 0.5454666511285581, 0.40391777223475833, 0.46470545164434374], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.328607], dtype=float32), -1.6694821]. 
=============================================
[2019-03-26 18:12:20,683] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.4205194e-13 5.6599474e-05 7.0405691e-12 9.9994338e-01 1.3867522e-18], sum to 1.0000
[2019-03-26 18:12:20,693] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4142
[2019-03-26 18:12:20,701] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [34.7, 51.0, 1.0, 2.0, 0.9854860264401444, 1.0, 2.0, 0.9854860264401444, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2756662.345061321, 2756662.345061321, 520271.8127704652], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5504400.0000, 
sim time next is 5505000.0000, 
raw observation next is [34.45, 52.33333333333333, 1.0, 2.0, 0.4142963058549877, 1.0, 2.0, 0.4142963058549877, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1158073.689023341, 1158073.689023341, 275793.5286256754], 
processed observation next is [1.0, 0.7391304347826086, 0.8317535545023698, 0.5233333333333333, 1.0, 1.0, 0.29433289862046713, 1.0, 1.0, 0.29433289862046713, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.32168713583981695, 0.32168713583981695, 0.41163213227712747], 
reward next is 0.5884, 
noisyNet noise sample is [array([-1.4068967], dtype=float32), 0.44551158]. 
=============================================
[2019-03-26 18:12:20,718] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[53.54246 ]
 [53.33203 ]
 [52.891563]
 [52.64613 ]
 [52.409485]], R is [[57.11847687]
 [56.77076721]
 [56.43675613]
 [56.09791565]
 [55.74668503]].
[2019-03-26 18:12:20,966] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.8903475e-11 3.1406093e-02 1.4221987e-10 9.6859390e-01 2.9556662e-17], sum to 1.0000
[2019-03-26 18:12:20,974] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2390
[2019-03-26 18:12:20,978] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.59999999999999, 51.5, 1.0, 2.0, 0.8607451576365364, 1.0, 2.0, 0.8607451576365364, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2407393.327248119, 2407393.327248119, 450520.9553057878], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5585400.0000, 
sim time next is 5586000.0000, 
raw observation next is [33.53333333333333, 52.0, 1.0, 2.0, 0.8634770301384399, 1.0, 2.0, 0.8634770301384399, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2415041.406095639, 2415041.406095639, 451950.847576105], 
processed observation next is [1.0, 0.6521739130434783, 0.7883096366508688, 0.52, 1.0, 1.0, 0.8355144941426986, 1.0, 1.0, 0.8355144941426986, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6708448350265663, 0.6708448350265663, 0.6745535038449328], 
reward next is 0.3254, 
noisyNet noise sample is [array([-0.02238292], dtype=float32), 0.8687966]. 
=============================================
[2019-03-26 18:12:21,004] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[55.545418]
 [55.604465]
 [55.69369 ]
 [55.47978 ]
 [55.31556 ]], R is [[55.15807343]
 [54.9340744 ]
 [54.72010803]
 [54.52830505]
 [54.31519318]].
[2019-03-26 18:12:22,966] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.3192376e-18 1.0000000e+00 5.5561748e-20 2.9130590e-20 1.5426389e-30], sum to 1.0000
[2019-03-26 18:12:22,977] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6437
[2019-03-26 18:12:22,980] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.13333333333333, 87.66666666666667, 1.0, 2.0, 0.5386799251324969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 752740.6522951062, 752740.6522951062, 189878.0200447449], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5787600.0000, 
sim time next is 5788200.0000, 
raw observation next is [27.11666666666667, 87.83333333333334, 1.0, 2.0, 0.5385871617696738, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 752610.9806883385, 752610.9806883378, 189862.4496862481], 
processed observation next is [0.0, 1.0, 0.4842022116903636, 0.8783333333333334, 1.0, 1.0, 0.4440809177947877, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2090586057467607, 0.2090586057467605, 0.2833767905764897], 
reward next is 0.7166, 
noisyNet noise sample is [array([-1.4744829], dtype=float32), -0.869571]. 
=============================================
[2019-03-26 18:12:23,552] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0891411e-10 7.3877489e-03 5.2279919e-10 9.9261224e-01 1.1773804e-16], sum to 1.0000
[2019-03-26 18:12:23,562] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9896
[2019-03-26 18:12:23,569] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.7, 60.33333333333334, 1.0, 2.0, 0.8472920334845337, 1.0, 2.0, 0.8472920334845337, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2369730.995339381, 2369730.995339381, 443551.8184702814], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5570400.0000, 
sim time next is 5571000.0000, 
raw observation next is [32.8, 59.5, 1.0, 2.0, 0.812375891785435, 1.0, 2.0, 0.812375891785435, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2271987.745457377, 2271987.745457377, 425941.897606652], 
processed observation next is [1.0, 0.4782608695652174, 0.7535545023696681, 0.595, 1.0, 1.0, 0.7739468575728132, 1.0, 1.0, 0.7739468575728132, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6311077070714936, 0.6311077070714936, 0.6357341755323164], 
reward next is 0.3643, 
noisyNet noise sample is [array([0.46016747], dtype=float32), -0.7024981]. 
=============================================
[2019-03-26 18:12:23,582] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[54.742786]
 [53.847965]
 [53.544815]
 [56.229527]
 [55.073055]], R is [[55.49824524]
 [55.28124619]
 [54.72843552]
 [54.49772644]
 [54.31807327]].
[2019-03-26 18:12:34,493] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.0456454e-17 1.0000000e+00 4.3345547e-20 1.2824515e-19 3.7781831e-29], sum to 1.0000
[2019-03-26 18:12:34,503] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0790
[2019-03-26 18:12:34,507] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.63333333333333, 54.66666666666667, 1.0, 2.0, 0.5401031139084347, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 754730.0946113296, 754730.0946113289, 190118.7845046877], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5757600.0000, 
sim time next is 5758200.0000, 
raw observation next is [33.45, 55.5, 1.0, 2.0, 0.5402883518491643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 754989.0346719248, 754989.0346719254, 190150.0236700869], 
processed observation next is [0.0, 0.6521739130434783, 0.7843601895734599, 0.555, 1.0, 1.0, 0.4461305443965835, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20971917629775688, 0.20971917629775705, 0.28380600547774165], 
reward next is 0.7162, 
noisyNet noise sample is [array([-1.6509637], dtype=float32), 0.5061773]. 
=============================================
[2019-03-26 18:12:36,777] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.9445592e-15 1.0000000e+00 4.3530181e-18 2.5360732e-14 1.7137224e-26], sum to 1.0000
[2019-03-26 18:12:36,788] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4740
[2019-03-26 18:12:36,791] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.9, 78.0, 1.0, 2.0, 0.5386367175919351, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 752680.2535426113, 752680.2535426107, 189871.5060304962], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6030000.0000, 
sim time next is 6030600.0000, 
raw observation next is [28.73333333333333, 79.0, 1.0, 2.0, 0.5401148189327852, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 754746.4568066583, 754746.4568066589, 190120.2302943042], 
processed observation next is [1.0, 0.8260869565217391, 0.560821484992101, 0.79, 1.0, 1.0, 0.4459214685937171, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2096517935574051, 0.20965179355740524, 0.28376153775269286], 
reward next is 0.7162, 
noisyNet noise sample is [array([-1.4015315], dtype=float32), 0.35486892]. 
=============================================
[2019-03-26 18:12:55,641] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.3492909e-17 1.0000000e+00 7.0206591e-21 5.9277277e-21 1.4169666e-30], sum to 1.0000
[2019-03-26 18:12:55,652] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0394
[2019-03-26 18:12:55,660] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.66666666666667, 63.00000000000001, 1.0, 2.0, 0.5446081712998979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 761027.6335776714, 761027.633577672, 190880.4809788294], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6351600.0000, 
sim time next is 6352200.0000, 
raw observation next is [31.5, 63.0, 1.0, 2.0, 0.5382711482541161, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 752169.2333426882, 752169.2333426889, 189809.7982757424], 
processed observation next is [0.0, 0.5217391304347826, 0.6919431279620853, 0.63, 1.0, 1.0, 0.443700178619417, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20893589815074673, 0.20893589815074692, 0.28329820638170505], 
reward next is 0.7167, 
noisyNet noise sample is [array([-0.93281156], dtype=float32), 1.3232359]. 
=============================================
[2019-03-26 18:12:55,802] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.6501194e-09 7.8288871e-01 5.2928146e-09 2.1711130e-01 3.5102570e-15], sum to 1.0000
[2019-03-26 18:12:55,810] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3685
[2019-03-26 18:12:55,818] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2182603.565261641 W.
[2019-03-26 18:12:55,824] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.8, 80.0, 1.0, 2.0, 0.7804449731294173, 1.0, 2.0, 0.7804449731294173, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2182603.565261641, 2182603.56526164, 410463.388136537], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6170400.0000, 
sim time next is 6171000.0000, 
raw observation next is [28.88333333333333, 79.5, 1.0, 2.0, 0.880075567625777, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.996307518573488, 6.9112, 168.9124498280121, 2127148.179761168, 2066770.158024838, 428955.9007726204], 
processed observation next is [1.0, 0.43478260869565216, 0.5679304897314374, 0.795, 1.0, 1.0, 0.8555127320792494, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.008510751857348797, 0.0, 0.8294374571096655, 0.5908744943781022, 0.5741028216735661, 0.6402326877203289], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.31214902], dtype=float32), -0.39064088]. 
=============================================
[2019-03-26 18:12:55,846] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[51.442295]
 [49.08633 ]
 [47.28352 ]
 [48.59663 ]
 [47.250538]], R is [[51.41212082]
 [51.28536606]
 [50.77251434]
 [50.26478958]
 [49.76214218]].
[2019-03-26 18:12:56,517] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-26 18:12:56,519] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 18:12:56,520] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 18:12:56,521] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:12:56,522] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:12:56,522] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 18:12:56,523] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:12:56,523] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 18:12:56,524] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:12:56,525] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 18:12:56,525] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:12:56,546] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run84
[2019-03-26 18:12:56,575] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run84
[2019-03-26 18:12:56,575] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run84
[2019-03-26 18:12:56,598] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run84
[2019-03-26 18:12:56,642] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run84
[2019-03-26 18:13:18,096] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10902248], dtype=float32), 0.09176778]
[2019-03-26 18:13:18,099] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [27.7, 47.0, 1.0, 2.0, 0.2938467618083276, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 472266.7523173749, 472266.7523173749, 165116.9695589521]
[2019-03-26 18:13:18,100] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:13:18,103] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [5.7815702e-18 1.0000000e+00 1.6586391e-21 7.9992313e-23 5.8055997e-31], sampled 0.7345569846123123
[2019-03-26 18:13:19,904] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10902248], dtype=float32), 0.09176778]
[2019-03-26 18:13:19,905] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [23.2, 79.33333333333334, 1.0, 2.0, 0.3326118800926124, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 522445.0590604196, 522445.0590604189, 168674.6374688537]
[2019-03-26 18:13:19,905] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 18:13:19,908] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.3507399e-18 1.0000000e+00 1.0847000e-21 1.5569759e-22 2.8645015e-31], sampled 0.23476514249040814
[2019-03-26 18:13:31,070] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10902248], dtype=float32), 0.09176778]
[2019-03-26 18:13:31,072] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [25.2, 80.0, 1.0, 2.0, 0.6200725711146545, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 915632.4348883927, 915632.4348883921, 210788.198257825]
[2019-03-26 18:13:31,072] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:13:31,074] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.7756054e-17 1.0000000e+00 1.0205924e-20 1.5222212e-21 6.4895519e-30], sampled 0.9151027992192114
[2019-03-26 18:13:54,386] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10902248], dtype=float32), 0.09176778]
[2019-03-26 18:13:54,389] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [35.13333333333333, 47.33333333333334, 1.0, 2.0, 0.7521055006989211, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.989268359474736, 6.9112, 168.9124280359414, 1948045.33872014, 1892661.130883166, 396978.3670906026]
[2019-03-26 18:13:54,390] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:13:54,392] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [4.3410384e-10 9.9335599e-01 3.1843059e-10 6.6440199e-03 2.0455460e-17], sampled 0.7358682499102001
[2019-03-26 18:13:54,394] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1948045.33872014 W.
[2019-03-26 18:13:54,445] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10902248], dtype=float32), 0.09176778]
[2019-03-26 18:13:54,446] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [35.5, 47.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.070701639162243, 6.9112, 168.9119595617704, 2405846.899895081, 2292691.615313404, 476179.3103378349]
[2019-03-26 18:13:54,447] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:13:54,448] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [5.2493970e-10 9.6491611e-01 7.0710071e-10 3.5083856e-02 4.6794851e-17], sampled 0.5520231894839669
[2019-03-26 18:13:54,449] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2405846.899895081 W.
[2019-03-26 18:13:57,466] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10902248], dtype=float32), 0.09176778]
[2019-03-26 18:13:57,468] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [35.04933364666667, 68.16750335333333, 1.0, 2.0, 0.6884935315717595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 962182.0422663459, 962182.0422663466, 218393.1181497739]
[2019-03-26 18:13:57,469] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:13:57,471] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [4.1729297e-17 1.0000000e+00 7.3350040e-20 1.7735543e-17 4.6373275e-29], sampled 0.33930408299553316
[2019-03-26 18:13:59,975] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10902248], dtype=float32), 0.09176778]
[2019-03-26 18:13:59,978] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [32.06666666666666, 62.66666666666667, 1.0, 2.0, 0.5577867465027396, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 779449.9419672729, 779449.9419672729, 193145.1441081412]
[2019-03-26 18:13:59,979] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 18:13:59,983] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.6932414e-17 1.0000000e+00 1.7057445e-20 7.7352599e-20 8.4170910e-30], sampled 0.8841234528876399
[2019-03-26 18:14:23,463] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.10902248], dtype=float32), 0.09176778]
[2019-03-26 18:14:23,463] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.38333333333333, 79.0, 1.0, 2.0, 0.5254278565227833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 734216.0742925534, 734216.074292554, 187676.5075501182]
[2019-03-26 18:14:23,465] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 18:14:23,469] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.1068496e-16 1.0000000e+00 8.8599005e-19 1.0665918e-15 7.5255501e-28], sampled 0.5878180115813875
[2019-03-26 18:14:28,830] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10902248], dtype=float32), 0.09176778]
[2019-03-26 18:14:28,831] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.54213997333333, 77.04473359333333, 1.0, 2.0, 0.5067306274573077, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 708080.4567181981, 708080.4567181976, 184656.3789586912]
[2019-03-26 18:14:28,832] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 18:14:28,834] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.7353008e-17 1.0000000e+00 1.4767169e-20 2.8816039e-20 7.6851616e-30], sampled 0.30939150273601745
[2019-03-26 18:14:50,197] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7929.1734 3159509402.5468 1643.0000
[2019-03-26 18:14:50,281] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8265.2882 2926126668.0557 1299.0000
[2019-03-26 18:14:50,299] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8662.6614 2779131819.7352 928.0000
[2019-03-26 18:14:50,414] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8028.1488 3003471367.3155 1670.0000
[2019-03-26 18:14:50,529] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8509.9078 2840711102.0695 1097.0000
[2019-03-26 18:14:51,546] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 2075000, evaluation results [2075000.0, 7929.173366339789, 3159509402.5467706, 1643.0, 8265.288159485455, 2926126668.0557027, 1299.0, 8662.661433457173, 2779131819.7351832, 928.0, 8028.148771596825, 3003471367.3154807, 1670.0, 8509.907773343624, 2840711102.0694723, 1097.0]
[2019-03-26 18:14:52,194] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.8160859e-12 9.9992275e-01 9.1843666e-13 7.7194374e-05 7.3689845e-21], sum to 1.0000
[2019-03-26 18:14:52,204] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5456
[2019-03-26 18:14:52,209] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.8, 71.5, 1.0, 2.0, 0.2439553747200983, 1.0, 1.0, 0.2439553747200983, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 681771.9364006859, 681771.9364006866, 239972.2173801669], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6111000.0000, 
sim time next is 6111600.0000, 
raw observation next is [29.63333333333333, 72.33333333333333, 1.0, 2.0, 0.499823282513006, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 698425.2995806138, 698425.2995806132, 183570.9197383905], 
processed observation next is [1.0, 0.7391304347826086, 0.6034755134281199, 0.7233333333333333, 1.0, 1.0, 0.3973774488108506, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1940070276612816, 0.19400702766128142, 0.27398644737073213], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.21167818], dtype=float32), -0.21845856]. 
=============================================
[2019-03-26 18:14:57,569] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.7932546e-13 9.9999928e-01 4.9585160e-14 6.8926369e-07 2.2844856e-22], sum to 1.0000
[2019-03-26 18:14:57,578] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8734
[2019-03-26 18:14:57,584] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.66666666666667, 78.0, 1.0, 2.0, 0.5008950369945377, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 699923.4031623874, 699923.4031623874, 183738.8669468875], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6198000.0000, 
sim time next is 6198600.0000, 
raw observation next is [28.58333333333333, 78.5, 1.0, 2.0, 0.5156090711698571, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 720490.9646937053, 720490.964693706, 186079.335229529], 
processed observation next is [1.0, 0.7391304347826086, 0.5537124802527644, 0.785, 1.0, 1.0, 0.41639647128898444, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2001363790815848, 0.200136379081585, 0.27773035108884925], 
reward next is 0.7223, 
noisyNet noise sample is [array([-0.5580588], dtype=float32), -0.00034011964]. 
=============================================
[2019-03-26 18:14:57,719] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.0535162e-17 1.0000000e+00 1.2980531e-20 1.0459549e-21 6.8733942e-30], sum to 1.0000
[2019-03-26 18:14:57,729] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3633
[2019-03-26 18:14:57,734] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.8, 89.5, 1.0, 2.0, 0.5272986350211235, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 736831.1469815219, 736831.1469815212, 187984.0942567497], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6240600.0000, 
sim time next is 6241200.0000, 
raw observation next is [26.86666666666667, 89.33333333333333, 1.0, 2.0, 0.52786251708802, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 737619.3722879834, 737619.3722879834, 188077.1312553247], 
processed observation next is [0.0, 0.21739130434782608, 0.4723538704581361, 0.8933333333333333, 1.0, 1.0, 0.43115965914219273, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2048942700799954, 0.2048942700799954, 0.28071213620197716], 
reward next is 0.7193, 
noisyNet noise sample is [array([0.59776443], dtype=float32), 0.312395]. 
=============================================
[2019-03-26 18:14:59,446] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.3189243e-10 7.1493483e-01 2.7531225e-10 2.8506514e-01 3.0308976e-17], sum to 1.0000
[2019-03-26 18:14:59,461] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6325
[2019-03-26 18:14:59,472] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2255136.408568065 W.
[2019-03-26 18:14:59,477] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.0, 68.0, 1.0, 2.0, 0.8063559298528766, 1.0, 2.0, 0.8063559298528766, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2255136.408568065, 2255136.408568065, 422971.0277337322], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6445800.0000, 
sim time next is 6446400.0000, 
raw observation next is [30.0, 68.0, 1.0, 2.0, 0.7969400133555669, 1.0, 2.0, 0.7969400133555669, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2228779.424929156, 2228779.424929157, 418378.1383914484], 
processed observation next is [1.0, 0.6086956521739131, 0.6208530805687204, 0.68, 1.0, 1.0, 0.7553494136814058, 1.0, 1.0, 0.7553494136814058, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6191053958136544, 0.6191053958136546, 0.6244449826738037], 
reward next is 0.3756, 
noisyNet noise sample is [array([-0.16013934], dtype=float32), 0.63186973]. 
=============================================
[2019-03-26 18:15:07,986] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.9603002e-17 1.0000000e+00 1.4206610e-18 6.5505809e-17 3.0616071e-27], sum to 1.0000
[2019-03-26 18:15:07,995] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2948
[2019-03-26 18:15:07,999] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.96666666666667, 91.0, 1.0, 2.0, 0.7025669105951161, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 981858.9333790259, 981858.9333790265, 221398.4840133816], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6586800.0000, 
sim time next is 6587400.0000, 
raw observation next is [26.03333333333333, 90.5, 1.0, 2.0, 0.6809257936400074, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 951601.2546873514, 951601.2546873514, 216780.1846437203], 
processed observation next is [1.0, 0.21739130434782608, 0.4328593996840442, 0.905, 1.0, 1.0, 0.6155732453494065, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2643336818575976, 0.2643336818575976, 0.3235525143936124], 
reward next is 0.6764, 
noisyNet noise sample is [array([-0.2615764], dtype=float32), 0.054106545]. 
=============================================
[2019-03-26 18:15:09,087] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.3284023e-16 1.0000000e+00 3.0599848e-19 7.3598726e-18 6.2792991e-28], sum to 1.0000
[2019-03-26 18:15:09,098] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6977
[2019-03-26 18:15:09,109] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 87.66666666666667, 1.0, 2.0, 0.5308826972178836, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 741841.1558172234, 741841.1558172228, 188576.1381549454], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6478800.0000, 
sim time next is 6479400.0000, 
raw observation next is [26.95, 87.83333333333334, 1.0, 2.0, 0.5296403702742243, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 740104.556893132, 740104.5568931315, 188370.3616267271], 
processed observation next is [1.0, 1.0, 0.476303317535545, 0.8783333333333334, 1.0, 1.0, 0.4333016509328003, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20558459913698113, 0.20558459913698096, 0.281149793472727], 
reward next is 0.7189, 
noisyNet noise sample is [array([-0.1755596], dtype=float32), -1.2238592]. 
=============================================
[2019-03-26 18:15:12,748] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.7549202e-10 9.7389776e-01 1.1480385e-10 2.6102180e-02 2.5073557e-17], sum to 1.0000
[2019-03-26 18:15:12,756] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2464
[2019-03-26 18:15:12,764] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2028432.203563083 W.
[2019-03-26 18:15:12,768] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.1, 61.5, 1.0, 2.0, 0.7253692583571993, 1.0, 2.0, 0.7253692583571993, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2028432.203563083, 2028432.203563083, 385162.3649564158], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6705000.0000, 
sim time next is 6705600.0000, 
raw observation next is [30.06666666666667, 62.0, 1.0, 2.0, 0.4876997666587306, 1.0, 2.0, 0.4876997666587306, 1.0, 1.0, 0.8252049051048642, 6.9112, 6.9112, 170.5573041426782, 2045731.634495299, 2045731.634495299, 402850.6158366944], 
processed observation next is [1.0, 0.6086956521739131, 0.6240126382306479, 0.62, 1.0, 1.0, 0.3827708032032899, 1.0, 1.0, 0.3827708032032899, 1.0, 0.5, 0.7868352501278832, 0.0, 0.0, 0.8375144448122397, 0.5682587873598053, 0.5682587873598053, 0.6012695758756632], 
reward next is 0.3987, 
noisyNet noise sample is [array([0.27514952], dtype=float32), 0.09834104]. 
=============================================
[2019-03-26 18:15:21,771] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.2945511e-10 9.9636430e-01 2.5921590e-10 3.6357311e-03 5.5754230e-17], sum to 1.0000
[2019-03-26 18:15:21,778] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1519
[2019-03-26 18:15:21,788] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2187543.523837968 W.
[2019-03-26 18:15:21,796] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.33333333333334, 62.0, 1.0, 2.0, 0.5214730520336662, 1.0, 2.0, 0.5214730520336662, 1.0, 2.0, 0.8985784634493392, 6.9112, 6.9112, 170.5573041426782, 2187543.523837968, 2187543.523837968, 428976.1874866427], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6615600.0000, 
sim time next is 6616200.0000, 
raw observation next is [31.41666666666666, 61.0, 1.0, 2.0, 0.930792886276423, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.984302699910219, 6.9112, 168.9125210616532, 2198137.881746459, 2146276.444125815, 443522.685542018], 
processed observation next is [1.0, 0.5652173913043478, 0.6879936808846759, 0.61, 1.0, 1.0, 0.9166179352727988, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.0073102699910219116, 0.0, 0.8294378068994543, 0.6105938560406831, 0.5961879011460597, 0.6619741575254], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5591784], dtype=float32), -0.29393607]. 
=============================================
[2019-03-26 18:15:32,451] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.8578052e-18 1.0000000e+00 1.9592960e-21 1.1248711e-22 1.4721761e-30], sum to 1.0000
[2019-03-26 18:15:32,458] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5029
[2019-03-26 18:15:32,462] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.56666666666667, 34.66666666666667, 1.0, 2.0, 0.2648799904228961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 432452.1975484979, 432452.1975484979, 162377.8519226228], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6873600.0000, 
sim time next is 6874200.0000, 
raw observation next is [29.65, 33.5, 1.0, 2.0, 0.2608519516318573, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 427038.6891723659, 427038.6891723666, 161990.3035745148], 
processed observation next is [0.0, 0.5652173913043478, 0.6042654028436019, 0.335, 1.0, 1.0, 0.1094601826889847, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11862185810343497, 0.11862185810343516, 0.24177657249927584], 
reward next is 0.7582, 
noisyNet noise sample is [array([-0.04318238], dtype=float32), 1.3351989]. 
=============================================
[2019-03-26 18:15:37,240] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.4785591e-16 1.0000000e+00 2.9707080e-19 8.2980708e-17 1.5342549e-27], sum to 1.0000
[2019-03-26 18:15:37,249] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1615
[2019-03-26 18:15:37,254] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 91.0, 1.0, 2.0, 0.4736726639397326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 662746.8627646222, 662746.8627646222, 179686.7581658885], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7088400.0000, 
sim time next is 7089000.0000, 
raw observation next is [24.96666666666667, 91.16666666666667, 1.0, 2.0, 0.4740211407467417, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 663354.1910249898, 663354.1910249904, 179754.1539608379], 
processed observation next is [1.0, 0.043478260869565216, 0.3823064770932071, 0.9116666666666667, 1.0, 1.0, 0.36629053102017073, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18426505306249719, 0.18426505306249732, 0.2682897820311013], 
reward next is 0.7317, 
noisyNet noise sample is [array([0.25725624], dtype=float32), -0.9136167]. 
=============================================
[2019-03-26 18:15:37,267] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[71.576  ]
 [71.51544]
 [71.64019]
 [71.75546]
 [72.04891]], R is [[71.50988007]
 [71.52659607]
 [71.54314423]
 [71.55943298]
 [71.57540131]].
[2019-03-26 18:15:46,681] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.5020392e-16 1.0000000e+00 3.1004518e-19 1.1139507e-17 1.7470417e-27], sum to 1.0000
[2019-03-26 18:15:46,690] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1607
[2019-03-26 18:15:46,696] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.85, 82.5, 1.0, 2.0, 0.4589341912793157, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 651848.6962443208, 651848.6962443208, 178774.2511549591], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7005000.0000, 
sim time next is 7005600.0000, 
raw observation next is [25.8, 83.0, 1.0, 2.0, 0.4602755579210497, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 653117.9531069922, 653117.9531069922, 178890.5725801206], 
processed observation next is [1.0, 0.08695652173913043, 0.42180094786729866, 0.83, 1.0, 1.0, 0.34972958785668634, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18142165364083115, 0.18142165364083115, 0.26700085459719497], 
reward next is 0.7330, 
noisyNet noise sample is [array([0.15780498], dtype=float32), -0.20203014]. 
=============================================
[2019-03-26 18:15:47,235] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-26 18:15:47,238] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 18:15:47,239] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:15:47,241] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 18:15:47,242] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 18:15:47,243] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:15:47,244] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:15:47,243] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 18:15:47,246] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 18:15:47,246] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:15:47,247] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:15:47,266] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run85
[2019-03-26 18:15:47,292] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run85
[2019-03-26 18:15:47,319] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run85
[2019-03-26 18:15:47,320] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run85
[2019-03-26 18:15:47,373] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run85
[2019-03-26 18:16:01,172] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.11117261], dtype=float32), 0.093902804]
[2019-03-26 18:16:01,173] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [21.9, 92.0, 1.0, 2.0, 0.3448697611830409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 536393.5695826844, 536393.569582685, 169664.6349999202]
[2019-03-26 18:16:01,175] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 18:16:01,179] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.3622195e-17 1.0000000e+00 4.7450004e-21 4.5360759e-22 1.8608771e-30], sampled 0.5059057610050773
[2019-03-26 18:16:03,230] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.11117261], dtype=float32), 0.093902804]
[2019-03-26 18:16:03,231] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [21.43333333333333, 96.66666666666667, 1.0, 2.0, 0.3371600872445006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 522255.1675875294, 522255.1675875288, 168469.7412859084]
[2019-03-26 18:16:03,232] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 18:16:03,234] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.5936713e-17 1.0000000e+00 1.3584655e-20 6.6987764e-21 7.3977993e-30], sampled 0.7777898310656796
[2019-03-26 18:16:08,991] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.11117261], dtype=float32), 0.093902804]
[2019-03-26 18:16:08,993] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.610011465, 66.91724468166666, 1.0, 2.0, 0.4740651924334734, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 668700.5258969329, 668700.5258969323, 180441.279504326]
[2019-03-26 18:16:08,994] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 18:16:08,998] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.8494179e-17 1.0000000e+00 1.1039234e-20 2.3665481e-20 4.5871641e-30], sampled 0.08561223426421427
[2019-03-26 18:16:20,599] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.11117261], dtype=float32), 0.093902804]
[2019-03-26 18:16:20,600] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [23.1, 92.5, 1.0, 2.0, 0.3980268650155868, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 595856.4668218048, 595856.4668218048, 174213.0426611147]
[2019-03-26 18:16:20,601] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 18:16:20,605] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [4.2613576e-17 1.0000000e+00 3.1996377e-20 6.1623366e-20 2.7460168e-29], sampled 0.4789233198788213
[2019-03-26 18:16:51,336] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.11117261], dtype=float32), 0.093902804]
[2019-03-26 18:16:51,338] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [36.7, 47.0, 1.0, 2.0, 0.5863405886912058, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 819366.4067026186, 819366.4067026186, 198228.7748470604]
[2019-03-26 18:16:51,340] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:16:51,346] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.8643035e-17 1.0000000e+00 2.5782785e-20 2.3056778e-19 1.0939246e-29], sampled 0.9176040559333172
[2019-03-26 18:16:54,741] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.11117261], dtype=float32), 0.093902804]
[2019-03-26 18:16:54,742] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.0, 66.0, 1.0, 2.0, 0.9913740815923034, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.990244146857611, 6.9112, 168.9124231649531, 2282928.547182573, 2226852.085975126, 461251.2325016756]
[2019-03-26 18:16:54,744] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 18:16:54,746] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.59225538e-10 9.89314914e-01 2.21040741e-10 1.06851095e-02
 2.13263242e-17], sampled 0.7741862849249739
[2019-03-26 18:16:54,747] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2282928.547182573 W.
[2019-03-26 18:17:07,769] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.11117261], dtype=float32), 0.093902804]
[2019-03-26 18:17:07,770] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [31.38901415666667, 66.91195904, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.788446940661927, 6.9112, 168.9081639542181, 2076512.752124869, 1454181.237781892, 311352.5986669476]
[2019-03-26 18:17:07,771] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:17:07,775] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.5552947e-12 1.0000000e+00 4.1887354e-13 3.4510208e-08 1.0206819e-20], sampled 0.3198894951649055
[2019-03-26 18:17:07,776] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2076512.752124869 W.
[2019-03-26 18:17:41,126] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8666.0829 2778399893.4319 906.0000
[2019-03-26 18:17:41,144] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8095.4025 2995998462.7111 1474.0000
[2019-03-26 18:17:41,146] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7985.6021 3152796920.2396 1464.0000
[2019-03-26 18:17:41,204] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8292.4659 2922980245.1359 1220.0000
[2019-03-26 18:17:41,525] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8532.7362 2838488879.8983 1025.0000
[2019-03-26 18:17:42,542] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 2100000, evaluation results [2100000.0, 7985.602053701802, 3152796920.239613, 1464.0, 8292.465928234129, 2922980245.1358843, 1220.0, 8666.082873291985, 2778399893.431933, 906.0, 8095.402519121878, 2995998462.7110777, 1474.0, 8532.736179130854, 2838488879.8983054, 1025.0]
[2019-03-26 18:17:45,478] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.6614049e-10 9.9999344e-01 2.8578813e-11 6.5257518e-06 1.1627716e-17], sum to 1.0000
[2019-03-26 18:17:45,489] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8352
[2019-03-26 18:17:45,498] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1737224.574460585 W.
[2019-03-26 18:17:45,503] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.1, 70.0, 1.0, 2.0, 0.4142116613863185, 1.0, 1.0, 0.4142116613863185, 1.0, 2.0, 0.695309069588711, 6.9112, 6.9112, 170.5573041426782, 1737224.574460585, 1737224.574460585, 357293.2061003831], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7120800.0000, 
sim time next is 7121400.0000, 
raw observation next is [28.18333333333333, 69.5, 1.0, 2.0, 0.6718764220050304, 1.0, 2.0, 0.6718764220050304, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1878712.970325882, 1878712.970325882, 362303.9305370449], 
processed observation next is [1.0, 0.43478260869565216, 0.5347551342812005, 0.695, 1.0, 1.0, 0.6046703879578679, 1.0, 1.0, 0.6046703879578679, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5218647139794117, 0.5218647139794117, 0.5407521351299177], 
reward next is 0.4592, 
noisyNet noise sample is [array([1.2237], dtype=float32), -0.60230184]. 
=============================================
[2019-03-26 18:17:48,055] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.2365765e-16 1.0000000e+00 4.7992166e-19 7.9593509e-17 1.9453485e-27], sum to 1.0000
[2019-03-26 18:17:48,062] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9477
[2019-03-26 18:17:48,069] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.35, 74.33333333333334, 1.0, 2.0, 0.3809585040310223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 575809.4812119086, 575809.4812119086, 172561.7600756117], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7333800.0000, 
sim time next is 7334400.0000, 
raw observation next is [25.3, 74.66666666666667, 1.0, 2.0, 0.3851772154447255, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 582164.1210056443, 582164.1210056443, 173128.0558478968], 
processed observation next is [1.0, 0.9130434782608695, 0.39810426540284366, 0.7466666666666667, 1.0, 1.0, 0.25924965716231985, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1617122558349012, 0.1617122558349012, 0.2584000833550698], 
reward next is 0.7416, 
noisyNet noise sample is [array([-0.38305143], dtype=float32), -0.7730654]. 
=============================================
[2019-03-26 18:17:51,849] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.2861081e-16 1.0000000e+00 4.5251603e-19 4.9183947e-17 9.9001524e-28], sum to 1.0000
[2019-03-26 18:17:51,858] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4932
[2019-03-26 18:17:51,862] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.3, 84.0, 1.0, 2.0, 0.2855715078731841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 460644.8240181939, 460644.8240181946, 164316.5141094386], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7412400.0000, 
sim time next is 7413000.0000, 
raw observation next is [21.36666666666667, 83.66666666666667, 1.0, 2.0, 0.2860117294206158, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 461116.4562357008, 461116.4562357002, 164349.0661752169], 
processed observation next is [1.0, 0.8260869565217391, 0.21169036334913136, 0.8366666666666667, 1.0, 1.0, 0.13977316797664555, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1280879045099169, 0.12808790450991672, 0.24529711369435359], 
reward next is 0.7547, 
noisyNet noise sample is [array([1.7783359], dtype=float32), -1.9065372]. 
=============================================
[2019-03-26 18:17:51,877] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[71.98985 ]
 [71.961266]
 [71.99224 ]
 [71.98995 ]
 [71.9236  ]], R is [[72.03272247]
 [72.0671463 ]
 [72.1011734 ]
 [72.13489532]
 [72.16831207]].
[2019-03-26 18:17:55,020] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:17:55,021] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:17:55,105] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run11
[2019-03-26 18:17:55,178] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.6123079e-18 1.0000000e+00 1.8351200e-21 2.4935432e-21 4.8729784e-31], sum to 1.0000
[2019-03-26 18:17:55,184] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7327
[2019-03-26 18:17:55,190] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.2, 87.0, 1.0, 2.0, 0.4043482749404768, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 597252.8594319754, 597252.8594319754, 174104.4724803634], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7506000.0000, 
sim time next is 7506600.0000, 
raw observation next is [24.15, 87.5, 1.0, 2.0, 0.4043904469570637, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 597081.3529848715, 597081.3529848715, 174081.5188522395], 
processed observation next is [0.0, 0.9130434782608695, 0.34360189573459715, 0.875, 1.0, 1.0, 0.2823981288639322, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16585593138468652, 0.16585593138468652, 0.2598231624660291], 
reward next is 0.7402, 
noisyNet noise sample is [array([0.6233265], dtype=float32), 0.7484975]. 
=============================================
[2019-03-26 18:17:56,866] A3C_AGENT_WORKER-Thread-10 INFO:Local step 132500, global step 2106527: loss 75.6107
[2019-03-26 18:17:56,868] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 132500, global step 2106527: learning rate 0.0000
[2019-03-26 18:17:57,421] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.8656273e-16 1.0000000e+00 9.6505911e-19 3.9214658e-17 7.3089427e-28], sum to 1.0000
[2019-03-26 18:17:57,428] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6358
[2019-03-26 18:17:57,434] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.7, 78.0, 1.0, 2.0, 0.6158571413611812, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 960038.4330644807, 960038.4330644801, 215619.9456759862], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7290000.0000, 
sim time next is 7290600.0000, 
raw observation next is [23.91666666666666, 77.0, 1.0, 2.0, 0.6188979037045651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 963114.0137039186, 963114.0137039186, 216104.6805326202], 
processed observation next is [1.0, 0.391304347826087, 0.3325434439178513, 0.77, 1.0, 1.0, 0.5408408478368254, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2675316704733107, 0.2675316704733107, 0.32254429930241824], 
reward next is 0.6775, 
noisyNet noise sample is [array([-0.07788749], dtype=float32), 0.20516582]. 
=============================================
[2019-03-26 18:18:03,793] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.4005686e-18 1.0000000e+00 1.9500947e-21 3.0663500e-21 9.1249235e-31], sum to 1.0000
[2019-03-26 18:18:03,801] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6726
[2019-03-26 18:18:03,809] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.26666666666667, 75.83333333333334, 1.0, 2.0, 0.4176749148650095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 607589.897698016, 607589.897698016, 174791.688336351], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7488600.0000, 
sim time next is 7489200.0000, 
raw observation next is [26.33333333333334, 75.66666666666667, 1.0, 2.0, 0.4192357920482003, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 608953.8282641704, 608953.8282641704, 174894.0318396651], 
processed observation next is [0.0, 0.6956521739130435, 0.44707740916271754, 0.7566666666666667, 1.0, 1.0, 0.3002840868050606, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16915384118449178, 0.16915384118449178, 0.2610358684174106], 
reward next is 0.7390, 
noisyNet noise sample is [array([-0.13598444], dtype=float32), 0.787631]. 
=============================================
[2019-03-26 18:18:11,040] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:18:11,041] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:18:11,127] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run11
[2019-03-26 18:18:12,770] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:18:12,771] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:18:12,772] A3C_AGENT_WORKER-Thread-9 INFO:Local step 132500, global step 2113834: loss 67.0101
[2019-03-26 18:18:12,778] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 132500, global step 2113836: learning rate 0.0000
[2019-03-26 18:18:12,837] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run11
[2019-03-26 18:18:13,629] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.8213153e-18 1.0000000e+00 1.5324990e-21 1.3156601e-21 6.0315739e-31], sum to 1.0000
[2019-03-26 18:18:13,634] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9688
[2019-03-26 18:18:13,642] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.6, 76.5, 1.0, 2.0, 0.3189954601228765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 500832.1816611238, 500832.1816611232, 167006.4024585263], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 311400.0000, 
sim time next is 312000.0000, 
raw observation next is [23.53333333333333, 76.66666666666666, 1.0, 2.0, 0.3175818045138651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 499111.3738603957, 499111.3738603957, 166889.5330736959], 
processed observation next is [0.0, 0.6086956521739131, 0.3143759873617693, 0.7666666666666666, 1.0, 1.0, 0.17780940302875312, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13864204829455437, 0.13864204829455437, 0.24908885533387448], 
reward next is 0.7509, 
noisyNet noise sample is [array([-0.9444061], dtype=float32), 0.7009037]. 
=============================================
[2019-03-26 18:18:13,661] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[76.50544 ]
 [76.475395]
 [76.44786 ]
 [76.40401 ]
 [76.35871 ]], R is [[76.51932526]
 [76.50487518]
 [76.49037933]
 [76.47587585]
 [76.46151733]].
[2019-03-26 18:18:13,665] A3C_AGENT_WORKER-Thread-10 INFO:Local step 133000, global step 2114306: loss 0.0047
[2019-03-26 18:18:13,667] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 133000, global step 2114307: learning rate 0.0000
[2019-03-26 18:18:14,366] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.8117232e-15 1.0000000e+00 5.2382410e-17 2.1505277e-14 7.4290675e-25], sum to 1.0000
[2019-03-26 18:18:14,376] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6441
[2019-03-26 18:18:14,380] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 64.33333333333334, 1.0, 2.0, 0.8970109981965372, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1356564.801339249, 1356564.80133925, 283653.159163759], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 44400.0000, 
sim time next is 45000.0000, 
raw observation next is [27.1, 64.0, 1.0, 2.0, 0.8708015056141055, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1315394.22188225, 1315394.221882251, 275750.6015969994], 
processed observation next is [1.0, 0.5217391304347826, 0.4834123222748816, 0.64, 1.0, 1.0, 0.8443391633904885, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3653872838561805, 0.36538728385618086, 0.41156806208507374], 
reward next is 0.5884, 
noisyNet noise sample is [array([1.7169702], dtype=float32), 0.66753167]. 
=============================================
[2019-03-26 18:18:14,396] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[66.21869 ]
 [66.24046 ]
 [66.143524]
 [66.29837 ]
 [66.596146]], R is [[66.14955902]
 [66.0647049 ]
 [65.98012543]
 [65.85687256]
 [65.71463776]].
[2019-03-26 18:18:14,525] A3C_AGENT_WORKER-Thread-13 INFO:Local step 132500, global step 2114748: loss 74.0621
[2019-03-26 18:18:14,526] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 132500, global step 2114748: learning rate 0.0000
[2019-03-26 18:18:16,415] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.0349595e-15 1.0000000e+00 3.0521889e-17 5.1558548e-15 8.7220110e-26], sum to 1.0000
[2019-03-26 18:18:16,424] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6353
[2019-03-26 18:18:16,433] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2195738.066200659 W.
[2019-03-26 18:18:16,439] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.56666666666667, 81.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.956398564560557, 6.9112, 168.9074413263596, 2195738.066200659, 1454262.442285448, 311349.1207600065], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7892400.0000, 
sim time next is 7893000.0000, 
raw observation next is [27.7, 80.5, 1.0, 2.0, 0.7040452410156575, 1.0, 1.0, 0.7040452410156575, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1968746.647557265, 1968746.647557265, 375855.7168597497], 
processed observation next is [1.0, 0.34782608695652173, 0.5118483412322274, 0.805, 1.0, 1.0, 0.6434280012236837, 1.0, 0.5, 0.6434280012236837, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5468740687659069, 0.5468740687659069, 0.5609786818802234], 
reward next is 0.4390, 
noisyNet noise sample is [array([-0.2699254], dtype=float32), -0.9587385]. 
=============================================
[2019-03-26 18:18:16,454] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[66.26367 ]
 [67.52009 ]
 [67.85661 ]
 [67.79228 ]
 [67.785774]], R is [[62.68701935]
 [62.06015015]
 [62.04925537]
 [62.1011467 ]
 [62.15420532]].
[2019-03-26 18:18:20,878] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:18:20,879] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:18:20,950] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run11
[2019-03-26 18:18:21,508] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:18:21,508] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:18:21,551] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run11
[2019-03-26 18:18:22,456] A3C_AGENT_WORKER-Thread-14 INFO:Local step 132500, global step 2118471: loss 74.9995
[2019-03-26 18:18:22,458] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 132500, global step 2118471: learning rate 0.0000
[2019-03-26 18:18:23,064] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:18:23,065] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:18:23,122] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run11
[2019-03-26 18:18:23,196] A3C_AGENT_WORKER-Thread-2 INFO:Local step 132500, global step 2118822: loss 69.0730
[2019-03-26 18:18:23,198] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 132500, global step 2118823: learning rate 0.0000
[2019-03-26 18:18:23,485] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:18:23,486] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:18:23,561] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run11
[2019-03-26 18:18:24,678] A3C_AGENT_WORKER-Thread-3 INFO:Local step 132500, global step 2119689: loss 78.9496
[2019-03-26 18:18:24,682] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 132500, global step 2119690: learning rate 0.0000
[2019-03-26 18:18:25,259] A3C_AGENT_WORKER-Thread-15 INFO:Local step 132500, global step 2119960: loss 81.7044
[2019-03-26 18:18:25,263] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 132500, global step 2119962: learning rate 0.0000
[2019-03-26 18:18:26,793] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:18:26,794] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:18:26,874] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run11
[2019-03-26 18:18:27,989] A3C_AGENT_WORKER-Thread-9 INFO:Local step 133000, global step 2121302: loss 0.0047
[2019-03-26 18:18:27,991] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 133000, global step 2121302: learning rate 0.0000
[2019-03-26 18:18:28,561] A3C_AGENT_WORKER-Thread-22 INFO:Local step 132500, global step 2121563: loss 68.7355
[2019-03-26 18:18:28,567] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 132500, global step 2121564: learning rate 0.0000
[2019-03-26 18:18:29,020] A3C_AGENT_WORKER-Thread-10 INFO:Local step 133500, global step 2121770: loss 0.0208
[2019-03-26 18:18:29,023] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 133500, global step 2121770: learning rate 0.0000
[2019-03-26 18:18:29,350] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:18:29,351] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:18:29,437] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run11
[2019-03-26 18:18:29,901] A3C_AGENT_WORKER-Thread-13 INFO:Local step 133000, global step 2122188: loss 0.0039
[2019-03-26 18:18:29,903] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 133000, global step 2122188: learning rate 0.0000
[2019-03-26 18:18:30,557] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.1112424e-18 1.0000000e+00 6.1585232e-22 2.3895874e-22 2.3608993e-31], sum to 1.0000
[2019-03-26 18:18:30,567] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9673
[2019-03-26 18:18:30,572] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.78333333333333, 83.5, 1.0, 2.0, 0.2943319659023842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 470804.6572689256, 470804.6572689256, 164999.0932222761], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 327000.0000, 
sim time next is 327600.0000, 
raw observation next is [21.7, 84.0, 1.0, 2.0, 0.2923484757194712, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 467795.4244397502, 467795.4244397502, 164790.8867092818], 
processed observation next is [0.0, 0.8260869565217391, 0.2274881516587678, 0.84, 1.0, 1.0, 0.14740780207165205, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.12994317345548617, 0.12994317345548617, 0.24595654732728625], 
reward next is 0.7540, 
noisyNet noise sample is [array([2.0451334], dtype=float32), 0.07273211]. 
=============================================
[2019-03-26 18:18:31,086] A3C_AGENT_WORKER-Thread-16 INFO:Local step 132500, global step 2122821: loss 77.9447
[2019-03-26 18:18:31,087] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 132500, global step 2122821: learning rate 0.0000
[2019-03-26 18:18:31,809] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:18:31,811] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:18:31,881] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run11
[2019-03-26 18:18:32,048] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:18:32,049] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:18:32,120] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run11
[2019-03-26 18:18:32,724] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.5003383e-18 1.0000000e+00 1.7211429e-21 3.1558500e-22 1.1638943e-30], sum to 1.0000
[2019-03-26 18:18:32,729] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1585
[2019-03-26 18:18:32,735] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.88333333333334, 91.66666666666667, 1.0, 2.0, 0.301606091918902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 481326.6202784381, 481326.6202784388, 165731.2482351321], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 213000.0000, 
sim time next is 213600.0000, 
raw observation next is [20.96666666666667, 91.33333333333334, 1.0, 2.0, 0.3037413313631027, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 484300.2789703728, 484300.2789703728, 165939.3758367369], 
processed observation next is [0.0, 0.4782608695652174, 0.1927330173775673, 0.9133333333333334, 1.0, 1.0, 0.1611341341724129, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.134527855269548, 0.134527855269548, 0.24767071020408493], 
reward next is 0.7523, 
noisyNet noise sample is [array([0.51305366], dtype=float32), 2.3735769]. 
=============================================
[2019-03-26 18:18:33,219] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:18:33,219] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:18:33,230] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:18:33,231] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:18:33,281] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run11
[2019-03-26 18:18:33,321] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run11
[2019-03-26 18:18:33,379] A3C_AGENT_WORKER-Thread-20 INFO:Local step 132500, global step 2124000: loss 79.7135
[2019-03-26 18:18:33,380] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 132500, global step 2124000: learning rate 0.0000
[2019-03-26 18:18:33,594] A3C_AGENT_WORKER-Thread-17 INFO:Local step 132500, global step 2124138: loss 69.2589
[2019-03-26 18:18:33,595] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 132500, global step 2124138: learning rate 0.0000
[2019-03-26 18:18:33,809] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:18:33,809] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:18:33,857] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run11
[2019-03-26 18:18:33,966] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:18:33,967] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:18:34,015] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run11
[2019-03-26 18:18:34,411] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:18:34,411] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:18:34,457] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run11
[2019-03-26 18:18:34,790] A3C_AGENT_WORKER-Thread-12 INFO:Local step 132500, global step 2124840: loss 66.4180
[2019-03-26 18:18:34,794] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 132500, global step 2124841: learning rate 0.0000
[2019-03-26 18:18:34,826] A3C_AGENT_WORKER-Thread-18 INFO:Local step 132500, global step 2124863: loss 69.4528
[2019-03-26 18:18:34,829] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 132500, global step 2124863: learning rate 0.0000
[2019-03-26 18:18:35,034] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-26 18:18:35,036] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 18:18:35,037] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:18:35,037] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 18:18:35,038] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 18:18:35,038] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:18:35,039] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 18:18:35,039] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:18:35,038] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 18:18:35,040] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:18:35,041] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:18:35,051] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run86
[2019-03-26 18:18:35,073] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run86
[2019-03-26 18:18:35,093] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run86
[2019-03-26 18:18:35,096] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run86
[2019-03-26 18:18:35,133] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run86
[2019-03-26 18:18:49,526] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.11229238], dtype=float32), 0.09609096]
[2019-03-26 18:18:49,527] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [22.84197640666667, 77.22114495666666, 1.0, 2.0, 0.3000154383212053, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 478229.5634081936, 478229.5634081942, 165502.5169192029]
[2019-03-26 18:18:49,529] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:18:49,532] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [6.2315345e-18 1.0000000e+00 1.5863051e-21 1.4487942e-22 5.0359556e-31], sampled 0.020337352901471206
[2019-03-26 18:19:47,617] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.11229238], dtype=float32), 0.09609096]
[2019-03-26 18:19:47,620] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.86902387333334, 87.12852194333334, 1.0, 2.0, 0.5267015706771515, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 735996.5383042195, 735996.5383042202, 187885.0787896812]
[2019-03-26 18:19:47,622] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 18:19:47,625] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.5189120e-17 1.0000000e+00 1.5797478e-20 2.0210987e-20 9.7895064e-30], sampled 0.484422874908476
[2019-03-26 18:19:52,418] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.11229238], dtype=float32), 0.09609096]
[2019-03-26 18:19:52,420] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.16666666666666, 74.33333333333334, 1.0, 2.0, 0.6761495896883333, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.001410487378198, 6.9112, 168.912347624564, 1841754.155216316, 1777755.961362005, 379738.3053521616]
[2019-03-26 18:19:52,422] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 18:19:52,424] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [4.4718823e-10 9.1774291e-01 6.1059063e-10 8.2257114e-02 2.1812768e-17], sampled 0.5403613540493467
[2019-03-26 18:19:52,426] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1841754.155216316 W.
[2019-03-26 18:20:24,175] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.11229238], dtype=float32), 0.09609096]
[2019-03-26 18:20:24,177] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.06666666666667, 76.33333333333333, 1.0, 2.0, 0.5483270971163285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 766226.2814403186, 766226.2814403186, 191513.724959382]
[2019-03-26 18:20:24,180] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:20:24,183] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.1832188e-17 1.0000000e+00 8.3615092e-21 6.2044407e-20 2.8575290e-30], sampled 0.7611306497609045
[2019-03-26 18:20:28,347] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8285.3117 2923644231.3332 1240.0000
[2019-03-26 18:20:28,866] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7978.3332 3154380183.1922 1500.0000
[2019-03-26 18:20:28,966] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8524.5231 2838924903.6396 1046.0000
[2019-03-26 18:20:29,010] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8064.7170 2998489975.4481 1532.0000
[2019-03-26 18:20:29,170] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8668.3164 2778347612.4242 912.0000
[2019-03-26 18:20:30,188] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 2125000, evaluation results [2125000.0, 7978.333198637718, 3154380183.1921625, 1500.0, 8285.311657904314, 2923644231.333164, 1240.0, 8668.316403059545, 2778347612.424154, 912.0, 8064.717031261837, 2998489975.448115, 1532.0, 8524.523143958444, 2838924903.6396027, 1046.0]
[2019-03-26 18:20:30,728] A3C_AGENT_WORKER-Thread-21 INFO:Local step 132500, global step 2125245: loss 75.7787
[2019-03-26 18:20:30,733] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 132500, global step 2125248: learning rate 0.0000
[2019-03-26 18:20:30,846] A3C_AGENT_WORKER-Thread-11 INFO:Local step 132500, global step 2125307: loss 75.9021
[2019-03-26 18:20:30,847] A3C_AGENT_WORKER-Thread-19 INFO:Local step 132500, global step 2125307: loss 68.5084
[2019-03-26 18:20:30,851] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 132500, global step 2125307: learning rate 0.0000
[2019-03-26 18:20:30,851] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 132500, global step 2125307: learning rate 0.0000
[2019-03-26 18:20:31,000] A3C_AGENT_WORKER-Thread-14 INFO:Local step 133000, global step 2125372: loss 0.0003
[2019-03-26 18:20:31,007] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 133000, global step 2125375: learning rate 0.0000
[2019-03-26 18:20:31,787] A3C_AGENT_WORKER-Thread-2 INFO:Local step 133000, global step 2125725: loss 0.0002
[2019-03-26 18:20:31,788] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 133000, global step 2125725: learning rate 0.0000
[2019-03-26 18:20:34,050] A3C_AGENT_WORKER-Thread-3 INFO:Local step 133000, global step 2126748: loss 0.0003
[2019-03-26 18:20:34,053] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 133000, global step 2126749: learning rate 0.0000
[2019-03-26 18:20:34,871] A3C_AGENT_WORKER-Thread-15 INFO:Local step 133000, global step 2127115: loss 0.0001
[2019-03-26 18:20:34,875] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 133000, global step 2127116: learning rate 0.0000
[2019-03-26 18:20:36,082] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.4673800e-18 1.0000000e+00 6.9760724e-22 9.4853449e-23 3.0997704e-31], sum to 1.0000
[2019-03-26 18:20:36,091] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4686
[2019-03-26 18:20:36,095] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.76666666666667, 94.66666666666666, 1.0, 2.0, 0.2734517028126561, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 442613.6084806612, 442613.6084806618, 163106.7859766746], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 272400.0000, 
sim time next is 273000.0000, 
raw observation next is [19.68333333333334, 94.83333333333333, 1.0, 2.0, 0.271873520447051, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 440555.6388244175, 440555.6388244175, 162968.2208868575], 
processed observation next is [0.0, 0.13043478260869565, 0.13191153238546643, 0.9483333333333333, 1.0, 1.0, 0.12273918126150721, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.12237656634011597, 0.12237656634011597, 0.24323615057739928], 
reward next is 0.7568, 
noisyNet noise sample is [array([-0.44653252], dtype=float32), 1.5066377]. 
=============================================
[2019-03-26 18:20:36,109] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[77.23893]
 [77.32352]
 [77.33986]
 [77.38029]
 [77.42674]], R is [[77.13841248]
 [77.12358093]
 [77.10862732]
 [77.09352875]
 [77.07829285]].
[2019-03-26 18:20:37,669] A3C_AGENT_WORKER-Thread-9 INFO:Local step 133500, global step 2128495: loss 0.0092
[2019-03-26 18:20:37,671] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 133500, global step 2128496: learning rate 0.0000
[2019-03-26 18:20:37,712] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.6419097e-17 1.0000000e+00 1.9802991e-20 2.8286418e-19 5.5813221e-29], sum to 1.0000
[2019-03-26 18:20:37,719] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8062
[2019-03-26 18:20:37,722] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.05, 89.5, 1.0, 2.0, 0.2628025625747001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 427839.1772719586, 427839.1772719593, 162122.1209462835], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 364200.0000, 
sim time next is 364800.0000, 
raw observation next is [20.1, 89.0, 1.0, 2.0, 0.2577437023177542, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 419668.4362613151, 419668.4362613158, 161610.9908548877], 
processed observation next is [1.0, 0.21739130434782608, 0.15165876777251197, 0.89, 1.0, 1.0, 0.10571530399729417, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11657456562814307, 0.11657456562814326, 0.24121043411177268], 
reward next is 0.7588, 
noisyNet noise sample is [array([-0.18204993], dtype=float32), 0.16143243]. 
=============================================
[2019-03-26 18:20:38,031] A3C_AGENT_WORKER-Thread-22 INFO:Local step 133000, global step 2128714: loss 0.0003
[2019-03-26 18:20:38,034] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 133000, global step 2128714: learning rate 0.0000
[2019-03-26 18:20:38,616] A3C_AGENT_WORKER-Thread-10 INFO:Local step 134000, global step 2128998: loss 0.0025
[2019-03-26 18:20:38,620] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 134000, global step 2128999: learning rate 0.0000
[2019-03-26 18:20:39,544] A3C_AGENT_WORKER-Thread-13 INFO:Local step 133500, global step 2129417: loss 0.0058
[2019-03-26 18:20:39,545] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 133500, global step 2129418: learning rate 0.0000
[2019-03-26 18:20:41,333] A3C_AGENT_WORKER-Thread-16 INFO:Local step 133000, global step 2130150: loss 0.0001
[2019-03-26 18:20:41,334] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 133000, global step 2130151: learning rate 0.0000
[2019-03-26 18:20:41,450] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.9565133e-18 1.0000000e+00 9.8253123e-22 3.7891062e-23 3.6724846e-31], sum to 1.0000
[2019-03-26 18:20:41,452] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0391
[2019-03-26 18:20:41,458] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.76666666666667, 92.33333333333333, 1.0, 2.0, 0.3016456660709038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 481606.5066932109, 481606.5066932116, 165753.8694256359], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 211200.0000, 
sim time next is 211800.0000, 
raw observation next is [20.78333333333333, 92.16666666666667, 1.0, 2.0, 0.3010305345907621, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 480659.1345238702, 480659.1345238708, 165686.503816592], 
processed observation next is [0.0, 0.43478260869565216, 0.18404423380726695, 0.9216666666666667, 1.0, 1.0, 0.15786811396477363, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1335164262566306, 0.13351642625663077, 0.24729328927849553], 
reward next is 0.7527, 
noisyNet noise sample is [array([0.34761408], dtype=float32), -0.29537565]. 
=============================================
[2019-03-26 18:20:43,929] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.9275808e-16 1.0000000e+00 1.4493989e-19 1.1596468e-18 9.0146335e-29], sum to 1.0000
[2019-03-26 18:20:43,941] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9307
[2019-03-26 18:20:43,947] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.23333333333333, 87.66666666666667, 1.0, 2.0, 0.2570072202831113, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 418694.6661228547, 418694.6661228547, 161545.5676615469], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 355200.0000, 
sim time next is 355800.0000, 
raw observation next is [20.21666666666667, 87.83333333333334, 1.0, 2.0, 0.2554891253045659, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 416197.0379709683, 416197.0379709689, 161392.5708607158], 
processed observation next is [1.0, 0.08695652173913043, 0.15718799368088482, 0.8783333333333334, 1.0, 1.0, 0.1029989461500794, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11561028832526897, 0.11561028832526914, 0.24088443412047134], 
reward next is 0.7591, 
noisyNet noise sample is [array([1.1252022], dtype=float32), 1.9906826]. 
=============================================
[2019-03-26 18:20:44,494] A3C_AGENT_WORKER-Thread-20 INFO:Local step 133000, global step 2131579: loss 0.0004
[2019-03-26 18:20:44,497] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 133000, global step 2131579: learning rate 0.0000
[2019-03-26 18:20:45,034] A3C_AGENT_WORKER-Thread-17 INFO:Local step 133000, global step 2131820: loss 0.0002
[2019-03-26 18:20:45,038] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 133000, global step 2131820: learning rate 0.0000
[2019-03-26 18:20:47,316] A3C_AGENT_WORKER-Thread-12 INFO:Local step 133000, global step 2132849: loss 0.0002
[2019-03-26 18:20:47,318] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 133000, global step 2132849: learning rate 0.0000
[2019-03-26 18:20:47,373] A3C_AGENT_WORKER-Thread-18 INFO:Local step 133000, global step 2132873: loss 0.0003
[2019-03-26 18:20:47,378] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 133000, global step 2132876: learning rate 0.0000
[2019-03-26 18:20:48,171] A3C_AGENT_WORKER-Thread-21 INFO:Local step 133000, global step 2133224: loss 0.0001
[2019-03-26 18:20:48,173] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 133000, global step 2133227: learning rate 0.0000
[2019-03-26 18:20:48,303] A3C_AGENT_WORKER-Thread-19 INFO:Local step 133000, global step 2133285: loss 0.0001
[2019-03-26 18:20:48,304] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 133000, global step 2133285: learning rate 0.0000
[2019-03-26 18:20:48,399] A3C_AGENT_WORKER-Thread-14 INFO:Local step 133500, global step 2133328: loss 0.0057
[2019-03-26 18:20:48,403] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 133500, global step 2133331: learning rate 0.0000
[2019-03-26 18:20:48,529] A3C_AGENT_WORKER-Thread-11 INFO:Local step 133000, global step 2133386: loss 0.0001
[2019-03-26 18:20:48,533] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 133000, global step 2133386: learning rate 0.0000
[2019-03-26 18:20:49,218] A3C_AGENT_WORKER-Thread-2 INFO:Local step 133500, global step 2133696: loss 0.0064
[2019-03-26 18:20:49,220] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 133500, global step 2133696: learning rate 0.0000
[2019-03-26 18:20:50,938] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.85605481e-17 1.00000000e+00 1.23491215e-20 1.96361549e-19
 2.54968750e-29], sum to 1.0000
[2019-03-26 18:20:50,951] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5288
[2019-03-26 18:20:50,957] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.85, 82.0, 1.0, 2.0, 0.2625000250971872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 428190.0392884404, 428190.0392884411, 162121.5575474764], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 372600.0000, 
sim time next is 373200.0000, 
raw observation next is [20.9, 81.33333333333333, 1.0, 2.0, 0.2632798901781312, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 429699.1839963064, 429699.1839963064, 162208.926143423], 
processed observation next is [1.0, 0.30434782608695654, 0.1895734597156398, 0.8133333333333332, 1.0, 1.0, 0.1123854098531701, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.11936088444341844, 0.11936088444341844, 0.24210287484092988], 
reward next is 0.7579, 
noisyNet noise sample is [array([-0.12490446], dtype=float32), -0.34365782]. 
=============================================
[2019-03-26 18:20:51,694] A3C_AGENT_WORKER-Thread-3 INFO:Local step 133500, global step 2134808: loss 0.0062
[2019-03-26 18:20:51,696] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 133500, global step 2134808: learning rate 0.0000
[2019-03-26 18:20:52,341] A3C_AGENT_WORKER-Thread-15 INFO:Local step 133500, global step 2135101: loss 0.0062
[2019-03-26 18:20:52,345] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 133500, global step 2135101: learning rate 0.0000
[2019-03-26 18:20:55,381] A3C_AGENT_WORKER-Thread-9 INFO:Local step 134000, global step 2136484: loss 0.0033
[2019-03-26 18:20:55,382] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 134000, global step 2136484: learning rate 0.0000
[2019-03-26 18:20:55,911] A3C_AGENT_WORKER-Thread-22 INFO:Local step 133500, global step 2136727: loss 0.0050
[2019-03-26 18:20:55,915] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 133500, global step 2136727: learning rate 0.0000
[2019-03-26 18:20:56,620] A3C_AGENT_WORKER-Thread-10 INFO:Local step 134500, global step 2137046: loss 3.0543
[2019-03-26 18:20:56,622] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 134500, global step 2137046: learning rate 0.0000
[2019-03-26 18:20:57,561] A3C_AGENT_WORKER-Thread-13 INFO:Local step 134000, global step 2137470: loss 0.0046
[2019-03-26 18:20:57,563] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 134000, global step 2137470: learning rate 0.0000
[2019-03-26 18:20:58,234] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.0561517e-16 1.0000000e+00 8.9891604e-20 4.8376161e-18 6.1334653e-28], sum to 1.0000
[2019-03-26 18:20:58,244] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6824
[2019-03-26 18:20:58,251] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.2, 61.0, 1.0, 2.0, 0.2450129090338873, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 403502.7665618007, 403502.7665618007, 160408.1908090874], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 496800.0000, 
sim time next is 497400.0000, 
raw observation next is [22.95, 62.33333333333334, 1.0, 2.0, 0.2468573924072627, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 406673.5049488174, 406673.504948818, 160583.7274971596], 
processed observation next is [1.0, 0.782608695652174, 0.28672985781990523, 0.6233333333333334, 1.0, 1.0, 0.09259926796055747, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11296486248578262, 0.11296486248578277, 0.23967720521964117], 
reward next is 0.7603, 
noisyNet noise sample is [array([-0.2669376], dtype=float32), 0.19180708]. 
=============================================
[2019-03-26 18:20:58,634] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.5948777e-16 1.0000000e+00 1.8049083e-18 2.1596189e-15 3.5914172e-27], sum to 1.0000
[2019-03-26 18:20:58,644] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3735
[2019-03-26 18:20:58,652] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1780997.064492748 W.
[2019-03-26 18:20:58,659] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.01666666666667, 74.33333333333333, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.329390880512875, 6.9112, 168.9110677347442, 1780997.064492748, 1484321.378286425, 316201.3668282327], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1246200.0000, 
sim time next is 1246800.0000, 
raw observation next is [27.23333333333334, 73.66666666666667, 1.0, 2.0, 0.586624993963457, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9821851794979696, 6.911200000000001, 6.9112, 168.9126160012299, 1654672.817811926, 1654672.817811925, 352071.2666277591], 
processed observation next is [1.0, 0.43478260869565216, 0.4897314375987366, 0.7366666666666667, 1.0, 1.0, 0.5019578240523578, 0.0, 1.0, -0.20481927710843376, 1.0, 0.5, 0.9782746091438652, 8.881784197001253e-17, 0.0, 0.8294382730962395, 0.45963133828109054, 0.45963133828109026, 0.5254795024294912], 
reward next is 0.4745, 
noisyNet noise sample is [array([-0.15262176], dtype=float32), 0.9075013]. 
=============================================
[2019-03-26 18:20:59,007] A3C_AGENT_WORKER-Thread-16 INFO:Local step 133500, global step 2138120: loss 0.0043
[2019-03-26 18:20:59,010] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 133500, global step 2138120: learning rate 0.0000
[2019-03-26 18:21:01,389] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.3879648e-17 1.0000000e+00 2.9877424e-20 3.7718084e-19 1.1737133e-28], sum to 1.0000
[2019-03-26 18:21:01,399] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1267
[2019-03-26 18:21:01,406] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 93.0, 1.0, 2.0, 0.3803033263627877, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 589522.8986981047, 589522.8986981041, 174136.7082311656], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 976200.0000, 
sim time next is 976800.0000, 
raw observation next is [21.9, 93.0, 1.0, 2.0, 0.3449124497226351, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 534645.4057453935, 534645.4057453941, 169474.8919889455], 
processed observation next is [1.0, 0.30434782608695654, 0.23696682464454974, 0.93, 1.0, 1.0, 0.21073789123209044, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14851261270705374, 0.1485126127070539, 0.25294759998350075], 
reward next is 0.7471, 
noisyNet noise sample is [array([0.06059456], dtype=float32), 0.6429155]. 
=============================================
[2019-03-26 18:21:02,240] A3C_AGENT_WORKER-Thread-20 INFO:Local step 133500, global step 2139563: loss 0.0045
[2019-03-26 18:21:02,245] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 133500, global step 2139563: learning rate 0.0000
[2019-03-26 18:21:02,729] A3C_AGENT_WORKER-Thread-17 INFO:Local step 133500, global step 2139784: loss 0.0044
[2019-03-26 18:21:02,731] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 133500, global step 2139784: learning rate 0.0000
[2019-03-26 18:21:04,963] A3C_AGENT_WORKER-Thread-18 INFO:Local step 133500, global step 2140794: loss 0.0042
[2019-03-26 18:21:04,965] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 133500, global step 2140794: learning rate 0.0000
[2019-03-26 18:21:05,113] A3C_AGENT_WORKER-Thread-12 INFO:Local step 133500, global step 2140862: loss 0.0042
[2019-03-26 18:21:05,115] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 133500, global step 2140862: learning rate 0.0000
[2019-03-26 18:21:05,905] A3C_AGENT_WORKER-Thread-21 INFO:Local step 133500, global step 2141217: loss 0.0045
[2019-03-26 18:21:05,906] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 133500, global step 2141217: learning rate 0.0000
[2019-03-26 18:21:06,002] A3C_AGENT_WORKER-Thread-19 INFO:Local step 133500, global step 2141257: loss 0.0043
[2019-03-26 18:21:06,004] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 133500, global step 2141258: learning rate 0.0000
[2019-03-26 18:21:06,226] A3C_AGENT_WORKER-Thread-14 INFO:Local step 134000, global step 2141361: loss 0.0041
[2019-03-26 18:21:06,227] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 134000, global step 2141361: learning rate 0.0000
[2019-03-26 18:21:06,269] A3C_AGENT_WORKER-Thread-11 INFO:Local step 133500, global step 2141378: loss 0.0043
[2019-03-26 18:21:06,271] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 133500, global step 2141378: learning rate 0.0000
[2019-03-26 18:21:06,958] A3C_AGENT_WORKER-Thread-2 INFO:Local step 134000, global step 2141689: loss 0.0061
[2019-03-26 18:21:06,960] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 134000, global step 2141691: learning rate 0.0000
[2019-03-26 18:21:09,574] A3C_AGENT_WORKER-Thread-3 INFO:Local step 134000, global step 2142871: loss 0.0034
[2019-03-26 18:21:09,577] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 134000, global step 2142871: learning rate 0.0000
[2019-03-26 18:21:10,186] A3C_AGENT_WORKER-Thread-15 INFO:Local step 134000, global step 2143145: loss 0.0030
[2019-03-26 18:21:10,188] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 134000, global step 2143146: learning rate 0.0000
[2019-03-26 18:21:13,081] A3C_AGENT_WORKER-Thread-9 INFO:Local step 134500, global step 2144453: loss 3.1428
[2019-03-26 18:21:13,083] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 134500, global step 2144454: learning rate 0.0000
[2019-03-26 18:21:13,755] A3C_AGENT_WORKER-Thread-22 INFO:Local step 134000, global step 2144757: loss 0.0027
[2019-03-26 18:21:13,760] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 134000, global step 2144758: learning rate 0.0000
[2019-03-26 18:21:14,533] A3C_AGENT_WORKER-Thread-10 INFO:Local step 135000, global step 2145107: loss 0.0005
[2019-03-26 18:21:14,536] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 135000, global step 2145108: learning rate 0.0000
[2019-03-26 18:21:15,418] A3C_AGENT_WORKER-Thread-13 INFO:Local step 134500, global step 2145508: loss 3.1871
[2019-03-26 18:21:15,420] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 134500, global step 2145508: learning rate 0.0000
[2019-03-26 18:21:16,631] A3C_AGENT_WORKER-Thread-16 INFO:Local step 134000, global step 2146040: loss 0.0024
[2019-03-26 18:21:16,636] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 134000, global step 2146042: learning rate 0.0000
[2019-03-26 18:21:19,902] A3C_AGENT_WORKER-Thread-20 INFO:Local step 134000, global step 2147514: loss 0.0012
[2019-03-26 18:21:19,904] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 134000, global step 2147514: learning rate 0.0000
[2019-03-26 18:21:20,589] A3C_AGENT_WORKER-Thread-17 INFO:Local step 134000, global step 2147821: loss 0.0017
[2019-03-26 18:21:20,591] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 134000, global step 2147822: learning rate 0.0000
[2019-03-26 18:21:21,435] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0598869e-16 1.0000000e+00 1.5340630e-18 5.2456422e-16 5.9465984e-27], sum to 1.0000
[2019-03-26 18:21:21,442] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8333
[2019-03-26 18:21:21,448] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.88333333333333, 63.5, 1.0, 2.0, 0.5262258908200603, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 801873.4452989831, 801873.4452989837, 195883.366619986], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1169400.0000, 
sim time next is 1170000.0000, 
raw observation next is [27.0, 63.0, 1.0, 2.0, 0.5250589993288421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 799527.1029328268, 799527.1029328268, 195610.9273368673], 
processed observation next is [1.0, 0.5652173913043478, 0.4786729857819906, 0.63, 1.0, 1.0, 0.42778192690221944, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22209086192578523, 0.22209086192578523, 0.29195660796547357], 
reward next is 0.7080, 
noisyNet noise sample is [array([1.8390074], dtype=float32), -0.38649657]. 
=============================================
[2019-03-26 18:21:21,464] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[71.03527]
 [70.86943]
 [70.62194]
 [70.54421]
 [70.44803]], R is [[71.18473816]
 [71.18052673]
 [71.17202759]
 [71.13582611]
 [71.09236908]].
[2019-03-26 18:21:21,475] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.9759893e-18 1.0000000e+00 2.1875296e-21 2.3311283e-21 4.0698492e-31], sum to 1.0000
[2019-03-26 18:21:21,486] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1726
[2019-03-26 18:21:21,490] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.1, 89.0, 1.0, 2.0, 0.2935083253260662, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 469225.7463031584, 469225.7463031584, 164885.6876700621], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 871200.0000, 
sim time next is 871800.0000, 
raw observation next is [21.08333333333334, 89.0, 1.0, 2.0, 0.292641747443764, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 468052.1249192206, 468052.12491922, 164806.3618896688], 
processed observation next is [0.0, 0.08695652173913043, 0.1982622432859403, 0.89, 1.0, 1.0, 0.1477611414985108, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13001447914422792, 0.13001447914422778, 0.24597964461144597], 
reward next is 0.7540, 
noisyNet noise sample is [array([-0.95908], dtype=float32), 0.16176835]. 
=============================================
[2019-03-26 18:21:22,698] A3C_AGENT_WORKER-Thread-18 INFO:Local step 134000, global step 2148767: loss 0.0008
[2019-03-26 18:21:22,700] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 134000, global step 2148768: learning rate 0.0000
[2019-03-26 18:21:22,821] A3C_AGENT_WORKER-Thread-12 INFO:Local step 134000, global step 2148821: loss 0.0007
[2019-03-26 18:21:22,823] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 134000, global step 2148821: learning rate 0.0000
[2019-03-26 18:21:23,651] A3C_AGENT_WORKER-Thread-21 INFO:Local step 134000, global step 2149200: loss 0.0021
[2019-03-26 18:21:23,653] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 134000, global step 2149201: learning rate 0.0000
[2019-03-26 18:21:23,853] A3C_AGENT_WORKER-Thread-19 INFO:Local step 134000, global step 2149289: loss 0.0013
[2019-03-26 18:21:23,856] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 134000, global step 2149289: learning rate 0.0000
[2019-03-26 18:21:23,955] A3C_AGENT_WORKER-Thread-14 INFO:Local step 134500, global step 2149337: loss 3.1127
[2019-03-26 18:21:23,956] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 134500, global step 2149337: learning rate 0.0000
[2019-03-26 18:21:24,122] A3C_AGENT_WORKER-Thread-11 INFO:Local step 134000, global step 2149406: loss 0.0013
[2019-03-26 18:21:24,127] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 134000, global step 2149410: learning rate 0.0000
[2019-03-26 18:21:24,554] A3C_AGENT_WORKER-Thread-2 INFO:Local step 134500, global step 2149603: loss 3.0264
[2019-03-26 18:21:24,557] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 134500, global step 2149604: learning rate 0.0000
[2019-03-26 18:21:25,440] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-26 18:21:25,441] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 18:21:25,442] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:21:25,442] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 18:21:25,443] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 18:21:25,445] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:21:25,445] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:21:25,446] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 18:21:25,446] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 18:21:25,449] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:21:25,451] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:21:25,474] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run87
[2019-03-26 18:21:25,500] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run87
[2019-03-26 18:21:25,522] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run87
[2019-03-26 18:21:25,523] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run87
[2019-03-26 18:21:25,575] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run87
[2019-03-26 18:21:44,739] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.11241935], dtype=float32), 0.09619229]
[2019-03-26 18:21:44,740] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.55921190833333, 78.21195088, 1.0, 2.0, 0.5718651523669529, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 806847.9733802415, 806847.973380241, 196612.6069938871]
[2019-03-26 18:21:44,740] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 18:21:44,743] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.4156173e-17 1.0000000e+00 2.4858989e-20 5.8820723e-20 1.8612685e-29], sampled 0.8724469000451023
[2019-03-26 18:22:08,453] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.11241935], dtype=float32), 0.09619229]
[2019-03-26 18:22:08,454] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [34.2, 56.0, 1.0, 2.0, 0.8649154078539688, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1208875.11555356, 1208875.115553561, 260472.2704924075]
[2019-03-26 18:22:08,455] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 18:22:08,459] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.3027535e-16 1.0000000e+00 2.6469438e-19 1.8038768e-17 2.9142028e-28], sampled 0.4309350185855957
[2019-03-26 18:22:15,229] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.11241935], dtype=float32), 0.09619229]
[2019-03-26 18:22:15,231] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [23.08586013333333, 79.84412064333334, 1.0, 2.0, 0.9643475056218843, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1527163.363337717, 1527163.363337716, 312796.3822469249]
[2019-03-26 18:22:15,231] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 18:22:15,233] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0170499e-16 1.0000000e+00 1.0520906e-19 1.2958924e-18 1.5136460e-28], sampled 0.2902163775543176
[2019-03-26 18:22:25,463] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.11241935], dtype=float32), 0.09619229]
[2019-03-26 18:22:25,464] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.71958660333333, 73.47253441333334, 1.0, 2.0, 0.8894775518759893, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.976377372585898, 6.9112, 168.9125095536242, 2140308.089972328, 2094069.140980026, 432181.1273265388]
[2019-03-26 18:22:25,468] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 18:22:25,470] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [9.3677777e-10 9.8004788e-01 1.3450856e-09 1.9952156e-02 1.1794690e-16], sampled 0.6051208221189779
[2019-03-26 18:22:25,473] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2140308.089972328 W.
[2019-03-26 18:22:30,762] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.11241935], dtype=float32), 0.09619229]
[2019-03-26 18:22:30,763] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.21199799166667, 98.89720789333334, 1.0, 2.0, 1.03100000683458, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.9128848988433, 1441165.825693831, 1441165.825693832, 308515.1230861274]
[2019-03-26 18:22:30,764] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 18:22:30,767] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.3665772e-15 1.0000000e+00 8.9087766e-18 1.5067178e-14 8.2549633e-27], sampled 0.6130042914998172
[2019-03-26 18:22:33,046] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.11241935], dtype=float32), 0.09619229]
[2019-03-26 18:22:33,047] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.10831460666667, 84.39679476, 1.0, 2.0, 0.8155182089598255, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1139796.573344853, 1139796.573344852, 247756.81318701]
[2019-03-26 18:22:33,048] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:22:33,053] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.1375221e-16 1.0000000e+00 2.3530913e-19 1.1026289e-17 2.6860418e-28], sampled 0.25609858551369336
[2019-03-26 18:23:14,017] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7960.9067 3155760249.4184 1527.0000
[2019-03-26 18:23:14,673] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.11241935], dtype=float32), 0.09619229]
[2019-03-26 18:23:14,674] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [32.10138365666667, 67.28064752166667, 1.0, 2.0, 0.7991185344327676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1116863.764372572, 1116863.764372573, 243698.5351761742]
[2019-03-26 18:23:14,675] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 18:23:14,678] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [8.6431560e-17 1.0000000e+00 1.1101572e-19 1.1789516e-18 1.1506078e-28], sampled 0.6474660435694489
[2019-03-26 18:23:14,968] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8281.6155 2924162264.9186 1253.0000
[2019-03-26 18:23:15,097] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8527.4568 2838926029.1366 1043.0000
[2019-03-26 18:23:15,114] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8662.3106 2778837312.5192 917.0000
[2019-03-26 18:23:15,190] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8060.9778 2999528530.3231 1558.0000
[2019-03-26 18:23:16,206] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 2150000, evaluation results [2150000.0, 7960.906724237236, 3155760249.418399, 1527.0, 8281.615462834348, 2924162264.9185667, 1253.0, 8662.310561732627, 2778837312.5191927, 917.0, 8060.977801917044, 2999528530.3230643, 1558.0, 8527.456826535197, 2838926029.1366396, 1043.0]
[2019-03-26 18:23:16,713] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.3678015e-17 1.0000000e+00 1.6284082e-21 3.5261579e-21 1.8714842e-30], sum to 1.0000
[2019-03-26 18:23:16,726] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4293
[2019-03-26 18:23:16,730] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.1, 92.0, 1.0, 2.0, 0.3410723180482942, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 527645.53783535, 527645.5378353494, 168880.0675782755], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 943200.0000, 
sim time next is 943800.0000, 
raw observation next is [22.05, 92.33333333333334, 1.0, 2.0, 0.3412681066332428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 527977.0730229522, 527977.0730229522, 168907.5150377784], 
processed observation next is [0.0, 0.9565217391304348, 0.24407582938388633, 0.9233333333333335, 1.0, 1.0, 0.20634711642559375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14666029806193115, 0.14666029806193115, 0.25210076871310205], 
reward next is 0.7479, 
noisyNet noise sample is [array([-1.7201028], dtype=float32), 0.18262549]. 
=============================================
[2019-03-26 18:23:16,962] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.13525435e-17 1.00000000e+00 1.18050298e-20 4.94393251e-20
 5.31078041e-30], sum to 1.0000
[2019-03-26 18:23:16,974] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6292
[2019-03-26 18:23:16,985] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.3, 97.5, 1.0, 2.0, 0.3068023820804128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 488327.5231009396, 488327.5231009396, 166219.2769416711], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1387800.0000, 
sim time next is 1388400.0000, 
raw observation next is [20.26666666666667, 97.66666666666666, 1.0, 2.0, 0.3058459772450906, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 486958.926968225, 486958.9269682244, 166122.0727794527], 
processed observation next is [0.0, 0.043478260869565216, 0.15955766192733034, 0.9766666666666666, 1.0, 1.0, 0.1636698521025188, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13526636860228472, 0.13526636860228455, 0.24794339220813835], 
reward next is 0.7521, 
noisyNet noise sample is [array([0.98868567], dtype=float32), -0.38717136]. 
=============================================
[2019-03-26 18:23:17,972] A3C_AGENT_WORKER-Thread-3 INFO:Local step 134500, global step 2150800: loss 3.0240
[2019-03-26 18:23:17,980] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 134500, global step 2150802: learning rate 0.0000
[2019-03-26 18:23:18,736] A3C_AGENT_WORKER-Thread-15 INFO:Local step 134500, global step 2151145: loss 3.0114
[2019-03-26 18:23:18,738] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 134500, global step 2151145: learning rate 0.0000
[2019-03-26 18:23:19,227] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0033467e-16 1.0000000e+00 1.6895168e-19 2.2005811e-18 1.7100635e-28], sum to 1.0000
[2019-03-26 18:23:19,237] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7179
[2019-03-26 18:23:19,243] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.93333333333333, 91.66666666666667, 1.0, 2.0, 0.345449281210454, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 537458.4168164312, 537458.4168164312, 169755.1575519492], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1219800.0000, 
sim time next is 1220400.0000, 
raw observation next is [21.9, 92.0, 1.0, 2.0, 0.3420071343676661, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 531989.4497294846, 531989.4497294846, 169310.1688530309], 
processed observation next is [1.0, 0.13043478260869565, 0.23696682464454974, 0.92, 1.0, 1.0, 0.2072375112863447, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14777484714707906, 0.14777484714707906, 0.25270174455676253], 
reward next is 0.7473, 
noisyNet noise sample is [array([0.39572677], dtype=float32), 0.5067809]. 
=============================================
[2019-03-26 18:23:19,989] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.0514511e-18 1.0000000e+00 3.6464266e-21 1.9145508e-22 3.6664816e-30], sum to 1.0000
[2019-03-26 18:23:20,000] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7717
[2019-03-26 18:23:20,004] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 97.0, 1.0, 2.0, 0.3277733108839336, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 513609.3363222133, 513609.3363222133, 167957.7200052232], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1479600.0000, 
sim time next is 1480200.0000, 
raw observation next is [20.93333333333333, 97.16666666666667, 1.0, 2.0, 0.3254563981357907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 510594.4042223032, 510594.4042223032, 167740.3976730386], 
processed observation next is [0.0, 0.13043478260869565, 0.19115323854660338, 0.9716666666666667, 1.0, 1.0, 0.1872968652238442, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14183177895063978, 0.14183177895063978, 0.25035880249707254], 
reward next is 0.7496, 
noisyNet noise sample is [array([0.02725186], dtype=float32), -1.332889]. 
=============================================
[2019-03-26 18:23:20,625] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.4091235e-17 1.0000000e+00 1.3676123e-19 1.6598062e-18 4.3995197e-29], sum to 1.0000
[2019-03-26 18:23:20,634] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7710
[2019-03-26 18:23:20,639] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.05, 93.5, 1.0, 2.0, 0.2889763351293487, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 466575.7557576234, 466575.7557576234, 164720.1972861002], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1135800.0000, 
sim time next is 1136400.0000, 
raw observation next is [20.0, 93.66666666666667, 1.0, 2.0, 0.2836976881972058, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 458312.5188377349, 458312.5188377356, 164155.6497084287], 
processed observation next is [1.0, 0.13043478260869565, 0.1469194312796209, 0.9366666666666668, 1.0, 1.0, 0.1369851665026576, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1273090330104819, 0.1273090330104821, 0.24500843240063988], 
reward next is 0.7550, 
noisyNet noise sample is [array([-0.7560811], dtype=float32), -0.6521285]. 
=============================================
[2019-03-26 18:23:21,843] A3C_AGENT_WORKER-Thread-9 INFO:Local step 135000, global step 2152540: loss 0.0050
[2019-03-26 18:23:21,846] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 135000, global step 2152541: learning rate 0.0000
[2019-03-26 18:23:22,014] A3C_AGENT_WORKER-Thread-22 INFO:Local step 134500, global step 2152615: loss 2.9573
[2019-03-26 18:23:22,015] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 134500, global step 2152616: learning rate 0.0000
[2019-03-26 18:23:23,309] A3C_AGENT_WORKER-Thread-10 INFO:Local step 135500, global step 2153197: loss 0.0047
[2019-03-26 18:23:23,313] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 135500, global step 2153198: learning rate 0.0000
[2019-03-26 18:23:24,186] A3C_AGENT_WORKER-Thread-13 INFO:Local step 135000, global step 2153589: loss 0.0046
[2019-03-26 18:23:24,189] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 135000, global step 2153591: learning rate 0.0000
[2019-03-26 18:23:25,135] A3C_AGENT_WORKER-Thread-16 INFO:Local step 134500, global step 2154020: loss 3.0182
[2019-03-26 18:23:25,138] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 134500, global step 2154021: learning rate 0.0000
[2019-03-26 18:23:28,315] A3C_AGENT_WORKER-Thread-20 INFO:Local step 134500, global step 2155454: loss 3.0911
[2019-03-26 18:23:28,320] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 134500, global step 2155456: learning rate 0.0000
[2019-03-26 18:23:28,795] A3C_AGENT_WORKER-Thread-17 INFO:Local step 134500, global step 2155674: loss 3.0886
[2019-03-26 18:23:28,796] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 134500, global step 2155674: learning rate 0.0000
[2019-03-26 18:23:31,171] A3C_AGENT_WORKER-Thread-12 INFO:Local step 134500, global step 2156742: loss 3.0813
[2019-03-26 18:23:31,174] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 134500, global step 2156744: learning rate 0.0000
[2019-03-26 18:23:31,179] A3C_AGENT_WORKER-Thread-18 INFO:Local step 134500, global step 2156746: loss 3.0204
[2019-03-26 18:23:31,181] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 134500, global step 2156746: learning rate 0.0000
[2019-03-26 18:23:31,668] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.0337003e-17 1.0000000e+00 3.8283971e-21 9.3733760e-22 2.6402229e-30], sum to 1.0000
[2019-03-26 18:23:31,678] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3806
[2019-03-26 18:23:31,683] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333333, 98.66666666666667, 1.0, 2.0, 0.3104452244773311, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 492129.4430516197, 492129.4430516197, 166464.6233860319], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1485600.0000, 
sim time next is 1486200.0000, 
raw observation next is [20.26666666666667, 98.83333333333333, 1.0, 2.0, 0.3089550858985022, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 490307.2586242497, 490307.2586242491, 166340.6201551674], 
processed observation next is [0.0, 0.17391304347826086, 0.15955766192733034, 0.9883333333333333, 1.0, 1.0, 0.1674157661427737, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13619646072895825, 0.13619646072895808, 0.24826958232114535], 
reward next is 0.7517, 
noisyNet noise sample is [array([-1.2992325], dtype=float32), 0.24916567]. 
=============================================
[2019-03-26 18:23:32,143] A3C_AGENT_WORKER-Thread-21 INFO:Local step 134500, global step 2157179: loss 3.0595
[2019-03-26 18:23:32,146] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 134500, global step 2157180: learning rate 0.0000
[2019-03-26 18:23:32,348] A3C_AGENT_WORKER-Thread-19 INFO:Local step 134500, global step 2157271: loss 3.0798
[2019-03-26 18:23:32,351] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 134500, global step 2157272: learning rate 0.0000
[2019-03-26 18:23:32,471] A3C_AGENT_WORKER-Thread-11 INFO:Local step 134500, global step 2157324: loss 3.0933
[2019-03-26 18:23:32,473] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 134500, global step 2157325: learning rate 0.0000
[2019-03-26 18:23:32,685] A3C_AGENT_WORKER-Thread-14 INFO:Local step 135000, global step 2157424: loss 0.0051
[2019-03-26 18:23:32,686] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 135000, global step 2157424: learning rate 0.0000
[2019-03-26 18:23:33,236] A3C_AGENT_WORKER-Thread-2 INFO:Local step 135000, global step 2157668: loss 0.0059
[2019-03-26 18:23:33,237] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 135000, global step 2157668: learning rate 0.0000
[2019-03-26 18:23:35,805] A3C_AGENT_WORKER-Thread-3 INFO:Local step 135000, global step 2158813: loss 0.0098
[2019-03-26 18:23:35,807] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 135000, global step 2158813: learning rate 0.0000
[2019-03-26 18:23:36,579] A3C_AGENT_WORKER-Thread-15 INFO:Local step 135000, global step 2159165: loss 0.0082
[2019-03-26 18:23:36,584] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 135000, global step 2159166: learning rate 0.0000
[2019-03-26 18:23:39,427] A3C_AGENT_WORKER-Thread-9 INFO:Local step 135500, global step 2160454: loss 0.0084
[2019-03-26 18:23:39,428] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 135500, global step 2160454: learning rate 0.0000
[2019-03-26 18:23:39,687] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.6839343e-16 1.0000000e+00 6.4209833e-19 3.2887917e-17 2.4721306e-27], sum to 1.0000
[2019-03-26 18:23:39,697] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4055
[2019-03-26 18:23:39,702] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.73333333333333, 94.66666666666667, 1.0, 2.0, 0.3454634586150254, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 534966.4854327029, 534966.4854327029, 169486.1505677609], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1815600.0000, 
sim time next is 1816200.0000, 
raw observation next is [21.75, 94.5, 1.0, 2.0, 0.345240149552733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 534673.2999001088, 534673.2999001088, 169463.8258038351], 
processed observation next is [1.0, 0.0, 0.2298578199052133, 0.945, 1.0, 1.0, 0.21113271030449762, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14852036108336356, 0.14852036108336356, 0.2529310832893061], 
reward next is 0.7471, 
noisyNet noise sample is [array([-0.874769], dtype=float32), 0.632603]. 
=============================================
[2019-03-26 18:23:39,968] A3C_AGENT_WORKER-Thread-22 INFO:Local step 135000, global step 2160693: loss 0.0091
[2019-03-26 18:23:39,971] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 135000, global step 2160694: learning rate 0.0000
[2019-03-26 18:23:41,390] A3C_AGENT_WORKER-Thread-10 INFO:Local step 136000, global step 2161334: loss 0.0038
[2019-03-26 18:23:41,392] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 136000, global step 2161336: learning rate 0.0000
[2019-03-26 18:23:42,019] A3C_AGENT_WORKER-Thread-13 INFO:Local step 135500, global step 2161613: loss 0.0056
[2019-03-26 18:23:42,024] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 135500, global step 2161614: learning rate 0.0000
[2019-03-26 18:23:42,952] A3C_AGENT_WORKER-Thread-16 INFO:Local step 135000, global step 2162036: loss 0.0062
[2019-03-26 18:23:42,955] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 135000, global step 2162037: learning rate 0.0000
[2019-03-26 18:23:46,096] A3C_AGENT_WORKER-Thread-20 INFO:Local step 135000, global step 2163457: loss 0.0102
[2019-03-26 18:23:46,098] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 135000, global step 2163458: learning rate 0.0000
[2019-03-26 18:23:46,582] A3C_AGENT_WORKER-Thread-17 INFO:Local step 135000, global step 2163673: loss 0.0097
[2019-03-26 18:23:46,586] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 135000, global step 2163675: learning rate 0.0000
[2019-03-26 18:23:48,940] A3C_AGENT_WORKER-Thread-12 INFO:Local step 135000, global step 2164743: loss 0.0145
[2019-03-26 18:23:48,944] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 135000, global step 2164743: learning rate 0.0000
[2019-03-26 18:23:48,976] A3C_AGENT_WORKER-Thread-18 INFO:Local step 135000, global step 2164760: loss 0.0132
[2019-03-26 18:23:48,982] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 135000, global step 2164765: learning rate 0.0000
[2019-03-26 18:23:49,881] A3C_AGENT_WORKER-Thread-21 INFO:Local step 135000, global step 2165167: loss 0.0114
[2019-03-26 18:23:49,885] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 135000, global step 2165170: learning rate 0.0000
[2019-03-26 18:23:50,147] A3C_AGENT_WORKER-Thread-19 INFO:Local step 135000, global step 2165280: loss 0.0108
[2019-03-26 18:23:50,149] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 135000, global step 2165280: learning rate 0.0000
[2019-03-26 18:23:50,287] A3C_AGENT_WORKER-Thread-11 INFO:Local step 135000, global step 2165338: loss 0.0116
[2019-03-26 18:23:50,291] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 135000, global step 2165340: learning rate 0.0000
[2019-03-26 18:23:50,316] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.1265128e-17 1.0000000e+00 4.7350397e-20 8.8886664e-21 3.2591956e-30], sum to 1.0000
[2019-03-26 18:23:50,322] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3082
[2019-03-26 18:23:50,326] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.75, 51.83333333333334, 1.0, 2.0, 0.3751803408185347, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 563479.9992026711, 563479.9992026711, 171361.2091889103], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1518600.0000, 
sim time next is 1519200.0000, 
raw observation next is [29.8, 52.0, 1.0, 2.0, 0.3793120855017446, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 568262.6690425077, 568262.6690425084, 171734.2656770618], 
processed observation next is [0.0, 0.6086956521739131, 0.6113744075829385, 0.52, 1.0, 1.0, 0.25218323554427063, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15785074140069658, 0.15785074140069677, 0.2563197995180027], 
reward next is 0.7437, 
noisyNet noise sample is [array([-0.76752365], dtype=float32), 1.5415313]. 
=============================================
[2019-03-26 18:23:50,537] A3C_AGENT_WORKER-Thread-14 INFO:Local step 135500, global step 2165452: loss 0.0078
[2019-03-26 18:23:50,540] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 135500, global step 2165453: learning rate 0.0000
[2019-03-26 18:23:51,031] A3C_AGENT_WORKER-Thread-2 INFO:Local step 135500, global step 2165671: loss 0.0086
[2019-03-26 18:23:51,034] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 135500, global step 2165673: learning rate 0.0000
[2019-03-26 18:23:53,743] A3C_AGENT_WORKER-Thread-3 INFO:Local step 135500, global step 2166882: loss 0.0112
[2019-03-26 18:23:53,747] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 135500, global step 2166883: learning rate 0.0000
[2019-03-26 18:23:54,349] A3C_AGENT_WORKER-Thread-15 INFO:Local step 135500, global step 2167155: loss 0.0095
[2019-03-26 18:23:54,353] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 135500, global step 2167157: learning rate 0.0000
[2019-03-26 18:23:54,538] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.3829151e-16 1.0000000e+00 3.7313655e-19 7.8724453e-17 2.7619249e-27], sum to 1.0000
[2019-03-26 18:23:54,550] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9741
[2019-03-26 18:23:54,556] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.2, 99.0, 1.0, 2.0, 0.4307036621911839, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 623146.2886445399, 623146.2886445393, 176193.1442550745], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1647000.0000, 
sim time next is 1647600.0000, 
raw observation next is [23.2, 99.0, 1.0, 2.0, 0.4304915605067013, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 622839.2347772637, 622839.2347772631, 176163.1343832005], 
processed observation next is [1.0, 0.043478260869565216, 0.29857819905213273, 0.99, 1.0, 1.0, 0.3138452536225317, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17301089854923993, 0.17301089854923976, 0.2629300513182097], 
reward next is 0.7371, 
noisyNet noise sample is [array([0.4959679], dtype=float32), 0.08034213]. 
=============================================
[2019-03-26 18:23:56,998] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.66503437e-15 1.00000000e+00 1.54208355e-18 6.02230566e-17
 1.15980965e-27], sum to 1.0000
[2019-03-26 18:23:57,007] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7854
[2019-03-26 18:23:57,010] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.05, 95.5, 1.0, 2.0, 0.5617894000303773, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 797783.5587414213, 797783.5587414213, 195476.5331771226], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1909800.0000, 
sim time next is 1910400.0000, 
raw observation next is [24.0, 95.33333333333333, 1.0, 2.0, 0.5244621872118427, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 747096.4184764257, 747096.4184764257, 189335.1929466597], 
processed observation next is [1.0, 0.08695652173913043, 0.3364928909952607, 0.9533333333333333, 1.0, 1.0, 0.4270628761588466, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20752678291011825, 0.20752678291011825, 0.28258984021889505], 
reward next is 0.7174, 
noisyNet noise sample is [array([0.7528635], dtype=float32), -0.72807205]. 
=============================================
[2019-03-26 18:23:57,385] A3C_AGENT_WORKER-Thread-9 INFO:Local step 136000, global step 2168528: loss 0.0017
[2019-03-26 18:23:57,391] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 136000, global step 2168528: learning rate 0.0000
[2019-03-26 18:23:57,576] A3C_AGENT_WORKER-Thread-22 INFO:Local step 135500, global step 2168612: loss 0.0095
[2019-03-26 18:23:57,579] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 135500, global step 2168613: learning rate 0.0000
[2019-03-26 18:23:59,489] A3C_AGENT_WORKER-Thread-10 INFO:Local step 136500, global step 2169471: loss 0.0433
[2019-03-26 18:23:59,492] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 136500, global step 2169472: learning rate 0.0000
[2019-03-26 18:23:59,998] A3C_AGENT_WORKER-Thread-13 INFO:Local step 136000, global step 2169704: loss 0.0006
[2019-03-26 18:24:00,000] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 136000, global step 2169704: learning rate 0.0000
[2019-03-26 18:24:00,172] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.5375783e-16 1.0000000e+00 8.3615175e-19 1.6585936e-15 9.9242766e-28], sum to 1.0000
[2019-03-26 18:24:00,181] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4416
[2019-03-26 18:24:00,186] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.1, 95.66666666666666, 1.0, 2.0, 0.6128098543949384, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 867515.407018361, 867515.407018361, 204600.2939709414], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1909200.0000, 
sim time next is 1909800.0000, 
raw observation next is [24.05, 95.5, 1.0, 2.0, 0.5617894000303773, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 797783.5587414213, 797783.5587414213, 195476.5331771226], 
processed observation next is [1.0, 0.08695652173913043, 0.3388625592417062, 0.955, 1.0, 1.0, 0.47203542172334606, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22160654409483926, 0.22160654409483926, 0.29175601966734716], 
reward next is 0.7082, 
noisyNet noise sample is [array([-0.30388692], dtype=float32), -0.5143014]. 
=============================================
[2019-03-26 18:24:00,584] A3C_AGENT_WORKER-Thread-16 INFO:Local step 135500, global step 2169965: loss 0.0153
[2019-03-26 18:24:00,585] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 135500, global step 2169965: learning rate 0.0000
[2019-03-26 18:24:03,828] A3C_AGENT_WORKER-Thread-20 INFO:Local step 135500, global step 2171434: loss 0.0153
[2019-03-26 18:24:03,830] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 135500, global step 2171434: learning rate 0.0000
[2019-03-26 18:24:04,231] A3C_AGENT_WORKER-Thread-17 INFO:Local step 135500, global step 2171609: loss 0.0173
[2019-03-26 18:24:04,232] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 135500, global step 2171609: learning rate 0.0000
[2019-03-26 18:24:06,461] A3C_AGENT_WORKER-Thread-18 INFO:Local step 135500, global step 2172614: loss 0.0151
[2019-03-26 18:24:06,463] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 135500, global step 2172614: learning rate 0.0000
[2019-03-26 18:24:06,552] A3C_AGENT_WORKER-Thread-12 INFO:Local step 135500, global step 2172647: loss 0.0152
[2019-03-26 18:24:06,555] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 135500, global step 2172647: learning rate 0.0000
[2019-03-26 18:24:07,101] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.2649017e-12 9.9999988e-01 2.3673508e-13 9.6082715e-08 2.1033902e-20], sum to 1.0000
[2019-03-26 18:24:07,112] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5264
[2019-03-26 18:24:07,121] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.06666666666667, 83.66666666666667, 1.0, 2.0, 0.5824676816433633, 1.0, 2.0, 0.5824676816433633, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1628516.662889316, 1628516.662889316, 327860.9923435312], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1866000.0000, 
sim time next is 1866600.0000, 
raw observation next is [27.05, 84.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.566555968187854, 6.9112, 168.9092991121784, 1918995.396001925, 1454073.383528432, 311348.8222123539], 
processed observation next is [1.0, 0.6086956521739131, 0.4810426540284361, 0.84, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.06553559681878536, 0.0, 0.8294219856525182, 0.5330542766672014, 0.40390927320234227, 0.4646997346453043], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.40644327], dtype=float32), -1.4336619]. 
=============================================
[2019-03-26 18:24:07,445] A3C_AGENT_WORKER-Thread-21 INFO:Local step 135500, global step 2173051: loss 0.0145
[2019-03-26 18:24:07,446] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 135500, global step 2173051: learning rate 0.0000
[2019-03-26 18:24:07,736] A3C_AGENT_WORKER-Thread-19 INFO:Local step 135500, global step 2173178: loss 0.0136
[2019-03-26 18:24:07,737] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 135500, global step 2173179: learning rate 0.0000
[2019-03-26 18:24:07,919] A3C_AGENT_WORKER-Thread-11 INFO:Local step 135500, global step 2173257: loss 0.0141
[2019-03-26 18:24:07,921] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 135500, global step 2173258: learning rate 0.0000
[2019-03-26 18:24:08,552] A3C_AGENT_WORKER-Thread-14 INFO:Local step 136000, global step 2173543: loss 0.0008
[2019-03-26 18:24:08,554] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 136000, global step 2173544: learning rate 0.0000
[2019-03-26 18:24:08,959] A3C_AGENT_WORKER-Thread-2 INFO:Local step 136000, global step 2173728: loss 0.0006
[2019-03-26 18:24:08,962] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 136000, global step 2173728: learning rate 0.0000
[2019-03-26 18:24:10,158] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.4912971e-16 1.0000000e+00 6.0087837e-19 5.2401423e-16 1.3674189e-27], sum to 1.0000
[2019-03-26 18:24:10,166] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5362
[2019-03-26 18:24:10,174] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.1, 80.0, 1.0, 2.0, 0.5613385714576048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 784415.086834244, 784415.086834244, 193764.4831830124], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2325600.0000, 
sim time next is 2326200.0000, 
raw observation next is [29.01666666666667, 80.16666666666667, 1.0, 2.0, 0.5599498469338116, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 782473.7669935346, 782473.7669935353, 193521.8926222118], 
processed observation next is [1.0, 0.9565217391304348, 0.5742496050552924, 0.8016666666666667, 1.0, 1.0, 0.4698190926913392, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21735382416487073, 0.21735382416487092, 0.28883864570479373], 
reward next is 0.7112, 
noisyNet noise sample is [array([0.8302167], dtype=float32), -0.74077547]. 
=============================================
[2019-03-26 18:24:11,438] A3C_AGENT_WORKER-Thread-3 INFO:Local step 136000, global step 2174845: loss 0.0005
[2019-03-26 18:24:11,440] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 136000, global step 2174846: learning rate 0.0000
[2019-03-26 18:24:11,788] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-26 18:24:11,790] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 18:24:11,792] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 18:24:11,793] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:24:11,795] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:24:11,796] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 18:24:11,798] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 18:24:11,797] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 18:24:11,799] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:24:11,800] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:24:11,800] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:24:11,827] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run88
[2019-03-26 18:24:11,857] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run88
[2019-03-26 18:24:11,883] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run88
[2019-03-26 18:24:11,883] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run88
[2019-03-26 18:24:11,926] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run88
[2019-03-26 18:24:14,183] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.11094799], dtype=float32), 0.09479864]
[2019-03-26 18:24:14,185] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [22.76190829, 94.80087572, 1.0, 2.0, 0.4000145931119454, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 599728.8928327528, 599728.8928327528, 174591.039369092]
[2019-03-26 18:24:14,187] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:24:14,189] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.1613392e-17 1.0000000e+00 2.0098812e-20 7.5325600e-20 8.4890636e-30], sampled 0.16098824991285043
[2019-03-26 18:24:17,578] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.11094799], dtype=float32), 0.09479864]
[2019-03-26 18:24:17,580] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [21.65557076, 82.94942037666667, 1.0, 2.0, 0.291411577334683, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 468615.9738583775, 468615.9738583768, 164863.782886331]
[2019-03-26 18:24:17,580] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:24:17,585] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [9.04123630e-18 1.00000000e+00 3.43346799e-21 7.50896980e-22
 1.21595985e-30], sampled 0.4951097284399877
[2019-03-26 18:24:18,089] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.11094799], dtype=float32), 0.09479864]
[2019-03-26 18:24:18,091] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [19.27040845, 89.87667794, 1.0, 2.0, 0.2468417980309946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 406194.3645682748, 406194.3645682742, 160592.84834936]
[2019-03-26 18:24:18,092] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 18:24:18,096] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.7376325e-17 1.0000000e+00 8.5601884e-21 1.2703942e-21 4.1896819e-30], sampled 0.5559686930699016
[2019-03-26 18:24:20,275] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.11094799], dtype=float32), 0.09479864]
[2019-03-26 18:24:20,278] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [19.1500055, 70.88362319666666, 1.0, 2.0, 0.208447825168272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 348604.5386605043, 348604.5386605037, 150402.6403860066]
[2019-03-26 18:24:20,280] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 18:24:20,281] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.4189545e-17 1.0000000e+00 2.2979496e-20 1.2761360e-20 2.1754292e-29], sampled 0.9958841939030612
[2019-03-26 18:24:26,521] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.11094799], dtype=float32), 0.09479864]
[2019-03-26 18:24:26,524] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [25.9, 65.0, 1.0, 2.0, 0.3441332969575231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 534173.9609378815, 534173.9609378821, 169456.7464312418]
[2019-03-26 18:24:26,525] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:24:26,527] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.2485750e-17 1.0000000e+00 6.0381196e-21 3.2534591e-21 2.3059727e-30], sampled 0.2880937216849916
[2019-03-26 18:24:43,563] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.11094799], dtype=float32), 0.09479864]
[2019-03-26 18:24:43,564] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [25.11666666666667, 89.83333333333333, 1.0, 2.0, 0.4767537007360342, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 668166.3557353725, 668166.3557353718, 180290.3064465809]
[2019-03-26 18:24:43,566] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:24:43,570] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.3329198e-17 1.0000000e+00 2.4986291e-20 1.5827880e-20 1.4897065e-29], sampled 0.5840752269943847
[2019-03-26 18:24:56,202] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.11094799], dtype=float32), 0.09479864]
[2019-03-26 18:24:56,205] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [30.88333333333334, 66.16666666666667, 1.0, 2.0, 0.5707621625747646, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9770291543188998, 6.911200000000001, 6.9112, 168.9123501924603, 1595776.501418537, 1595776.501418536, 346198.9218288509]
[2019-03-26 18:24:56,206] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:24:56,209] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.0493433e-10 9.8415750e-01 2.1244541e-10 1.5842505e-02 1.8995231e-18], sampled 0.7206523966199863
[2019-03-26 18:25:33,640] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.11094799], dtype=float32), 0.09479864]
[2019-03-26 18:25:33,643] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [24.69473691, 86.84465969666667, 1.0, 2.0, 0.4248488626087814, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 624613.7190906986, 624613.719090698, 176608.3545457744]
[2019-03-26 18:25:33,645] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 18:25:33,650] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.2501786e-17 1.0000000e+00 2.4655470e-20 1.6961479e-20 1.4138303e-29], sampled 0.6715237553103588
[2019-03-26 18:25:49,777] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.11094799], dtype=float32), 0.09479864]
[2019-03-26 18:25:49,779] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.2, 83.33333333333334, 1.0, 2.0, 0.3474344319468126, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 538128.9982267176, 538128.9982267176, 169746.7032450415]
[2019-03-26 18:25:49,780] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 18:25:49,785] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.8839747e-17 1.0000000e+00 8.4231681e-21 9.6692961e-22 4.2963408e-30], sampled 0.7244917694495284
[2019-03-26 18:25:56,799] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.11094799], dtype=float32), 0.09479864]
[2019-03-26 18:25:56,800] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.8, 67.5, 1.0, 2.0, 0.3844436291327872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 575146.5214300234, 575146.5214300241, 172319.7016298247]
[2019-03-26 18:25:56,801] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 18:25:56,805] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.9892304e-16 1.0000000e+00 8.8550015e-19 5.8705140e-17 9.9569634e-28], sampled 0.3474860170433609
[2019-03-26 18:26:02,429] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.11094799], dtype=float32), 0.09479864]
[2019-03-26 18:26:02,430] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.45, 80.5, 1.0, 2.0, 0.5911016568520058, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 826022.2246685576, 826022.2246685576, 199098.9488331152]
[2019-03-26 18:26:02,431] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 18:26:02,434] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [7.7713255e-17 1.0000000e+00 1.1202650e-19 3.2978731e-18 1.8415720e-28], sampled 0.6525768487164251
[2019-03-26 18:26:05,609] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8303.5339 2922117014.1469 1193.0000
[2019-03-26 18:26:05,730] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8538.0564 2837842413.7285 1005.0000
[2019-03-26 18:26:05,814] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8669.2671 2777707000.2920 898.0000
[2019-03-26 18:26:05,821] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7994.9274 3151097163.1871 1426.0000
[2019-03-26 18:26:06,018] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8100.0369 2995203338.4053 1449.0000
[2019-03-26 18:26:07,035] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 2175000, evaluation results [2175000.0, 7994.92742511733, 3151097163.187057, 1426.0, 8303.533942428745, 2922117014.14695, 1193.0, 8669.267111028053, 2777707000.291967, 898.0, 8100.0369195645135, 2995203338.4052987, 1449.0, 8538.056354366257, 2837842413.7285323, 1005.0]
[2019-03-26 18:26:07,398] A3C_AGENT_WORKER-Thread-15 INFO:Local step 136000, global step 2175166: loss 0.0005
[2019-03-26 18:26:07,401] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 136000, global step 2175166: learning rate 0.0000
[2019-03-26 18:26:09,062] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.5753581e-16 1.0000000e+00 8.6674524e-18 1.3979978e-15 2.4295566e-26], sum to 1.0000
[2019-03-26 18:26:09,073] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4572
[2019-03-26 18:26:09,078] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.85, 81.66666666666667, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.009109463974895, 6.9112, 168.9124048539953, 1553421.696664891, 1483961.579989437, 316169.3551255277], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1933800.0000, 
sim time next is 1934400.0000, 
raw observation next is [25.9, 81.33333333333334, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.914983226132993, 6.9112, 168.9125319223211, 1486490.029086788, 1483806.085005962, 316152.0432385501], 
processed observation next is [1.0, 0.391304347826087, 0.42654028436018954, 0.8133333333333335, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0003783226132992645, 0.0, 0.8294378602303059, 0.4129138969685522, 0.41216835694610054, 0.47186872125156726], 
reward next is 0.5092, 
noisyNet noise sample is [array([-0.60287833], dtype=float32), 0.77158695]. 
=============================================
[2019-03-26 18:26:10,500] A3C_AGENT_WORKER-Thread-9 INFO:Local step 136500, global step 2176565: loss 0.0419
[2019-03-26 18:26:10,505] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 136500, global step 2176565: learning rate 0.0000
[2019-03-26 18:26:10,574] A3C_AGENT_WORKER-Thread-22 INFO:Local step 136000, global step 2176595: loss 0.0005
[2019-03-26 18:26:10,576] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 136000, global step 2176595: learning rate 0.0000
[2019-03-26 18:26:12,295] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.2593018e-15 1.0000000e+00 7.8021843e-18 7.8823054e-16 8.0061487e-26], sum to 1.0000
[2019-03-26 18:26:12,305] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6486
[2019-03-26 18:26:12,309] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.2, 86.0, 1.0, 2.0, 0.6677336840332496, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 933157.0374939744, 933157.0374939751, 214031.9107158564], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2257200.0000, 
sim time next is 2257800.0000, 
raw observation next is [26.16666666666666, 86.16666666666667, 1.0, 2.0, 0.7564965720769556, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1057264.817172797, 1057264.817172797, 233509.6306334129], 
processed observation next is [1.0, 0.13043478260869565, 0.4391785150078987, 0.8616666666666667, 1.0, 1.0, 0.706622375996332, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.29368467143688803, 0.29368467143688803, 0.3485218367662879], 
reward next is 0.6515, 
noisyNet noise sample is [array([1.4954135], dtype=float32), -2.0081286]. 
=============================================
[2019-03-26 18:26:12,777] A3C_AGENT_WORKER-Thread-10 INFO:Local step 137000, global step 2177589: loss 0.0390
[2019-03-26 18:26:12,778] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 137000, global step 2177589: learning rate 0.0000
[2019-03-26 18:26:13,147] A3C_AGENT_WORKER-Thread-13 INFO:Local step 136500, global step 2177754: loss 0.0416
[2019-03-26 18:26:13,150] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 136500, global step 2177754: learning rate 0.0000
[2019-03-26 18:26:13,736] A3C_AGENT_WORKER-Thread-16 INFO:Local step 136000, global step 2178017: loss 0.0004
[2019-03-26 18:26:13,738] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 136000, global step 2178017: learning rate 0.0000
[2019-03-26 18:26:16,821] A3C_AGENT_WORKER-Thread-20 INFO:Local step 136000, global step 2179410: loss 0.0005
[2019-03-26 18:26:16,823] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 136000, global step 2179410: learning rate 0.0000
[2019-03-26 18:26:17,219] A3C_AGENT_WORKER-Thread-17 INFO:Local step 136000, global step 2179589: loss 0.0004
[2019-03-26 18:26:17,224] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 136000, global step 2179591: learning rate 0.0000
[2019-03-26 18:26:19,331] A3C_AGENT_WORKER-Thread-18 INFO:Local step 136000, global step 2180541: loss 0.0001
[2019-03-26 18:26:19,335] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 136000, global step 2180541: learning rate 0.0000
[2019-03-26 18:26:19,797] A3C_AGENT_WORKER-Thread-12 INFO:Local step 136000, global step 2180753: loss 0.0001
[2019-03-26 18:26:19,799] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 136000, global step 2180753: learning rate 0.0000
[2019-03-26 18:26:20,522] A3C_AGENT_WORKER-Thread-21 INFO:Local step 136000, global step 2181074: loss 0.0001
[2019-03-26 18:26:20,524] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 136000, global step 2181075: learning rate 0.0000
[2019-03-26 18:26:20,747] A3C_AGENT_WORKER-Thread-19 INFO:Local step 136000, global step 2181178: loss 0.0002
[2019-03-26 18:26:20,749] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 136000, global step 2181178: learning rate 0.0000
[2019-03-26 18:26:20,973] A3C_AGENT_WORKER-Thread-11 INFO:Local step 136000, global step 2181276: loss 0.0002
[2019-03-26 18:26:20,974] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 136000, global step 2181276: learning rate 0.0000
[2019-03-26 18:26:21,665] A3C_AGENT_WORKER-Thread-14 INFO:Local step 136500, global step 2181590: loss 0.0437
[2019-03-26 18:26:21,668] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 136500, global step 2181590: learning rate 0.0000
[2019-03-26 18:26:21,738] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.6770346e-17 1.0000000e+00 5.4572789e-20 1.8341480e-20 5.0355382e-29], sum to 1.0000
[2019-03-26 18:26:21,746] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8665
[2019-03-26 18:26:21,752] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.33333333333333, 75.66666666666667, 1.0, 2.0, 0.5775610225557228, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 807092.9690326591, 807092.9690326591, 196640.2359953894], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2128200.0000, 
sim time next is 2128800.0000, 
raw observation next is [30.36666666666667, 75.33333333333334, 1.0, 2.0, 0.5736805237774774, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 801668.2518703135, 801668.251870313, 195945.5078429384], 
processed observation next is [0.0, 0.6521739130434783, 0.6382306477093209, 0.7533333333333334, 1.0, 1.0, 0.48636207684033417, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22268562551953153, 0.2226856255195314, 0.29245598185513194], 
reward next is 0.7075, 
noisyNet noise sample is [array([-0.76723766], dtype=float32), -1.2805519]. 
=============================================
[2019-03-26 18:26:21,791] A3C_AGENT_WORKER-Thread-2 INFO:Local step 136500, global step 2181644: loss 0.0440
[2019-03-26 18:26:21,793] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 136500, global step 2181645: learning rate 0.0000
[2019-03-26 18:26:24,709] A3C_AGENT_WORKER-Thread-3 INFO:Local step 136500, global step 2182945: loss 0.0471
[2019-03-26 18:26:24,712] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 136500, global step 2182945: learning rate 0.0000
[2019-03-26 18:26:25,134] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.4012426e-15 1.0000000e+00 4.1996787e-17 1.0064989e-14 1.4827814e-25], sum to 1.0000
[2019-03-26 18:26:25,140] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7590
[2019-03-26 18:26:25,145] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.83333333333334, 74.5, 1.0, 2.0, 0.781209157663075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1091820.399190727, 1091820.399190727, 239349.6336851854], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2358600.0000, 
sim time next is 2359200.0000, 
raw observation next is [28.96666666666667, 74.0, 1.0, 2.0, 0.7996931649827262, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1117667.301985129, 1117667.301985129, 243834.6053594766], 
processed observation next is [1.0, 0.30434782608695654, 0.5718799368088469, 0.74, 1.0, 1.0, 0.7586664638346099, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3104631394403136, 0.3104631394403136, 0.363932246805189], 
reward next is 0.6361, 
noisyNet noise sample is [array([-0.76751864], dtype=float32), 0.6556249]. 
=============================================
[2019-03-26 18:26:25,371] A3C_AGENT_WORKER-Thread-15 INFO:Local step 136500, global step 2183247: loss 0.0703
[2019-03-26 18:26:25,372] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 136500, global step 2183248: learning rate 0.0000
[2019-03-26 18:26:28,317] A3C_AGENT_WORKER-Thread-22 INFO:Local step 136500, global step 2184574: loss 0.0495
[2019-03-26 18:26:28,320] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 136500, global step 2184574: learning rate 0.0000
[2019-03-26 18:26:28,361] A3C_AGENT_WORKER-Thread-9 INFO:Local step 137000, global step 2184595: loss 0.0553
[2019-03-26 18:26:28,363] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 137000, global step 2184595: learning rate 0.0000
[2019-03-26 18:26:30,181] A3C_AGENT_WORKER-Thread-10 INFO:Local step 137500, global step 2185423: loss 0.3837
[2019-03-26 18:26:30,188] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 137500, global step 2185426: learning rate 0.0000
[2019-03-26 18:26:30,939] A3C_AGENT_WORKER-Thread-13 INFO:Local step 137000, global step 2185762: loss 0.0609
[2019-03-26 18:26:30,941] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 137000, global step 2185762: learning rate 0.0000
[2019-03-26 18:26:31,593] A3C_AGENT_WORKER-Thread-16 INFO:Local step 136500, global step 2186056: loss 0.7955
[2019-03-26 18:26:31,599] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 136500, global step 2186057: learning rate 0.0000
[2019-03-26 18:26:34,658] A3C_AGENT_WORKER-Thread-20 INFO:Local step 136500, global step 2187436: loss 0.5825
[2019-03-26 18:26:34,668] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 136500, global step 2187441: learning rate 0.0000
[2019-03-26 18:26:35,069] A3C_AGENT_WORKER-Thread-17 INFO:Local step 136500, global step 2187616: loss 0.5752
[2019-03-26 18:26:35,071] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 136500, global step 2187616: learning rate 0.0000
[2019-03-26 18:26:37,131] A3C_AGENT_WORKER-Thread-18 INFO:Local step 136500, global step 2188549: loss 0.0672
[2019-03-26 18:26:37,134] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 136500, global step 2188550: learning rate 0.0000
[2019-03-26 18:26:37,739] A3C_AGENT_WORKER-Thread-12 INFO:Local step 136500, global step 2188825: loss 0.0438
[2019-03-26 18:26:37,740] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 136500, global step 2188825: learning rate 0.0000
[2019-03-26 18:26:38,319] A3C_AGENT_WORKER-Thread-21 INFO:Local step 136500, global step 2189083: loss 0.7754
[2019-03-26 18:26:38,321] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 136500, global step 2189084: learning rate 0.0000
[2019-03-26 18:26:38,661] A3C_AGENT_WORKER-Thread-19 INFO:Local step 136500, global step 2189237: loss 0.6786
[2019-03-26 18:26:38,662] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 136500, global step 2189238: learning rate 0.0000
[2019-03-26 18:26:38,768] A3C_AGENT_WORKER-Thread-11 INFO:Local step 136500, global step 2189287: loss 0.0679
[2019-03-26 18:26:38,772] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 136500, global step 2189287: learning rate 0.0000
[2019-03-26 18:26:39,569] A3C_AGENT_WORKER-Thread-14 INFO:Local step 137000, global step 2189638: loss 0.0457
[2019-03-26 18:26:39,572] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 137000, global step 2189638: learning rate 0.0000
[2019-03-26 18:26:39,600] A3C_AGENT_WORKER-Thread-2 INFO:Local step 137000, global step 2189653: loss 0.0417
[2019-03-26 18:26:39,603] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 137000, global step 2189653: learning rate 0.0000
[2019-03-26 18:26:42,282] A3C_AGENT_WORKER-Thread-3 INFO:Local step 137000, global step 2190861: loss 0.0342
[2019-03-26 18:26:42,283] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 137000, global step 2190861: learning rate 0.0000
[2019-03-26 18:26:43,016] A3C_AGENT_WORKER-Thread-15 INFO:Local step 137000, global step 2191190: loss 0.0319
[2019-03-26 18:26:43,020] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 137000, global step 2191191: learning rate 0.0000
[2019-03-26 18:26:43,625] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.7778506e-15 1.0000000e+00 7.1969825e-18 5.1592582e-15 1.2080707e-25], sum to 1.0000
[2019-03-26 18:26:43,634] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6647
[2019-03-26 18:26:43,638] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.3, 96.0, 1.0, 2.0, 0.7202641454632446, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1006603.086568345, 1006603.086568346, 225280.8807705682], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2517000.0000, 
sim time next is 2517600.0000, 
raw observation next is [26.3, 96.0, 1.0, 2.0, 0.691170751088145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 965925.2059823722, 965925.2059823722, 218951.8724617126], 
processed observation next is [1.0, 0.13043478260869565, 0.4454976303317536, 0.96, 1.0, 1.0, 0.6279165675760783, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2683125572173256, 0.2683125572173256, 0.32679383949509344], 
reward next is 0.6732, 
noisyNet noise sample is [array([-0.6588069], dtype=float32), -1.5923042]. 
=============================================
[2019-03-26 18:26:45,740] A3C_AGENT_WORKER-Thread-9 INFO:Local step 137500, global step 2192418: loss 0.3040
[2019-03-26 18:26:45,743] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 137500, global step 2192419: learning rate 0.0000
[2019-03-26 18:26:45,971] A3C_AGENT_WORKER-Thread-22 INFO:Local step 137000, global step 2192522: loss 0.0299
[2019-03-26 18:26:45,974] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 137000, global step 2192522: learning rate 0.0000
[2019-03-26 18:26:46,271] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.39393210e-17 1.00000000e+00 2.29036214e-20 7.30367652e-20
 1.10827285e-29], sum to 1.0000
[2019-03-26 18:26:46,279] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0138
[2019-03-26 18:26:46,285] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 84.0, 1.0, 2.0, 0.4792880274897444, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 669721.429146401, 669721.4291464004, 180414.0429977915], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3286800.0000, 
sim time next is 3287400.0000, 
raw observation next is [26.0, 84.0, 1.0, 2.0, 0.4782232211128876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 668336.4610090401, 668336.4610090401, 180267.3459203605], 
processed observation next is [0.0, 0.043478260869565216, 0.4312796208530806, 0.84, 1.0, 1.0, 0.37135327844926214, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1856490169469556, 0.1856490169469556, 0.26905574017964257], 
reward next is 0.7309, 
noisyNet noise sample is [array([-0.3593992], dtype=float32), -1.1209089]. 
=============================================
[2019-03-26 18:26:47,693] A3C_AGENT_WORKER-Thread-10 INFO:Local step 138000, global step 2193300: loss 0.0034
[2019-03-26 18:26:47,698] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 138000, global step 2193302: learning rate 0.0000
[2019-03-26 18:26:48,300] A3C_AGENT_WORKER-Thread-13 INFO:Local step 137500, global step 2193573: loss 0.2812
[2019-03-26 18:26:48,302] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 137500, global step 2193573: learning rate 0.0000
[2019-03-26 18:26:49,387] A3C_AGENT_WORKER-Thread-16 INFO:Local step 137000, global step 2194065: loss 0.0234
[2019-03-26 18:26:49,390] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 137000, global step 2194066: learning rate 0.0000
[2019-03-26 18:26:49,781] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.4447200e-16 1.0000000e+00 3.4265256e-18 1.7265141e-15 2.6706664e-27], sum to 1.0000
[2019-03-26 18:26:49,787] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4905
[2019-03-26 18:26:49,793] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666667, 96.0, 1.0, 2.0, 0.8303671613011229, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1197061.096569232, 1197061.096569233, 256670.0873613879], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3080400.0000, 
sim time next is 3081000.0000, 
raw observation next is [23.83333333333333, 95.0, 1.0, 2.0, 0.8422351893929869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1212111.288152422, 1212111.288152422, 259527.3534516696], 
processed observation next is [1.0, 0.6521739130434783, 0.32859399684044216, 0.95, 1.0, 1.0, 0.8099219149313095, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.33669758004233946, 0.33669758004233946, 0.38735425888308894], 
reward next is 0.6126, 
noisyNet noise sample is [array([0.8920734], dtype=float32), -0.18135647]. 
=============================================
[2019-03-26 18:26:49,807] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[69.45915 ]
 [69.443825]
 [69.38119 ]
 [69.24509 ]
 [69.00472 ]], R is [[69.36726379]
 [69.29050446]
 [69.22085571]
 [69.15940857]
 [69.0994339 ]].
[2019-03-26 18:26:50,435] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.1184898e-17 1.0000000e+00 1.6974804e-21 1.2734746e-22 1.4719740e-30], sum to 1.0000
[2019-03-26 18:26:50,441] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5041
[2019-03-26 18:26:50,447] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.9, 92.0, 1.0, 2.0, 0.428529180383058, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 624286.9111452859, 624286.9111452859, 176423.2470706619], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2610000.0000, 
sim time next is 2610600.0000, 
raw observation next is [23.86666666666667, 92.16666666666667, 1.0, 2.0, 0.4286972102784189, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 624853.7127108527, 624853.7127108522, 176487.1746390595], 
processed observation next is [0.0, 0.21739130434782608, 0.33017377567140627, 0.9216666666666667, 1.0, 1.0, 0.3116833858776131, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17357047575301465, 0.17357047575301449, 0.2634136934911336], 
reward next is 0.7366, 
noisyNet noise sample is [array([-0.9818373], dtype=float32), 0.5954283]. 
=============================================
[2019-03-26 18:26:52,527] A3C_AGENT_WORKER-Thread-20 INFO:Local step 137000, global step 2195477: loss 0.0224
[2019-03-26 18:26:52,531] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 137000, global step 2195478: learning rate 0.0000
[2019-03-26 18:26:52,968] A3C_AGENT_WORKER-Thread-17 INFO:Local step 137000, global step 2195674: loss 0.0226
[2019-03-26 18:26:52,970] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 137000, global step 2195675: learning rate 0.0000
[2019-03-26 18:26:55,409] A3C_AGENT_WORKER-Thread-18 INFO:Local step 137000, global step 2196768: loss 0.0239
[2019-03-26 18:26:55,414] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 137000, global step 2196768: learning rate 0.0000
[2019-03-26 18:26:55,747] A3C_AGENT_WORKER-Thread-12 INFO:Local step 137000, global step 2196920: loss 0.0228
[2019-03-26 18:26:55,748] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 137000, global step 2196920: learning rate 0.0000
[2019-03-26 18:26:56,418] A3C_AGENT_WORKER-Thread-21 INFO:Local step 137000, global step 2197221: loss 0.0221
[2019-03-26 18:26:56,422] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 137000, global step 2197221: learning rate 0.0000
[2019-03-26 18:26:56,654] A3C_AGENT_WORKER-Thread-19 INFO:Local step 137000, global step 2197326: loss 0.0217
[2019-03-26 18:26:56,656] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 137000, global step 2197326: learning rate 0.0000
[2019-03-26 18:26:56,751] A3C_AGENT_WORKER-Thread-11 INFO:Local step 137000, global step 2197368: loss 0.0219
[2019-03-26 18:26:56,755] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 137000, global step 2197368: learning rate 0.0000
[2019-03-26 18:26:57,014] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.7322642e-18 1.0000000e+00 5.1704928e-21 4.9469154e-19 7.6981301e-30], sum to 1.0000
[2019-03-26 18:26:57,025] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2681
[2019-03-26 18:26:57,029] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 93.33333333333334, 1.0, 2.0, 0.4839596938315129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 676251.3459021929, 676251.3459021929, 181120.9643241533], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3201600.0000, 
sim time next is 3202200.0000, 
raw observation next is [25.0, 93.0, 1.0, 2.0, 0.482662126705178, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 674437.641003603, 674437.641003603, 180924.049788991], 
processed observation next is [0.0, 0.043478260869565216, 0.38388625592417064, 0.93, 1.0, 1.0, 0.3767013574761181, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1873437891676675, 0.1873437891676675, 0.27003589520744925], 
reward next is 0.7300, 
noisyNet noise sample is [array([-1.8091928], dtype=float32), 0.7604953]. 
=============================================
[2019-03-26 18:26:57,252] A3C_AGENT_WORKER-Thread-2 INFO:Local step 137500, global step 2197596: loss 0.2494
[2019-03-26 18:26:57,255] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 137500, global step 2197596: learning rate 0.0000
[2019-03-26 18:26:57,271] A3C_AGENT_WORKER-Thread-14 INFO:Local step 137500, global step 2197603: loss 0.2419
[2019-03-26 18:26:57,278] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 137500, global step 2197604: learning rate 0.0000
[2019-03-26 18:26:59,983] A3C_AGENT_WORKER-Thread-3 INFO:Local step 137500, global step 2198833: loss 0.2541
[2019-03-26 18:26:59,987] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 137500, global step 2198834: learning rate 0.0000
[2019-03-26 18:27:00,720] A3C_AGENT_WORKER-Thread-15 INFO:Local step 137500, global step 2199166: loss 0.2527
[2019-03-26 18:27:00,724] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 137500, global step 2199166: learning rate 0.0000
[2019-03-26 18:27:02,577] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-26 18:27:02,579] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 18:27:02,580] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 18:27:02,581] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 18:27:02,581] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:27:02,580] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:27:02,582] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:27:02,584] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 18:27:02,581] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 18:27:02,586] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:27:02,588] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:27:02,611] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run89
[2019-03-26 18:27:02,634] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run89
[2019-03-26 18:27:02,662] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run89
[2019-03-26 18:27:02,695] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run89
[2019-03-26 18:27:02,696] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run89
[2019-03-26 18:27:20,525] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.11183888], dtype=float32), 0.09571132]
[2019-03-26 18:27:20,525] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [24.94141573, 72.41312223333334, 1.0, 2.0, 0.5677858054435965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 874752.1054101908, 874752.1054101908, 204680.3870562241]
[2019-03-26 18:27:20,527] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:27:20,530] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.5117272e-17 1.0000000e+00 6.4811204e-21 2.7042901e-21 5.1862920e-30], sampled 0.10417192961500987
[2019-03-26 18:27:26,284] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.11183888], dtype=float32), 0.09571132]
[2019-03-26 18:27:26,286] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [21.53189416, 100.0, 1.0, 2.0, 0.3652776473358444, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 559359.1203731516, 559359.1203731516, 171345.181957597]
[2019-03-26 18:27:26,288] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:27:26,290] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.2370436e-18 1.0000000e+00 6.6465159e-22 3.7151539e-22 1.7997399e-31], sampled 0.03305160300063015
[2019-03-26 18:27:49,969] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.11183888], dtype=float32), 0.09571132]
[2019-03-26 18:27:49,969] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [25.72985776166666, 88.81252710500002, 1.0, 2.0, 0.5078496398825365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 709644.6319472617, 709644.6319472612, 184833.9157101887]
[2019-03-26 18:27:49,971] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 18:27:49,973] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [5.81909650e-18 1.00000000e+00 3.06466620e-21 1.13041695e-20
 1.15755367e-30], sampled 0.26322097887058815
[2019-03-26 18:28:02,161] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.11183888], dtype=float32), 0.09571132]
[2019-03-26 18:28:02,162] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [33.16666666666667, 65.0, 1.0, 2.0, 0.59571298699098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 832468.7535263541, 832468.7535263541, 199951.0652718619]
[2019-03-26 18:28:02,163] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 18:28:02,167] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [6.0435251e-13 1.0000000e+00 2.7107345e-14 2.8073035e-08 1.6861532e-22], sampled 0.05634791312070131
[2019-03-26 18:28:14,479] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.11183888], dtype=float32), 0.09571132]
[2019-03-26 18:28:14,480] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.63248955166667, 86.76109764666667, 1.0, 2.0, 0.5453393382474966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 762049.7222678286, 762049.7222678286, 191004.8374220266]
[2019-03-26 18:28:14,484] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 18:28:14,487] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [8.3358845e-18 1.0000000e+00 5.4372444e-21 2.4313905e-20 2.4856588e-30], sampled 0.041605686926867946
[2019-03-26 18:28:15,417] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.11183888], dtype=float32), 0.09571132]
[2019-03-26 18:28:15,418] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.55, 80.5, 1.0, 2.0, 0.5837528668407074, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 815748.873471136, 815748.873471136, 197757.9629940962]
[2019-03-26 18:28:15,419] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 18:28:15,425] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.9420210e-17 1.0000000e+00 2.1654871e-20 1.1018373e-19 2.3985380e-29], sampled 0.5863187332757607
[2019-03-26 18:28:29,509] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.11183888], dtype=float32), 0.09571132]
[2019-03-26 18:28:29,511] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.85, 84.33333333333333, 1.0, 2.0, 0.538561888943381, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 752575.652433318, 752575.6524333173, 189858.779793614]
[2019-03-26 18:28:29,513] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 18:28:29,517] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.4045606e-17 1.0000000e+00 1.0783881e-20 2.9845429e-19 5.9164278e-30], sampled 0.409680068122387
[2019-03-26 18:28:56,178] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8514.6892 2839685011.1340 1071.0000
[2019-03-26 18:28:56,241] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8664.0596 2778734566.1737 922.0000
[2019-03-26 18:28:56,570] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8051.4228 3000716060.9862 1593.0000
[2019-03-26 18:28:56,614] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8281.8241 2924402336.3813 1254.0000
[2019-03-26 18:28:56,824] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7947.3580 3156752240.1336 1566.0000
[2019-03-26 18:28:57,846] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 2200000, evaluation results [2200000.0, 7947.358033582516, 3156752240.13365, 1566.0, 8281.824050744812, 2924402336.3812647, 1254.0, 8664.059627721203, 2778734566.1736665, 922.0, 8051.422842781777, 3000716060.986217, 1593.0, 8514.689188780574, 2839685011.133964, 1071.0]
[2019-03-26 18:28:58,098] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.4989965e-16 1.0000000e+00 1.7346836e-19 2.0478757e-18 9.3995890e-29], sum to 1.0000
[2019-03-26 18:28:58,106] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2653
[2019-03-26 18:28:58,113] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 100.0, 1.0, 2.0, 0.594342783005197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 895015.1927884435, 895015.1927884435, 207700.950212236], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3060000.0000, 
sim time next is 3060600.0000, 
raw observation next is [22.16666666666667, 99.00000000000001, 1.0, 2.0, 0.6628962343878047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 997140.1535652278, 997140.1535652272, 222029.2964895704], 
processed observation next is [1.0, 0.43478260869565216, 0.24960505529225935, 0.9900000000000001, 1.0, 1.0, 0.5938508848045839, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.27698337599034106, 0.2769833759903409, 0.331387009685926], 
reward next is 0.6686, 
noisyNet noise sample is [array([-0.8810911], dtype=float32), 0.62349033]. 
=============================================
[2019-03-26 18:28:58,688] A3C_AGENT_WORKER-Thread-9 INFO:Local step 138000, global step 2200389: loss 0.0071
[2019-03-26 18:28:58,692] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 138000, global step 2200390: learning rate 0.0000
[2019-03-26 18:28:59,012] A3C_AGENT_WORKER-Thread-22 INFO:Local step 137500, global step 2200537: loss 0.2563
[2019-03-26 18:28:59,018] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 137500, global step 2200537: learning rate 0.0000
[2019-03-26 18:29:00,160] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.7363147e-18 1.0000000e+00 2.1803741e-20 8.8534769e-20 1.5170962e-29], sum to 1.0000
[2019-03-26 18:29:00,166] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5959
[2019-03-26 18:29:00,173] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.3426318834560549, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 527812.8876769763, 527812.8876769756, 168824.2942452934], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2872200.0000, 
sim time next is 2872800.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.3413625741345345, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 525862.5531479786, 525862.5531479786, 168667.6136828982], 
processed observation next is [1.0, 0.2608695652173913, 0.2417061611374408, 0.94, 1.0, 1.0, 0.20646093269221027, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14607293142999406, 0.14607293142999406, 0.2517427069894003], 
reward next is 0.7483, 
noisyNet noise sample is [array([-1.1181482], dtype=float32), -0.24816617]. 
=============================================
[2019-03-26 18:29:01,083] A3C_AGENT_WORKER-Thread-10 INFO:Local step 138500, global step 2201469: loss 6.4914
[2019-03-26 18:29:01,085] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 138500, global step 2201469: learning rate 0.0000
[2019-03-26 18:29:01,191] A3C_AGENT_WORKER-Thread-13 INFO:Local step 138000, global step 2201519: loss 0.0070
[2019-03-26 18:29:01,197] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 138000, global step 2201521: learning rate 0.0000
[2019-03-26 18:29:02,476] A3C_AGENT_WORKER-Thread-16 INFO:Local step 137500, global step 2202095: loss 0.2602
[2019-03-26 18:29:02,482] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 137500, global step 2202098: learning rate 0.0000
[2019-03-26 18:29:05,461] A3C_AGENT_WORKER-Thread-20 INFO:Local step 137500, global step 2203440: loss 0.2491
[2019-03-26 18:29:05,464] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 137500, global step 2203440: learning rate 0.0000
[2019-03-26 18:29:05,941] A3C_AGENT_WORKER-Thread-17 INFO:Local step 137500, global step 2203666: loss 0.2527
[2019-03-26 18:29:05,946] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 137500, global step 2203667: learning rate 0.0000
[2019-03-26 18:29:08,285] A3C_AGENT_WORKER-Thread-18 INFO:Local step 137500, global step 2204728: loss 0.2677
[2019-03-26 18:29:08,288] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 137500, global step 2204730: learning rate 0.0000
[2019-03-26 18:29:08,552] A3C_AGENT_WORKER-Thread-12 INFO:Local step 137500, global step 2204846: loss 0.2710
[2019-03-26 18:29:08,555] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 137500, global step 2204847: learning rate 0.0000
[2019-03-26 18:29:09,153] A3C_AGENT_WORKER-Thread-21 INFO:Local step 137500, global step 2205129: loss 0.2734
[2019-03-26 18:29:09,160] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 137500, global step 2205129: learning rate 0.0000
[2019-03-26 18:29:09,533] A3C_AGENT_WORKER-Thread-19 INFO:Local step 137500, global step 2205299: loss 0.2709
[2019-03-26 18:29:09,535] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 137500, global step 2205299: learning rate 0.0000
[2019-03-26 18:29:09,603] A3C_AGENT_WORKER-Thread-11 INFO:Local step 137500, global step 2205325: loss 0.2729
[2019-03-26 18:29:09,604] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 137500, global step 2205325: learning rate 0.0000
[2019-03-26 18:29:10,220] A3C_AGENT_WORKER-Thread-14 INFO:Local step 138000, global step 2205610: loss 0.0043
[2019-03-26 18:29:10,224] A3C_AGENT_WORKER-Thread-2 INFO:Local step 138000, global step 2205611: loss 0.0043
[2019-03-26 18:29:10,225] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 138000, global step 2205610: learning rate 0.0000
[2019-03-26 18:29:10,228] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 138000, global step 2205612: learning rate 0.0000
[2019-03-26 18:29:10,801] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.4186544e-17 1.0000000e+00 3.7937237e-21 6.9296571e-22 4.3743651e-30], sum to 1.0000
[2019-03-26 18:29:10,809] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8864
[2019-03-26 18:29:10,817] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 89.0, 1.0, 2.0, 0.4577248384834284, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 648075.29979201, 648075.2997920093, 178333.5326944034], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3211800.0000, 
sim time next is 3212400.0000, 
raw observation next is [25.0, 89.0, 1.0, 2.0, 0.4581765049879287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 648725.3603336428, 648725.3603336435, 178400.9513597907], 
processed observation next is [0.0, 0.17391304347826086, 0.38388625592417064, 0.89, 1.0, 1.0, 0.3472006084191912, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18020148898156746, 0.18020148898156765, 0.266270076656404], 
reward next is 0.7337, 
noisyNet noise sample is [array([0.8278118], dtype=float32), 0.38796297]. 
=============================================
[2019-03-26 18:29:12,965] A3C_AGENT_WORKER-Thread-3 INFO:Local step 138000, global step 2206828: loss 0.0016
[2019-03-26 18:29:12,969] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 138000, global step 2206829: learning rate 0.0000
[2019-03-26 18:29:13,628] A3C_AGENT_WORKER-Thread-15 INFO:Local step 138000, global step 2207131: loss 0.0016
[2019-03-26 18:29:13,634] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 138000, global step 2207133: learning rate 0.0000
[2019-03-26 18:29:16,717] A3C_AGENT_WORKER-Thread-22 INFO:Local step 138000, global step 2208523: loss 0.0013
[2019-03-26 18:29:16,718] A3C_AGENT_WORKER-Thread-9 INFO:Local step 138500, global step 2208523: loss 5.8878
[2019-03-26 18:29:16,720] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 138000, global step 2208523: learning rate 0.0000
[2019-03-26 18:29:16,725] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 138500, global step 2208523: learning rate 0.0000
[2019-03-26 18:29:19,038] A3C_AGENT_WORKER-Thread-10 INFO:Local step 139000, global step 2209572: loss 0.0049
[2019-03-26 18:29:19,042] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 139000, global step 2209573: learning rate 0.0000
[2019-03-26 18:29:19,145] A3C_AGENT_WORKER-Thread-13 INFO:Local step 138500, global step 2209623: loss 5.6530
[2019-03-26 18:29:19,147] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 138500, global step 2209623: learning rate 0.0000
[2019-03-26 18:29:20,285] A3C_AGENT_WORKER-Thread-16 INFO:Local step 138000, global step 2210133: loss 0.0003
[2019-03-26 18:29:20,288] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 138000, global step 2210135: learning rate 0.0000
[2019-03-26 18:29:20,514] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.8496034e-18 1.0000000e+00 4.0906957e-21 2.0438922e-21 3.6658539e-29], sum to 1.0000
[2019-03-26 18:29:20,526] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3151
[2019-03-26 18:29:20,533] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.83333333333334, 70.66666666666667, 1.0, 2.0, 0.495279537346645, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 692074.0541447345, 692074.0541447351, 182859.9811153516], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3315000.0000, 
sim time next is 3315600.0000, 
raw observation next is [29.0, 70.0, 1.0, 2.0, 0.4972080054590089, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 694769.66157284, 694769.6615728405, 183159.9795494174], 
processed observation next is [0.0, 0.391304347826087, 0.5734597156398105, 0.7, 1.0, 1.0, 0.3942265126012155, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1929915726591222, 0.19299157265912237, 0.2733731038051006], 
reward next is 0.7266, 
noisyNet noise sample is [array([0.3166469], dtype=float32), -0.50676113]. 
=============================================
[2019-03-26 18:29:23,121] A3C_AGENT_WORKER-Thread-20 INFO:Local step 138000, global step 2211407: loss 0.0004
[2019-03-26 18:29:23,122] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 138000, global step 2211407: learning rate 0.0000
[2019-03-26 18:29:23,609] A3C_AGENT_WORKER-Thread-17 INFO:Local step 138000, global step 2211622: loss 0.0003
[2019-03-26 18:29:23,611] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 138000, global step 2211623: learning rate 0.0000
[2019-03-26 18:29:26,045] A3C_AGENT_WORKER-Thread-12 INFO:Local step 138000, global step 2212722: loss 0.0002
[2019-03-26 18:29:26,047] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 138000, global step 2212723: learning rate 0.0000
[2019-03-26 18:29:26,056] A3C_AGENT_WORKER-Thread-18 INFO:Local step 138000, global step 2212725: loss 0.0002
[2019-03-26 18:29:26,058] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 138000, global step 2212725: learning rate 0.0000
[2019-03-26 18:29:26,696] A3C_AGENT_WORKER-Thread-21 INFO:Local step 138000, global step 2213007: loss 0.0002
[2019-03-26 18:29:26,700] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 138000, global step 2213008: learning rate 0.0000
[2019-03-26 18:29:27,189] A3C_AGENT_WORKER-Thread-11 INFO:Local step 138000, global step 2213229: loss 0.0002
[2019-03-26 18:29:27,191] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 138000, global step 2213230: learning rate 0.0000
[2019-03-26 18:29:27,272] A3C_AGENT_WORKER-Thread-19 INFO:Local step 138000, global step 2213267: loss 0.0003
[2019-03-26 18:29:27,283] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 138000, global step 2213271: learning rate 0.0000
[2019-03-26 18:29:27,483] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.1923751e-17 1.0000000e+00 1.9581773e-19 1.8832856e-16 2.7118852e-27], sum to 1.0000
[2019-03-26 18:29:27,495] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9714
[2019-03-26 18:29:27,499] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 84.0, 1.0, 2.0, 0.5435752090157918, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 759583.6708194437, 759583.6708194437, 190705.1947949817], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4050600.0000, 
sim time next is 4051200.0000, 
raw observation next is [28.0, 84.0, 1.0, 2.0, 0.5446465093164412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 761081.2257639385, 761081.2257639385, 190886.9765032092], 
processed observation next is [1.0, 0.9130434782608695, 0.5260663507109005, 0.84, 1.0, 1.0, 0.45138133652583273, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21141145160109404, 0.21141145160109404, 0.28490593507941675], 
reward next is 0.7151, 
noisyNet noise sample is [array([-0.84838915], dtype=float32), 0.8995757]. 
=============================================
[2019-03-26 18:29:28,120] A3C_AGENT_WORKER-Thread-14 INFO:Local step 138500, global step 2213636: loss 4.8989
[2019-03-26 18:29:28,122] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 138500, global step 2213636: learning rate 0.0000
[2019-03-26 18:29:28,283] A3C_AGENT_WORKER-Thread-2 INFO:Local step 138500, global step 2213710: loss 4.8492
[2019-03-26 18:29:28,286] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 138500, global step 2213712: learning rate 0.0000
[2019-03-26 18:29:30,977] A3C_AGENT_WORKER-Thread-3 INFO:Local step 138500, global step 2214932: loss 4.8550
[2019-03-26 18:29:30,980] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 138500, global step 2214932: learning rate 0.0000
[2019-03-26 18:29:31,383] A3C_AGENT_WORKER-Thread-15 INFO:Local step 138500, global step 2215112: loss 4.7266
[2019-03-26 18:29:31,388] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 138500, global step 2215114: learning rate 0.0000
[2019-03-26 18:29:32,104] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.7111142e-16 1.0000000e+00 7.4295114e-20 5.1851116e-20 5.6231049e-28], sum to 1.0000
[2019-03-26 18:29:32,110] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8737
[2019-03-26 18:29:32,116] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 75.0, 1.0, 2.0, 0.5629570964367421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 786677.6528210016, 786677.6528210023, 194047.9523203448], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3830400.0000, 
sim time next is 3831000.0000, 
raw observation next is [30.16666666666666, 74.16666666666667, 1.0, 2.0, 0.5646765470082263, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 789081.3098386107, 789081.3098386107, 194349.8064461348], 
processed observation next is [0.0, 0.34782608695652173, 0.6287519747235385, 0.7416666666666667, 1.0, 1.0, 0.475513912058104, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21918925273294743, 0.21918925273294743, 0.2900743379793057], 
reward next is 0.7099, 
noisyNet noise sample is [array([0.81680137], dtype=float32), 0.4162409]. 
=============================================
[2019-03-26 18:29:32,145] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[71.72738 ]
 [71.7188  ]
 [71.74678 ]
 [71.770546]
 [71.79331 ]], R is [[71.72566223]
 [71.71878052]
 [71.7124939 ]
 [71.70708466]
 [71.70253754]].
[2019-03-26 18:29:34,515] A3C_AGENT_WORKER-Thread-9 INFO:Local step 139000, global step 2216530: loss 0.0024
[2019-03-26 18:29:34,519] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 139000, global step 2216531: learning rate 0.0000
[2019-03-26 18:29:34,675] A3C_AGENT_WORKER-Thread-22 INFO:Local step 138500, global step 2216599: loss 3.7447
[2019-03-26 18:29:34,678] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 138500, global step 2216601: learning rate 0.0000
[2019-03-26 18:29:36,810] A3C_AGENT_WORKER-Thread-13 INFO:Local step 139000, global step 2217562: loss 0.0023
[2019-03-26 18:29:36,812] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 139000, global step 2217563: learning rate 0.0000
[2019-03-26 18:29:37,199] A3C_AGENT_WORKER-Thread-10 INFO:Local step 139500, global step 2217736: loss 16.4371
[2019-03-26 18:29:37,202] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 139500, global step 2217736: learning rate 0.0000
[2019-03-26 18:29:38,128] A3C_AGENT_WORKER-Thread-16 INFO:Local step 138500, global step 2218152: loss 4.4402
[2019-03-26 18:29:38,131] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 138500, global step 2218154: learning rate 0.0000
[2019-03-26 18:29:41,031] A3C_AGENT_WORKER-Thread-20 INFO:Local step 138500, global step 2219475: loss 4.3859
[2019-03-26 18:29:41,033] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 138500, global step 2219476: learning rate 0.0000
[2019-03-26 18:29:41,510] A3C_AGENT_WORKER-Thread-17 INFO:Local step 138500, global step 2219689: loss 3.3865
[2019-03-26 18:29:41,513] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 138500, global step 2219689: learning rate 0.0000
[2019-03-26 18:29:43,671] A3C_AGENT_WORKER-Thread-18 INFO:Local step 138500, global step 2220656: loss 4.4207
[2019-03-26 18:29:43,672] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 138500, global step 2220656: learning rate 0.0000
[2019-03-26 18:29:43,787] A3C_AGENT_WORKER-Thread-12 INFO:Local step 138500, global step 2220704: loss 3.9875
[2019-03-26 18:29:43,793] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 138500, global step 2220707: learning rate 0.0000
[2019-03-26 18:29:44,371] A3C_AGENT_WORKER-Thread-21 INFO:Local step 138500, global step 2220968: loss 3.5276
[2019-03-26 18:29:44,373] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 138500, global step 2220969: learning rate 0.0000
[2019-03-26 18:29:44,381] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.9525559e-16 1.0000000e+00 4.6899545e-20 3.9390651e-18 3.3641709e-28], sum to 1.0000
[2019-03-26 18:29:44,389] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1987
[2019-03-26 18:29:44,394] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.83333333333334, 84.83333333333333, 1.0, 2.0, 0.586725941692012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 819905.1160749003, 819905.1160749003, 198298.557284411], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3888600.0000, 
sim time next is 3889200.0000, 
raw observation next is [28.66666666666667, 85.66666666666667, 1.0, 2.0, 0.5839132199405105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 815973.0404311869, 815973.0404311869, 197786.8549785381], 
processed observation next is [0.0, 0.0, 0.5576619273301741, 0.8566666666666667, 1.0, 1.0, 0.49869062643434997, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2266591778975519, 0.2266591778975519, 0.29520426116199716], 
reward next is 0.7048, 
noisyNet noise sample is [array([-0.7216324], dtype=float32), -0.19456933]. 
=============================================
[2019-03-26 18:29:44,817] A3C_AGENT_WORKER-Thread-11 INFO:Local step 138500, global step 2221165: loss 4.3025
[2019-03-26 18:29:44,823] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 138500, global step 2221166: learning rate 0.0000
[2019-03-26 18:29:44,916] A3C_AGENT_WORKER-Thread-19 INFO:Local step 138500, global step 2221210: loss 4.0742
[2019-03-26 18:29:44,918] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 138500, global step 2221210: learning rate 0.0000
[2019-03-26 18:29:45,122] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.6878968e-10 3.9125022e-02 1.1697664e-10 9.6087503e-01 5.9886890e-17], sum to 1.0000
[2019-03-26 18:29:45,134] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9319
[2019-03-26 18:29:45,143] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.33333333333334, 63.00000000000001, 1.0, 2.0, 0.8208762163090825, 1.0, 2.0, 0.8208762163090825, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2295782.60715491, 2295782.607154911, 430164.5267638274], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3673200.0000, 
sim time next is 3673800.0000, 
raw observation next is [32.5, 63.0, 1.0, 2.0, 0.8291136758717621, 1.0, 2.0, 0.8291136758717621, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2318842.066225529, 2318842.066225529, 434296.5469285522], 
processed observation next is [1.0, 0.5217391304347826, 0.7393364928909952, 0.63, 1.0, 1.0, 0.7941128624960989, 1.0, 1.0, 0.7941128624960989, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6441227961737581, 0.6441227961737581, 0.6482038013858988], 
reward next is 0.3518, 
noisyNet noise sample is [array([0.33291504], dtype=float32), 0.29540446]. 
=============================================
[2019-03-26 18:29:45,739] A3C_AGENT_WORKER-Thread-14 INFO:Local step 139000, global step 2221580: loss 0.0023
[2019-03-26 18:29:45,743] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 139000, global step 2221580: learning rate 0.0000
[2019-03-26 18:29:46,029] A3C_AGENT_WORKER-Thread-2 INFO:Local step 139000, global step 2221707: loss 0.0023
[2019-03-26 18:29:46,031] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 139000, global step 2221707: learning rate 0.0000
[2019-03-26 18:29:48,374] A3C_AGENT_WORKER-Thread-3 INFO:Local step 139000, global step 2222763: loss 0.0024
[2019-03-26 18:29:48,378] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 139000, global step 2222763: learning rate 0.0000
[2019-03-26 18:29:48,897] A3C_AGENT_WORKER-Thread-15 INFO:Local step 139000, global step 2223000: loss 0.0023
[2019-03-26 18:29:48,899] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 139000, global step 2223001: learning rate 0.0000
[2019-03-26 18:29:52,139] A3C_AGENT_WORKER-Thread-22 INFO:Local step 139000, global step 2224463: loss 0.0023
[2019-03-26 18:29:52,144] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 139000, global step 2224465: learning rate 0.0000
[2019-03-26 18:29:52,719] A3C_AGENT_WORKER-Thread-9 INFO:Local step 139500, global step 2224723: loss 29.0983
[2019-03-26 18:29:52,721] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 139500, global step 2224724: learning rate 0.0000
[2019-03-26 18:29:53,325] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-26 18:29:53,327] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 18:29:53,328] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 18:29:53,330] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 18:29:53,331] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 18:29:53,331] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 18:29:53,333] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:29:53,332] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:29:53,334] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:29:53,334] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:29:53,338] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:29:53,361] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run90
[2019-03-26 18:29:53,387] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run90
[2019-03-26 18:29:53,424] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run90
[2019-03-26 18:29:53,425] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run90
[2019-03-26 18:29:53,446] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run90
[2019-03-26 18:30:00,759] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10945749], dtype=float32), 0.09335376]
[2019-03-26 18:30:00,761] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.56666666666667, 72.5, 1.0, 2.0, 0.588804067305549, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 830545.0324271279, 830545.0324271279, 199674.6859351951]
[2019-03-26 18:30:00,762] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 18:30:00,766] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [9.0010472e-17 1.0000000e+00 8.9016673e-20 1.3812862e-19 1.4305023e-28], sampled 0.11575471720745378
[2019-03-26 18:30:04,000] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10945749], dtype=float32), 0.09335376]
[2019-03-26 18:30:04,002] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [23.1, 64.5, 1.0, 2.0, 0.2670509937758575, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 437513.9586475513, 437513.9586475507, 162634.5595424622]
[2019-03-26 18:30:04,003] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 18:30:04,007] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [8.067655e-17 1.000000e+00 7.010734e-20 6.732647e-20 8.315194e-29], sampled 0.053747895559129066
[2019-03-26 18:30:07,449] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10945749], dtype=float32), 0.09335376]
[2019-03-26 18:30:07,449] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [25.51666666666667, 66.33333333333334, 1.0, 2.0, 0.3369757887346764, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 525182.1150973529, 525182.1150973529, 168793.0266745017]
[2019-03-26 18:30:07,451] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:30:07,455] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.0125015e-17 1.0000000e+00 1.4937365e-20 3.4586946e-21 1.3073000e-29], sampled 0.3057284282380034
[2019-03-26 18:30:12,882] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10945749], dtype=float32), 0.09335376]
[2019-03-26 18:30:12,885] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [25.23333333333333, 43.33333333333334, 1.0, 2.0, 0.2214732417225825, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 368663.2467142401, 368663.2467142408, 157801.2752354397]
[2019-03-26 18:30:12,886] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:30:12,888] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [5.9655776e-17 1.0000000e+00 4.5070861e-20 5.9106152e-20 5.3909391e-29], sampled 0.9865058159776827
[2019-03-26 18:30:17,156] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10945749], dtype=float32), 0.09335376]
[2019-03-26 18:30:17,158] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [23.38333333333333, 85.0, 1.0, 2.0, 0.3561559051675922, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 545130.6715466215, 545130.6715466221, 170135.5140260558]
[2019-03-26 18:30:17,160] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:30:17,168] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [6.5522055e-17 1.0000000e+00 3.9532716e-20 1.3340415e-20 5.9628567e-29], sampled 0.9278038755178858
[2019-03-26 18:30:18,341] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10945749], dtype=float32), 0.09335376]
[2019-03-26 18:30:18,342] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [23.0, 96.0, 1.0, 2.0, 0.4899577096211878, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 724605.9768557679, 724605.9768557679, 187031.6612792342]
[2019-03-26 18:30:18,346] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:30:18,347] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.17634718e-16 1.00000000e+00 1.06948236e-19 2.96372403e-19
 2.68460768e-28], sampled 0.11298103685265859
[2019-03-26 18:30:34,196] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10945749], dtype=float32), 0.09335376]
[2019-03-26 18:30:34,197] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [21.99922746, 94.76598743, 1.0, 2.0, 0.3451352568908524, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 533437.6193380662, 533437.6193380668, 169333.3155668387]
[2019-03-26 18:30:34,201] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:30:34,203] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.6845181e-17 1.0000000e+00 9.3425737e-21 9.4556583e-21 5.6483384e-30], sampled 0.6375427120078624
[2019-03-26 18:30:34,976] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10945749], dtype=float32), 0.09335376]
[2019-03-26 18:30:34,978] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [24.65944674, 79.00250277, 1.0, 2.0, 0.4408972452711016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 661896.6099014947, 661896.6099014954, 180560.2854188081]
[2019-03-26 18:30:34,979] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 18:30:34,983] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [5.8699992e-17 1.0000000e+00 6.0603678e-20 2.1623349e-19 6.9202545e-29], sampled 0.8402706383904421
[2019-03-26 18:30:48,020] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10945749], dtype=float32), 0.09335376]
[2019-03-26 18:30:48,022] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [33.7, 61.0, 1.0, 2.0, 0.7721843630398215, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005979791104314, 6.9112, 168.9123159155093, 1976145.078227641, 1908905.287354486, 401083.2497606193]
[2019-03-26 18:30:48,024] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:30:48,026] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [6.3921405e-13 1.0000000e+00 2.4535731e-14 4.4968453e-11 9.9744058e-22], sampled 0.7152143120977568
[2019-03-26 18:30:48,027] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1976145.078227641 W.
[2019-03-26 18:31:10,721] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10945749], dtype=float32), 0.09335376]
[2019-03-26 18:31:10,722] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [33.07307002833333, 57.193421055, 1.0, 2.0, 0.3425875734555719, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5880586809900608, 6.911199999999999, 6.9112, 168.9128920162121, 957542.4497646102, 957542.4497646109, 235808.6722049093]
[2019-03-26 18:31:10,724] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:31:10,726] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.8548314e-10 9.8524123e-01 1.6677418e-10 1.4758723e-02 1.0351731e-17], sampled 0.023000228063935646
[2019-03-26 18:31:21,968] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10945749], dtype=float32), 0.09335376]
[2019-03-26 18:31:21,970] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.53333333333333, 74.66666666666666, 1.0, 2.0, 0.5520030844711062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 771364.9310768677, 771364.9310768677, 192144.5343634106]
[2019-03-26 18:31:21,971] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:31:21,974] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.4118117e-16 1.0000000e+00 3.3264006e-19 4.0125907e-18 1.1686699e-27], sampled 0.48160610151714756
[2019-03-26 18:31:46,558] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8317.3494 2920587537.7371 1146.0000
[2019-03-26 18:31:46,909] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8138.6492 2991073384.5401 1345.0000
[2019-03-26 18:31:47,128] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 8030.4093 3148510586.9961 1331.0000
[2019-03-26 18:31:47,220] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8675.9693 2777377918.6980 877.0000
[2019-03-26 18:31:47,272] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8541.4764 2836029437.9512 967.0000
[2019-03-26 18:31:48,291] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 2225000, evaluation results [2225000.0, 8030.409271166396, 3148510586.996147, 1331.0, 8317.349444798476, 2920587537.737059, 1146.0, 8675.969265306554, 2777377918.6980476, 877.0, 8138.649201456748, 2991073384.5401044, 1345.0, 8541.476449781318, 2836029437.9512286, 967.0]
[2019-03-26 18:31:49,691] A3C_AGENT_WORKER-Thread-13 INFO:Local step 139500, global step 2225635: loss 29.1476
[2019-03-26 18:31:49,692] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 139500, global step 2225635: learning rate 0.0000
[2019-03-26 18:31:50,273] A3C_AGENT_WORKER-Thread-10 INFO:Local step 140000, global step 2225898: loss 0.0149
[2019-03-26 18:31:50,276] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 140000, global step 2225898: learning rate 0.0000
[2019-03-26 18:31:50,908] A3C_AGENT_WORKER-Thread-16 INFO:Local step 139000, global step 2226182: loss 0.0026
[2019-03-26 18:31:50,909] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 139000, global step 2226182: learning rate 0.0000
[2019-03-26 18:31:53,664] A3C_AGENT_WORKER-Thread-20 INFO:Local step 139000, global step 2227434: loss 0.0032
[2019-03-26 18:31:53,668] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 139000, global step 2227434: learning rate 0.0000
[2019-03-26 18:31:54,016] A3C_AGENT_WORKER-Thread-17 INFO:Local step 139000, global step 2227591: loss 0.0034
[2019-03-26 18:31:54,022] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 139000, global step 2227591: learning rate 0.0000
[2019-03-26 18:31:56,240] A3C_AGENT_WORKER-Thread-18 INFO:Local step 139000, global step 2228595: loss 0.0028
[2019-03-26 18:31:56,242] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 139000, global step 2228596: learning rate 0.0000
[2019-03-26 18:31:56,449] A3C_AGENT_WORKER-Thread-12 INFO:Local step 139000, global step 2228689: loss 0.0024
[2019-03-26 18:31:56,452] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 139000, global step 2228689: learning rate 0.0000
[2019-03-26 18:31:56,938] A3C_AGENT_WORKER-Thread-21 INFO:Local step 139000, global step 2228906: loss 0.0023
[2019-03-26 18:31:56,945] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 139000, global step 2228908: learning rate 0.0000
[2019-03-26 18:31:57,355] A3C_AGENT_WORKER-Thread-11 INFO:Local step 139000, global step 2229092: loss 0.0023
[2019-03-26 18:31:57,358] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 139000, global step 2229094: learning rate 0.0000
[2019-03-26 18:31:57,512] A3C_AGENT_WORKER-Thread-19 INFO:Local step 139000, global step 2229162: loss 0.0023
[2019-03-26 18:31:57,515] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 139000, global step 2229162: learning rate 0.0000
[2019-03-26 18:31:58,549] A3C_AGENT_WORKER-Thread-14 INFO:Local step 139500, global step 2229634: loss 41.6352
[2019-03-26 18:31:58,551] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 139500, global step 2229635: learning rate 0.0000
[2019-03-26 18:31:58,943] A3C_AGENT_WORKER-Thread-2 INFO:Local step 139500, global step 2229809: loss 26.4990
[2019-03-26 18:31:58,947] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 139500, global step 2229809: learning rate 0.0000
[2019-03-26 18:32:01,116] A3C_AGENT_WORKER-Thread-3 INFO:Local step 139500, global step 2230786: loss 41.9368
[2019-03-26 18:32:01,118] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 139500, global step 2230786: learning rate 0.0000
[2019-03-26 18:32:01,553] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.7370758e-16 1.0000000e+00 5.0194922e-19 3.2948049e-18 5.8544245e-28], sum to 1.0000
[2019-03-26 18:32:01,561] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0904
[2019-03-26 18:32:01,564] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.16666666666667, 78.33333333333334, 1.0, 2.0, 0.6243460041974962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 872497.900132628, 872497.900132628, 205369.7574011352], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4439400.0000, 
sim time next is 4440000.0000, 
raw observation next is [31.33333333333334, 77.66666666666667, 1.0, 2.0, 0.6266804102499258, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 875761.4816794852, 875761.4816794852, 205822.278183216], 
processed observation next is [0.0, 0.391304347826087, 0.6840442338072673, 0.7766666666666667, 1.0, 1.0, 0.5502173617468986, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.24326707824430144, 0.24326707824430144, 0.307197430124203], 
reward next is 0.6928, 
noisyNet noise sample is [array([0.0640067], dtype=float32), -0.45436627]. 
=============================================
[2019-03-26 18:32:01,572] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[71.140236]
 [71.13259 ]
 [71.11338 ]
 [71.1282  ]
 [71.14091 ]], R is [[71.11644745]
 [71.09876251]
 [71.08328247]
 [71.06977844]
 [71.05810547]].
[2019-03-26 18:32:01,588] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.1026549e-14 1.0000000e+00 7.1562531e-16 1.5053864e-12 8.0702119e-24], sum to 1.0000
[2019-03-26 18:32:01,598] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1142
[2019-03-26 18:32:01,606] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.33333333333334, 79.0, 1.0, 2.0, 0.9187025758693804, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1284097.835336189, 1284097.835336189, 275136.2849042831], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4256400.0000, 
sim time next is 4257000.0000, 
raw observation next is [29.5, 79.0, 1.0, 2.0, 0.9834529039382823, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1374659.88324726, 1374659.883247259, 293927.35968535], 
processed observation next is [1.0, 0.2608695652173913, 0.5971563981042655, 0.79, 1.0, 1.0, 0.9800637396846775, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.38184996756868334, 0.38184996756868306, 0.4386975517691791], 
reward next is 0.5613, 
noisyNet noise sample is [array([0.95353746], dtype=float32), 0.4980722]. 
=============================================
[2019-03-26 18:32:01,620] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[62.08442 ]
 [62.711613]
 [64.206665]
 [64.88212 ]
 [65.54148 ]], R is [[61.492836  ]
 [61.46725464]
 [61.40497208]
 [61.40750885]
 [61.40497971]].
[2019-03-26 18:32:01,650] A3C_AGENT_WORKER-Thread-15 INFO:Local step 139500, global step 2231008: loss 28.1305
[2019-03-26 18:32:01,651] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 139500, global step 2231008: learning rate 0.0000
[2019-03-26 18:32:01,716] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.7089585e-11 9.8686129e-01 5.2234328e-10 1.3138770e-02 1.4682036e-17], sum to 1.0000
[2019-03-26 18:32:01,729] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3342
[2019-03-26 18:32:01,735] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 84.0, 1.0, 2.0, 0.9723174822166177, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1359084.947307518, 1359084.947307518, 290608.2201761422], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3993000.0000, 
sim time next is 3993600.0000, 
raw observation next is [29.0, 84.0, 1.0, 2.0, 0.939300760562163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1312906.330865904, 1312906.330865904, 280980.4600007791], 
processed observation next is [1.0, 0.21739130434782608, 0.5734597156398105, 0.84, 1.0, 1.0, 0.9268683862194735, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3646962030183067, 0.3646962030183067, 0.4193738208966852], 
reward next is 0.5806, 
noisyNet noise sample is [array([0.24970746], dtype=float32), 0.9858478]. 
=============================================
[2019-03-26 18:32:04,840] A3C_AGENT_WORKER-Thread-22 INFO:Local step 139500, global step 2232454: loss 26.5876
[2019-03-26 18:32:04,849] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 139500, global step 2232457: learning rate 0.0000
[2019-03-26 18:32:05,763] A3C_AGENT_WORKER-Thread-9 INFO:Local step 140000, global step 2232867: loss 0.0201
[2019-03-26 18:32:05,765] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 140000, global step 2232868: learning rate 0.0000
[2019-03-26 18:32:07,788] A3C_AGENT_WORKER-Thread-13 INFO:Local step 140000, global step 2233772: loss 0.0211
[2019-03-26 18:32:07,794] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 140000, global step 2233773: learning rate 0.0000
[2019-03-26 18:32:07,971] A3C_AGENT_WORKER-Thread-10 INFO:Local step 140500, global step 2233859: loss 1.8474
[2019-03-26 18:32:07,975] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 140500, global step 2233860: learning rate 0.0000
[2019-03-26 18:32:08,776] A3C_AGENT_WORKER-Thread-16 INFO:Local step 139500, global step 2234215: loss 54.1451
[2019-03-26 18:32:08,779] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 139500, global step 2234215: learning rate 0.0000
[2019-03-26 18:32:11,510] A3C_AGENT_WORKER-Thread-20 INFO:Local step 139500, global step 2235440: loss 52.4816
[2019-03-26 18:32:11,512] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 139500, global step 2235440: learning rate 0.0000
[2019-03-26 18:32:11,898] A3C_AGENT_WORKER-Thread-17 INFO:Local step 139500, global step 2235612: loss 26.2375
[2019-03-26 18:32:11,901] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 139500, global step 2235613: learning rate 0.0000
[2019-03-26 18:32:13,920] A3C_AGENT_WORKER-Thread-18 INFO:Local step 139500, global step 2236526: loss 56.0216
[2019-03-26 18:32:13,922] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 139500, global step 2236526: learning rate 0.0000
[2019-03-26 18:32:14,184] A3C_AGENT_WORKER-Thread-12 INFO:Local step 139500, global step 2236643: loss 39.0209
[2019-03-26 18:32:14,188] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 139500, global step 2236644: learning rate 0.0000
[2019-03-26 18:32:14,677] A3C_AGENT_WORKER-Thread-21 INFO:Local step 139500, global step 2236860: loss 38.8143
[2019-03-26 18:32:14,680] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 139500, global step 2236862: learning rate 0.0000
[2019-03-26 18:32:15,077] A3C_AGENT_WORKER-Thread-11 INFO:Local step 139500, global step 2237042: loss 47.7630
[2019-03-26 18:32:15,080] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 139500, global step 2237042: learning rate 0.0000
[2019-03-26 18:32:15,287] A3C_AGENT_WORKER-Thread-19 INFO:Local step 139500, global step 2237134: loss 48.5704
[2019-03-26 18:32:15,289] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 139500, global step 2237136: learning rate 0.0000
[2019-03-26 18:32:16,523] A3C_AGENT_WORKER-Thread-14 INFO:Local step 140000, global step 2237686: loss 0.0193
[2019-03-26 18:32:16,527] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 140000, global step 2237687: learning rate 0.0000
[2019-03-26 18:32:16,811] A3C_AGENT_WORKER-Thread-2 INFO:Local step 140000, global step 2237800: loss 0.0200
[2019-03-26 18:32:16,813] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 140000, global step 2237800: learning rate 0.0000
[2019-03-26 18:32:18,489] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.5174613e-16 1.0000000e+00 3.1829370e-19 3.1622179e-19 2.2863721e-28], sum to 1.0000
[2019-03-26 18:32:18,500] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3793
[2019-03-26 18:32:18,509] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.66666666666667, 80.66666666666667, 1.0, 2.0, 0.5844406942784548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 816710.4279373143, 816710.4279373143, 197883.1917347989], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4434000.0000, 
sim time next is 4434600.0000, 
raw observation next is [29.83333333333333, 79.83333333333334, 1.0, 2.0, 0.5856148241911059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 818351.8152719805, 818351.8152719805, 198096.7304769898], 
processed observation next is [0.0, 0.30434782608695654, 0.6129541864139019, 0.7983333333333335, 1.0, 1.0, 0.5007407520374769, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22731994868666125, 0.22731994868666125, 0.2956667619059549], 
reward next is 0.7043, 
noisyNet noise sample is [array([2.9868112], dtype=float32), -0.6439844]. 
=============================================
[2019-03-26 18:32:18,908] A3C_AGENT_WORKER-Thread-3 INFO:Local step 140000, global step 2238746: loss 0.0198
[2019-03-26 18:32:18,911] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 140000, global step 2238747: learning rate 0.0000
[2019-03-26 18:32:19,563] A3C_AGENT_WORKER-Thread-15 INFO:Local step 140000, global step 2239035: loss 0.0184
[2019-03-26 18:32:19,564] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 140000, global step 2239035: learning rate 0.0000
[2019-03-26 18:32:19,710] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.1060432e-17 8.8836477e-14 5.0250009e-15 1.0000000e+00 3.2085971e-20], sum to 1.0000
[2019-03-26 18:32:19,715] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1056
[2019-03-26 18:32:19,726] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 3 has been changed to 4 for the demand 3449523.561523785 W.
[2019-03-26 18:32:19,731] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [38.0, 52.0, 1.0, 2.0, 1.002602719180425, 1.0, 2.0, 0.8218913991044751, 1.0, 2.0, 1.03, 7.005121604239135, 6.9112, 170.5573041426782, 3449523.561523785, 3382243.695920699, 633967.8366295117], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4284000.0000, 
sim time next is 4284600.0000, 
raw observation next is [38.0, 51.83333333333334, 1.0, 2.0, 0.9688784483359016, 1.0, 2.0, 0.8050292636822133, 1.0, 2.0, 1.03, 7.005118942555843, 6.9112, 170.5573041426782, 3378656.496688614, 3311378.53775754, 619721.6397830901], 
processed observation next is [1.0, 0.6086956521739131, 1.0, 0.5183333333333334, 1.0, 1.0, 0.9625041546215682, 1.0, 1.0, 0.7650954984123052, 1.0, 1.0, 1.0365853658536586, 0.009391894255584265, 0.0, 0.8375144448122397, 0.9385156935246151, 0.9198273715993167, 0.924957671318045], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.07143269], dtype=float32), -0.60383236]. 
=============================================
[2019-03-26 18:32:21,133] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.42693252e-17 1.00000000e+00 2.65341268e-20 1.27175446e-17
 4.85493235e-28], sum to 1.0000
[2019-03-26 18:32:21,140] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0728
[2019-03-26 18:32:21,146] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 73.0, 1.0, 2.0, 0.6138371803709566, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 857806.3199818324, 857806.3199818324, 203352.9630802807], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4311000.0000, 
sim time next is 4311600.0000, 
raw observation next is [31.66666666666666, 75.0, 1.0, 2.0, 0.6159248780729145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 860724.9537543136, 860724.9537543142, 203751.033751722], 
processed observation next is [1.0, 0.9130434782608695, 0.6998420221169034, 0.75, 1.0, 1.0, 0.5372588892444753, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.23909026493175378, 0.23909026493175395, 0.30410602052495816], 
reward next is 0.6959, 
noisyNet noise sample is [array([-0.7014202], dtype=float32), 2.0951784]. 
=============================================
[2019-03-26 18:32:22,948] A3C_AGENT_WORKER-Thread-22 INFO:Local step 140000, global step 2240564: loss 0.0168
[2019-03-26 18:32:22,951] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 140000, global step 2240564: learning rate 0.0000
[2019-03-26 18:32:22,963] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.0688905e-17 1.0000000e+00 7.8344460e-20 7.9769116e-19 2.0994781e-28], sum to 1.0000
[2019-03-26 18:32:22,973] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2454
[2019-03-26 18:32:22,978] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 82.33333333333334, 1.0, 2.0, 0.5351957552558767, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 747870.2284100746, 747870.2284100752, 189294.3949329485], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4570800.0000, 
sim time next is 4571400.0000, 
raw observation next is [28.0, 83.16666666666666, 1.0, 2.0, 0.539813751100717, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 754325.6008058469, 754325.6008058469, 190069.2940472838], 
processed observation next is [0.0, 0.9130434782608695, 0.5260663507109005, 0.8316666666666666, 1.0, 1.0, 0.4455587362659241, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20953488911273524, 0.20953488911273524, 0.28368551350340865], 
reward next is 0.7163, 
noisyNet noise sample is [array([-1.2929804], dtype=float32), 0.90311354]. 
=============================================
[2019-03-26 18:32:23,199] A3C_AGENT_WORKER-Thread-9 INFO:Local step 140500, global step 2240673: loss -56.5461
[2019-03-26 18:32:23,203] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 140500, global step 2240673: learning rate 0.0000
[2019-03-26 18:32:25,351] A3C_AGENT_WORKER-Thread-13 INFO:Local step 140500, global step 2241650: loss 3.4281
[2019-03-26 18:32:25,353] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 140500, global step 2241650: learning rate 0.0000
[2019-03-26 18:32:25,569] A3C_AGENT_WORKER-Thread-10 INFO:Local step 141000, global step 2241746: loss 0.0235
[2019-03-26 18:32:25,573] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 141000, global step 2241746: learning rate 0.0000
[2019-03-26 18:32:26,686] A3C_AGENT_WORKER-Thread-16 INFO:Local step 140000, global step 2242246: loss 0.0138
[2019-03-26 18:32:26,690] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 140000, global step 2242247: learning rate 0.0000
[2019-03-26 18:32:29,374] A3C_AGENT_WORKER-Thread-20 INFO:Local step 140000, global step 2243457: loss 0.0100
[2019-03-26 18:32:29,378] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 140000, global step 2243459: learning rate 0.0000
[2019-03-26 18:32:29,531] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.6958287e-18 1.0000000e+00 3.7025095e-20 8.1054580e-21 1.0125686e-28], sum to 1.0000
[2019-03-26 18:32:29,541] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6432
[2019-03-26 18:32:29,545] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.5053978247127924, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 706217.4446298716, 706217.4446298716, 184445.782531365], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4514400.0000, 
sim time next is 4515000.0000, 
raw observation next is [26.16666666666667, 88.16666666666667, 1.0, 2.0, 0.5062047223269435, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 707345.3380824012, 707345.3380824012, 184573.6595479667], 
processed observation next is [0.0, 0.2608695652173913, 0.4391785150078992, 0.8816666666666667, 1.0, 1.0, 0.4050659305143897, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19648481613400035, 0.19648481613400035, 0.27548307395218913], 
reward next is 0.7245, 
noisyNet noise sample is [array([0.8191341], dtype=float32), 1.182145]. 
=============================================
[2019-03-26 18:32:29,566] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[71.942085]
 [71.88406 ]
 [71.8655  ]
 [71.84631 ]
 [71.82719 ]], R is [[71.99375153]
 [71.9985199 ]
 [72.00317383]
 [72.00778198]
 [72.01243591]].
[2019-03-26 18:32:29,855] A3C_AGENT_WORKER-Thread-17 INFO:Local step 140000, global step 2243672: loss 0.0088
[2019-03-26 18:32:29,859] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 140000, global step 2243673: learning rate 0.0000
[2019-03-26 18:32:31,938] A3C_AGENT_WORKER-Thread-18 INFO:Local step 140000, global step 2244611: loss 0.0084
[2019-03-26 18:32:31,941] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 140000, global step 2244611: learning rate 0.0000
[2019-03-26 18:32:32,236] A3C_AGENT_WORKER-Thread-12 INFO:Local step 140000, global step 2244723: loss 0.0081
[2019-03-26 18:32:32,241] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 140000, global step 2244723: learning rate 0.0000
[2019-03-26 18:32:32,637] A3C_AGENT_WORKER-Thread-21 INFO:Local step 140000, global step 2244901: loss 0.0081
[2019-03-26 18:32:32,642] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 140000, global step 2244902: learning rate 0.0000
[2019-03-26 18:32:32,771] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.0758493e-09 9.7064680e-01 6.0266632e-09 2.9353192e-02 8.4798687e-16], sum to 1.0000
[2019-03-26 18:32:32,784] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4769
[2019-03-26 18:32:32,796] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2178858.116844314 W.
[2019-03-26 18:32:32,804] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.5, 68.0, 1.0, 2.0, 0.9170186122542281, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.988130826420431, 6.9112, 168.9124345822202, 2178858.116844314, 2124280.909466906, 439479.7131236948], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4786200.0000, 
sim time next is 4786800.0000, 
raw observation next is [30.66666666666666, 67.33333333333334, 1.0, 2.0, 0.753015588979809, 1.0, 1.0, 0.753015588979809, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2105818.755880468, 2105818.755880469, 397644.2896585754], 
processed observation next is [1.0, 0.391304347826087, 0.6524486571879934, 0.6733333333333335, 1.0, 1.0, 0.7024284204576012, 1.0, 0.5, 0.7024284204576012, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5849496544112411, 0.5849496544112414, 0.5934989397889184], 
reward next is 0.4065, 
noisyNet noise sample is [array([0.73539764], dtype=float32), 0.12674263]. 
=============================================
[2019-03-26 18:32:33,295] A3C_AGENT_WORKER-Thread-19 INFO:Local step 140000, global step 2245199: loss 0.0081
[2019-03-26 18:32:33,297] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 140000, global step 2245199: learning rate 0.0000
[2019-03-26 18:32:33,331] A3C_AGENT_WORKER-Thread-11 INFO:Local step 140000, global step 2245214: loss 0.0082
[2019-03-26 18:32:33,335] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 140000, global step 2245214: learning rate 0.0000
[2019-03-26 18:32:34,314] A3C_AGENT_WORKER-Thread-14 INFO:Local step 140500, global step 2245654: loss -74.5436
[2019-03-26 18:32:34,316] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 140500, global step 2245654: learning rate 0.0000
[2019-03-26 18:32:34,411] A3C_AGENT_WORKER-Thread-2 INFO:Local step 140500, global step 2245699: loss 0.5192
[2019-03-26 18:32:34,413] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 140500, global step 2245699: learning rate 0.0000
[2019-03-26 18:32:36,948] A3C_AGENT_WORKER-Thread-3 INFO:Local step 140500, global step 2246845: loss 0.0393
[2019-03-26 18:32:36,952] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 140500, global step 2246845: learning rate 0.0000
[2019-03-26 18:32:37,320] A3C_AGENT_WORKER-Thread-15 INFO:Local step 140500, global step 2247011: loss -0.0503
[2019-03-26 18:32:37,324] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 140500, global step 2247011: learning rate 0.0000
[2019-03-26 18:32:39,464] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.1085191e-11 4.6968585e-04 2.7826099e-11 9.9953032e-01 1.3615692e-17], sum to 1.0000
[2019-03-26 18:32:39,473] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3721
[2019-03-26 18:32:39,479] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.5, 68.5, 1.0, 2.0, 0.8687214466657879, 1.0, 2.0, 0.8687214466657879, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2429723.668706472, 2429723.668706472, 454716.60750897], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4725000.0000, 
sim time next is 4725600.0000, 
raw observation next is [31.33333333333333, 69.0, 1.0, 2.0, 0.8612478352445541, 1.0, 2.0, 0.8612478352445541, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2408800.606825833, 2408800.606825833, 450792.6430452687], 
processed observation next is [1.0, 0.6956521739130435, 0.6840442338072668, 0.69, 1.0, 1.0, 0.8328287171621133, 1.0, 1.0, 0.8328287171621133, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6691112796738425, 0.6691112796738425, 0.6728248403660727], 
reward next is 0.3272, 
noisyNet noise sample is [array([1.7210935], dtype=float32), -1.0050547]. 
=============================================
[2019-03-26 18:32:40,720] A3C_AGENT_WORKER-Thread-22 INFO:Local step 140500, global step 2248541: loss 1.7718
[2019-03-26 18:32:40,721] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 140500, global step 2248541: learning rate 0.0000
[2019-03-26 18:32:40,874] A3C_AGENT_WORKER-Thread-9 INFO:Local step 141000, global step 2248613: loss 0.0311
[2019-03-26 18:32:40,881] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 141000, global step 2248614: learning rate 0.0000
[2019-03-26 18:32:43,252] A3C_AGENT_WORKER-Thread-13 INFO:Local step 141000, global step 2249685: loss 0.0278
[2019-03-26 18:32:43,255] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 141000, global step 2249685: learning rate 0.0000
[2019-03-26 18:32:43,580] A3C_AGENT_WORKER-Thread-10 INFO:Local step 141500, global step 2249833: loss -84.4749
[2019-03-26 18:32:43,582] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 141500, global step 2249833: learning rate 0.0000
[2019-03-26 18:32:43,780] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.4208207e-14 1.0000000e+00 5.2126291e-16 6.5616111e-13 2.3545759e-24], sum to 1.0000
[2019-03-26 18:32:43,788] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7584
[2019-03-26 18:32:43,792] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.5, 86.5, 1.0, 2.0, 0.9592886103637915, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1340861.963088486, 1340861.963088486, 286767.4255070675], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4689000.0000, 
sim time next is 4689600.0000, 
raw observation next is [27.66666666666666, 85.66666666666667, 1.0, 2.0, 0.830988013210304, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1161429.53381116, 1161429.53381116, 251659.916831695], 
processed observation next is [1.0, 0.2608695652173913, 0.5102685624012636, 0.8566666666666667, 1.0, 1.0, 0.7963711002533783, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3226193149475444, 0.3226193149475444, 0.37561181616670897], 
reward next is 0.6244, 
noisyNet noise sample is [array([-0.35664818], dtype=float32), 0.56997323]. 
=============================================
[2019-03-26 18:32:43,900] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.8798403e-10 7.2281361e-02 2.9218680e-10 9.2771864e-01 8.7599353e-17], sum to 1.0000
[2019-03-26 18:32:43,906] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0121
[2019-03-26 18:32:43,913] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2201503.06412083 W.
[2019-03-26 18:32:43,918] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 66.0, 1.0, 2.0, 0.7871960279933515, 1.0, 2.0, 0.7871960279933515, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2201503.06412083, 2201503.064120831, 413683.9889965698], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4709400.0000, 
sim time next is 4710000.0000, 
raw observation next is [31.0, 66.0, 1.0, 2.0, 0.5972852855578619, 1.0, 2.0, 0.5972852855578619, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 1669977.360361011, 1669977.360361011, 333252.3150793207], 
processed observation next is [1.0, 0.5217391304347826, 0.6682464454976303, 0.66, 1.0, 1.0, 0.5148015488648938, 1.0, 1.0, 0.5148015488648938, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.4638826001002808, 0.4638826001002808, 0.4973915150437622], 
reward next is 0.5026, 
noisyNet noise sample is [array([-0.5465831], dtype=float32), -1.2170025]. 
=============================================
[2019-03-26 18:32:43,937] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[57.405964]
 [58.03511 ]
 [57.91953 ]
 [57.848   ]
 [57.69778 ]], R is [[58.15904617]
 [57.96001816]
 [57.7964592 ]
 [57.63415146]
 [57.47141266]].
[2019-03-26 18:32:43,955] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-26 18:32:43,956] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 18:32:43,957] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:32:43,958] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 18:32:43,960] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 18:32:43,960] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 18:32:43,962] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:32:43,963] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 18:32:43,961] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:32:43,965] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:32:43,963] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:32:43,998] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run91
[2019-03-26 18:32:44,030] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run91
[2019-03-26 18:32:44,031] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run91
[2019-03-26 18:32:44,053] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run91
[2019-03-26 18:32:44,082] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run91
[2019-03-26 18:33:06,777] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.11003743], dtype=float32), 0.09418562]
[2019-03-26 18:33:06,781] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [21.3, 87.0, 1.0, 2.0, 0.3017044403387181, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 482937.6583922363, 482937.6583922363, 165861.2233978735]
[2019-03-26 18:33:06,782] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:33:06,786] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.77314037e-17 1.00000000e+00 1.44602933e-20 1.38975188e-21
 1.12689426e-29], sampled 0.31313264496059523
[2019-03-26 18:33:17,171] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.11003743], dtype=float32), 0.09418562]
[2019-03-26 18:33:17,172] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.78333333333333, 83.83333333333334, 1.0, 2.0, 0.4505045115848335, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 660977.4354925336, 660977.4354925329, 180189.043000163]
[2019-03-26 18:33:17,172] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 18:33:17,174] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [6.6058875e-17 1.0000000e+00 9.5052087e-20 3.1885393e-19 8.5839919e-29], sampled 0.880038497767626
[2019-03-26 18:34:01,867] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.11003743], dtype=float32), 0.09418562]
[2019-03-26 18:34:01,868] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.88111337, 92.858755215, 1.0, 2.0, 0.8207678911325635, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1147137.674808043, 1147137.674808042, 249076.3220096533]
[2019-03-26 18:34:01,870] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:34:01,873] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [7.6956014e-16 1.0000000e+00 3.1888938e-18 1.5352647e-16 8.2661499e-27], sampled 0.7325899549287269
[2019-03-26 18:34:06,563] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.11003743], dtype=float32), 0.09418562]
[2019-03-26 18:34:06,564] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.78177508, 65.6420183, 1.0, 2.0, 0.4526025461856968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 655952.807133973, 655952.8071339737, 179503.2462335299]
[2019-03-26 18:34:06,566] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 18:34:06,569] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.8678628e-17 1.0000000e+00 5.0104220e-20 2.3779788e-19 3.0297237e-29], sampled 0.7742992376019102
[2019-03-26 18:34:12,799] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.11003743], dtype=float32), 0.09418562]
[2019-03-26 18:34:12,801] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [34.36666666666667, 55.83333333333334, 1.0, 2.0, 0.630242624983405, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 6.984416477622618, 6.9112, 168.9119321171362, 1762214.180057642, 1710272.205925843, 370280.5541429119]
[2019-03-26 18:34:12,802] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 18:34:12,805] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.1620034e-13 1.0000000e+00 9.4492327e-15 1.4339949e-11 1.3381839e-22], sampled 0.6651257894410403
[2019-03-26 18:34:12,806] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1762214.180057642 W.
[2019-03-26 18:34:22,909] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.11003743], dtype=float32), 0.09418562]
[2019-03-26 18:34:22,910] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.05, 66.66666666666666, 1.0, 2.0, 0.4377453511170085, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 630702.9727467664, 630702.972746767, 176865.3861288442]
[2019-03-26 18:34:22,912] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 18:34:22,914] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.7300171e-17 1.0000000e+00 2.8470112e-20 7.3399823e-21 2.1689659e-29], sampled 0.7077546676306776
[2019-03-26 18:34:33,663] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.11003743], dtype=float32), 0.09418562]
[2019-03-26 18:34:33,664] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [23.50718252, 95.33858609, 1.0, 2.0, 0.4636225445387591, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 666912.9177705823, 666912.9177705823, 180531.0220897071]
[2019-03-26 18:34:33,664] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 18:34:33,668] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [5.1387275e-17 1.0000000e+00 9.0639498e-20 9.0456822e-19 6.6259110e-29], sampled 0.8613089432744492
[2019-03-26 18:34:37,469] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8673.3795 2777636059.9126 891.0000
[2019-03-26 18:34:37,544] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7999.0812 3150882871.0255 1429.0000
[2019-03-26 18:34:37,604] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8307.6789 2922045182.2075 1190.0000
[2019-03-26 18:34:37,774] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8537.6957 2837113278.3094 1003.0000
[2019-03-26 18:34:37,907] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8103.5256 2994651809.5401 1439.0000
[2019-03-26 18:34:38,927] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 2250000, evaluation results [2250000.0, 7999.081174965936, 3150882871.025466, 1429.0, 8307.678879810363, 2922045182.2074785, 1190.0, 8673.379508914557, 2777636059.912589, 891.0, 8103.525557624667, 2994651809.540075, 1439.0, 8537.695738888402, 2837113278.3093596, 1003.0]
[2019-03-26 18:34:39,577] A3C_AGENT_WORKER-Thread-16 INFO:Local step 140500, global step 2250298: loss 0.7038
[2019-03-26 18:34:39,583] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 140500, global step 2250300: learning rate 0.0000
[2019-03-26 18:34:42,326] A3C_AGENT_WORKER-Thread-20 INFO:Local step 140500, global step 2251534: loss 0.1412
[2019-03-26 18:34:42,328] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 140500, global step 2251535: learning rate 0.0000
[2019-03-26 18:34:42,714] A3C_AGENT_WORKER-Thread-17 INFO:Local step 140500, global step 2251711: loss 2.1391
[2019-03-26 18:34:42,718] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 140500, global step 2251711: learning rate 0.0000
[2019-03-26 18:34:44,637] A3C_AGENT_WORKER-Thread-18 INFO:Local step 140500, global step 2252577: loss 0.0118
[2019-03-26 18:34:44,641] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 140500, global step 2252579: learning rate 0.0000
[2019-03-26 18:34:45,030] A3C_AGENT_WORKER-Thread-12 INFO:Local step 140500, global step 2252755: loss -74.3465
[2019-03-26 18:34:45,031] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 140500, global step 2252755: learning rate 0.0000
[2019-03-26 18:34:45,279] A3C_AGENT_WORKER-Thread-21 INFO:Local step 140500, global step 2252844: loss 0.3060
[2019-03-26 18:34:45,284] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 140500, global step 2252844: learning rate 0.0000
[2019-03-26 18:34:46,103] A3C_AGENT_WORKER-Thread-19 INFO:Local step 140500, global step 2253218: loss -35.8394
[2019-03-26 18:34:46,105] A3C_AGENT_WORKER-Thread-11 INFO:Local step 140500, global step 2253219: loss 2.1553
[2019-03-26 18:34:46,106] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 140500, global step 2253218: learning rate 0.0000
[2019-03-26 18:34:46,107] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 140500, global step 2253219: learning rate 0.0000
[2019-03-26 18:34:46,906] A3C_AGENT_WORKER-Thread-14 INFO:Local step 141000, global step 2253577: loss 0.0387
[2019-03-26 18:34:46,909] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 141000, global step 2253578: learning rate 0.0000
[2019-03-26 18:34:47,054] A3C_AGENT_WORKER-Thread-2 INFO:Local step 141000, global step 2253647: loss 0.0366
[2019-03-26 18:34:47,056] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 141000, global step 2253647: learning rate 0.0000
[2019-03-26 18:34:49,742] A3C_AGENT_WORKER-Thread-3 INFO:Local step 141000, global step 2254853: loss 0.0415
[2019-03-26 18:34:49,744] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 141000, global step 2254854: learning rate 0.0000
[2019-03-26 18:34:49,887] A3C_AGENT_WORKER-Thread-15 INFO:Local step 141000, global step 2254916: loss 0.0380
[2019-03-26 18:34:49,889] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 141000, global step 2254917: learning rate 0.0000
[2019-03-26 18:34:53,342] A3C_AGENT_WORKER-Thread-22 INFO:Local step 141000, global step 2256471: loss 0.0407
[2019-03-26 18:34:53,347] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 141000, global step 2256473: learning rate 0.0000
[2019-03-26 18:34:53,824] A3C_AGENT_WORKER-Thread-9 INFO:Local step 141500, global step 2256692: loss -84.8285
[2019-03-26 18:34:53,828] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 141500, global step 2256692: learning rate 0.0000
[2019-03-26 18:34:56,130] A3C_AGENT_WORKER-Thread-10 INFO:Local step 142000, global step 2257726: loss 0.0814
[2019-03-26 18:34:56,133] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 142000, global step 2257727: learning rate 0.0000
[2019-03-26 18:34:56,210] A3C_AGENT_WORKER-Thread-13 INFO:Local step 141500, global step 2257765: loss -84.3486
[2019-03-26 18:34:56,214] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 141500, global step 2257767: learning rate 0.0000
[2019-03-26 18:34:57,278] A3C_AGENT_WORKER-Thread-16 INFO:Local step 141000, global step 2258248: loss 0.0447
[2019-03-26 18:34:57,280] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 141000, global step 2258248: learning rate 0.0000
[2019-03-26 18:35:00,221] A3C_AGENT_WORKER-Thread-20 INFO:Local step 141000, global step 2259570: loss 0.0389
[2019-03-26 18:35:00,223] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 141000, global step 2259570: learning rate 0.0000
[2019-03-26 18:35:00,408] A3C_AGENT_WORKER-Thread-17 INFO:Local step 141000, global step 2259653: loss 0.0399
[2019-03-26 18:35:00,410] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 141000, global step 2259653: learning rate 0.0000
[2019-03-26 18:35:02,476] A3C_AGENT_WORKER-Thread-18 INFO:Local step 141000, global step 2260567: loss 0.0323
[2019-03-26 18:35:02,478] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 141000, global step 2260568: learning rate 0.0000
[2019-03-26 18:35:02,943] A3C_AGENT_WORKER-Thread-12 INFO:Local step 141000, global step 2260788: loss 0.0299
[2019-03-26 18:35:02,947] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 141000, global step 2260788: learning rate 0.0000
[2019-03-26 18:35:02,984] A3C_AGENT_WORKER-Thread-21 INFO:Local step 141000, global step 2260803: loss 0.0298
[2019-03-26 18:35:02,985] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 141000, global step 2260803: learning rate 0.0000
[2019-03-26 18:35:03,842] A3C_AGENT_WORKER-Thread-19 INFO:Local step 141000, global step 2261194: loss 0.0263
[2019-03-26 18:35:03,844] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 141000, global step 2261195: learning rate 0.0000
[2019-03-26 18:35:03,915] A3C_AGENT_WORKER-Thread-11 INFO:Local step 141000, global step 2261223: loss 0.0282
[2019-03-26 18:35:03,918] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 141000, global step 2261223: learning rate 0.0000
[2019-03-26 18:35:04,759] A3C_AGENT_WORKER-Thread-14 INFO:Local step 141500, global step 2261605: loss -82.8961
[2019-03-26 18:35:04,765] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 141500, global step 2261606: learning rate 0.0000
[2019-03-26 18:35:04,874] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.4435695e-15 1.0000000e+00 2.9436471e-18 9.6316249e-13 1.2021903e-26], sum to 1.0000
[2019-03-26 18:35:04,882] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5287
[2019-03-26 18:35:04,888] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.55, 70.0, 1.0, 2.0, 0.5429226798948982, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 758671.5109867644, 758671.5109867644, 190595.2286941812], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5596200.0000, 
sim time next is 5596800.0000, 
raw observation next is [30.26666666666667, 71.66666666666667, 1.0, 2.0, 0.5476704144670246, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 765308.3097198021, 765308.3097198021, 191402.5517945991], 
processed observation next is [1.0, 0.782608695652174, 0.6334913112164299, 0.7166666666666667, 1.0, 1.0, 0.4550245957434031, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21258564158883392, 0.21258564158883392, 0.28567545043970016], 
reward next is 0.7143, 
noisyNet noise sample is [array([0.7340571], dtype=float32), -1.6024103]. 
=============================================
[2019-03-26 18:35:05,228] A3C_AGENT_WORKER-Thread-2 INFO:Local step 141500, global step 2261811: loss -82.7330
[2019-03-26 18:35:05,230] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 141500, global step 2261811: learning rate 0.0000
[2019-03-26 18:35:07,857] A3C_AGENT_WORKER-Thread-15 INFO:Local step 141500, global step 2262995: loss -82.1115
[2019-03-26 18:35:07,859] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 141500, global step 2262996: learning rate 0.0000
[2019-03-26 18:35:07,867] A3C_AGENT_WORKER-Thread-3 INFO:Local step 141500, global step 2263000: loss -82.0429
[2019-03-26 18:35:07,868] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 141500, global step 2263000: learning rate 0.0000
[2019-03-26 18:35:10,269] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.8924180e-11 1.6430276e-03 7.7448048e-10 9.9835700e-01 1.6500162e-16], sum to 1.0000
[2019-03-26 18:35:10,278] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6939
[2019-03-26 18:35:10,283] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 68.0, 1.0, 2.0, 0.8578539524502417, 1.0, 2.0, 0.8578539524502417, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2399299.235765735, 2399299.235765735, 449018.3551391917], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5221800.0000, 
sim time next is 5222400.0000, 
raw observation next is [31.0, 68.66666666666667, 1.0, 2.0, 0.8591173078912541, 1.0, 2.0, 0.8591173078912541, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2402836.063908042, 2402836.063908042, 449677.5723923345], 
processed observation next is [1.0, 0.43478260869565216, 0.6682464454976303, 0.6866666666666668, 1.0, 1.0, 0.8302618167364507, 1.0, 1.0, 0.8302618167364507, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6674544621966784, 0.6674544621966784, 0.6711605558094546], 
reward next is 0.3288, 
noisyNet noise sample is [array([0.5685546], dtype=float32), 0.054043535]. 
=============================================
[2019-03-26 18:35:10,396] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.7760103e-12 1.0000000e+00 2.2060836e-13 1.7169706e-08 5.7905006e-21], sum to 1.0000
[2019-03-26 18:35:10,403] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3547
[2019-03-26 18:35:10,409] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.9, 92.0, 1.0, 2.0, 1.020823415403356, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.9128490411629, 1426931.089766331, 1426931.089766331, 305338.4033111521], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5454000.0000, 
sim time next is 5454600.0000, 
raw observation next is [27.86666666666667, 92.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.946319293159664, 6.9112, 168.9125736448559, 1478686.769019689, 1453771.990212504, 311353.9108632685], 
processed observation next is [1.0, 0.13043478260869565, 0.519747235387046, 0.92, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0035119293159663555, 0.0, 0.8294380651070524, 0.41074632472769135, 0.40382555283680666, 0.4647073296466694], 
reward next is 0.3597, 
noisyNet noise sample is [array([-1.0357323], dtype=float32), 0.24247766]. 
=============================================
[2019-03-26 18:35:11,401] A3C_AGENT_WORKER-Thread-22 INFO:Local step 141500, global step 2264582: loss -58.7117
[2019-03-26 18:35:11,406] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 141500, global step 2264582: learning rate 0.0000
[2019-03-26 18:35:11,554] A3C_AGENT_WORKER-Thread-9 INFO:Local step 142000, global step 2264651: loss 0.1261
[2019-03-26 18:35:11,557] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 142000, global step 2264652: learning rate 0.0000
[2019-03-26 18:35:13,935] A3C_AGENT_WORKER-Thread-10 INFO:Local step 142500, global step 2265725: loss -1.3153
[2019-03-26 18:35:13,937] A3C_AGENT_WORKER-Thread-13 INFO:Local step 142000, global step 2265725: loss 0.1353
[2019-03-26 18:35:13,939] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 142500, global step 2265725: learning rate 0.0000
[2019-03-26 18:35:13,941] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 142000, global step 2265726: learning rate 0.0000
[2019-03-26 18:35:15,230] A3C_AGENT_WORKER-Thread-16 INFO:Local step 141500, global step 2266310: loss -80.0700
[2019-03-26 18:35:15,231] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 141500, global step 2266311: learning rate 0.0000
[2019-03-26 18:35:16,400] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.5009044e-12 9.9999976e-01 2.6107413e-12 2.0961289e-07 4.2790097e-19], sum to 1.0000
[2019-03-26 18:35:16,408] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0691
[2019-03-26 18:35:16,416] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1686343.671717935 W.
[2019-03-26 18:35:16,422] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.4, 75.0, 1.0, 2.0, 0.402089513363187, 1.0, 1.0, 0.402089513363187, 1.0, 1.0, 0.6982965116778396, 6.9112, 6.9112, 170.5573041426782, 1686343.671717935, 1686343.671717935, 354049.7095742002], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5384400.0000, 
sim time next is 5385000.0000, 
raw observation next is [31.6, 74.0, 1.0, 2.0, 0.5701543442131454, 1.0, 2.0, 0.5701543442131454, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1594064.299340367, 1594064.299340367, 323504.703993274], 
processed observation next is [1.0, 0.30434782608695654, 0.6966824644549764, 0.74, 1.0, 1.0, 0.4821136677266811, 1.0, 1.0, 0.4821136677266811, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.4427956387056575, 0.4427956387056575, 0.482842841781006], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2232188], dtype=float32), 2.423369]. 
=============================================
[2019-03-26 18:35:16,435] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[50.28848 ]
 [53.923656]
 [53.29876 ]
 [54.92782 ]
 [55.035988]], R is [[49.92035294]
 [49.42115021]
 [48.92694092]
 [48.43767166]
 [47.95329666]].
[2019-03-26 18:35:18,108] A3C_AGENT_WORKER-Thread-20 INFO:Local step 141500, global step 2267592: loss -79.2793
[2019-03-26 18:35:18,110] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 141500, global step 2267592: learning rate 0.0000
[2019-03-26 18:35:18,412] A3C_AGENT_WORKER-Thread-17 INFO:Local step 141500, global step 2267730: loss -79.3170
[2019-03-26 18:35:18,415] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 141500, global step 2267730: learning rate 0.0000
[2019-03-26 18:35:20,283] A3C_AGENT_WORKER-Thread-18 INFO:Local step 141500, global step 2268567: loss -79.0826
[2019-03-26 18:35:20,286] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 141500, global step 2268567: learning rate 0.0000
[2019-03-26 18:35:20,854] A3C_AGENT_WORKER-Thread-21 INFO:Local step 141500, global step 2268825: loss -78.9963
[2019-03-26 18:35:20,861] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 141500, global step 2268826: learning rate 0.0000
[2019-03-26 18:35:20,981] A3C_AGENT_WORKER-Thread-12 INFO:Local step 141500, global step 2268881: loss -56.0952
[2019-03-26 18:35:20,985] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 141500, global step 2268883: learning rate 0.0000
[2019-03-26 18:35:21,708] A3C_AGENT_WORKER-Thread-11 INFO:Local step 141500, global step 2269207: loss -78.6603
[2019-03-26 18:35:21,711] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 141500, global step 2269208: learning rate 0.0000
[2019-03-26 18:35:21,794] A3C_AGENT_WORKER-Thread-19 INFO:Local step 141500, global step 2269242: loss -78.7239
[2019-03-26 18:35:21,797] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 141500, global step 2269243: learning rate 0.0000
[2019-03-26 18:35:22,418] A3C_AGENT_WORKER-Thread-14 INFO:Local step 142000, global step 2269528: loss 0.1507
[2019-03-26 18:35:22,422] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 142000, global step 2269528: learning rate 0.0000
[2019-03-26 18:35:22,837] A3C_AGENT_WORKER-Thread-2 INFO:Local step 142000, global step 2269718: loss 0.1540
[2019-03-26 18:35:22,840] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 142000, global step 2269718: learning rate 0.0000
[2019-03-26 18:35:23,036] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.2796793e-14 1.0000000e+00 1.5638686e-15 2.8615490e-11 5.1066808e-24], sum to 1.0000
[2019-03-26 18:35:23,045] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5595
[2019-03-26 18:35:23,059] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.7, 92.0, 1.0, 2.0, 0.9211757236426925, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1287556.723439645, 1287556.723439645, 275832.0907661517], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5457600.0000, 
sim time next is 5458200.0000, 
raw observation next is [27.68333333333333, 92.0, 1.0, 2.0, 0.979417190625841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1369015.16930083, 1369015.169300831, 292720.3300779311], 
processed observation next is [1.0, 0.17391304347826086, 0.5110584518167456, 0.92, 1.0, 1.0, 0.975201434488965, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3802819914724528, 0.380281991472453, 0.43689601504168823], 
reward next is 0.5631, 
noisyNet noise sample is [array([0.38337573], dtype=float32), -1.271612]. 
=============================================
[2019-03-26 18:35:25,449] A3C_AGENT_WORKER-Thread-15 INFO:Local step 142000, global step 2270887: loss 0.1493
[2019-03-26 18:35:25,452] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 142000, global step 2270887: learning rate 0.0000
[2019-03-26 18:35:25,472] A3C_AGENT_WORKER-Thread-3 INFO:Local step 142000, global step 2270899: loss 0.1509
[2019-03-26 18:35:25,475] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 142000, global step 2270900: learning rate 0.0000
[2019-03-26 18:35:27,878] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.0404598e-15 1.0000000e+00 1.0350024e-17 1.3694247e-14 1.6869163e-25], sum to 1.0000
[2019-03-26 18:35:27,884] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2459
[2019-03-26 18:35:27,890] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.86666666666667, 83.16666666666667, 1.0, 2.0, 0.8239101206838724, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1151531.760519927, 1151531.760519927, 249867.2128934293], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5991000.0000, 
sim time next is 5991600.0000, 
raw observation next is [29.03333333333333, 82.33333333333334, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.821479272219213, 6.9112, 168.9081532308424, 2099962.375537966, 1454197.294199544, 311353.450260544], 
processed observation next is [1.0, 0.34782608695652173, 0.5750394944707741, 0.8233333333333335, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.09102792722192125, 0.0, 0.8294163588505717, 0.5833228820938794, 0.4039436928332067, 0.4647066421799165], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.85512984], dtype=float32), -0.0862249]. 
=============================================
[2019-03-26 18:35:29,022] A3C_AGENT_WORKER-Thread-22 INFO:Local step 142000, global step 2272496: loss 0.1308
[2019-03-26 18:35:29,024] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 142000, global step 2272496: learning rate 0.0000
[2019-03-26 18:35:29,171] A3C_AGENT_WORKER-Thread-9 INFO:Local step 142500, global step 2272565: loss -196.9187
[2019-03-26 18:35:29,177] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 142500, global step 2272565: learning rate 0.0000
[2019-03-26 18:35:30,823] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.1413557e-10 1.2674880e-02 2.4910116e-09 9.8732507e-01 1.4500005e-14], sum to 1.0000
[2019-03-26 18:35:30,833] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5112
[2019-03-26 18:35:30,840] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.76666666666667, 74.33333333333333, 1.0, 2.0, 0.8363776699586385, 1.0, 1.0, 0.8363776699586385, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2339176.816431732, 2339176.816431732, 437975.3667730644], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5998200.0000, 
sim time next is 5998800.0000, 
raw observation next is [30.93333333333334, 73.66666666666667, 1.0, 2.0, 0.8620735987348972, 1.0, 2.0, 0.8620735987348972, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2411112.390376026, 2411112.390376026, 451227.5269004514], 
processed observation next is [1.0, 0.43478260869565216, 0.6650868878357034, 0.7366666666666667, 1.0, 1.0, 0.8338236129336111, 1.0, 1.0, 0.8338236129336111, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6697534417711183, 0.6697534417711183, 0.6734739207469423], 
reward next is 0.3265, 
noisyNet noise sample is [array([0.43372282], dtype=float32), 1.7741984]. 
=============================================
[2019-03-26 18:35:31,629] A3C_AGENT_WORKER-Thread-10 INFO:Local step 143000, global step 2273659: loss 0.0457
[2019-03-26 18:35:31,631] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 143000, global step 2273659: learning rate 0.0000
[2019-03-26 18:35:31,671] A3C_AGENT_WORKER-Thread-13 INFO:Local step 142500, global step 2273676: loss -106.2485
[2019-03-26 18:35:31,674] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 142500, global step 2273677: learning rate 0.0000
[2019-03-26 18:35:32,058] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.1862502e-10 2.7825863e-03 3.2876830e-09 9.9721742e-01 5.8077411e-15], sum to 1.0000
[2019-03-26 18:35:32,069] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2690
[2019-03-26 18:35:32,075] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.7, 71.33333333333333, 1.0, 2.0, 0.8587874913773571, 1.0, 2.0, 0.8587874913773571, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2401912.724750973, 2401912.724750973, 449506.8802514052], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5823600.0000, 
sim time next is 5824200.0000, 
raw observation next is [30.85, 70.66666666666667, 1.0, 2.0, 0.8744899439514984, 1.0, 2.0, 0.8744899439514984, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2445873.346454006, 2445873.346454006, 457765.8200490825], 
processed observation next is [1.0, 0.391304347826087, 0.661137440758294, 0.7066666666666667, 1.0, 1.0, 0.8487830650018052, 1.0, 1.0, 0.8487830650018052, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6794092629038906, 0.6794092629038906, 0.6832325672374366], 
reward next is 0.3168, 
noisyNet noise sample is [array([-0.07844236], dtype=float32), 3.0084229]. 
=============================================
[2019-03-26 18:35:32,996] A3C_AGENT_WORKER-Thread-16 INFO:Local step 142000, global step 2274274: loss 0.1159
[2019-03-26 18:35:33,000] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 142000, global step 2274274: learning rate 0.0000
[2019-03-26 18:35:34,604] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-26 18:35:34,607] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 18:35:34,607] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:35:34,608] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 18:35:34,608] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 18:35:34,608] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 18:35:34,609] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:35:34,611] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 18:35:34,611] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:35:34,612] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:35:34,613] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:35:34,648] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run92
[2019-03-26 18:35:34,673] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run92
[2019-03-26 18:35:34,708] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run92
[2019-03-26 18:35:34,729] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run92
[2019-03-26 18:35:34,730] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run92
[2019-03-26 18:36:00,392] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.11038723], dtype=float32), 0.094337665]
[2019-03-26 18:36:00,393] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.85303763, 80.19660346, 1.0, 2.0, 0.8019516136651355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1120825.421315553, 1120825.421315554, 244389.2673870806]
[2019-03-26 18:36:00,393] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:36:00,395] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.3757562e-16 1.0000000e+00 2.8473710e-19 3.0100416e-18 7.9967702e-28], sampled 0.39094652458717527
[2019-03-26 18:36:13,837] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.11038723], dtype=float32), 0.094337665]
[2019-03-26 18:36:13,841] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [24.33133863, 87.37679442, 1.0, 2.0, 0.4372414035289441, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 639063.7138869013, 639063.7138869013, 177928.3273139501]
[2019-03-26 18:36:13,843] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:36:13,846] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.8106499e-17 1.0000000e+00 1.8461233e-20 8.5142363e-21 2.3598212e-29], sampled 0.4039032589214798
[2019-03-26 18:36:17,667] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.11038723], dtype=float32), 0.094337665]
[2019-03-26 18:36:17,668] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [30.0, 69.0, 1.0, 2.0, 0.734744345163781, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1026849.631984408, 1026849.631984407, 228523.0867357938]
[2019-03-26 18:36:17,671] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:36:17,675] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.1621501e-16 1.0000000e+00 1.8255910e-19 5.3064153e-19 4.4568874e-28], sampled 0.4875990400808614
[2019-03-26 18:37:10,017] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.11038723], dtype=float32), 0.094337665]
[2019-03-26 18:37:10,018] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [31.96639270166667, 77.42379833166667, 1.0, 2.0, 0.8123812835040077, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005982301536637, 6.9112, 168.9123159950277, 2032401.644513348, 1965160.0726282, 410943.6362290211]
[2019-03-26 18:37:10,019] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:37:10,021] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.0142296e-10 9.9992836e-01 1.3079272e-10 7.1665570e-05 1.3658787e-17], sampled 0.28414008408045055
[2019-03-26 18:37:10,023] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2032401.644513348 W.
[2019-03-26 18:37:27,287] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7964.9188 3155282973.5132 1538.0000
[2019-03-26 18:37:28,705] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8287.5529 2923872521.4254 1237.0000
[2019-03-26 18:37:28,812] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8060.5963 2999901954.6618 1569.0000
[2019-03-26 18:37:28,850] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8665.2216 2778707520.6041 921.0000
[2019-03-26 18:37:28,883] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8519.1577 2839602254.3071 1060.0000
[2019-03-26 18:37:29,900] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 2275000, evaluation results [2275000.0, 7964.91884948898, 3155282973.513249, 1538.0, 8287.552867775783, 2923872521.425413, 1237.0, 8665.221578510618, 2778707520.6041355, 921.0, 8060.59625042462, 2999901954.6617713, 1569.0, 8519.15767753944, 2839602254.307131, 1060.0]
[2019-03-26 18:37:30,946] A3C_AGENT_WORKER-Thread-20 INFO:Local step 142000, global step 2275479: loss 0.0913
[2019-03-26 18:37:30,948] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 142000, global step 2275479: learning rate 0.0000
[2019-03-26 18:37:31,509] A3C_AGENT_WORKER-Thread-17 INFO:Local step 142000, global step 2275728: loss 0.0941
[2019-03-26 18:37:31,512] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 142000, global step 2275729: learning rate 0.0000
[2019-03-26 18:37:31,564] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.6663648e-18 1.0000000e+00 8.1292394e-21 6.3335220e-21 5.5558497e-30], sum to 1.0000
[2019-03-26 18:37:31,576] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7679
[2019-03-26 18:37:31,581] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.18333333333333, 82.16666666666667, 1.0, 2.0, 0.5121313591848884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 715629.715685423, 715629.715685423, 185518.3057289357], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6390600.0000, 
sim time next is 6391200.0000, 
raw observation next is [27.16666666666667, 82.33333333333334, 1.0, 2.0, 0.5122766213681439, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 715832.7670303946, 715832.767030394, 185541.6009069304], 
processed observation next is [0.0, 1.0, 0.4865718799368091, 0.8233333333333335, 1.0, 1.0, 0.4123814715278842, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19884243528622073, 0.19884243528622056, 0.27692776254765733], 
reward next is 0.7231, 
noisyNet noise sample is [array([0.05060355], dtype=float32), 0.71367115]. 
=============================================
[2019-03-26 18:37:33,305] A3C_AGENT_WORKER-Thread-18 INFO:Local step 142000, global step 2276533: loss 0.0898
[2019-03-26 18:37:33,306] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 142000, global step 2276533: learning rate 0.0000
[2019-03-26 18:37:34,088] A3C_AGENT_WORKER-Thread-12 INFO:Local step 142000, global step 2276884: loss 0.0940
[2019-03-26 18:37:34,089] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 142000, global step 2276884: learning rate 0.0000
[2019-03-26 18:37:34,110] A3C_AGENT_WORKER-Thread-21 INFO:Local step 142000, global step 2276893: loss 0.0945
[2019-03-26 18:37:34,111] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 142000, global step 2276893: learning rate 0.0000
[2019-03-26 18:37:34,764] A3C_AGENT_WORKER-Thread-19 INFO:Local step 142000, global step 2277193: loss 0.1041
[2019-03-26 18:37:34,766] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 142000, global step 2277194: learning rate 0.0000
[2019-03-26 18:37:34,824] A3C_AGENT_WORKER-Thread-11 INFO:Local step 142000, global step 2277216: loss 0.1043
[2019-03-26 18:37:34,825] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 142000, global step 2277216: learning rate 0.0000
[2019-03-26 18:37:35,652] A3C_AGENT_WORKER-Thread-14 INFO:Local step 142500, global step 2277591: loss -135.0274
[2019-03-26 18:37:35,655] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 142500, global step 2277591: learning rate 0.0000
[2019-03-26 18:37:36,080] A3C_AGENT_WORKER-Thread-2 INFO:Local step 142500, global step 2277782: loss -23.9264
[2019-03-26 18:37:36,084] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 142500, global step 2277783: learning rate 0.0000
[2019-03-26 18:37:38,498] A3C_AGENT_WORKER-Thread-15 INFO:Local step 142500, global step 2278872: loss -184.0477
[2019-03-26 18:37:38,501] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 142500, global step 2278872: learning rate 0.0000
[2019-03-26 18:37:38,734] A3C_AGENT_WORKER-Thread-3 INFO:Local step 142500, global step 2278975: loss -78.3710
[2019-03-26 18:37:38,737] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 142500, global step 2278976: learning rate 0.0000
[2019-03-26 18:37:42,054] A3C_AGENT_WORKER-Thread-22 INFO:Local step 142500, global step 2280466: loss -27.0150
[2019-03-26 18:37:42,058] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 142500, global step 2280468: learning rate 0.0000
[2019-03-26 18:37:42,413] A3C_AGENT_WORKER-Thread-9 INFO:Local step 143000, global step 2280629: loss 0.0549
[2019-03-26 18:37:42,415] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 143000, global step 2280629: learning rate 0.0000
[2019-03-26 18:37:42,425] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.3913580e-11 8.4475143e-04 8.2474244e-12 9.9915528e-01 1.8567306e-17], sum to 1.0000
[2019-03-26 18:37:42,432] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3280
[2019-03-26 18:37:42,436] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.6, 62.0, 1.0, 2.0, 1.007866393103678, 1.0, 2.0, 1.007866393103678, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2819336.732213841, 2819336.732213841, 533754.4604043418], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5842800.0000, 
sim time next is 5843400.0000, 
raw observation next is [32.55, 62.16666666666667, 1.0, 2.0, 0.8877548980970035, 1.0, 2.0, 0.8877548980970035, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2483011.147169054, 2483011.147169055, 464855.7422388227], 
processed observation next is [1.0, 0.6521739130434783, 0.7417061611374406, 0.6216666666666667, 1.0, 1.0, 0.8647649374662693, 1.0, 1.0, 0.8647649374662693, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6897253186580705, 0.6897253186580709, 0.6938145406549592], 
reward next is 0.3062, 
noisyNet noise sample is [array([-1.9927932], dtype=float32), -1.5300539]. 
=============================================
[2019-03-26 18:37:44,783] A3C_AGENT_WORKER-Thread-13 INFO:Local step 143000, global step 2281691: loss 0.0584
[2019-03-26 18:37:44,785] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 143000, global step 2281692: learning rate 0.0000
[2019-03-26 18:37:44,977] A3C_AGENT_WORKER-Thread-10 INFO:Local step 143500, global step 2281777: loss -24.4757
[2019-03-26 18:37:44,981] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 143500, global step 2281778: learning rate 0.0000
[2019-03-26 18:37:46,023] A3C_AGENT_WORKER-Thread-16 INFO:Local step 142500, global step 2282246: loss -172.9558
[2019-03-26 18:37:46,025] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 142500, global step 2282247: learning rate 0.0000
[2019-03-26 18:37:47,394] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.09887607e-15 1.00000000e+00 1.13448375e-17 1.41024143e-16
 1.72492547e-25], sum to 1.0000
[2019-03-26 18:37:47,401] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4431
[2019-03-26 18:37:47,404] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.06666666666667, 89.66666666666667, 1.0, 2.0, 0.6813980085189678, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 952261.4760156533, 952261.4760156539, 216881.8717542713], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6157200.0000, 
sim time next is 6157800.0000, 
raw observation next is [27.15, 89.5, 1.0, 2.0, 0.6817961923517586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 952818.1920814232, 952818.1920814238, 216965.8095385381], 
processed observation next is [1.0, 0.2608695652173913, 0.485781990521327, 0.895, 1.0, 1.0, 0.6166219184960947, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2646717200226176, 0.26467172002261774, 0.32382956647543], 
reward next is 0.6762, 
noisyNet noise sample is [array([0.97564656], dtype=float32), 0.3495344]. 
=============================================
[2019-03-26 18:37:48,732] A3C_AGENT_WORKER-Thread-20 INFO:Local step 142500, global step 2283472: loss -135.8141
[2019-03-26 18:37:48,733] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 142500, global step 2283472: learning rate 0.0000
[2019-03-26 18:37:48,754] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.0339431e-16 1.0000000e+00 9.1188887e-19 1.9246903e-17 5.0976808e-27], sum to 1.0000
[2019-03-26 18:37:48,762] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6271
[2019-03-26 18:37:48,766] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.2, 93.66666666666667, 1.0, 2.0, 0.6639687041702164, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 927893.1840765299, 927893.1840765305, 213257.4504737729], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6675000.0000, 
sim time next is 6675600.0000, 
raw observation next is [25.3, 93.33333333333334, 1.0, 2.0, 0.5781019979394263, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 807849.2241314964, 807849.2241314964, 196731.3767457523], 
processed observation next is [1.0, 0.2608695652173913, 0.39810426540284366, 0.9333333333333335, 1.0, 1.0, 0.4916891541438871, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.224402562258749, 0.224402562258749, 0.2936289205160482], 
reward next is 0.7064, 
noisyNet noise sample is [array([1.2400385], dtype=float32), 2.475072]. 
=============================================
[2019-03-26 18:37:49,362] A3C_AGENT_WORKER-Thread-17 INFO:Local step 142500, global step 2283754: loss -304.7854
[2019-03-26 18:37:49,368] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 142500, global step 2283754: learning rate 0.0000
[2019-03-26 18:37:49,717] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.1421049e-16 1.0000000e+00 2.4169473e-19 8.0388085e-17 1.6811843e-27], sum to 1.0000
[2019-03-26 18:37:49,725] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5823
[2019-03-26 18:37:49,731] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 91.33333333333334, 1.0, 2.0, 0.5486649305677026, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 766698.5365819472, 766698.5365819478, 191572.0490867477], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5960400.0000, 
sim time next is 5961000.0000, 
raw observation next is [26.95, 91.16666666666667, 1.0, 2.0, 0.5459869711336645, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 762955.0406100419, 762955.0406100419, 191114.8963855663], 
processed observation next is [1.0, 1.0, 0.476303317535545, 0.9116666666666667, 1.0, 1.0, 0.4529963507634511, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21193195572501164, 0.21193195572501164, 0.2852461140083079], 
reward next is 0.7148, 
noisyNet noise sample is [array([0.72816414], dtype=float32), 1.3715413]. 
=============================================
[2019-03-26 18:37:49,746] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[70.147835]
 [70.12256 ]
 [70.09648 ]
 [70.069336]
 [70.020996]], R is [[70.18333435]
 [70.1955719 ]
 [70.20698547]
 [70.21762848]
 [70.22756195]].
[2019-03-26 18:37:50,924] A3C_AGENT_WORKER-Thread-18 INFO:Local step 142500, global step 2284451: loss -139.5740
[2019-03-26 18:37:50,926] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 142500, global step 2284451: learning rate 0.0000
[2019-03-26 18:37:51,734] A3C_AGENT_WORKER-Thread-12 INFO:Local step 142500, global step 2284816: loss -89.5832
[2019-03-26 18:37:51,739] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 142500, global step 2284818: learning rate 0.0000
[2019-03-26 18:37:51,803] A3C_AGENT_WORKER-Thread-21 INFO:Local step 142500, global step 2284844: loss -77.6854
[2019-03-26 18:37:51,807] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 142500, global step 2284846: learning rate 0.0000
[2019-03-26 18:37:52,335] A3C_AGENT_WORKER-Thread-19 INFO:Local step 142500, global step 2285081: loss -239.6570
[2019-03-26 18:37:52,339] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 142500, global step 2285081: learning rate 0.0000
[2019-03-26 18:37:52,798] A3C_AGENT_WORKER-Thread-11 INFO:Local step 142500, global step 2285289: loss -30.4043
[2019-03-26 18:37:52,808] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 142500, global step 2285290: learning rate 0.0000
[2019-03-26 18:37:53,411] A3C_AGENT_WORKER-Thread-14 INFO:Local step 143000, global step 2285564: loss 0.0727
[2019-03-26 18:37:53,416] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 143000, global step 2285565: learning rate 0.0000
[2019-03-26 18:37:54,017] A3C_AGENT_WORKER-Thread-2 INFO:Local step 143000, global step 2285836: loss 0.0765
[2019-03-26 18:37:54,020] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 143000, global step 2285836: learning rate 0.0000
[2019-03-26 18:37:56,302] A3C_AGENT_WORKER-Thread-15 INFO:Local step 143000, global step 2286867: loss 0.0715
[2019-03-26 18:37:56,307] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 143000, global step 2286868: learning rate 0.0000
[2019-03-26 18:37:56,368] A3C_AGENT_WORKER-Thread-3 INFO:Local step 143000, global step 2286894: loss 0.0707
[2019-03-26 18:37:56,370] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 143000, global step 2286895: learning rate 0.0000
[2019-03-26 18:37:59,929] A3C_AGENT_WORKER-Thread-22 INFO:Local step 143000, global step 2288492: loss 0.0853
[2019-03-26 18:37:59,931] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 143000, global step 2288493: learning rate 0.0000
[2019-03-26 18:38:00,390] A3C_AGENT_WORKER-Thread-9 INFO:Local step 143500, global step 2288704: loss 33.5448
[2019-03-26 18:38:00,394] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 143500, global step 2288704: learning rate 0.0000
[2019-03-26 18:38:02,583] A3C_AGENT_WORKER-Thread-10 INFO:Local step 144000, global step 2289685: loss 1.7362
[2019-03-26 18:38:02,586] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 144000, global step 2289685: learning rate 0.0000
[2019-03-26 18:38:02,695] A3C_AGENT_WORKER-Thread-13 INFO:Local step 143500, global step 2289735: loss -79.2738
[2019-03-26 18:38:02,698] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 143500, global step 2289735: learning rate 0.0000
[2019-03-26 18:38:03,601] A3C_AGENT_WORKER-Thread-16 INFO:Local step 143000, global step 2290143: loss 0.0877
[2019-03-26 18:38:03,606] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 143000, global step 2290144: learning rate 0.0000
[2019-03-26 18:38:03,743] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.1750708e-18 1.0000000e+00 4.3856825e-20 1.3017394e-17 5.5776429e-28], sum to 1.0000
[2019-03-26 18:38:03,755] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9064
[2019-03-26 18:38:03,762] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.3, 86.0, 1.0, 2.0, 0.5304955854144774, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 741300.0274749437, 741300.0274749431, 188512.1514061113], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6210000.0000, 
sim time next is 6210600.0000, 
raw observation next is [27.25, 86.16666666666667, 1.0, 2.0, 0.5296273506821226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 740086.3573434277, 740086.3573434271, 188368.3708849643], 
processed observation next is [1.0, 0.9130434782608695, 0.490521327014218, 0.8616666666666667, 1.0, 1.0, 0.43328596467725616, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2055795437065077, 0.20557954370650755, 0.2811468222163646], 
reward next is 0.7189, 
noisyNet noise sample is [array([-1.320441], dtype=float32), 1.969955]. 
=============================================
[2019-03-26 18:38:06,372] A3C_AGENT_WORKER-Thread-20 INFO:Local step 143000, global step 2291394: loss 0.0998
[2019-03-26 18:38:06,375] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 143000, global step 2291395: learning rate 0.0000
[2019-03-26 18:38:06,665] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.9070369e-16 1.0000000e+00 6.3019810e-19 4.7487403e-17 6.1036424e-26], sum to 1.0000
[2019-03-26 18:38:06,676] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3799
[2019-03-26 18:38:06,680] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.38333333333333, 91.00000000000001, 1.0, 2.0, 1.002744314557542, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1401643.011032975, 1401643.011032975, 299762.3359514407], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6487800.0000, 
sim time next is 6488400.0000, 
raw observation next is [26.36666666666667, 91.0, 1.0, 2.0, 0.8897702990469574, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1243634.649434489, 1243634.64943449, 267138.3405819759], 
processed observation next is [1.0, 0.08695652173913043, 0.4486571879936811, 0.91, 1.0, 1.0, 0.8671931313818764, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.34545406928735806, 0.3454540692873583, 0.39871394116712816], 
reward next is 0.6013, 
noisyNet noise sample is [array([-0.4090562], dtype=float32), 0.51274616]. 
=============================================
[2019-03-26 18:38:07,269] A3C_AGENT_WORKER-Thread-17 INFO:Local step 143000, global step 2291795: loss 0.0982
[2019-03-26 18:38:07,272] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 143000, global step 2291795: learning rate 0.0000
[2019-03-26 18:38:08,679] A3C_AGENT_WORKER-Thread-18 INFO:Local step 143000, global step 2292435: loss 0.0946
[2019-03-26 18:38:08,682] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 143000, global step 2292435: learning rate 0.0000
[2019-03-26 18:38:09,132] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.00047641e-16 1.00000000e+00 1.05003373e-19 3.86399680e-18
 8.45088141e-28], sum to 1.0000
[2019-03-26 18:38:09,141] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5201
[2019-03-26 18:38:09,147] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.1, 85.66666666666667, 1.0, 2.0, 0.5202028244912935, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 726912.2835005831, 726912.2835005831, 186822.1572256739], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6564000.0000, 
sim time next is 6564600.0000, 
raw observation next is [27.05, 86.0, 1.0, 2.0, 0.5203364587886706, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 727099.0830599112, 727099.0830599112, 186843.8861402845], 
processed observation next is [1.0, 1.0, 0.4810426540284361, 0.86, 1.0, 1.0, 0.4220921190224947, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20197196751664198, 0.20197196751664198, 0.2788714718511709], 
reward next is 0.7211, 
noisyNet noise sample is [array([-1.2014561], dtype=float32), 1.9791241]. 
=============================================
[2019-03-26 18:38:09,615] A3C_AGENT_WORKER-Thread-21 INFO:Local step 143000, global step 2292852: loss 0.0935
[2019-03-26 18:38:09,617] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 143000, global step 2292853: learning rate 0.0000
[2019-03-26 18:38:09,626] A3C_AGENT_WORKER-Thread-12 INFO:Local step 143000, global step 2292857: loss 0.0891
[2019-03-26 18:38:09,627] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 143000, global step 2292857: learning rate 0.0000
[2019-03-26 18:38:10,096] A3C_AGENT_WORKER-Thread-19 INFO:Local step 143000, global step 2293067: loss 0.0945
[2019-03-26 18:38:10,104] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 143000, global step 2293067: learning rate 0.0000
[2019-03-26 18:38:10,640] A3C_AGENT_WORKER-Thread-11 INFO:Local step 143000, global step 2293309: loss 0.0891
[2019-03-26 18:38:10,643] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 143000, global step 2293309: learning rate 0.0000
[2019-03-26 18:38:11,357] A3C_AGENT_WORKER-Thread-14 INFO:Local step 143500, global step 2293630: loss 59.9242
[2019-03-26 18:38:11,368] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 143500, global step 2293631: learning rate 0.0000
[2019-03-26 18:38:11,992] A3C_AGENT_WORKER-Thread-2 INFO:Local step 143500, global step 2293919: loss 17.6687
[2019-03-26 18:38:11,996] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 143500, global step 2293919: learning rate 0.0000
[2019-03-26 18:38:13,067] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.6121120e-18 1.0000000e+00 5.4272770e-21 1.4054795e-21 1.4158643e-30], sum to 1.0000
[2019-03-26 18:38:13,081] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0944
[2019-03-26 18:38:13,089] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.5, 63.0, 1.0, 2.0, 0.5382711482541161, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 752169.2333426882, 752169.2333426889, 189809.7982757424], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6352200.0000, 
sim time next is 6352800.0000, 
raw observation next is [31.33333333333333, 63.0, 1.0, 2.0, 0.5339955561636565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 746192.5087479838, 746192.5087479833, 189093.9941111217], 
processed observation next is [0.0, 0.5217391304347826, 0.6840442338072668, 0.63, 1.0, 1.0, 0.43854886284777883, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20727569687443995, 0.2072756968744398, 0.28222984195689804], 
reward next is 0.7178, 
noisyNet noise sample is [array([1.1319473], dtype=float32), -0.43723014]. 
=============================================
[2019-03-26 18:38:14,239] A3C_AGENT_WORKER-Thread-3 INFO:Local step 143500, global step 2294922: loss 24.3778
[2019-03-26 18:38:14,244] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 143500, global step 2294925: learning rate 0.0000
[2019-03-26 18:38:14,371] A3C_AGENT_WORKER-Thread-15 INFO:Local step 143500, global step 2294984: loss 21.4248
[2019-03-26 18:38:14,372] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 143500, global step 2294984: learning rate 0.0000
[2019-03-26 18:38:16,865] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.9973247e-09 6.5617990e-01 5.7486504e-09 3.4382007e-01 1.0724896e-14], sum to 1.0000
[2019-03-26 18:38:16,874] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2171
[2019-03-26 18:38:16,883] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2070832.0307697 W.
[2019-03-26 18:38:16,887] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.08333333333333, 73.66666666666667, 1.0, 2.0, 0.740516835657006, 1.0, 2.0, 0.740516835657006, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2070832.0307697, 2070832.0307697, 391947.4248911945], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6429000.0000, 
sim time next is 6429600.0000, 
raw observation next is [29.2, 73.0, 1.0, 2.0, 0.4941527265827987, 1.0, 2.0, 0.4941527265827987, 1.0, 1.0, 0.8489660395344208, 6.911200000000001, 6.9112, 170.5573041426782, 2072825.754312986, 2072825.754312985, 409476.8551329462], 
processed observation next is [1.0, 0.43478260869565216, 0.5829383886255924, 0.73, 1.0, 1.0, 0.39054545371421534, 1.0, 1.0, 0.39054545371421534, 1.0, 0.5, 0.8158122433346594, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5757849317536072, 0.575784931753607, 0.6111594852730541], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.672825], dtype=float32), -0.65999]. 
=============================================
[2019-03-26 18:38:17,771] A3C_AGENT_WORKER-Thread-22 INFO:Local step 143500, global step 2296520: loss 15.7306
[2019-03-26 18:38:17,774] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 143500, global step 2296520: learning rate 0.0000
[2019-03-26 18:38:17,992] A3C_AGENT_WORKER-Thread-9 INFO:Local step 144000, global step 2296619: loss 1.8306
[2019-03-26 18:38:17,995] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 144000, global step 2296620: learning rate 0.0000
[2019-03-26 18:38:19,609] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.5240789e-09 1.1136120e-01 4.9498283e-10 8.8863879e-01 8.5135800e-16], sum to 1.0000
[2019-03-26 18:38:19,617] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3509
[2019-03-26 18:38:19,620] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.4, 58.0, 1.0, 2.0, 0.7785861570990139, 1.0, 1.0, 0.7785861570990139, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2177399.890148565, 2177399.890148565, 409571.572134561], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6534000.0000, 
sim time next is 6534600.0000, 
raw observation next is [31.26666666666667, 58.5, 1.0, 2.0, 0.7493143970235975, 1.0, 2.0, 0.7493143970235975, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2095458.196657986, 2095458.196657987, 395941.1910411631], 
processed observation next is [1.0, 0.6521739130434783, 0.6808846761453398, 0.585, 1.0, 1.0, 0.6979691530404789, 1.0, 1.0, 0.6979691530404789, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.582071721293885, 0.5820717212938853, 0.5909570015539748], 
reward next is 0.4090, 
noisyNet noise sample is [array([-1.063294], dtype=float32), 1.0494772]. 
=============================================
[2019-03-26 18:38:20,315] A3C_AGENT_WORKER-Thread-13 INFO:Local step 144000, global step 2297667: loss 1.8290
[2019-03-26 18:38:20,318] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 144000, global step 2297669: learning rate 0.0000
[2019-03-26 18:38:20,529] A3C_AGENT_WORKER-Thread-10 INFO:Local step 144500, global step 2297762: loss 5.9690
[2019-03-26 18:38:20,532] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 144500, global step 2297763: learning rate 0.0000
[2019-03-26 18:38:21,281] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.5848425e-16 1.0000000e+00 5.5054572e-19 2.9034003e-17 3.5346989e-27], sum to 1.0000
[2019-03-26 18:38:21,289] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9313
[2019-03-26 18:38:21,294] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.68333333333334, 94.83333333333334, 1.0, 2.0, 0.5503152292301223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 769005.48115764, 769005.4811576394, 191850.0694632815], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6671400.0000, 
sim time next is 6672000.0000, 
raw observation next is [24.76666666666667, 94.66666666666667, 1.0, 2.0, 0.514986512681467, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 719620.7323303864, 719620.7323303871, 185975.4179810555], 
processed observation next is [1.0, 0.21739130434782608, 0.3728278041074251, 0.9466666666666668, 1.0, 1.0, 0.41564640082104454, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19989464786955177, 0.19989464786955197, 0.27757525071799327], 
reward next is 0.7224, 
noisyNet noise sample is [array([-1.2953597], dtype=float32), 0.5935506]. 
=============================================
[2019-03-26 18:38:21,305] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[67.32391 ]
 [67.271324]
 [67.3358  ]
 [67.38635 ]
 [67.39223 ]], R is [[67.42288208]
 [67.46231079]
 [67.49760437]
 [67.53652954]
 [67.57238007]].
[2019-03-26 18:38:21,524] A3C_AGENT_WORKER-Thread-16 INFO:Local step 143500, global step 2298202: loss 32.7106
[2019-03-26 18:38:21,530] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 143500, global step 2298203: learning rate 0.0000
[2019-03-26 18:38:24,213] A3C_AGENT_WORKER-Thread-20 INFO:Local step 143500, global step 2299414: loss 27.6558
[2019-03-26 18:38:24,219] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 143500, global step 2299414: learning rate 0.0000
[2019-03-26 18:38:25,143] A3C_AGENT_WORKER-Thread-17 INFO:Local step 143500, global step 2299838: loss 13.7147
[2019-03-26 18:38:25,146] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 143500, global step 2299838: learning rate 0.0000
[2019-03-26 18:38:25,543] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-26 18:38:25,545] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 18:38:25,546] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:38:25,547] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 18:38:25,548] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 18:38:25,548] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:38:25,549] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 18:38:25,550] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 18:38:25,550] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:38:25,552] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:38:25,553] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:38:25,580] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run93
[2019-03-26 18:38:25,608] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run93
[2019-03-26 18:38:25,609] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run93
[2019-03-26 18:38:25,664] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run93
[2019-03-26 18:38:25,685] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run93
[2019-03-26 18:38:29,909] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.11179609], dtype=float32), 0.09572267]
[2019-03-26 18:38:29,911] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [21.8, 87.0, 1.0, 2.0, 0.3115171818356229, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 493323.9484018233, 493323.9484018227, 166543.1612208481]
[2019-03-26 18:38:29,912] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 18:38:29,915] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.6756664e-18 1.0000000e+00 3.4826964e-22 2.2275005e-23 1.6225836e-31], sampled 0.249586273125887
[2019-03-26 18:38:48,400] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.11179609], dtype=float32), 0.09572267]
[2019-03-26 18:38:48,401] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.68432523, 69.9364431, 1.0, 2.0, 0.4540923246650478, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 648041.0617051099, 648041.0617051093, 178456.9613565781]
[2019-03-26 18:38:48,402] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:38:48,405] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [6.2226031e-18 1.0000000e+00 2.2063777e-21 3.3531370e-22 1.7504012e-30], sampled 0.39341379803340826
[2019-03-26 18:38:51,687] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.11179609], dtype=float32), 0.09572267]
[2019-03-26 18:38:51,690] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.06666666666667, 90.66666666666667, 1.0, 2.0, 0.5102235314160604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 712962.9068680446, 712962.9068680452, 185213.433450836]
[2019-03-26 18:38:51,692] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 18:38:51,698] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.8039894e-18 1.0000000e+00 1.8894334e-21 3.4893071e-21 1.1240815e-30], sampled 0.27221254273754014
[2019-03-26 18:38:51,887] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.11179609], dtype=float32), 0.09572267]
[2019-03-26 18:38:51,889] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.49313612666667, 97.77025332999999, 1.0, 2.0, 0.4410847244289561, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 632882.1149193702, 632882.1149193696, 177011.4014886663]
[2019-03-26 18:38:51,891] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:38:51,893] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.2365167e-17 1.0000000e+00 5.9995697e-21 1.0367034e-21 5.9442985e-30], sampled 0.6782262026346315
[2019-03-26 18:39:11,254] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.11179609], dtype=float32), 0.09572267]
[2019-03-26 18:39:11,255] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.0, 100.0, 1.0, 2.0, 0.6208827562282309, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 934995.076949588, 934995.0769495873, 213121.615267202]
[2019-03-26 18:39:11,256] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 18:39:11,258] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.1800005e-17 1.0000000e+00 6.2551988e-21 2.1198785e-21 7.4441119e-30], sampled 0.22697929547689288
[2019-03-26 18:39:25,811] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.11179609], dtype=float32), 0.09572267]
[2019-03-26 18:39:25,813] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.85, 65.5, 1.0, 2.0, 1.03701508929766, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912800943252, 1449579.647814794, 1449579.647814794, 310404.5287938757]
[2019-03-26 18:39:25,814] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:39:25,817] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.2344773e-15 1.0000000e+00 1.0488898e-17 2.1213189e-13 3.4310504e-26], sampled 0.5279748551206745
[2019-03-26 18:39:36,941] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.11179609], dtype=float32), 0.09572267]
[2019-03-26 18:39:36,943] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.0, 66.0, 1.0, 2.0, 0.7746232417681806, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.990044178999291, 6.9112, 168.9124238001594, 1979558.262050888, 1923623.664266211, 402263.7775812225]
[2019-03-26 18:39:36,945] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 18:39:36,948] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0258432e-10 9.9921417e-01 3.3359371e-11 7.8584900e-04 1.0360048e-18], sampled 0.9581804456689004
[2019-03-26 18:39:36,949] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1979558.262050888 W.
[2019-03-26 18:39:41,397] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.11179609], dtype=float32), 0.09572267]
[2019-03-26 18:39:41,398] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [30.5, 77.66666666666667, 1.0, 2.0, 1.004425631324443, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1403994.721485584, 1403994.721485584, 300281.9053895543]
[2019-03-26 18:39:41,400] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:39:41,403] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.2542903e-16 1.0000000e+00 4.8651331e-19 4.0147363e-17 3.9811946e-27], sampled 0.6907585618624469
[2019-03-26 18:40:01,000] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.11179609], dtype=float32), 0.09572267]
[2019-03-26 18:40:01,002] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.73333333333334, 87.0, 1.0, 2.0, 0.6559225515875734, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 916643.8706559733, 916643.8706559733, 211617.5633366281]
[2019-03-26 18:40:01,003] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 18:40:01,006] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.3489985e-17 1.0000000e+00 5.9899457e-20 1.4134007e-19 1.2228828e-28], sampled 0.126157581088855
[2019-03-26 18:40:18,544] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8279.1710 2925055662.9322 1266.0000
[2019-03-26 18:40:19,438] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8515.5496 2840505865.7589 1084.0000
[2019-03-26 18:40:19,694] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8037.4630 3002322218.1972 1628.0000
[2019-03-26 18:40:19,705] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.6104 2778698479.2238 918.0000
[2019-03-26 18:40:19,728] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7942.0262 3157640098.8707 1599.0000
[2019-03-26 18:40:20,746] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 2300000, evaluation results [2300000.0, 7942.026231640271, 3157640098.87068, 1599.0, 8279.170971850497, 2925055662.932179, 1266.0, 8661.610448269863, 2778698479.22379, 918.0, 8037.463003232788, 3002322218.197239, 1628.0, 8515.54964888008, 2840505865.758943, 1084.0]
[2019-03-26 18:40:21,646] A3C_AGENT_WORKER-Thread-18 INFO:Local step 143500, global step 2300405: loss 27.1631
[2019-03-26 18:40:21,648] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 143500, global step 2300405: learning rate 0.0000
[2019-03-26 18:40:22,724] A3C_AGENT_WORKER-Thread-12 INFO:Local step 143500, global step 2300891: loss 48.1419
[2019-03-26 18:40:22,725] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 143500, global step 2300891: learning rate 0.0000
[2019-03-26 18:40:22,750] A3C_AGENT_WORKER-Thread-21 INFO:Local step 143500, global step 2300901: loss 40.0320
[2019-03-26 18:40:22,752] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 143500, global step 2300901: learning rate 0.0000
[2019-03-26 18:40:23,056] A3C_AGENT_WORKER-Thread-19 INFO:Local step 143500, global step 2301036: loss 21.9484
[2019-03-26 18:40:23,058] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 143500, global step 2301036: learning rate 0.0000
[2019-03-26 18:40:23,655] A3C_AGENT_WORKER-Thread-11 INFO:Local step 143500, global step 2301309: loss -18.8850
[2019-03-26 18:40:23,660] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 143500, global step 2301309: learning rate 0.0000
[2019-03-26 18:40:24,217] A3C_AGENT_WORKER-Thread-14 INFO:Local step 144000, global step 2301562: loss 1.9691
[2019-03-26 18:40:24,218] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 144000, global step 2301562: learning rate 0.0000
[2019-03-26 18:40:24,797] A3C_AGENT_WORKER-Thread-2 INFO:Local step 144000, global step 2301824: loss 1.9952
[2019-03-26 18:40:24,799] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 144000, global step 2301824: learning rate 0.0000
[2019-03-26 18:40:24,901] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.4991398e-16 1.0000000e+00 4.1622896e-19 9.3153640e-18 1.3488922e-27], sum to 1.0000
[2019-03-26 18:40:24,910] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0814
[2019-03-26 18:40:24,917] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.55, 82.33333333333334, 1.0, 2.0, 0.3224284864050937, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 508826.4533915703, 508826.4533915709, 167671.5322751641], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6745800.0000, 
sim time next is 6746400.0000, 
raw observation next is [22.4, 83.0, 1.0, 2.0, 0.320177754526889, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 505965.5815278277, 505965.5815278277, 167467.7537844985], 
processed observation next is [1.0, 0.08695652173913043, 0.2606635071090047, 0.83, 1.0, 1.0, 0.18093705364685422, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14054599486884103, 0.14054599486884103, 0.249951871320147], 
reward next is 0.7500, 
noisyNet noise sample is [array([0.25421825], dtype=float32), -0.0988714]. 
=============================================
[2019-03-26 18:40:25,011] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.5969841e-18 1.0000000e+00 5.4955088e-20 4.0282649e-18 1.0674722e-28], sum to 1.0000
[2019-03-26 18:40:25,018] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6672
[2019-03-26 18:40:25,021] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.43333333333333, 87.0, 1.0, 2.0, 0.5050167554446137, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 705684.7807713365, 705684.7807713359, 184385.8573360562], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6648600.0000, 
sim time next is 6649200.0000, 
raw observation next is [26.4, 87.0, 1.0, 2.0, 0.5043772921234793, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 704790.9307557036, 704790.9307557043, 184284.7388195243], 
processed observation next is [1.0, 1.0, 0.45023696682464454, 0.87, 1.0, 1.0, 0.4028642073776858, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.195775258543251, 0.1957752585432512, 0.27505184898436463], 
reward next is 0.7249, 
noisyNet noise sample is [array([-0.00649127], dtype=float32), -0.1503902]. 
=============================================
[2019-03-26 18:40:27,049] A3C_AGENT_WORKER-Thread-3 INFO:Local step 144000, global step 2302835: loss 1.9910
[2019-03-26 18:40:27,051] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 144000, global step 2302836: learning rate 0.0000
[2019-03-26 18:40:27,207] A3C_AGENT_WORKER-Thread-15 INFO:Local step 144000, global step 2302911: loss 2.0159
[2019-03-26 18:40:27,216] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 144000, global step 2302913: learning rate 0.0000
[2019-03-26 18:40:30,248] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.2900208e-17 1.0000000e+00 3.2516509e-19 6.6912526e-18 2.0784576e-27], sum to 1.0000
[2019-03-26 18:40:30,258] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6933
[2019-03-26 18:40:30,261] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.06666666666667, 84.33333333333333, 1.0, 2.0, 0.7052206546148992, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 985569.34343799, 985569.34343799, 221977.3092704298], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7199400.0000, 
sim time next is 7200000.0000, 
raw observation next is [28.2, 84.0, 1.0, 2.0, 0.6548218342147747, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 915104.9686728433, 915104.9686728439, 211397.2321037971], 
processed observation next is [1.0, 0.34782608695652173, 0.5355450236966824, 0.84, 1.0, 1.0, 0.5841226918250297, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2541958246313454, 0.25419582463134555, 0.315518256871339], 
reward next is 0.6845, 
noisyNet noise sample is [array([-1.1478353], dtype=float32), -1.1277754]. 
=============================================
[2019-03-26 18:40:30,276] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[69.185585]
 [69.31232 ]
 [69.42691 ]
 [69.38698 ]
 [69.28764 ]], R is [[69.26346588]
 [69.23952484]
 [69.22358704]
 [69.22440338]
 [69.22618103]].
[2019-03-26 18:40:30,500] A3C_AGENT_WORKER-Thread-22 INFO:Local step 144000, global step 2304390: loss 2.0471
[2019-03-26 18:40:30,501] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 144000, global step 2304390: learning rate 0.0000
[2019-03-26 18:40:31,112] A3C_AGENT_WORKER-Thread-9 INFO:Local step 144500, global step 2304661: loss -41.0732
[2019-03-26 18:40:31,115] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 144500, global step 2304661: learning rate 0.0000
[2019-03-26 18:40:33,226] A3C_AGENT_WORKER-Thread-10 INFO:Local step 145000, global step 2305615: loss 0.0057
[2019-03-26 18:40:33,228] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 145000, global step 2305615: learning rate 0.0000
[2019-03-26 18:40:33,317] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.1255809e-18 1.0000000e+00 8.4707243e-22 2.4169989e-22 5.6233075e-32], sum to 1.0000
[2019-03-26 18:40:33,325] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9931
[2019-03-26 18:40:33,330] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.65, 91.66666666666667, 1.0, 2.0, 0.4041958767938847, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 595491.0337763424, 595491.0337763424, 173894.3569860906], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7512600.0000, 
sim time next is 7513200.0000, 
raw observation next is [23.6, 92.0, 1.0, 2.0, 0.403860478297237, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 595147.3893444547, 595147.3893444554, 173866.9479302722], 
processed observation next is [0.0, 1.0, 0.3175355450236968, 0.92, 1.0, 1.0, 0.2817596124063096, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16531871926234853, 0.16531871926234873, 0.25950290735861525], 
reward next is 0.7405, 
noisyNet noise sample is [array([1.4396834], dtype=float32), -0.79620147]. 
=============================================
[2019-03-26 18:40:33,394] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.8776546e-16 1.0000000e+00 1.9474502e-19 1.3192159e-17 1.5560806e-28], sum to 1.0000
[2019-03-26 18:40:33,404] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2539
[2019-03-26 18:40:33,413] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.95, 55.5, 1.0, 2.0, 0.3219236388233854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 507651.7098080955, 507651.709808095, 167574.4371042627], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6809400.0000, 
sim time next is 6810000.0000, 
raw observation next is [26.8, 56.0, 1.0, 2.0, 0.3208807839871262, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 506548.4462990309, 506548.4462990315, 167501.6409878361], 
processed observation next is [1.0, 0.8260869565217391, 0.4691943127962086, 0.56, 1.0, 1.0, 0.18178407709292316, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1407079017497308, 0.14070790174973097, 0.25000244923557624], 
reward next is 0.7500, 
noisyNet noise sample is [array([0.3359132], dtype=float32), -0.7055024]. 
=============================================
[2019-03-26 18:40:33,434] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[71.244804]
 [71.090614]
 [70.93515 ]
 [70.75428 ]
 [70.663956]], R is [[71.44007874]
 [71.47556305]
 [71.51067352]
 [71.5454483 ]
 [71.57981873]].
[2019-03-26 18:40:33,631] A3C_AGENT_WORKER-Thread-13 INFO:Local step 144500, global step 2305793: loss 29.2688
[2019-03-26 18:40:33,635] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 144500, global step 2305794: learning rate 0.0000
[2019-03-26 18:40:33,926] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.9636924e-17 1.0000000e+00 2.7368252e-21 5.7633698e-22 2.3632522e-30], sum to 1.0000
[2019-03-26 18:40:33,935] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4147
[2019-03-26 18:40:33,939] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 81.33333333333334, 1.0, 2.0, 0.3348032250494946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 523490.193815575, 523490.1938155757, 168702.180518861], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6837600.0000, 
sim time next is 6838200.0000, 
raw observation next is [23.1, 81.5, 1.0, 2.0, 0.3354535179623437, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 524204.8813087184, 524204.881308719, 168751.2134081709], 
processed observation next is [0.0, 0.13043478260869565, 0.2938388625592418, 0.815, 1.0, 1.0, 0.19934158790643816, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14561246703019956, 0.14561246703019973, 0.2518674826987625], 
reward next is 0.7481, 
noisyNet noise sample is [array([0.6186917], dtype=float32), -1.3532958]. 
=============================================
[2019-03-26 18:40:34,582] A3C_AGENT_WORKER-Thread-16 INFO:Local step 144000, global step 2306213: loss 2.0348
[2019-03-26 18:40:34,585] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 144000, global step 2306214: learning rate 0.0000
[2019-03-26 18:40:37,287] A3C_AGENT_WORKER-Thread-20 INFO:Local step 144000, global step 2307431: loss 2.0992
[2019-03-26 18:40:37,290] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 144000, global step 2307431: learning rate 0.0000
[2019-03-26 18:40:37,372] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.4359737e-15 1.0000000e+00 3.2259806e-17 3.2255931e-13 5.4727960e-25], sum to 1.0000
[2019-03-26 18:40:37,380] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7255
[2019-03-26 18:40:37,386] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.5, 63.0, 1.0, 2.0, 0.8965846925796068, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1345635.751955853, 1345635.751955853, 282170.7008805568], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7317000.0000, 
sim time next is 7317600.0000, 
raw observation next is [27.46666666666667, 63.33333333333333, 1.0, 2.0, 0.9239121924343107, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1385454.020382266, 1385454.020382266, 290211.8001244636], 
processed observation next is [1.0, 0.6956521739130435, 0.500789889415482, 0.6333333333333333, 1.0, 1.0, 0.9083279426919405, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.38484833899507387, 0.38484833899507387, 0.4331519404842741], 
reward next is 0.5668, 
noisyNet noise sample is [array([-1.0777149], dtype=float32), 0.20509173]. 
=============================================
[2019-03-26 18:40:38,237] A3C_AGENT_WORKER-Thread-17 INFO:Local step 144000, global step 2307855: loss 2.0747
[2019-03-26 18:40:38,241] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 144000, global step 2307858: learning rate 0.0000
[2019-03-26 18:40:39,394] A3C_AGENT_WORKER-Thread-18 INFO:Local step 144000, global step 2308380: loss 2.0982
[2019-03-26 18:40:39,396] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 144000, global step 2308380: learning rate 0.0000
[2019-03-26 18:40:40,079] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.8934426e-16 1.0000000e+00 3.5363302e-20 2.4427429e-19 2.8005737e-28], sum to 1.0000
[2019-03-26 18:40:40,086] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2824
[2019-03-26 18:40:40,101] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 89.5, 1.0, 2.0, 0.4182794883963654, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 634819.724282945, 634819.7242829445, 178037.3241111551], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7363800.0000, 
sim time next is 7364400.0000, 
raw observation next is [22.8, 89.66666666666667, 1.0, 2.0, 0.4051620648402793, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 618301.9594440827, 618301.9594440827, 176551.4574145646], 
processed observation next is [1.0, 0.21739130434782608, 0.2796208530805688, 0.8966666666666667, 1.0, 1.0, 0.2833277889641919, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17175054429002298, 0.17175054429002298, 0.26350963793218596], 
reward next is 0.7365, 
noisyNet noise sample is [array([-1.0209554], dtype=float32), 1.1639693]. 
=============================================
[2019-03-26 18:40:40,497] A3C_AGENT_WORKER-Thread-21 INFO:Local step 144000, global step 2308880: loss 2.0545
[2019-03-26 18:40:40,499] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 144000, global step 2308881: learning rate 0.0000
[2019-03-26 18:40:40,541] A3C_AGENT_WORKER-Thread-12 INFO:Local step 144000, global step 2308895: loss 2.0476
[2019-03-26 18:40:40,542] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 144000, global step 2308895: learning rate 0.0000
[2019-03-26 18:40:40,830] A3C_AGENT_WORKER-Thread-19 INFO:Local step 144000, global step 2309029: loss 2.0216
[2019-03-26 18:40:40,833] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 144000, global step 2309030: learning rate 0.0000
[2019-03-26 18:40:41,380] A3C_AGENT_WORKER-Thread-11 INFO:Local step 144000, global step 2309274: loss 2.0133
[2019-03-26 18:40:41,384] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 144000, global step 2309275: learning rate 0.0000
[2019-03-26 18:40:42,240] A3C_AGENT_WORKER-Thread-14 INFO:Local step 144500, global step 2309664: loss 34.8649
[2019-03-26 18:40:42,241] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 144500, global step 2309665: learning rate 0.0000
[2019-03-26 18:40:42,873] A3C_AGENT_WORKER-Thread-2 INFO:Local step 144500, global step 2309948: loss 11.5215
[2019-03-26 18:40:42,875] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 144500, global step 2309948: learning rate 0.0000
[2019-03-26 18:40:44,542] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.7442693e-16 1.0000000e+00 1.6168667e-18 1.2145268e-16 3.1682058e-27], sum to 1.0000
[2019-03-26 18:40:44,547] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9848
[2019-03-26 18:40:44,552] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.73333333333333, 91.16666666666667, 1.0, 2.0, 0.5776088857498417, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 924981.165246668, 924981.165246668, 209820.0580557807], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7397400.0000, 
sim time next is 7398000.0000, 
raw observation next is [20.7, 91.0, 1.0, 2.0, 0.5077998920721613, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 814044.519756606, 814044.519756606, 196386.7965715397], 
processed observation next is [1.0, 0.6521739130434783, 0.18009478672985785, 0.91, 1.0, 1.0, 0.40698782177368825, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22612347771016833, 0.22612347771016833, 0.2931146217485667], 
reward next is 0.7069, 
noisyNet noise sample is [array([1.9217781], dtype=float32), 0.17318147]. 
=============================================
[2019-03-26 18:40:44,575] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[69.23887]
 [69.25275]
 [69.22354]
 [68.90447]
 [68.48502]], R is [[69.51602173]
 [69.50769806]
 [69.5058136 ]
 [69.52381897]
 [69.5398941 ]].
[2019-03-26 18:40:45,091] A3C_AGENT_WORKER-Thread-3 INFO:Local step 144500, global step 2310928: loss -4.3066
[2019-03-26 18:40:45,094] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 144500, global step 2310929: learning rate 0.0000
[2019-03-26 18:40:45,396] A3C_AGENT_WORKER-Thread-15 INFO:Local step 144500, global step 2311065: loss -14.8645
[2019-03-26 18:40:45,398] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 144500, global step 2311065: learning rate 0.0000
[2019-03-26 18:40:48,372] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.2091543e-10 9.9002200e-01 4.8853277e-10 9.9779535e-03 9.5912940e-18], sum to 1.0000
[2019-03-26 18:40:48,381] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7700
[2019-03-26 18:40:48,387] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.5, 48.33333333333334, 1.0, 2.0, 0.5649184064001237, 1.0, 2.0, 0.5649184064001237, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1609436.026677088, 1609436.026677088, 325251.2243820241], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7044000.0000, 
sim time next is 7044600.0000, 
raw observation next is [31.6, 47.66666666666667, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.661824832102775, 6.9112, 168.9087841802647, 2040480.138915599, 1507974.20229842, 319879.2167300665], 
processed observation next is [1.0, 0.5217391304347826, 0.6966824644549764, 0.47666666666666674, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.07506248321027753, 0.0, 0.8294194571010851, 0.5668000385876664, 0.4188817228606722, 0.4774316667612933], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.21657985], dtype=float32), 0.7164042]. 
=============================================
[2019-03-26 18:40:48,496] A3C_AGENT_WORKER-Thread-22 INFO:Local step 144500, global step 2312465: loss -12.1165
[2019-03-26 18:40:48,499] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 144500, global step 2312465: learning rate 0.0000
[2019-03-26 18:40:48,652] A3C_AGENT_WORKER-Thread-9 INFO:Local step 145000, global step 2312533: loss 0.0034
[2019-03-26 18:40:48,655] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 145000, global step 2312533: learning rate 0.0000
[2019-03-26 18:40:51,232] A3C_AGENT_WORKER-Thread-13 INFO:Local step 145000, global step 2313692: loss 0.0036
[2019-03-26 18:40:51,234] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 145000, global step 2313693: learning rate 0.0000
[2019-03-26 18:40:51,259] A3C_AGENT_WORKER-Thread-10 INFO:Local step 145500, global step 2313702: loss 223.0082
[2019-03-26 18:40:51,262] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 145500, global step 2313702: learning rate 0.0000
[2019-03-26 18:40:52,536] A3C_AGENT_WORKER-Thread-16 INFO:Local step 144500, global step 2314279: loss 5.5734
[2019-03-26 18:40:52,541] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 144500, global step 2314280: learning rate 0.0000
[2019-03-26 18:40:55,345] A3C_AGENT_WORKER-Thread-20 INFO:Local step 144500, global step 2315539: loss -26.7200
[2019-03-26 18:40:55,348] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 144500, global step 2315540: learning rate 0.0000
[2019-03-26 18:40:55,587] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.1354405e-15 1.0000000e+00 2.4226636e-17 4.9091639e-13 9.3919690e-26], sum to 1.0000
[2019-03-26 18:40:55,594] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9069
[2019-03-26 18:40:55,601] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.1, 84.66666666666667, 1.0, 2.0, 0.4787848660057578, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 669018.1273309673, 669018.1273309673, 180338.8082001139], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7150800.0000, 
sim time next is 7151400.0000, 
raw observation next is [26.1, 84.5, 1.0, 2.0, 0.4783634998231688, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 668429.1565326115, 668429.1565326108, 180275.4326957307], 
processed observation next is [1.0, 0.782608695652174, 0.4360189573459717, 0.845, 1.0, 1.0, 0.37152228894357686, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1856747657035032, 0.185674765703503, 0.2690678099936279], 
reward next is 0.7309, 
noisyNet noise sample is [array([-0.07346339], dtype=float32), -0.6377143]. 
=============================================
[2019-03-26 18:40:56,073] A3C_AGENT_WORKER-Thread-17 INFO:Local step 144500, global step 2315865: loss -81.8018
[2019-03-26 18:40:56,079] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 144500, global step 2315866: learning rate 0.0000
[2019-03-26 18:40:57,347] A3C_AGENT_WORKER-Thread-18 INFO:Local step 144500, global step 2316442: loss -127.8161
[2019-03-26 18:40:57,350] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 144500, global step 2316444: learning rate 0.0000
[2019-03-26 18:40:58,550] A3C_AGENT_WORKER-Thread-21 INFO:Local step 144500, global step 2316979: loss -60.3427
[2019-03-26 18:40:58,551] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 144500, global step 2316979: learning rate 0.0000
[2019-03-26 18:40:58,600] A3C_AGENT_WORKER-Thread-19 INFO:Local step 144500, global step 2317001: loss -22.2789
[2019-03-26 18:40:58,605] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 144500, global step 2317003: learning rate 0.0000
[2019-03-26 18:40:58,621] A3C_AGENT_WORKER-Thread-12 INFO:Local step 144500, global step 2317011: loss 4.6315
[2019-03-26 18:40:58,623] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 144500, global step 2317012: learning rate 0.0000
[2019-03-26 18:40:58,920] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.8317972e-17 1.0000000e+00 3.5713725e-21 3.7817436e-22 3.6258121e-30], sum to 1.0000
[2019-03-26 18:40:58,930] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3332
[2019-03-26 18:40:58,934] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.3, 93.0, 1.0, 2.0, 0.3175647437520359, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 500191.5668919739, 500191.5668919745, 166997.5080082818], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7443000.0000, 
sim time next is 7443600.0000, 
raw observation next is [21.3, 93.33333333333334, 1.0, 2.0, 0.3195257311968136, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 502784.2935226548, 502784.2935226548, 167181.3515493146], 
processed observation next is [0.0, 0.13043478260869565, 0.2085308056872039, 0.9333333333333335, 1.0, 1.0, 0.18015148336965495, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.139662303756293, 0.139662303756293, 0.2495244052974845], 
reward next is 0.7505, 
noisyNet noise sample is [array([-0.9253337], dtype=float32), -0.03640631]. 
=============================================
[2019-03-26 18:40:59,282] A3C_AGENT_WORKER-Thread-11 INFO:Local step 144500, global step 2317296: loss -32.2539
[2019-03-26 18:40:59,285] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 144500, global step 2317298: learning rate 0.0000
[2019-03-26 18:40:59,479] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.4640857e-17 1.0000000e+00 7.4102077e-20 6.4680896e-18 1.0435798e-28], sum to 1.0000
[2019-03-26 18:40:59,489] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6899
[2019-03-26 18:40:59,494] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.53333333333333, 92.0, 1.0, 2.0, 0.3660153972335382, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 558996.2606867763, 558996.2606867768, 171270.7980575553], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7245600.0000, 
sim time next is 7246200.0000, 
raw observation next is [22.51666666666667, 92.0, 1.0, 2.0, 0.3657264946643853, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 558837.8636058999, 558837.8636058999, 171265.5716764953], 
processed observation next is [1.0, 0.8695652173913043, 0.2661927330173777, 0.92, 1.0, 1.0, 0.2358150538125124, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15523273989052774, 0.15523273989052774, 0.2556202562335751], 
reward next is 0.7444, 
noisyNet noise sample is [array([1.1581595], dtype=float32), -1.1941178]. 
=============================================
[2019-03-26 18:40:59,804] A3C_AGENT_WORKER-Thread-14 INFO:Local step 145000, global step 2317534: loss 0.0071
[2019-03-26 18:40:59,807] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 145000, global step 2317534: learning rate 0.0000
[2019-03-26 18:41:00,331] A3C_AGENT_WORKER-Thread-2 INFO:Local step 145000, global step 2317773: loss 0.0074
[2019-03-26 18:41:00,333] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 145000, global step 2317774: learning rate 0.0000
[2019-03-26 18:41:00,605] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:41:00,606] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:41:00,679] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run12
[2019-03-26 18:41:02,198] A3C_AGENT_WORKER-Thread-3 INFO:Local step 145000, global step 2318735: loss 0.0072
[2019-03-26 18:41:02,202] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 145000, global step 2318735: learning rate 0.0000
[2019-03-26 18:41:02,464] A3C_AGENT_WORKER-Thread-15 INFO:Local step 145000, global step 2318852: loss 0.0078
[2019-03-26 18:41:02,469] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 145000, global step 2318852: learning rate 0.0000
[2019-03-26 18:41:05,627] A3C_AGENT_WORKER-Thread-22 INFO:Local step 145000, global step 2320270: loss 0.0051
[2019-03-26 18:41:05,630] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 145000, global step 2320272: learning rate 0.0000
[2019-03-26 18:41:05,636] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.924772e-16 1.000000e+00 1.161276e-18 9.084941e-17 7.023370e-27], sum to 1.0000
[2019-03-26 18:41:05,646] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8355
[2019-03-26 18:41:05,652] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666666, 93.0, 1.0, 2.0, 0.6971100003796143, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1101304.569605126, 1101304.569605127, 235486.3110821837], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7382400.0000, 
sim time next is 7383000.0000, 
raw observation next is [21.23333333333333, 93.0, 1.0, 2.0, 0.6994920625006624, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1103318.787937988, 1103318.787937988, 235905.5648011823], 
processed observation next is [1.0, 0.43478260869565216, 0.2053712480252764, 0.93, 1.0, 1.0, 0.6379422439767017, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3064774410938856, 0.3064774410938856, 0.3520978579122124], 
reward next is 0.6479, 
noisyNet noise sample is [array([1.2515986], dtype=float32), -0.4336064]. 
=============================================
[2019-03-26 18:41:05,667] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[69.93608 ]
 [70.127335]
 [70.37908 ]
 [70.626396]
 [70.68575 ]], R is [[69.73720551]
 [69.68836212]
 [69.6402359 ]
 [69.60174561]
 [69.58492279]].
[2019-03-26 18:41:06,156] A3C_AGENT_WORKER-Thread-9 INFO:Local step 145500, global step 2320507: loss -118.2278
[2019-03-26 18:41:06,157] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 145500, global step 2320507: learning rate 0.0000
[2019-03-26 18:41:08,834] A3C_AGENT_WORKER-Thread-13 INFO:Local step 145500, global step 2321713: loss 20.0470
[2019-03-26 18:41:08,837] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 145500, global step 2321713: learning rate 0.0000
[2019-03-26 18:41:09,157] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.3150380e-10 2.2011054e-01 6.5142641e-10 7.7988946e-01 1.0078779e-16], sum to 1.0000
[2019-03-26 18:41:09,166] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9056
[2019-03-26 18:41:09,172] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.06666666666667, 71.33333333333334, 1.0, 2.0, 0.7528780176193752, 1.0, 2.0, 0.7528780176193752, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2105433.657544455, 2105433.657544455, 397581.9659334054], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7816800.0000, 
sim time next is 7817400.0000, 
raw observation next is [30.3, 71.0, 1.0, 2.0, 0.7690602648051506, 1.0, 2.0, 0.7690602648051506, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2150732.96323883, 2150732.96323883, 405089.8312029189], 
processed observation next is [1.0, 0.4782608695652174, 0.6350710900473934, 0.71, 1.0, 1.0, 0.7217593551869284, 1.0, 1.0, 0.7217593551869284, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5974258231218973, 0.5974258231218973, 0.6046116883625655], 
reward next is 0.3954, 
noisyNet noise sample is [array([0.7441963], dtype=float32), -1.0080382]. 
=============================================
[2019-03-26 18:41:09,775] A3C_AGENT_WORKER-Thread-16 INFO:Local step 145000, global step 2322137: loss 0.0063
[2019-03-26 18:41:09,777] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 145000, global step 2322137: learning rate 0.0000
[2019-03-26 18:41:09,941] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.4236028e-16 1.0000000e+00 1.0769504e-18 4.0828177e-16 8.1449835e-27], sum to 1.0000
[2019-03-26 18:41:09,951] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3171
[2019-03-26 18:41:09,956] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.65, 90.5, 1.0, 2.0, 0.6322900661969493, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1015932.425856937, 1015932.425856936, 221778.3248422539], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7399800.0000, 
sim time next is 7400400.0000, 
raw observation next is [20.63333333333333, 90.33333333333334, 1.0, 2.0, 0.6114700420070801, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 983143.4715254193, 983143.4715254187, 217231.662735039], 
processed observation next is [1.0, 0.6521739130434783, 0.17693522906793036, 0.9033333333333334, 1.0, 1.0, 0.5318916168760001, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2730954087570609, 0.27309540875706073, 0.32422636229110297], 
reward next is 0.6758, 
noisyNet noise sample is [array([0.03418669], dtype=float32), -0.71708274]. 
=============================================
[2019-03-26 18:41:11,114] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0088273e-16 1.0000000e+00 1.6753907e-19 5.0866152e-17 5.8563451e-28], sum to 1.0000
[2019-03-26 18:41:11,127] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6434
[2019-03-26 18:41:11,133] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.3, 89.0, 1.0, 2.0, 0.5417867536403723, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 757083.6200410072, 757083.6200410078, 190402.5900391622], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7848000.0000, 
sim time next is 7848600.0000, 
raw observation next is [27.25, 88.83333333333334, 1.0, 2.0, 0.5399535638434884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 754521.0418967716, 754521.0418967716, 190093.089776845], 
processed observation next is [1.0, 0.8695652173913043, 0.490521327014218, 0.8883333333333334, 1.0, 1.0, 0.4457271853536004, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20958917830465879, 0.20958917830465879, 0.28372102951767914], 
reward next is 0.7163, 
noisyNet noise sample is [array([-0.15837018], dtype=float32), -0.65828013]. 
=============================================
[2019-03-26 18:41:12,569] A3C_AGENT_WORKER-Thread-20 INFO:Local step 145000, global step 2323391: loss 0.0077
[2019-03-26 18:41:12,572] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 145000, global step 2323391: learning rate 0.0000
[2019-03-26 18:41:13,218] A3C_AGENT_WORKER-Thread-17 INFO:Local step 145000, global step 2323680: loss 0.0052
[2019-03-26 18:41:13,225] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 145000, global step 2323682: learning rate 0.0000
[2019-03-26 18:41:14,649] A3C_AGENT_WORKER-Thread-18 INFO:Local step 145000, global step 2324302: loss 0.0039
[2019-03-26 18:41:14,654] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 145000, global step 2324302: learning rate 0.0000
[2019-03-26 18:41:15,688] A3C_AGENT_WORKER-Thread-21 INFO:Local step 145000, global step 2324774: loss 0.0032
[2019-03-26 18:41:15,693] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 145000, global step 2324774: learning rate 0.0000
[2019-03-26 18:41:15,733] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:41:15,734] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:41:15,817] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run12
[2019-03-26 18:41:15,910] A3C_AGENT_WORKER-Thread-19 INFO:Local step 145000, global step 2324857: loss 0.0022
[2019-03-26 18:41:15,912] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 145000, global step 2324858: learning rate 0.0000
[2019-03-26 18:41:15,949] A3C_AGENT_WORKER-Thread-12 INFO:Local step 145000, global step 2324876: loss 0.0028
[2019-03-26 18:41:15,951] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 145000, global step 2324876: learning rate 0.0000
[2019-03-26 18:41:15,994] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.1806214e-10 2.5939891e-01 3.0683561e-10 7.4060112e-01 8.8618360e-17], sum to 1.0000
[2019-03-26 18:41:16,002] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6474
[2019-03-26 18:41:16,009] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.1, 59.16666666666667, 1.0, 2.0, 0.7332772541105556, 1.0, 2.0, 0.7332772541105556, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2050567.392283345, 2050567.392283345, 388693.1751306024], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7740600.0000, 
sim time next is 7741200.0000, 
raw observation next is [32.00000000000001, 59.33333333333334, 1.0, 2.0, 0.7115546752250783, 1.0, 2.0, 0.7115546752250783, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1989765.044817442, 1989765.044817442, 379107.7584150313], 
processed observation next is [1.0, 0.6086956521739131, 0.7156398104265407, 0.5933333333333334, 1.0, 1.0, 0.6524755123193714, 1.0, 1.0, 0.6524755123193714, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5527125124492894, 0.5527125124492894, 0.5658324752463154], 
reward next is 0.4342, 
noisyNet noise sample is [array([0.6933371], dtype=float32), -0.009542513]. 
=============================================
[2019-03-26 18:41:16,177] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-26 18:41:16,181] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 18:41:16,182] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 18:41:16,182] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:41:16,183] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:41:16,185] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 18:41:16,186] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 18:41:16,187] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:41:16,186] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 18:41:16,188] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:41:16,190] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:41:16,207] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run94
[2019-03-26 18:41:16,228] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run94
[2019-03-26 18:41:16,250] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run94
[2019-03-26 18:41:16,272] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run94
[2019-03-26 18:41:16,272] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run94
[2019-03-26 18:41:18,473] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.11249448], dtype=float32), 0.096744865]
[2019-03-26 18:41:18,475] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [22.85, 89.5, 1.0, 2.0, 0.3682352572099155, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 562343.0429005369, 562343.0429005363, 171556.797761098]
[2019-03-26 18:41:18,476] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:41:18,479] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.5289734e-17 1.0000000e+00 1.4086900e-20 7.6864870e-21 1.5290883e-29], sampled 0.7592230149894793
[2019-03-26 18:41:18,777] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.11249448], dtype=float32), 0.096744865]
[2019-03-26 18:41:18,779] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.8, 96.0, 1.0, 2.0, 0.8174763486541843, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1217378.522407393, 1217378.522407393, 258538.744758705]
[2019-03-26 18:41:18,781] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 18:41:18,783] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.8885433e-16 1.0000000e+00 7.5667779e-19 2.3780447e-17 1.8396772e-27], sampled 0.4026507687864882
[2019-03-26 18:41:19,264] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.11249448], dtype=float32), 0.096744865]
[2019-03-26 18:41:19,266] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [26.43333333333333, 40.0, 1.0, 2.0, 0.3341001851353729, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 554741.9783417335, 554741.9783417342, 170189.8365970876]
[2019-03-26 18:41:19,267] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 18:41:19,270] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.9337792e-17 1.0000000e+00 9.7190765e-21 4.1965631e-21 8.8707746e-30], sampled 0.8940984811182193
[2019-03-26 18:41:19,329] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.11249448], dtype=float32), 0.096744865]
[2019-03-26 18:41:19,331] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.672786025, 100.0, 1.0, 2.0, 0.6375254362109197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 905873.9061569659, 905873.9061569659, 209895.2129670237]
[2019-03-26 18:41:19,334] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:41:19,337] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.9745076e-17 1.0000000e+00 4.7376776e-20 3.7208755e-19 6.5846889e-29], sampled 0.5063742986882886
[2019-03-26 18:41:24,181] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.11249448], dtype=float32), 0.096744865]
[2019-03-26 18:41:24,182] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [25.7, 73.0, 1.0, 2.0, 0.6467065224044882, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 971575.5356810095, 971575.5356810101, 218339.6108024602]
[2019-03-26 18:41:24,183] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:41:24,189] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0649326e-16 1.0000000e+00 1.7275515e-19 2.5550277e-18 3.0847117e-28], sampled 0.8845525985968978
[2019-03-26 18:41:25,193] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.11249448], dtype=float32), 0.096744865]
[2019-03-26 18:41:25,194] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [19.27042519, 68.49724255, 1.0, 2.0, 0.2123979500606916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 355157.1902298761, 355157.1902298761, 146474.4780454019]
[2019-03-26 18:41:25,197] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:41:25,199] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [6.6854354e-18 1.0000000e+00 1.8661675e-21 1.2442783e-22 1.3561287e-30], sampled 0.6395255423539004
[2019-03-26 18:41:31,594] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.11249448], dtype=float32), 0.096744865]
[2019-03-26 18:41:31,596] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [19.67171204, 96.74105021666666, 1.0, 2.0, 0.3192586839589927, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 514226.1961122015, 514226.1961122015, 168159.6228588895]
[2019-03-26 18:41:31,596] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 18:41:31,598] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [6.6275154e-18 1.0000000e+00 2.2718005e-21 3.7024208e-22 1.5938434e-30], sampled 0.9544817402641003
[2019-03-26 18:41:51,110] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.11249448], dtype=float32), 0.096744865]
[2019-03-26 18:41:51,111] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.70237887666667, 92.76557076, 1.0, 2.0, 0.6309295571333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 881701.9638127425, 881701.9638127425, 206649.1432211359]
[2019-03-26 18:41:51,112] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 18:41:51,116] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [7.1359409e-17 1.0000000e+00 1.0809051e-19 2.4828593e-18 1.8006010e-28], sampled 0.461878809368124
[2019-03-26 18:42:05,665] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.11249448], dtype=float32), 0.096744865]
[2019-03-26 18:42:05,665] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.66666666666667, 82.33333333333334, 1.0, 2.0, 0.5256096394887132, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 734470.1798115391, 734470.1798115385, 187705.8302518916]
[2019-03-26 18:42:05,666] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 18:42:05,669] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0614076e-17 1.0000000e+00 7.4037334e-21 3.6955247e-20 4.4428447e-30], sampled 0.649209316225149
[2019-03-26 18:42:14,160] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.11249448], dtype=float32), 0.096744865]
[2019-03-26 18:42:14,161] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [36.65998754833333, 55.35565826, 1.0, 2.0, 0.6775360820410952, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 946861.983848994, 946861.983848994, 216079.9904893269]
[2019-03-26 18:42:14,163] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 18:42:14,164] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.9038989e-17 1.0000000e+00 2.7820259e-20 3.0366932e-19 2.6826510e-29], sampled 0.8387488618033916
[2019-03-26 18:42:36,115] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.11249448], dtype=float32), 0.096744865]
[2019-03-26 18:42:36,117] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [34.530485065, 61.26623488999999, 1.0, 2.0, 0.6050620606410005, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 845538.6541796116, 845538.6541796116, 201694.6741375408]
[2019-03-26 18:42:36,118] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:42:36,121] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.9485614e-16 1.0000000e+00 8.1642406e-19 1.6236410e-14 2.2483605e-27], sampled 0.7530150078257498
[2019-03-26 18:42:42,494] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.11249448], dtype=float32), 0.096744865]
[2019-03-26 18:42:42,495] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.2, 95.33333333333334, 1.0, 2.0, 0.9753900342399823, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1363382.453764927, 1363382.453764927, 291517.442517295]
[2019-03-26 18:42:42,496] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:42:42,498] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.2940016e-16 1.0000000e+00 2.1546443e-19 1.6200339e-18 4.4723517e-28], sampled 0.29825654493087417
[2019-03-26 18:42:47,768] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.11249448], dtype=float32), 0.096744865]
[2019-03-26 18:42:47,769] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.3135325, 67.48150722, 1.0, 2.0, 0.510959847498911, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 713992.1468972836, 713992.146897283, 185330.1446302492]
[2019-03-26 18:42:47,772] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:42:47,775] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.9642916e-17 1.0000000e+00 1.1088446e-20 6.9673795e-21 1.0753392e-29], sampled 0.47927484884815097
[2019-03-26 18:43:10,021] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8106.2259 2995682267.9669 1458.0000
[2019-03-26 18:43:10,189] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8300.6196 2922210496.0201 1197.0000
[2019-03-26 18:43:10,253] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8531.5703 2837798152.4484 1014.0000
[2019-03-26 18:43:10,275] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7994.9705 3151110987.3699 1439.0000
[2019-03-26 18:43:10,310] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8676.9130 2777706490.5340 887.0000
[2019-03-26 18:43:11,329] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 2325000, evaluation results [2325000.0, 7994.970508714165, 3151110987.36989, 1439.0, 8300.619634920617, 2922210496.020118, 1197.0, 8676.91299567459, 2777706490.5340366, 887.0, 8106.225892328293, 2995682267.966947, 1458.0, 8531.570309094133, 2837798152.4483905, 1014.0]
[2019-03-26 18:43:11,581] A3C_AGENT_WORKER-Thread-11 INFO:Local step 145000, global step 2325122: loss 0.0024
[2019-03-26 18:43:11,583] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 145000, global step 2325123: learning rate 0.0000
[2019-03-26 18:43:12,516] A3C_AGENT_WORKER-Thread-14 INFO:Local step 145500, global step 2325546: loss 33.1685
[2019-03-26 18:43:12,518] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 145500, global step 2325546: learning rate 0.0000
[2019-03-26 18:43:13,032] A3C_AGENT_WORKER-Thread-2 INFO:Local step 145500, global step 2325774: loss 10.9733
[2019-03-26 18:43:13,037] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 145500, global step 2325777: learning rate 0.0000
[2019-03-26 18:43:13,168] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:43:13,170] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:43:13,256] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run12
[2019-03-26 18:43:14,885] A3C_AGENT_WORKER-Thread-3 INFO:Local step 145500, global step 2326727: loss -15.2704
[2019-03-26 18:43:14,887] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 145500, global step 2326728: learning rate 0.0000
[2019-03-26 18:43:14,935] A3C_AGENT_WORKER-Thread-15 INFO:Local step 145500, global step 2326749: loss 49.3512
[2019-03-26 18:43:14,938] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 145500, global step 2326751: learning rate 0.0000
[2019-03-26 18:43:15,990] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.7167006e-09 9.3494397e-01 1.0953802e-09 6.5056078e-02 1.8814899e-16], sum to 1.0000
[2019-03-26 18:43:16,003] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2040
[2019-03-26 18:43:16,009] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2063545.704126762 W.
[2019-03-26 18:43:16,015] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.73333333333333, 67.33333333333334, 1.0, 2.0, 0.4919425313655452, 1.0, 2.0, 0.4919425313655452, 1.0, 1.0, 0.8398355462644114, 6.9112, 6.9112, 170.5573041426782, 2063545.704126762, 2063545.704126762, 407020.9862359969], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7659600.0000, 
sim time next is 7660200.0000, 
raw observation next is [29.61666666666667, 68.16666666666666, 1.0, 2.0, 0.7460259570843255, 1.0, 2.0, 0.7460259570843255, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2086253.117320642, 2086253.117320642, 394442.9396028647], 
processed observation next is [1.0, 0.6521739130434783, 0.6026856240126385, 0.6816666666666665, 1.0, 1.0, 0.6940071772100307, 1.0, 1.0, 0.6940071772100307, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5795147548112894, 0.5795147548112894, 0.58872080537741], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.9640572], dtype=float32), -0.47663423]. 
=============================================
[2019-03-26 18:43:16,373] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.7317673e-18 1.0000000e+00 4.4866018e-21 1.7235222e-20 8.5071523e-30], sum to 1.0000
[2019-03-26 18:43:16,381] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6683
[2019-03-26 18:43:16,385] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.93333333333334, 93.0, 1.0, 2.0, 0.4806535505448792, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 671630.1126504984, 671630.1126504991, 180620.2227451406], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7600200.0000, 
sim time next is 7600800.0000, 
raw observation next is [24.86666666666667, 93.0, 1.0, 2.0, 0.4789789298341152, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 669289.3830200105, 669289.3830200112, 180367.7979197154], 
processed observation next is [0.0, 1.0, 0.3775671406003162, 0.93, 1.0, 1.0, 0.3722637708844762, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1859137175055585, 0.18591371750555868, 0.26920566853688865], 
reward next is 0.7308, 
noisyNet noise sample is [array([0.35911608], dtype=float32), -0.3795915]. 
=============================================
[2019-03-26 18:43:18,187] A3C_AGENT_WORKER-Thread-22 INFO:Local step 145500, global step 2328162: loss 167.1555
[2019-03-26 18:43:18,189] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 145500, global step 2328162: learning rate 0.0000
[2019-03-26 18:43:19,529] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.1901317e-11 8.1232958e-02 1.7787878e-10 9.1876709e-01 1.2240780e-16], sum to 1.0000
[2019-03-26 18:43:19,543] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1269
[2019-03-26 18:43:19,550] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.7, 75.0, 1.0, 2.0, 0.6330040573312851, 1.0, 2.0, 0.6330040573312851, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 1769927.589345896, 1769927.589345896, 346758.1161742544], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7664400.0000, 
sim time next is 7665000.0000, 
raw observation next is [28.55, 75.66666666666667, 1.0, 2.0, 0.3205710085130982, 1.0, 2.0, 0.3205710085130982, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 895975.895116703, 895975.895116703, 253969.5131708918], 
processed observation next is [1.0, 0.7391304347826086, 0.552132701421801, 0.7566666666666667, 1.0, 1.0, 0.18141085363023882, 1.0, 1.0, 0.18141085363023882, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.24888219308797305, 0.24888219308797305, 0.379058974881928], 
reward next is 0.6209, 
noisyNet noise sample is [array([0.2462209], dtype=float32), 0.2339974]. 
=============================================
[2019-03-26 18:43:19,561] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[60.593975]
 [59.590527]
 [59.26705 ]
 [58.147064]
 [56.867126]], R is [[62.9590683 ]
 [62.81193161]
 [62.66117477]
 [62.5119133 ]
 [62.36355972]].
[2019-03-26 18:43:20,192] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.1240862e-10 3.3556408e-01 4.5430495e-10 6.6443586e-01 1.8487777e-16], sum to 1.0000
[2019-03-26 18:43:20,199] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9394
[2019-03-26 18:43:20,203] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.1, 72.0, 1.0, 2.0, 0.6429791690330634, 1.0, 2.0, 0.6429791690330634, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1797842.160190911, 1797842.160190911, 350664.278707323], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7662600.0000, 
sim time next is 7663200.0000, 
raw observation next is [28.96666666666667, 73.0, 1.0, 2.0, 0.6417431070410514, 1.0, 2.0, 0.6417431070410514, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1794383.097793995, 1794383.097793995, 350177.231934412], 
processed observation next is [1.0, 0.6956521739130435, 0.5718799368088469, 0.73, 1.0, 1.0, 0.568365189206086, 1.0, 1.0, 0.568365189206086, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.4984397493872208, 0.4984397493872208, 0.5226525849767343], 
reward next is 0.4773, 
noisyNet noise sample is [array([-0.262134], dtype=float32), 1.0746704]. 
=============================================
[2019-03-26 18:43:21,489] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:43:21,491] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:43:21,563] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run12
[2019-03-26 18:43:21,839] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:43:21,840] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:43:21,896] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run12
[2019-03-26 18:43:22,100] A3C_AGENT_WORKER-Thread-16 INFO:Local step 145500, global step 2329949: loss -23.8018
[2019-03-26 18:43:22,103] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 145500, global step 2329949: learning rate 0.0000
[2019-03-26 18:43:22,434] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.1079113e-10 9.5008863e-03 9.6354189e-11 9.9049908e-01 5.3776312e-17], sum to 1.0000
[2019-03-26 18:43:22,439] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6655
[2019-03-26 18:43:22,444] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 70.0, 1.0, 2.0, 0.7928025951688573, 1.0, 2.0, 0.7928025951688573, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2217198.161613202, 2217198.161613202, 416385.4655408986], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7819800.0000, 
sim time next is 7820400.0000, 
raw observation next is [31.0, 70.0, 1.0, 2.0, 0.6189361243957475, 1.0, 2.0, 0.6189361243957475, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1730560.813926478, 1730560.813926478, 341357.227640166], 
processed observation next is [1.0, 0.5217391304347826, 0.6682464454976303, 0.7, 1.0, 1.0, 0.5408868968623464, 1.0, 1.0, 0.5408868968623464, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.4807113372017994, 0.4807113372017994, 0.5094883994629343], 
reward next is 0.4905, 
noisyNet noise sample is [array([-1.5946026], dtype=float32), -2.1219032]. 
=============================================
[2019-03-26 18:43:23,355] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1075993e-09 1.0000000e+00 2.9048828e-11 7.7101076e-11 1.5351425e-15], sum to 1.0000
[2019-03-26 18:43:23,364] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5106
[2019-03-26 18:43:23,372] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.73333333333333, 85.0, 1.0, 2.0, 0.319080744944861, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 518586.0455341383, 518586.0455341383, 168404.7934761216], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 8400.0000, 
sim time next is 9000.0000, 
raw observation next is [20.8, 85.0, 1.0, 2.0, 0.2933257949748841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 476224.7608408195, 476224.7608408201, 165353.809551253], 
processed observation next is [1.0, 0.08695652173913043, 0.1848341232227489, 0.85, 1.0, 1.0, 0.14858529515046276, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13228465578911652, 0.1322846557891167, 0.24679673067351196], 
reward next is 0.7532, 
noisyNet noise sample is [array([-1.4791778], dtype=float32), 1.0169768]. 
=============================================
[2019-03-26 18:43:23,386] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[40.457207]
 [37.887512]
 [35.672455]
 [32.803097]
 [29.606337]], R is [[43.06770706]
 [43.38568115]
 [43.68938446]
 [44.00940704]
 [44.32649994]].
[2019-03-26 18:43:23,573] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:43:23,575] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:43:23,652] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run12
[2019-03-26 18:43:23,723] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:43:23,724] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:43:23,771] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run12
[2019-03-26 18:43:23,999] A3C_AGENT_WORKER-Thread-20 INFO:Local step 145500, global step 2330967: loss 3.7182
[2019-03-26 18:43:24,005] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 145500, global step 2330969: learning rate 0.0000
[2019-03-26 18:43:24,518] A3C_AGENT_WORKER-Thread-17 INFO:Local step 145500, global step 2331283: loss -32.5966
[2019-03-26 18:43:24,519] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 145500, global step 2331283: learning rate 0.0000
[2019-03-26 18:43:24,573] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.7626725e-10 5.2297688e-01 3.1342684e-10 4.7702309e-01 2.0271992e-16], sum to 1.0000
[2019-03-26 18:43:24,578] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4962
[2019-03-26 18:43:24,581] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2059690.552847578 W.
[2019-03-26 18:43:24,586] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.41666666666666, 68.33333333333334, 1.0, 2.0, 0.7365365379301463, 1.0, 2.0, 0.7365365379301463, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2059690.552847578, 2059690.552847578, 390156.1487462808], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7825800.0000, 
sim time next is 7826400.0000, 
raw observation next is [30.3, 68.0, 1.0, 2.0, 0.8505831096799744, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.987362065205645, 6.9112, 168.9125029965905, 2085868.790397119, 2031836.945114565, 421405.641536415], 
processed observation next is [1.0, 0.6086956521739131, 0.6350710900473934, 0.68, 1.0, 1.0, 0.8199796502168366, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.007616206520564539, 0.0, 0.8294377181917263, 0.579407997332533, 0.5643991514207125, 0.6289636440842015], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5830959], dtype=float32), 0.8022608]. 
=============================================
[2019-03-26 18:43:25,698] A3C_AGENT_WORKER-Thread-18 INFO:Local step 145500, global step 2331885: loss 90.9739
[2019-03-26 18:43:25,703] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 145500, global step 2331887: learning rate 0.0000
[2019-03-26 18:43:25,841] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:43:25,841] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:43:25,920] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run12
[2019-03-26 18:43:26,649] A3C_AGENT_WORKER-Thread-21 INFO:Local step 145500, global step 2332374: loss -145.9599
[2019-03-26 18:43:26,652] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 145500, global step 2332375: learning rate 0.0000
[2019-03-26 18:43:26,704] A3C_AGENT_WORKER-Thread-19 INFO:Local step 145500, global step 2332404: loss -59.0632
[2019-03-26 18:43:26,707] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 145500, global step 2332404: learning rate 0.0000
[2019-03-26 18:43:26,802] A3C_AGENT_WORKER-Thread-12 INFO:Local step 145500, global step 2332462: loss 142.3921
[2019-03-26 18:43:26,806] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 145500, global step 2332463: learning rate 0.0000
[2019-03-26 18:43:27,144] A3C_AGENT_WORKER-Thread-11 INFO:Local step 145500, global step 2332652: loss -55.4359
[2019-03-26 18:43:27,145] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 145500, global step 2332652: learning rate 0.0000
[2019-03-26 18:43:27,205] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.4636251e-15 1.0000000e+00 3.1895629e-18 1.7824053e-17 6.7680560e-27], sum to 1.0000
[2019-03-26 18:43:27,214] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7956
[2019-03-26 18:43:27,220] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.35, 55.5, 1.0, 2.0, 0.6145650588639401, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1010260.390179418, 1010260.390179418, 218778.4486695058], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 559800.0000, 
sim time next is 560400.0000, 
raw observation next is [24.56666666666666, 55.0, 1.0, 2.0, 0.633009382082244, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1039117.682835463, 1039117.682835462, 222885.9367263796], 
processed observation next is [1.0, 0.4782608695652174, 0.3633491311216427, 0.55, 1.0, 1.0, 0.5578426290147518, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2886438007876286, 0.28864380078762836, 0.3326655772035516], 
reward next is 0.6673, 
noisyNet noise sample is [array([-1.3812132], dtype=float32), 1.287912]. 
=============================================
[2019-03-26 18:43:29,647] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:43:29,648] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:43:29,739] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run12
[2019-03-26 18:43:31,969] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:43:31,970] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:43:32,034] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run12
[2019-03-26 18:43:32,542] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:43:32,542] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:43:32,591] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run12
[2019-03-26 18:43:33,669] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.2593248e-17 1.0000000e+00 1.1427787e-19 9.6827410e-20 2.4598158e-28], sum to 1.0000
[2019-03-26 18:43:33,676] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9533
[2019-03-26 18:43:33,682] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.7, 82.33333333333334, 1.0, 2.0, 0.2289946747030891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 378745.9979576253, 378745.9979576246, 158820.4414377433], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 448800.0000, 
sim time next is 449400.0000, 
raw observation next is [19.7, 82.16666666666667, 1.0, 2.0, 0.2283710658019763, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 377793.6542760348, 377793.6542760348, 158757.3940653998], 
processed observation next is [1.0, 0.17391304347826086, 0.1327014218009479, 0.8216666666666668, 1.0, 1.0, 0.07032658530358589, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.104942681743343, 0.104942681743343, 0.23695133442596986], 
reward next is 0.7630, 
noisyNet noise sample is [array([1.3917533], dtype=float32), 0.5210317]. 
=============================================
[2019-03-26 18:43:33,805] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:43:33,806] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:43:33,883] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run12
[2019-03-26 18:43:34,482] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:43:34,483] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:43:34,543] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run12
[2019-03-26 18:43:34,571] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:43:34,572] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:43:34,581] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:43:34,582] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:43:34,645] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run12
[2019-03-26 18:43:34,667] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run12
[2019-03-26 18:43:34,910] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:43:34,911] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:43:34,949] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run12
[2019-03-26 18:43:37,185] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.8585946e-17 1.0000000e+00 4.3047623e-20 4.1924714e-19 1.7646757e-29], sum to 1.0000
[2019-03-26 18:43:37,194] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4086
[2019-03-26 18:43:37,201] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.6, 91.0, 1.0, 2.0, 0.3666308478678393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 561238.6564266729, 561238.6564266729, 171500.5371181019], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 104400.0000, 
sim time next is 105000.0000, 
raw observation next is [22.61666666666667, 91.00000000000001, 1.0, 2.0, 0.4082551616796137, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 624520.2171965144, 624520.2171965144, 177155.8088613652], 
processed observation next is [1.0, 0.21739130434782608, 0.2709320695102688, 0.9100000000000001, 1.0, 1.0, 0.28705441166218515, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1734778381101429, 0.1734778381101429, 0.26441165501696295], 
reward next is 0.7356, 
noisyNet noise sample is [array([-1.2725064], dtype=float32), -0.791711]. 
=============================================
[2019-03-26 18:43:37,214] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[72.46995 ]
 [72.431595]
 [72.456   ]
 [72.472015]
 [72.5035  ]], R is [[72.42627716]
 [72.44604492]
 [72.46429443]
 [72.48259735]
 [72.50096893]].
[2019-03-26 18:43:39,543] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.7907027e-15 1.0000000e+00 6.5757141e-18 1.9823307e-14 1.2854689e-26], sum to 1.0000
[2019-03-26 18:43:39,553] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5164
[2019-03-26 18:43:39,558] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.6, 96.0, 1.0, 2.0, 0.7789358315697448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1167888.554337311, 1167888.554337311, 249431.4727295514], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 144000.0000, 
sim time next is 144600.0000, 
raw observation next is [22.58333333333334, 96.0, 1.0, 2.0, 0.8156846133887776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1223659.216140579, 1223659.216140578, 259213.1658876538], 
processed observation next is [1.0, 0.6956521739130435, 0.2693522906793052, 0.96, 1.0, 1.0, 0.7779332691431056, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.33990533781682747, 0.33990533781682725, 0.3868853222203788], 
reward next is 0.6131, 
noisyNet noise sample is [array([1.9816536], dtype=float32), -0.33155942]. 
=============================================
[2019-03-26 18:43:48,179] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.8840474e-16 1.0000000e+00 1.0967589e-19 7.2491412e-18 3.1847548e-29], sum to 1.0000
[2019-03-26 18:43:48,188] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8066
[2019-03-26 18:43:48,193] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.95, 67.66666666666666, 1.0, 2.0, 0.2407609549877426, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 397262.7553255308, 397262.7553255308, 159973.0869926063], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 499800.0000, 
sim time next is 500400.0000, 
raw observation next is [21.7, 69.0, 1.0, 2.0, 0.2408189506974966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 397554.5246586306, 397554.5246586306, 159969.3600277277], 
processed observation next is [1.0, 0.8260869565217391, 0.2274881516587678, 0.69, 1.0, 1.0, 0.08532403698493564, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.11043181240517516, 0.11043181240517516, 0.23876023884735478], 
reward next is 0.7612, 
noisyNet noise sample is [array([-1.4705467], dtype=float32), -0.15797403]. 
=============================================
[2019-03-26 18:43:56,080] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.0051133e-17 1.0000000e+00 4.9196444e-20 8.4886577e-19 1.7745324e-28], sum to 1.0000
[2019-03-26 18:43:56,088] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5977
[2019-03-26 18:43:56,091] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.56666666666667, 66.83333333333333, 1.0, 2.0, 0.4749960563640614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 779425.2878549513, 779425.2878549506, 191417.6931008899], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 471000.0000, 
sim time next is 471600.0000, 
raw observation next is [22.7, 66.0, 1.0, 2.0, 0.4512683783967227, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 740454.6143606105, 740454.6143606105, 187429.1215737147], 
processed observation next is [1.0, 0.4782608695652174, 0.27488151658767773, 0.66, 1.0, 1.0, 0.3388775643334008, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20568183732239181, 0.20568183732239181, 0.2797449575727085], 
reward next is 0.7203, 
noisyNet noise sample is [array([0.14848882], dtype=float32), 0.14926125]. 
=============================================
[2019-03-26 18:44:04,200] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-26 18:44:04,202] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 18:44:04,203] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:44:04,203] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 18:44:04,205] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 18:44:04,206] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 18:44:04,204] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 18:44:04,208] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:44:04,209] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:44:04,207] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:44:04,210] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:44:04,233] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run95
[2019-03-26 18:44:04,259] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run95
[2019-03-26 18:44:04,260] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run95
[2019-03-26 18:44:04,282] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run95
[2019-03-26 18:44:04,333] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run95
[2019-03-26 18:44:19,380] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.11442933], dtype=float32), 0.099754214]
[2019-03-26 18:44:19,383] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [21.1900707, 92.20044169, 1.0, 2.0, 0.3147977722415233, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 498153.497094987, 498153.497094987, 166894.3578748685]
[2019-03-26 18:44:19,385] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 18:44:19,388] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.0257791e-18 1.0000000e+00 8.1800337e-22 7.2244980e-23 3.3876424e-31], sampled 0.03477264479347908
[2019-03-26 18:44:35,647] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.11442933], dtype=float32), 0.099754214]
[2019-03-26 18:44:35,649] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [24.12766450666667, 96.11118737333332, 1.0, 2.0, 0.4566857381365207, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 648650.0963477992, 648650.0963477992, 178443.9579637912]
[2019-03-26 18:44:35,650] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 18:44:35,654] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [5.9142752e-18 1.0000000e+00 2.1224598e-21 3.2243113e-22 9.5382818e-31], sampled 0.517997118425583
[2019-03-26 18:44:39,038] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.11442933], dtype=float32), 0.099754214]
[2019-03-26 18:44:39,039] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.56666666666667, 68.66666666666667, 1.0, 2.0, 0.5619937678028335, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 785330.9973359333, 785330.9973359333, 193880.3136418756]
[2019-03-26 18:44:39,040] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 18:44:39,044] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [4.9067597e-16 1.0000000e+00 9.1059237e-19 5.0781600e-14 4.9123509e-27], sampled 0.6975591465422593
[2019-03-26 18:44:39,839] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.11442933], dtype=float32), 0.099754214]
[2019-03-26 18:44:39,840] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.0, 67.0, 1.0, 2.0, 0.9299918984992019, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.993074082248562, 6.9112, 168.9124036783209, 2197016.843341964, 2138932.741609407, 442996.4726729438]
[2019-03-26 18:44:39,842] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 18:44:39,846] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.2642785e-10 9.9995625e-01 7.9147626e-11 4.3780728e-05 2.5832480e-18], sampled 0.35681950518462924
[2019-03-26 18:44:39,847] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2197016.843341964 W.
[2019-03-26 18:44:41,306] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.11442933], dtype=float32), 0.099754214]
[2019-03-26 18:44:41,308] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.1, 89.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 8.142625555236979, 6.9112, 168.9060194887783, 2327919.836538329, 1454340.043444614, 311204.3429440143]
[2019-03-26 18:44:41,310] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 18:44:41,312] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.0123833e-11 9.9990058e-01 3.8076734e-12 9.9356497e-05 5.6799985e-20], sampled 0.052032502022273275
[2019-03-26 18:44:41,313] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2327919.836538329 W.
[2019-03-26 18:45:01,160] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.11442933], dtype=float32), 0.099754214]
[2019-03-26 18:45:01,163] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [32.18333333333334, 62.5, 1.0, 2.0, 0.5675849289443125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 793147.012020267, 793147.0120202675, 194861.8260446945]
[2019-03-26 18:45:01,166] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:45:01,169] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [4.6595009e-18 1.0000000e+00 2.6825800e-21 1.6755624e-20 9.7201017e-31], sampled 0.6296936116147954
[2019-03-26 18:45:07,002] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.11442933], dtype=float32), 0.099754214]
[2019-03-26 18:45:07,003] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [36.2, 50.66666666666666, 1.0, 2.0, 0.6039235025222446, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 843946.9540321201, 843946.9540321201, 201479.0596125891]
[2019-03-26 18:45:07,003] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 18:45:07,005] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [9.6528933e-15 1.0000000e+00 1.3076328e-16 5.8892835e-11 1.3125594e-25], sampled 0.30996591307990673
[2019-03-26 18:45:10,574] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.11442933], dtype=float32), 0.099754214]
[2019-03-26 18:45:10,574] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [37.96666666666667, 41.33333333333334, 1.0, 2.0, 0.5819567084641112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 813237.9220449821, 813237.9220449815, 197432.0231968279]
[2019-03-26 18:45:10,575] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:45:10,577] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [9.4014701e-18 1.0000000e+00 5.6726996e-21 1.9084640e-20 2.8918083e-30], sampled 0.45014604165497707
[2019-03-26 18:45:13,518] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.11442933], dtype=float32), 0.099754214]
[2019-03-26 18:45:13,519] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [30.7, 83.33333333333334, 1.0, 2.0, 0.6514623454264306, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 910408.1146855484, 910408.1146855478, 210725.0803246777]
[2019-03-26 18:45:13,520] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:45:13,522] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [7.4596785e-18 1.0000000e+00 7.1641564e-21 2.3849010e-19 3.1967669e-30], sampled 0.8985008185519214
[2019-03-26 18:45:34,475] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.11442933], dtype=float32), 0.099754214]
[2019-03-26 18:45:34,477] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [32.56292154333334, 72.1335913, 1.0, 2.0, 0.639759025299564, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 894046.0297682349, 894046.0297682355, 208387.2578238746]
[2019-03-26 18:45:34,478] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 18:45:34,483] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0265798e-17 1.0000000e+00 6.8911738e-21 2.2123458e-20 3.6022101e-30], sampled 0.46028942757851066
[2019-03-26 18:45:57,754] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8668.7043 2778181894.9814 904.0000
[2019-03-26 18:45:57,854] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8292.9105 2923534442.5103 1235.0000
[2019-03-26 18:45:57,898] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7965.9994 3155498160.0710 1529.0000
[2019-03-26 18:45:57,905] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8523.5086 2839598242.9052 1058.0000
[2019-03-26 18:45:57,919] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8065.2308 2999408617.3025 1559.0000
[2019-03-26 18:45:58,938] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 2350000, evaluation results [2350000.0, 7965.999423545155, 3155498160.0709944, 1529.0, 8292.910511160982, 2923534442.51032, 1235.0, 8668.704282018962, 2778181894.9813566, 904.0, 8065.230839359436, 2999408617.302467, 1559.0, 8523.50863604461, 2839598242.905205, 1058.0]
[2019-03-26 18:46:02,107] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.6690938e-17 1.0000000e+00 3.3312768e-19 8.6390359e-17 3.8862245e-28], sum to 1.0000
[2019-03-26 18:46:02,115] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1960
[2019-03-26 18:46:02,123] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.7, 54.00000000000001, 1.0, 2.0, 0.6100898542150202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1001676.027908061, 1001676.027908061, 217794.1535591017], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 663600.0000, 
sim time next is 664200.0000, 
raw observation next is [24.7, 54.0, 1.0, 2.0, 0.6459675601153325, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1060564.243799926, 1060564.243799927, 225845.9538199728], 
processed observation next is [1.0, 0.6956521739130435, 0.3696682464454976, 0.54, 1.0, 1.0, 0.5734548917052199, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.29460117883331277, 0.29460117883331305, 0.33708351316413854], 
reward next is 0.6629, 
noisyNet noise sample is [array([-0.21989438], dtype=float32), 1.3415661]. 
=============================================
[2019-03-26 18:46:04,240] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.1781757e-16 1.0000000e+00 3.6063276e-19 2.6976808e-17 5.6638359e-28], sum to 1.0000
[2019-03-26 18:46:04,247] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6679
[2019-03-26 18:46:04,256] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 55.66666666666667, 1.0, 2.0, 0.3498141191536414, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 573622.1155521977, 573622.1155521977, 172483.1554737045], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 564600.0000, 
sim time next is 565200.0000, 
raw observation next is [24.4, 56.0, 1.0, 2.0, 0.3915364578328762, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 642331.2885569048, 642331.2885569048, 178239.6055975177], 
processed observation next is [1.0, 0.5652173913043478, 0.3554502369668246, 0.56, 1.0, 1.0, 0.26691139497936894, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17842535793247355, 0.17842535793247355, 0.2660292620858473], 
reward next is 0.7340, 
noisyNet noise sample is [array([-0.23661435], dtype=float32), -0.44048244]. 
=============================================
[2019-03-26 18:46:05,820] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.1799248e-19 1.0000000e+00 1.8136226e-21 1.0135389e-20 4.4537728e-30], sum to 1.0000
[2019-03-26 18:46:05,831] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8766
[2019-03-26 18:46:05,836] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.26666666666667, 81.5, 1.0, 2.0, 0.2289954706381522, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 380504.1474334769, 380504.1474334762, 158613.0745081647], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 598200.0000, 
sim time next is 598800.0000, 
raw observation next is [19.13333333333333, 82.0, 1.0, 2.0, 0.2283519834090758, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 379638.9429128517, 379638.9429128511, 158517.9449274642], 
processed observation next is [1.0, 0.9565217391304348, 0.10584518167456543, 0.82, 1.0, 1.0, 0.07030359446876602, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.10545526192023658, 0.10545526192023642, 0.23659394765293165], 
reward next is 0.7634, 
noisyNet noise sample is [array([0.6700534], dtype=float32), -0.2831502]. 
=============================================
[2019-03-26 18:46:10,061] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.4415921e-17 1.0000000e+00 6.3530043e-20 9.7172000e-18 2.1291748e-28], sum to 1.0000
[2019-03-26 18:46:10,070] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0334
[2019-03-26 18:46:10,075] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 70.33333333333334, 1.0, 2.0, 0.2457068401454845, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 404915.7620557561, 404915.7620557561, 160467.7599854153], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 674400.0000, 
sim time next is 675000.0000, 
raw observation next is [21.45, 71.5, 1.0, 2.0, 0.2442429345325114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 402702.5802681952, 402702.5802681945, 160319.3379870274], 
processed observation next is [1.0, 0.8260869565217391, 0.2156398104265403, 0.715, 1.0, 1.0, 0.08944931871386913, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11186182785227644, 0.11186182785227625, 0.23928259401048865], 
reward next is 0.7607, 
noisyNet noise sample is [array([-0.57051057], dtype=float32), -0.59072787]. 
=============================================
[2019-03-26 18:46:10,093] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[74.624535]
 [74.503426]
 [74.358376]
 [74.265305]
 [74.23125 ]], R is [[74.76608276]
 [74.77892303]
 [74.79136658]
 [74.80355072]
 [74.8156662 ]].
[2019-03-26 18:46:13,877] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.6140451e-16 1.0000000e+00 3.4381767e-19 1.4277136e-17 2.8055688e-27], sum to 1.0000
[2019-03-26 18:46:13,888] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1415
[2019-03-26 18:46:13,892] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.86666666666667, 57.5, 1.0, 2.0, 0.4920830667418969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 799452.1430245123, 799452.1430245123, 194186.7736482679], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 731400.0000, 
sim time next is 732000.0000, 
raw observation next is [24.93333333333333, 57.0, 1.0, 2.0, 0.5367944882323397, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 872424.6141691782, 872424.6141691782, 202478.6110542036], 
processed observation next is [1.0, 0.4782608695652174, 0.38072669826224315, 0.57, 1.0, 1.0, 0.4419210701594454, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2423401706025495, 0.2423401706025495, 0.3022068821704531], 
reward next is 0.6978, 
noisyNet noise sample is [array([-0.56668615], dtype=float32), -2.379096]. 
=============================================
[2019-03-26 18:46:13,902] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[72.02231 ]
 [71.89483 ]
 [71.87743 ]
 [72.03847 ]
 [72.183685]], R is [[71.91680908]
 [71.9078064 ]
 [71.88354492]
 [71.84576416]
 [71.81490326]].
[2019-03-26 18:46:16,372] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.7407455e-19 1.0000000e+00 6.5229856e-22 8.1314640e-23 2.2608342e-32], sum to 1.0000
[2019-03-26 18:46:16,380] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6074
[2019-03-26 18:46:16,384] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.75, 73.83333333333334, 1.0, 2.0, 0.3114145046085787, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 491778.5111053013, 491778.5111053013, 166400.2785317352], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 839400.0000, 
sim time next is 840000.0000, 
raw observation next is [23.6, 74.66666666666667, 1.0, 2.0, 0.3109348703224167, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 491277.5409015107, 491277.5409015114, 166369.0214944375], 
processed observation next is [0.0, 0.7391304347826086, 0.3175355450236968, 0.7466666666666667, 1.0, 1.0, 0.1698010485812249, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13646598358375298, 0.13646598358375317, 0.24831197237975747], 
reward next is 0.7517, 
noisyNet noise sample is [array([1.3126494], dtype=float32), -1.2715396]. 
=============================================
[2019-03-26 18:46:16,400] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[79.95538]
 [79.90299]
 [79.84604]
 [79.82865]
 [79.80887]], R is [[79.94097137]
 [79.89320374]
 [79.84590912]
 [79.79924011]
 [79.75320435]].
[2019-03-26 18:46:18,585] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.0471849e-18 1.0000000e+00 1.5164139e-21 1.7119943e-22 4.3793884e-31], sum to 1.0000
[2019-03-26 18:46:18,592] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4898
[2019-03-26 18:46:18,597] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.95, 88.5, 1.0, 2.0, 0.2873202962730949, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 461280.7366350644, 461280.7366350638, 164354.9904660491], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 876600.0000, 
sim time next is 877200.0000, 
raw observation next is [20.93333333333333, 88.33333333333334, 1.0, 2.0, 0.2867807129147474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 460748.844830786, 460748.844830786, 164320.6354003196], 
processed observation next is [0.0, 0.13043478260869565, 0.19115323854660338, 0.8833333333333334, 1.0, 1.0, 0.14069965411415347, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1279857902307739, 0.1279857902307739, 0.24525467970196954], 
reward next is 0.7547, 
noisyNet noise sample is [array([-1.6271236], dtype=float32), 0.74854594]. 
=============================================
[2019-03-26 18:46:19,208] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.3868246e-18 1.0000000e+00 7.0847404e-22 5.9334033e-22 5.3701622e-31], sum to 1.0000
[2019-03-26 18:46:19,217] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0306
[2019-03-26 18:46:19,223] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.86666666666667, 62.66666666666667, 1.0, 2.0, 0.288554224655352, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 462045.0355241917, 462045.0355241924, 164396.7581199094], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 823200.0000, 
sim time next is 823800.0000, 
raw observation next is [24.83333333333334, 62.83333333333333, 1.0, 2.0, 0.2893466080141956, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 463352.7591582451, 463352.7591582457, 164487.1777494199], 
processed observation next is [0.0, 0.5217391304347826, 0.3759873617693526, 0.6283333333333333, 1.0, 1.0, 0.14379109399300674, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1287090997661792, 0.12870909976617936, 0.24550325037226853], 
reward next is 0.7545, 
noisyNet noise sample is [array([-0.27051154], dtype=float32), -0.3474342]. 
=============================================
[2019-03-26 18:46:22,875] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.3730292e-17 1.0000000e+00 2.9487580e-20 1.2653702e-19 3.7813716e-28], sum to 1.0000
[2019-03-26 18:46:22,885] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8231
[2019-03-26 18:46:22,893] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.15, 93.16666666666667, 1.0, 2.0, 0.3193508661226476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 515050.079920298, 515050.0799202973, 168215.7292246842], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1134600.0000, 
sim time next is 1135200.0000, 
raw observation next is [20.1, 93.33333333333334, 1.0, 2.0, 0.2942293455128591, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 474785.2745179156, 474785.2745179156, 165290.5602383536], 
processed observation next is [1.0, 0.13043478260869565, 0.15165876777251197, 0.9333333333333335, 1.0, 1.0, 0.14967391025645677, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13188479847719878, 0.13188479847719878, 0.24670232871396058], 
reward next is 0.7533, 
noisyNet noise sample is [array([0.42829508], dtype=float32), 0.6164035]. 
=============================================
[2019-03-26 18:46:22,923] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.6649696e-17 1.0000000e+00 6.6293040e-20 2.5210051e-19 3.3769885e-29], sum to 1.0000
[2019-03-26 18:46:22,934] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3639
[2019-03-26 18:46:22,939] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 93.66666666666667, 1.0, 2.0, 0.2836976881972058, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 458312.5188377349, 458312.5188377356, 164155.6497084287], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1136400.0000, 
sim time next is 1137000.0000, 
raw observation next is [19.95, 93.83333333333334, 1.0, 2.0, 0.2808686411031585, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 453996.2622211621, 453996.2622211621, 163863.8587897993], 
processed observation next is [1.0, 0.13043478260869565, 0.14454976303317538, 0.9383333333333335, 1.0, 1.0, 0.13357667602790183, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1261100728392117, 0.1261100728392117, 0.24457292356686464], 
reward next is 0.7554, 
noisyNet noise sample is [array([0.9701002], dtype=float32), -0.2450058]. 
=============================================
[2019-03-26 18:46:22,954] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[73.20151 ]
 [73.2433  ]
 [73.260735]
 [73.294464]
 [73.43053 ]], R is [[73.17635345]
 [73.19957733]
 [73.22173309]
 [73.24281311]
 [73.25931549]].
[2019-03-26 18:46:27,659] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.7117939e-16 1.0000000e+00 6.9702077e-18 9.1956539e-15 1.7633192e-26], sum to 1.0000
[2019-03-26 18:46:27,668] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3570
[2019-03-26 18:46:27,671] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.88333333333333, 63.5, 1.0, 2.0, 0.5262258908200603, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 801873.4452989831, 801873.4452989837, 195883.366619986], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1169400.0000, 
sim time next is 1170000.0000, 
raw observation next is [27.0, 63.0, 1.0, 2.0, 0.5250589993288421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 799527.1029328268, 799527.1029328268, 195610.9273368673], 
processed observation next is [1.0, 0.5652173913043478, 0.4786729857819906, 0.63, 1.0, 1.0, 0.42778192690221944, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22209086192578523, 0.22209086192578523, 0.29195660796547357], 
reward next is 0.7080, 
noisyNet noise sample is [array([-0.96071714], dtype=float32), 0.51145023]. 
=============================================
[2019-03-26 18:46:27,685] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[70.06946]
 [69.82244]
 [69.48393]
 [69.34472]
 [69.1906 ]], R is [[70.29498291]
 [70.29966736]
 [70.29998016]
 [70.27249908]
 [70.23767853]].
[2019-03-26 18:46:33,492] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.3112488e-10 8.2251149e-01 1.9762449e-10 1.7748848e-01 9.9843645e-17], sum to 1.0000
[2019-03-26 18:46:33,501] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5659
[2019-03-26 18:46:33,511] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2108145.911056648 W.
[2019-03-26 18:46:33,516] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.2, 74.33333333333334, 1.0, 2.0, 0.7538469337774495, 1.0, 2.0, 0.7538469337774495, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2108145.911056648, 2108145.911056648, 398018.0847443754], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1264800.0000, 
sim time next is 1265400.0000, 
raw observation next is [28.15, 74.5, 1.0, 2.0, 0.8826732217382695, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.970412546723431, 6.9112, 168.9126037750574, 2130784.085136366, 2088776.754274897, 430483.9562543673], 
processed observation next is [1.0, 0.6521739130434783, 0.533175355450237, 0.745, 1.0, 1.0, 0.8586424358292403, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.005921254672343057, 0.0, 0.8294382130601353, 0.591884468093435, 0.5802157650763603, 0.6425133675438318], 
reward next is 0.0614, 
noisyNet noise sample is [array([-0.2923714], dtype=float32), -0.11811498]. 
=============================================
[2019-03-26 18:46:37,208] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.9200913e-18 1.0000000e+00 4.9151002e-22 9.1540372e-23 9.5739332e-31], sum to 1.0000
[2019-03-26 18:46:37,217] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2604
[2019-03-26 18:46:37,224] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 88.5, 1.0, 2.0, 0.3892077527315075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 579847.4878503926, 579847.4878503919, 172664.7712648222], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1417800.0000, 
sim time next is 1418400.0000, 
raw observation next is [24.0, 89.0, 1.0, 2.0, 0.3987073290933262, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 589124.01544938, 589124.01544938, 173357.6767942892], 
processed observation next is [0.0, 0.43478260869565216, 0.3364928909952607, 0.89, 1.0, 1.0, 0.2755509989076219, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16364555984705, 0.16364555984705, 0.2587428011855063], 
reward next is 0.7413, 
noisyNet noise sample is [array([0.39660394], dtype=float32), 0.95521]. 
=============================================
[2019-03-26 18:46:37,326] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.7883749e-18 1.0000000e+00 1.5631907e-20 3.8227968e-19 1.7257578e-29], sum to 1.0000
[2019-03-26 18:46:37,335] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3737
[2019-03-26 18:46:37,340] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.86666666666667, 95.16666666666667, 1.0, 2.0, 0.3180440035163916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 502811.7905038574, 502811.7905038581, 167233.9838712227], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1375800.0000, 
sim time next is 1376400.0000, 
raw observation next is [20.83333333333333, 95.33333333333334, 1.0, 2.0, 0.3171240389280713, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 501519.2736703553, 501519.2736703559, 167139.9895251932], 
processed observation next is [1.0, 0.9565217391304348, 0.1864139020537123, 0.9533333333333335, 1.0, 1.0, 0.1772578782265919, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1393109093528765, 0.13931090935287663, 0.2494626709331242], 
reward next is 0.7505, 
noisyNet noise sample is [array([-0.78842074], dtype=float32), 0.51035243]. 
=============================================
[2019-03-26 18:46:42,738] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.3593022e-17 1.0000000e+00 2.5710878e-21 3.4355233e-22 2.4459649e-30], sum to 1.0000
[2019-03-26 18:46:42,746] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6490
[2019-03-26 18:46:42,753] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.36666666666667, 51.0, 1.0, 2.0, 0.3545495643181173, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 540696.9328101261, 540696.9328101267, 169702.3073243424], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1514400.0000, 
sim time next is 1515000.0000, 
raw observation next is [29.43333333333333, 51.0, 1.0, 2.0, 0.356860421157582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 543278.6023775876, 543278.6023775876, 169886.0060121602], 
processed observation next is [0.0, 0.5217391304347826, 0.5939968404423379, 0.51, 1.0, 1.0, 0.2251330375392554, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15091072288266322, 0.15091072288266322, 0.25356120300322416], 
reward next is 0.7464, 
noisyNet noise sample is [array([-0.07845332], dtype=float32), 0.9833493]. 
=============================================
[2019-03-26 18:46:42,771] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[77.41703 ]
 [77.36302 ]
 [77.304794]
 [77.245026]
 [77.16957 ]], R is [[77.43844604]
 [77.41077423]
 [77.38357544]
 [77.35675049]
 [77.33026123]].
[2019-03-26 18:46:49,043] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.7693463e-18 1.0000000e+00 8.0326306e-21 1.7701652e-20 8.5531273e-31], sum to 1.0000
[2019-03-26 18:46:49,051] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7112
[2019-03-26 18:46:49,056] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.75, 88.0, 1.0, 2.0, 0.3937778143103614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 587622.5538527947, 587622.5538527947, 173401.3058275043], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1452600.0000, 
sim time next is 1453200.0000, 
raw observation next is [23.5, 89.33333333333333, 1.0, 2.0, 0.3907755687023597, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 584580.0612230237, 584580.0612230243, 173168.24205628], 
processed observation next is [0.0, 0.8260869565217391, 0.31279620853080575, 0.8933333333333333, 1.0, 1.0, 0.26599466108718034, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1623833503397288, 0.16238335033972898, 0.25846006277056716], 
reward next is 0.7415, 
noisyNet noise sample is [array([-0.25959155], dtype=float32), 2.0117362]. 
=============================================
[2019-03-26 18:46:49,649] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.0473965e-17 1.0000000e+00 3.1304582e-20 1.7769529e-18 1.2391682e-28], sum to 1.0000
[2019-03-26 18:46:49,656] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7277
[2019-03-26 18:46:49,661] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.41666666666667, 85.00000000000001, 1.0, 2.0, 0.3914057450573952, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 598482.06138325, 598482.0613832506, 174773.1832725219], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1584600.0000, 
sim time next is 1585200.0000, 
raw observation next is [23.43333333333333, 85.0, 1.0, 2.0, 0.4809180021870427, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 734962.9368181376, 734962.9368181371, 188286.2661040828], 
processed observation next is [1.0, 0.34782608695652173, 0.30963665086887826, 0.85, 1.0, 1.0, 0.3746000026349912, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20415637133837156, 0.20415637133837142, 0.2810242777672878], 
reward next is 0.7190, 
noisyNet noise sample is [array([-0.0282845], dtype=float32), -0.089227274]. 
=============================================
[2019-03-26 18:46:49,846] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.2522704e-16 1.0000000e+00 1.5553051e-18 5.5077132e-16 9.8323317e-28], sum to 1.0000
[2019-03-26 18:46:49,851] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0295
[2019-03-26 18:46:49,858] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.93333333333333, 87.33333333333334, 1.0, 2.0, 0.686824532390248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1083132.043582678, 1083132.043582678, 232826.8951584674], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1788000.0000, 
sim time next is 1788600.0000, 
raw observation next is [22.16666666666667, 85.66666666666666, 1.0, 2.0, 0.6861049299627314, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1081520.073867193, 1081520.073867193, 232610.5293168236], 
processed observation next is [1.0, 0.6956521739130435, 0.24960505529225935, 0.8566666666666666, 1.0, 1.0, 0.6218131686297969, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3004222427408869, 0.3004222427408869, 0.3471798945027218], 
reward next is 0.6528, 
noisyNet noise sample is [array([-0.42136636], dtype=float32), 1.102806]. 
=============================================
[2019-03-26 18:46:54,657] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-26 18:46:54,660] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 18:46:54,661] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 18:46:54,662] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:46:54,664] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:46:54,665] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 18:46:54,665] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 18:46:54,663] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 18:46:54,666] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:46:54,667] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:46:54,667] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:46:54,683] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run96
[2019-03-26 18:46:54,708] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run96
[2019-03-26 18:46:54,731] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run96
[2019-03-26 18:46:54,755] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run96
[2019-03-26 18:46:54,777] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run96
[2019-03-26 18:46:56,750] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.11330286], dtype=float32), 0.098512806]
[2019-03-26 18:46:56,751] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [22.7, 90.0, 1.0, 2.0, 0.384289279937782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 588354.73792999, 588354.73792999, 173879.9875534299]
[2019-03-26 18:46:56,751] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 18:46:56,753] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.8024383e-17 1.0000000e+00 1.7819744e-20 1.4122682e-20 1.7912077e-29], sampled 0.335173288999132
[2019-03-26 18:47:03,764] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.11330286], dtype=float32), 0.098512806]
[2019-03-26 18:47:03,764] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [20.11480495333333, 83.44251711999999, 1.0, 2.0, 0.2488147013559291, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 409022.1218100299, 409022.1218100305, 160791.7125290961]
[2019-03-26 18:47:03,766] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:47:03,769] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.1213479e-17 1.0000000e+00 3.5868963e-21 3.0841801e-22 2.4998653e-30], sampled 0.4242209427853483
[2019-03-26 18:47:11,327] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.11330286], dtype=float32), 0.098512806]
[2019-03-26 18:47:11,327] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [21.26666666666667, 90.66666666666667, 1.0, 2.0, 0.4496890895787044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 713289.8769412781, 713289.8769412787, 185818.4565670592]
[2019-03-26 18:47:11,330] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:47:11,332] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.4688650e-17 1.0000000e+00 6.9064112e-21 3.0887144e-21 5.1768436e-30], sampled 0.2745409139541901
[2019-03-26 18:48:03,376] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.11330286], dtype=float32), 0.098512806]
[2019-03-26 18:48:03,377] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [37.3, 42.33333333333333, 1.0, 2.0, 0.5560873951893434, 0.0, 2.0, 0.0, 1.0, 2.0, 0.960720507793942, 6.911199999999999, 6.9112, 168.91288497745, 1554717.714410929, 1554717.71441093, 339217.3524405354]
[2019-03-26 18:48:03,377] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 18:48:03,380] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.5775653e-12 9.9999988e-01 3.9333838e-13 1.1907877e-07 2.5980439e-20], sampled 0.02043706693420755
[2019-03-26 18:48:44,414] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 8020.9373 3148963411.7132 1360.0000
[2019-03-26 18:48:44,795] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8314.7547 2920748874.1172 1158.0000
[2019-03-26 18:48:44,828] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8675.5390 2776817316.8045 872.0000
[2019-03-26 18:48:45,080] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8543.2631 2836810171.4754 986.0000
[2019-03-26 18:48:45,105] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8118.0563 2992700534.8161 1387.0000
[2019-03-26 18:48:46,122] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 2375000, evaluation results [2375000.0, 8020.937288707339, 3148963411.713168, 1360.0, 8314.754711760741, 2920748874.117229, 1158.0, 8675.538988913822, 2776817316.804454, 872.0, 8118.05625701224, 2992700534.81609, 1387.0, 8543.26306428159, 2836810171.475424, 986.0]
[2019-03-26 18:48:48,452] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.2087027e-17 1.0000000e+00 5.0631467e-19 2.1871001e-17 7.7770351e-28], sum to 1.0000
[2019-03-26 18:48:48,462] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5313
[2019-03-26 18:48:48,465] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.95, 90.66666666666667, 1.0, 2.0, 0.4827320287737497, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 678251.1483006797, 678251.1483006797, 181413.1688061994], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1753800.0000, 
sim time next is 1754400.0000, 
raw observation next is [25.0, 90.33333333333334, 1.0, 2.0, 0.4699067524590962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 660096.2476125918, 660096.2476125924, 179465.7918225708], 
processed observation next is [1.0, 0.30434782608695654, 0.38388625592417064, 0.9033333333333334, 1.0, 1.0, 0.36133343669770623, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1833600687812755, 0.18336006878127567, 0.26785939077995646], 
reward next is 0.7321, 
noisyNet noise sample is [array([-0.07920931], dtype=float32), 0.88841474]. 
=============================================
[2019-03-26 18:48:53,955] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.1343657e-16 1.0000000e+00 7.2949614e-20 4.1228308e-19 1.1992444e-27], sum to 1.0000
[2019-03-26 18:48:53,966] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4400
[2019-03-26 18:48:53,970] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 85.5, 1.0, 2.0, 0.4159657037320666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 640971.4273634896, 640971.4273634889, 178767.7052098467], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1582200.0000, 
sim time next is 1582800.0000, 
raw observation next is [23.2, 85.33333333333334, 1.0, 2.0, 0.3917076470776573, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 602260.0155573708, 602260.0155573714, 175180.5040984568], 
processed observation next is [1.0, 0.30434782608695654, 0.29857819905213273, 0.8533333333333334, 1.0, 1.0, 0.26711764708151486, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16729444876593635, 0.16729444876593652, 0.26146343895292057], 
reward next is 0.7385, 
noisyNet noise sample is [array([-1.2408115], dtype=float32), 0.43086883]. 
=============================================
[2019-03-26 18:49:10,502] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.6775363e-16 1.0000000e+00 1.9275613e-19 6.8951775e-19 2.1534595e-28], sum to 1.0000
[2019-03-26 18:49:10,512] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6236
[2019-03-26 18:49:10,573] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 76.83333333333334, 1.0, 2.0, 0.5684791045238861, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 794397.0062718627, 794397.006271862, 195021.0877695475], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2123400.0000, 
sim time next is 2124000.0000, 
raw observation next is [30.0, 77.0, 1.0, 2.0, 0.5688649918539387, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 794936.4499355687, 794936.4499355693, 195089.4460440906], 
processed observation next is [0.0, 0.6086956521739131, 0.6208530805687204, 0.77, 1.0, 1.0, 0.48056023114932367, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.220815680537658, 0.22081568053765815, 0.2911782776777472], 
reward next is 0.7088, 
noisyNet noise sample is [array([-1.9375095], dtype=float32), -1.2707341]. 
=============================================
[2019-03-26 18:49:10,590] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[75.16454 ]
 [75.135056]
 [75.10208 ]
 [75.06186 ]
 [75.014496]], R is [[75.1914978 ]
 [75.14850616]
 [75.10619354]
 [75.06486511]
 [75.02442932]].
[2019-03-26 18:49:25,530] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.4452081e-16 1.0000000e+00 1.1250622e-18 1.6570252e-15 7.9490239e-27], sum to 1.0000
[2019-03-26 18:49:25,538] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9103
[2019-03-26 18:49:25,546] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.55, 81.0, 1.0, 2.0, 0.5518384396192169, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 771134.7740927695, 771134.7740927688, 192116.342783177], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2329800.0000, 
sim time next is 2330400.0000, 
raw observation next is [28.5, 81.0, 1.0, 2.0, 0.5516730111975894, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 770903.5218070202, 770903.5218070202, 192087.7664275888], 
processed observation next is [1.0, 1.0, 0.5497630331753555, 0.81, 1.0, 1.0, 0.45984700144287877, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21413986716861672, 0.21413986716861672, 0.28669815884714744], 
reward next is 0.7133, 
noisyNet noise sample is [array([-0.10150747], dtype=float32), -1.160031]. 
=============================================
[2019-03-26 18:49:26,245] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.6053875e-15 1.0000000e+00 1.7287861e-17 1.7430092e-14 4.2074384e-25], sum to 1.0000
[2019-03-26 18:49:26,253] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7358
[2019-03-26 18:49:26,260] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.73333333333333, 81.33333333333334, 1.0, 2.0, 0.9507163204713617, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1328872.400031992, 1328872.400031992, 284268.3225965381], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2341200.0000, 
sim time next is 2341800.0000, 
raw observation next is [27.7, 81.5, 1.0, 2.0, 0.8924187544643202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1247338.578074932, 1247338.578074931, 267859.7291019847], 
processed observation next is [1.0, 0.08695652173913043, 0.5118483412322274, 0.815, 1.0, 1.0, 0.8703840415232773, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3464829383541478, 0.3464829383541475, 0.39979064045072343], 
reward next is 0.6002, 
noisyNet noise sample is [array([-0.6474178], dtype=float32), -2.4413986]. 
=============================================
[2019-03-26 18:49:27,260] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.9194467e-17 1.0000000e+00 3.3196170e-20 1.2891024e-19 9.7362921e-29], sum to 1.0000
[2019-03-26 18:49:27,272] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8892
[2019-03-26 18:49:27,278] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 75.16666666666667, 1.0, 2.0, 0.5585308538496467, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 780490.1379214241, 780490.1379214241, 193275.1673035178], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2117400.0000, 
sim time next is 2118000.0000, 
raw observation next is [30.0, 75.33333333333334, 1.0, 2.0, 0.5588145818713958, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 780886.7647537526, 780886.7647537532, 193324.6083505794], 
processed observation next is [0.0, 0.5217391304347826, 0.6208530805687204, 0.7533333333333334, 1.0, 1.0, 0.46845130345951297, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21691299020937574, 0.21691299020937588, 0.28854419156802896], 
reward next is 0.7115, 
noisyNet noise sample is [array([1.1071159], dtype=float32), -0.2653758]. 
=============================================
[2019-03-26 18:49:27,298] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[73.53429 ]
 [73.473854]
 [73.40462 ]
 [73.378334]
 [73.35297 ]], R is [[73.55337524]
 [73.52937317]
 [73.5061264 ]
 [73.48355103]
 [73.46161652]].
[2019-03-26 18:49:34,438] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.6738823e-11 4.6611267e-01 5.0500635e-11 5.3388733e-01 1.7458724e-17], sum to 1.0000
[2019-03-26 18:49:34,445] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0707
[2019-03-26 18:49:34,456] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2018165.059078146 W.
[2019-03-26 18:49:34,466] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.7, 84.0, 1.0, 2.0, 0.7217011729431894, 1.0, 2.0, 0.7217011729431894, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2018165.059078146, 2018165.059078146, 383550.7306948633], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2476800.0000, 
sim time next is 2477400.0000, 
raw observation next is [27.81666666666666, 83.66666666666667, 1.0, 2.0, 0.9239498209870332, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.988424033976605, 6.9112, 168.9124973004794, 2188560.151790509, 2133774.913181966, 441433.5803064891], 
processed observation next is [1.0, 0.6956521739130435, 0.5173775671406, 0.8366666666666667, 1.0, 1.0, 0.9083732782976303, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.007722403397660482, 0.0, 0.829437690221213, 0.6079333754973636, 0.5927152536616572, 0.6588560900096851], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.04001699], dtype=float32), -0.8617303]. 
=============================================
[2019-03-26 18:49:37,260] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.6005274e-09 1.7261617e-01 1.4458181e-09 8.2738382e-01 1.0905376e-15], sum to 1.0000
[2019-03-26 18:49:37,264] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7919
[2019-03-26 18:49:37,272] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.9, 62.5, 1.0, 2.0, 0.7076908077385385, 1.0, 1.0, 0.7076908077385385, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1978950.29016723, 1978950.29016723, 377435.3293430397], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2285400.0000, 
sim time next is 2286000.0000, 
raw observation next is [32.1, 62.0, 1.0, 2.0, 0.7134350520428693, 1.0, 2.0, 0.7134350520428693, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1995028.156608936, 1995028.156608936, 379930.4782919243], 
processed observation next is [1.0, 0.4782608695652174, 0.7203791469194314, 0.62, 1.0, 1.0, 0.6547410265576739, 1.0, 1.0, 0.6547410265576739, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5541744879469267, 0.5541744879469267, 0.567060415361081], 
reward next is 0.4329, 
noisyNet noise sample is [array([-1.787564], dtype=float32), -1.4440641]. 
=============================================
[2019-03-26 18:49:37,317] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[57.488083]
 [57.899357]
 [59.43881 ]
 [59.072018]
 [56.24818 ]], R is [[57.33129501]
 [56.75798416]
 [56.19040298]
 [55.62849808]
 [55.07221222]].
[2019-03-26 18:49:37,422] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.0064851e-15 1.0000000e+00 1.3943693e-17 1.6757521e-15 3.2236776e-26], sum to 1.0000
[2019-03-26 18:49:37,434] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2005
[2019-03-26 18:49:37,440] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.36666666666667, 81.0, 1.0, 2.0, 0.740376489022167, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1034724.728228783, 1034724.728228783, 229799.892047152], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2352000.0000, 
sim time next is 2352600.0000, 
raw observation next is [27.5, 80.5, 1.0, 2.0, 0.7381116248727769, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1031557.89457807, 1031557.89457807, 229284.8295948375], 
processed observation next is [1.0, 0.21739130434782608, 0.5023696682464456, 0.805, 1.0, 1.0, 0.6844718371961168, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.28654385960501944, 0.28654385960501944, 0.34221616357438434], 
reward next is 0.6578, 
noisyNet noise sample is [array([0.79954195], dtype=float32), 0.66940874]. 
=============================================
[2019-03-26 18:49:37,678] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.5527864e-17 1.0000000e+00 8.4699249e-20 8.3827966e-17 2.0644553e-27], sum to 1.0000
[2019-03-26 18:49:37,686] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9957
[2019-03-26 18:49:37,693] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.98333333333333, 87.33333333333333, 1.0, 2.0, 0.5316337481787876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 742891.0211590385, 742891.0211590378, 188700.5452140872], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2581800.0000, 
sim time next is 2582400.0000, 
raw observation next is [26.86666666666667, 87.66666666666667, 1.0, 2.0, 0.5300133249570241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 740625.8949625496, 740625.8949625501, 188431.7795252927], 
processed observation next is [1.0, 0.9130434782608695, 0.4723538704581361, 0.8766666666666667, 1.0, 1.0, 0.4337509939241254, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20572941526737487, 0.20572941526737504, 0.2812414619780488], 
reward next is 0.7188, 
noisyNet noise sample is [array([-1.1329377], dtype=float32), -1.1446205]. 
=============================================
[2019-03-26 18:49:38,937] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.4903948e-15 1.0000000e+00 3.2204229e-17 2.6455373e-14 3.3849659e-25], sum to 1.0000
[2019-03-26 18:49:38,950] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8697
[2019-03-26 18:49:38,954] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.5, 82.0, 1.0, 2.0, 0.7319434201240673, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1022933.284611925, 1022933.284611925, 227889.9815868014], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2344800.0000, 
sim time next is 2345400.0000, 
raw observation next is [27.45, 82.0, 1.0, 2.0, 0.7306106543892296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1021069.771913284, 1021069.771913284, 227589.8395192572], 
processed observation next is [1.0, 0.13043478260869565, 0.5, 0.82, 1.0, 1.0, 0.6754345233605176, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2836304921981344, 0.2836304921981344, 0.33968632764068235], 
reward next is 0.6603, 
noisyNet noise sample is [array([-0.79018146], dtype=float32), 0.31664813]. 
=============================================
[2019-03-26 18:49:41,712] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-26 18:49:41,715] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 18:49:41,716] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 18:49:41,716] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:49:41,717] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:49:41,718] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 18:49:41,720] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 18:49:41,721] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:49:41,721] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:49:41,723] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 18:49:41,724] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:49:41,751] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run97
[2019-03-26 18:49:41,780] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run97
[2019-03-26 18:49:41,781] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run97
[2019-03-26 18:49:41,781] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run97
[2019-03-26 18:49:41,781] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run97
[2019-03-26 18:49:47,696] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.11176211], dtype=float32), 0.09708988]
[2019-03-26 18:49:47,697] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [23.52748131333334, 87.00851113166667, 1.0, 2.0, 0.3788041733781577, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 572091.927557537, 572091.9275575376, 172218.7282101418]
[2019-03-26 18:49:47,698] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 18:49:47,701] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.08544724e-17 1.00000000e+00 3.94594717e-21 3.10235321e-21
 3.63079473e-30], sampled 0.05693751464399466
[2019-03-26 18:50:04,813] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.11176211], dtype=float32), 0.09708988]
[2019-03-26 18:50:04,814] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.1, 70.83333333333333, 1.0, 2.0, 0.3193297649647241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 505849.6570974989, 505849.6570974996, 167481.0242273982]
[2019-03-26 18:50:04,817] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 18:50:04,819] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [8.5530856e-18 1.0000000e+00 2.6526624e-21 1.6918110e-21 2.0932462e-30], sampled 0.5648876814208263
[2019-03-26 18:50:54,759] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.11176211], dtype=float32), 0.09708988]
[2019-03-26 18:50:54,760] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.16666666666667, 63.0, 1.0, 2.0, 0.5227724539329466, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 730504.2237892565, 730504.2237892571, 187241.4677359061]
[2019-03-26 18:50:54,761] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 18:50:54,764] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.4249075e-17 1.0000000e+00 3.8331188e-20 1.1423778e-19 5.9179434e-29], sampled 0.5500747486617505
[2019-03-26 18:51:34,889] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 8045.2920 3147512299.5713 1319.0000
[2019-03-26 18:51:34,985] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8332.9407 2919923440.3563 1132.0000
[2019-03-26 18:51:35,037] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8553.6884 2834937993.8916 946.0000
[2019-03-26 18:51:35,206] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8152.9452 2990502160.5759 1336.0000
[2019-03-26 18:51:35,345] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8688.7247 2776178189.2528 857.0000
[2019-03-26 18:51:36,366] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 2400000, evaluation results [2400000.0, 8045.291999451967, 3147512299.571319, 1319.0, 8332.940657733325, 2919923440.356307, 1132.0, 8688.724680874, 2776178189.252815, 857.0, 8152.945213867393, 2990502160.575879, 1336.0, 8553.688365334448, 2834937993.8916354, 946.0]
[2019-03-26 18:51:37,796] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.7875018e-09 5.5108869e-01 4.4103690e-09 4.4891125e-01 1.1379393e-15], sum to 1.0000
[2019-03-26 18:51:37,801] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4587
[2019-03-26 18:51:37,810] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1953211.854682833 W.
[2019-03-26 18:51:37,814] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.6, 87.66666666666667, 1.0, 2.0, 0.7557973113015984, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.978070813449012, 6.9112, 168.9125581616496, 1953211.854682833, 1905771.509985537, 398194.905574151], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2454000.0000, 
sim time next is 2454600.0000, 
raw observation next is [26.5, 87.83333333333334, 1.0, 2.0, 0.7471629906857085, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.975335591763155, 6.9112, 168.9125201647585, 1941128.564095532, 1895628.685460247, 396268.963310868], 
processed observation next is [1.0, 0.391304347826087, 0.4549763033175356, 0.8783333333333334, 1.0, 1.0, 0.6953770972116969, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.00641355917631552, 0.0, 0.8294378024952908, 0.5392023789154256, 0.5265635237389575, 0.591446213896818], 
reward next is 0.0879, 
noisyNet noise sample is [array([0.77448577], dtype=float32), -0.11415166]. 
=============================================
[2019-03-26 18:51:39,112] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.4700591e-16 1.0000000e+00 5.4760054e-20 1.0065386e-19 5.0879813e-29], sum to 1.0000
[2019-03-26 18:51:39,126] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5038
[2019-03-26 18:51:39,133] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333333, 80.66666666666667, 1.0, 2.0, 0.485298489297006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 678122.6819250647, 678122.6819250641, 181324.6432164886], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2646600.0000, 
sim time next is 2647200.0000, 
raw observation next is [26.66666666666667, 82.33333333333334, 1.0, 2.0, 0.4869201134928406, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 680389.353542873, 680389.3535428736, 181572.1421513857], 
processed observation next is [0.0, 0.6521739130434783, 0.4628751974723541, 0.8233333333333335, 1.0, 1.0, 0.38183146203956697, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18899704265079806, 0.18899704265079822, 0.2710031972408742], 
reward next is 0.7290, 
noisyNet noise sample is [array([-0.76725966], dtype=float32), 0.753615]. 
=============================================
[2019-03-26 18:51:43,625] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.9870616e-15 1.0000000e+00 1.1937187e-17 3.3482151e-15 8.5493972e-26], sum to 1.0000
[2019-03-26 18:51:43,632] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2427
[2019-03-26 18:51:43,636] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.45, 95.0, 1.0, 2.0, 0.5464744912966144, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 763636.5397815894, 763636.53978159, 191197.9855881855], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2511000.0000, 
sim time next is 2511600.0000, 
raw observation next is [26.43333333333333, 95.0, 1.0, 2.0, 0.5453855525236866, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 762114.3246316728, 762114.3246316728, 191012.578711956], 
processed observation next is [1.0, 0.043478260869565216, 0.4518167456556081, 0.95, 1.0, 1.0, 0.45227175002853803, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.211698423508798, 0.211698423508798, 0.28509340106262093], 
reward next is 0.7149, 
noisyNet noise sample is [array([0.51064336], dtype=float32), -0.09667269]. 
=============================================
[2019-03-26 18:51:44,329] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.8425653e-18 1.0000000e+00 1.5938569e-21 9.8329237e-22 1.2337522e-30], sum to 1.0000
[2019-03-26 18:51:44,338] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2508
[2019-03-26 18:51:44,344] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.3940908348551822, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 588042.7687557265, 588042.7687557265, 173438.3489397802], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2736000.0000, 
sim time next is 2736600.0000, 
raw observation next is [23.0, 94.00000000000001, 1.0, 2.0, 0.3937624702918596, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 587552.7706215467, 587552.7706215472, 173393.5499916874], 
processed observation next is [0.0, 0.6956521739130435, 0.28909952606635075, 0.9400000000000002, 1.0, 1.0, 0.26959333770103566, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16320910295042962, 0.16320910295042979, 0.25879634327117523], 
reward next is 0.7412, 
noisyNet noise sample is [array([0.51274717], dtype=float32), 1.0270859]. 
=============================================
[2019-03-26 18:51:47,487] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.5204802e-16 1.0000000e+00 3.5195630e-19 4.7898911e-18 1.9574973e-27], sum to 1.0000
[2019-03-26 18:51:47,496] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3187
[2019-03-26 18:51:47,502] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.00000000000001, 1.0, 2.0, 0.3761291680270729, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 579419.5824085322, 579419.5824085322, 173170.0991402411], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2790600.0000, 
sim time next is 2791200.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.3665892650802927, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 564709.399389607, 564709.399389607, 171892.6060205585], 
processed observation next is [1.0, 0.30434782608695654, 0.2417061611374408, 0.94, 1.0, 1.0, 0.23685453624131653, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1568637220526686, 0.1568637220526686, 0.2565561283888933], 
reward next is 0.7434, 
noisyNet noise sample is [array([1.6852858], dtype=float32), -0.6868786]. 
=============================================
[2019-03-26 18:51:55,971] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.7053596e-18 1.0000000e+00 1.6442317e-21 4.3903984e-22 7.1030821e-31], sum to 1.0000
[2019-03-26 18:51:55,980] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0580
[2019-03-26 18:51:55,983] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 96.33333333333333, 1.0, 2.0, 0.4534449733144243, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 643519.5455527379, 643519.5455527373, 177903.3227030699], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2693400.0000, 
sim time next is 2694000.0000, 
raw observation next is [24.0, 96.66666666666666, 1.0, 2.0, 0.4566216174588393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 646834.9573899852, 646834.9573899852, 178213.6869454508], 
processed observation next is [0.0, 0.17391304347826086, 0.3364928909952607, 0.9666666666666666, 1.0, 1.0, 0.3453272499504088, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17967637705277367, 0.17967637705277367, 0.2659905775305236], 
reward next is 0.7340, 
noisyNet noise sample is [array([0.7460329], dtype=float32), -0.52005756]. 
=============================================
[2019-03-26 18:51:56,004] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[74.80642 ]
 [74.82224 ]
 [74.839935]
 [74.92992 ]
 [75.0322  ]], R is [[74.79442596]
 [74.78096008]
 [74.76789856]
 [74.75497437]
 [74.74225616]].
[2019-03-26 18:51:58,488] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.4395693e-18 1.0000000e+00 1.0768378e-21 5.2144204e-23 6.2406285e-31], sum to 1.0000
[2019-03-26 18:51:58,498] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5333
[2019-03-26 18:51:58,505] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 100.0, 1.0, 2.0, 0.3839574923437666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 578313.4703016501, 578313.4703016507, 172724.3242511957], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2726400.0000, 
sim time next is 2727000.0000, 
raw observation next is [22.0, 100.0, 1.0, 2.0, 0.384584214123953, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 579257.4708017122, 579257.4708017122, 172808.7553396233], 
processed observation next is [0.0, 0.5652173913043478, 0.2417061611374408, 1.0, 1.0, 1.0, 0.2585351977397024, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16090485300047563, 0.16090485300047563, 0.2579235154322736], 
reward next is 0.7421, 
noisyNet noise sample is [array([0.2256219], dtype=float32), -2.064627]. 
=============================================
[2019-03-26 18:51:58,517] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[77.3873  ]
 [77.3554  ]
 [77.30102 ]
 [77.23695 ]
 [77.216995]], R is [[77.38157654]
 [77.34996796]
 [77.31864929]
 [77.28762054]
 [77.25688171]].
[2019-03-26 18:51:58,743] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.1362335e-17 1.0000000e+00 6.5804968e-21 3.7809973e-20 2.7774626e-30], sum to 1.0000
[2019-03-26 18:51:58,755] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7913
[2019-03-26 18:51:58,759] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.0, 63.0, 1.0, 2.0, 0.5817942227358855, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 813010.7743443921, 813010.7743443914, 197403.8150358533], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3250800.0000, 
sim time next is 3251400.0000, 
raw observation next is [33.0, 63.0, 1.0, 2.0, 0.5912967650527855, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 826294.9804577488, 826294.9804577488, 199135.6507573434], 
processed observation next is [0.0, 0.6521739130434783, 0.7630331753554502, 0.63, 1.0, 1.0, 0.5075864639190186, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22952638346048576, 0.22952638346048576, 0.29721738919006474], 
reward next is 0.7028, 
noisyNet noise sample is [array([1.9449208], dtype=float32), -1.1418617]. 
=============================================
[2019-03-26 18:51:59,925] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.6000220e-17 1.0000000e+00 2.5482310e-20 8.4287973e-20 3.2674256e-29], sum to 1.0000
[2019-03-26 18:51:59,938] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9732
[2019-03-26 18:51:59,945] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 82.33333333333334, 1.0, 2.0, 0.5391602199958581, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 753412.044838922, 753412.0448389213, 189958.9602197447], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3270000.0000, 
sim time next is 3270600.0000, 
raw observation next is [28.0, 81.5, 1.0, 2.0, 0.5350485252847587, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 747664.420231969, 747664.4202319696, 189269.4674526293], 
processed observation next is [0.0, 0.8695652173913043, 0.5260663507109005, 0.815, 1.0, 1.0, 0.4398175003430827, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20768456117554693, 0.2076845611755471, 0.2824917424666109], 
reward next is 0.7175, 
noisyNet noise sample is [array([-1.041556], dtype=float32), -2.1424327]. 
=============================================
[2019-03-26 18:52:06,037] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.0816898e-17 1.0000000e+00 5.3491334e-20 1.9319496e-18 2.2149704e-29], sum to 1.0000
[2019-03-26 18:52:06,045] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6097
[2019-03-26 18:52:06,054] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.08333333333334, 99.5, 1.0, 2.0, 0.3084631333891708, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 490992.1554524192, 490992.1554524192, 166413.9369656206], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2923800.0000, 
sim time next is 2924400.0000, 
raw observation next is [20.16666666666667, 99.0, 1.0, 2.0, 0.308800462644727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 491248.2889387395, 491248.2889387395, 166428.6719962212], 
processed observation next is [1.0, 0.8695652173913043, 0.15481832543443946, 0.99, 1.0, 1.0, 0.16722947306593614, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13645785803853874, 0.13645785803853874, 0.24840100297943463], 
reward next is 0.7516, 
noisyNet noise sample is [array([0.6550317], dtype=float32), 2.3496182]. 
=============================================
[2019-03-26 18:52:08,461] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.0243180e-18 1.0000000e+00 1.2105470e-19 1.6539543e-17 1.3723042e-28], sum to 1.0000
[2019-03-26 18:52:08,471] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9851
[2019-03-26 18:52:08,479] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.4865236335153158, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 679835.1618634638, 679835.1618634638, 181511.5270902766], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3196800.0000, 
sim time next is 3197400.0000, 
raw observation next is [25.0, 94.00000000000001, 1.0, 2.0, 0.4865847357625614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 679920.5693278117, 679920.5693278117, 181520.8536546495], 
processed observation next is [0.0, 0.0, 0.38388625592417064, 0.9400000000000002, 1.0, 1.0, 0.3814273924850138, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18886682481328104, 0.18886682481328104, 0.2709266472457455], 
reward next is 0.7291, 
noisyNet noise sample is [array([0.9724388], dtype=float32), -2.4543338]. 
=============================================
[2019-03-26 18:52:09,084] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4079677e-16 1.0000000e+00 1.8507640e-19 3.7369084e-18 1.1705884e-27], sum to 1.0000
[2019-03-26 18:52:09,096] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5992
[2019-03-26 18:52:09,101] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 88.00000000000001, 1.0, 2.0, 0.6197742906219627, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 973746.0532342028, 973746.0532342022, 217192.9058727489], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2974200.0000, 
sim time next is 2974800.0000, 
raw observation next is [22.0, 88.0, 1.0, 2.0, 0.6031809713445242, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 947686.2622197444, 947686.2622197444, 213650.3070876373], 
processed observation next is [1.0, 0.43478260869565216, 0.2417061611374408, 0.88, 1.0, 1.0, 0.5219047847524387, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.263246183949929, 0.263246183949929, 0.31888105535468253], 
reward next is 0.6811, 
noisyNet noise sample is [array([1.008501], dtype=float32), -0.5771365]. 
=============================================
[2019-03-26 18:52:20,423] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.3051617e-17 1.0000000e+00 1.1537028e-19 8.9012098e-16 2.9503099e-28], sum to 1.0000
[2019-03-26 18:52:20,428] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0953
[2019-03-26 18:52:20,437] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.33333333333334, 68.66666666666667, 1.0, 2.0, 0.5355508790187717, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 748366.6449905266, 748366.6449905266, 189353.8163472899], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3612000.0000, 
sim time next is 3612600.0000, 
raw observation next is [30.0, 70.0, 1.0, 2.0, 0.5328923514161268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 744650.3766942059, 744650.3766942065, 188910.2693065414], 
processed observation next is [1.0, 0.8260869565217391, 0.6208530805687204, 0.7, 1.0, 1.0, 0.43721970050135756, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20684732685950163, 0.2068473268595018, 0.2819556258306588], 
reward next is 0.7180, 
noisyNet noise sample is [array([0.04988678], dtype=float32), 0.15379511]. 
=============================================
[2019-03-26 18:52:21,621] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.7573612e-16 1.0000000e+00 2.3335864e-19 1.0379203e-17 1.5075378e-28], sum to 1.0000
[2019-03-26 18:52:21,630] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7868
[2019-03-26 18:52:21,634] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 95.0, 1.0, 2.0, 0.4899618961641709, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 731826.4920069216, 731826.4920069216, 187885.1833561346], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3118200.0000, 
sim time next is 3118800.0000, 
raw observation next is [22.66666666666667, 96.0, 1.0, 2.0, 0.4120562059347619, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 616328.7094646657, 616328.7094646663, 176091.7326102006], 
processed observation next is [1.0, 0.08695652173913043, 0.27330173775671435, 0.96, 1.0, 1.0, 0.29163398305392996, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17120241929574048, 0.17120241929574065, 0.2628234815077621], 
reward next is 0.7372, 
noisyNet noise sample is [array([-0.77923965], dtype=float32), 2.1965039]. 
=============================================
[2019-03-26 18:52:29,011] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.4943253e-16 1.0000000e+00 2.9884863e-18 1.2377733e-15 2.5963224e-26], sum to 1.0000
[2019-03-26 18:52:29,020] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7347
[2019-03-26 18:52:29,029] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 76.5, 1.0, 2.0, 0.5078738109730786, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 709678.4187477212, 709678.4187477205, 184838.7104194204], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3544200.0000, 
sim time next is 3544800.0000, 
raw observation next is [28.0, 75.66666666666666, 1.0, 2.0, 0.5040244115696126, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 704297.6701225686, 704297.6701225693, 184228.735297169], 
processed observation next is [1.0, 0.0, 0.5260663507109005, 0.7566666666666666, 1.0, 1.0, 0.4024390500838706, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1956382417007135, 0.1956382417007137, 0.2749682616375657], 
reward next is 0.7250, 
noisyNet noise sample is [array([0.86817783], dtype=float32), 0.5497323]. 
=============================================
[2019-03-26 18:52:31,899] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-26 18:52:31,900] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 18:52:31,901] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 18:52:31,902] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:52:31,902] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:52:31,903] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 18:52:31,905] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 18:52:31,907] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:52:31,909] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:52:31,905] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 18:52:31,911] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:52:31,936] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run98
[2019-03-26 18:52:31,964] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run98
[2019-03-26 18:52:31,964] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run98
[2019-03-26 18:52:31,965] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run98
[2019-03-26 18:52:32,031] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run98
[2019-03-26 18:52:35,704] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.11147813], dtype=float32), 0.09675803]
[2019-03-26 18:52:35,705] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [21.3, 75.0, 1.0, 2.0, 0.2601410734814552, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 427367.1385630933, 427367.1385630927, 161926.5910670688]
[2019-03-26 18:52:35,708] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 18:52:35,711] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [8.7083490e-18 1.0000000e+00 2.0466151e-21 5.9880399e-23 2.4621602e-30], sampled 0.7390641020851162
[2019-03-26 18:52:36,056] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.11147813], dtype=float32), 0.09675803]
[2019-03-26 18:52:36,057] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [18.67444578166667, 93.83983068333333, 1.0, 2.0, 0.2586897897675939, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 425645.423334459, 425645.4233344583, 161771.7830524036]
[2019-03-26 18:52:36,057] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:52:36,060] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [6.48071029e-18 1.00000000e+00 1.76817348e-21 1.61048604e-22
 1.47328845e-30], sampled 0.5072505941867707
[2019-03-26 18:52:48,496] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.11147813], dtype=float32), 0.09675803]
[2019-03-26 18:52:48,497] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [21.06666666666667, 91.66666666666666, 1.0, 2.0, 0.3142273307158396, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 499430.771945514, 499430.7719455134, 167025.9485425495]
[2019-03-26 18:52:48,499] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 18:52:48,501] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.1091212e-17 1.0000000e+00 3.9014935e-21 5.7243680e-22 4.9475861e-30], sampled 0.6594903267104583
[2019-03-26 18:52:55,207] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.11147813], dtype=float32), 0.09675803]
[2019-03-26 18:52:55,209] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [21.75307416, 93.675213705, 1.0, 2.0, 0.3517662291641466, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 546331.0131364572, 546331.0131364566, 170458.4280673398]
[2019-03-26 18:52:55,211] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 18:52:55,214] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.2690790e-17 1.0000000e+00 2.2825471e-20 2.4949145e-20 3.4476945e-29], sampled 0.917043886327989
[2019-03-26 18:53:16,051] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.11147813], dtype=float32), 0.09675803]
[2019-03-26 18:53:16,054] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [19.92676919833333, 84.50623720500002, 1.0, 2.0, 0.2470495994764124, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 406661.1462913475, 406661.1462913468, 160610.6462491942]
[2019-03-26 18:53:16,054] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:53:16,056] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.77383837e-17 1.00000000e+00 6.59776503e-21 1.07699804e-21
 1.05403355e-29], sampled 0.42125267304352876
[2019-03-26 18:53:48,800] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.11147813], dtype=float32), 0.09675803]
[2019-03-26 18:53:48,804] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.5, 77.0, 1.0, 2.0, 0.5630153313912694, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 786759.0606302316, 786759.0606302322, 194057.7410233389]
[2019-03-26 18:53:48,805] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 18:53:48,809] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.3633953e-16 1.0000000e+00 4.2073872e-19 9.4108355e-18 1.7173862e-27], sampled 0.014130957866878124
[2019-03-26 18:54:08,249] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.11147813], dtype=float32), 0.09675803]
[2019-03-26 18:54:08,250] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.71666666666667, 94.0, 1.0, 2.0, 0.500733783712295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 699698.002411956, 699698.0024119554, 183709.6590564825]
[2019-03-26 18:54:08,251] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 18:54:08,253] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [7.8924108e-17 1.0000000e+00 6.3178401e-20 9.9830948e-20 1.7718672e-28], sampled 0.27713831309550674
[2019-03-26 18:54:12,996] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.11147813], dtype=float32), 0.09675803]
[2019-03-26 18:54:12,999] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.26666666666667, 92.0, 1.0, 2.0, 0.5347695021629733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 747274.3826343121, 747274.3826343121, 189222.3388421227]
[2019-03-26 18:54:13,000] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:54:13,002] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [9.3618932e-17 1.0000000e+00 1.0813711e-19 1.3070131e-18 2.9785693e-28], sampled 0.0992225254486182
[2019-03-26 18:54:24,331] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.11147813], dtype=float32), 0.09675803]
[2019-03-26 18:54:24,333] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.1, 59.0, 1.0, 2.0, 0.2981128611571281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 480925.6622666058, 480925.6622666065, 165722.9554832788]
[2019-03-26 18:54:24,334] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 18:54:24,338] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0267521e-17 1.0000000e+00 4.3263751e-21 3.6246949e-21 4.5167360e-30], sampled 0.3168252693228669
[2019-03-26 18:54:24,603] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.11147813], dtype=float32), 0.09675803]
[2019-03-26 18:54:24,604] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.79482053333333, 68.94461096333333, 1.0, 2.0, 0.932110872597641, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1343796.158155267, 1343796.158155267, 285048.9734738913]
[2019-03-26 18:54:24,606] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:54:24,607] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.0000501e-15 1.0000000e+00 2.0689044e-17 1.0604217e-14 1.9751563e-25], sampled 0.5676382219480819
[2019-03-26 18:54:25,437] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8681.9935 2776615551.3327 870.0000
[2019-03-26 18:54:25,730] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8325.4357 2920376648.3763 1150.0000
[2019-03-26 18:54:25,792] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8125.5095 2992437030.8219 1383.0000
[2019-03-26 18:54:25,932] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 8017.8792 3148881891.6204 1366.0000
[2019-03-26 18:54:25,936] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8549.9633 2836236121.2595 968.0000
[2019-03-26 18:54:26,955] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 2425000, evaluation results [2425000.0, 8017.879159951314, 3148881891.620428, 1366.0, 8325.435748038626, 2920376648.376282, 1150.0, 8681.993465333238, 2776615551.3327265, 870.0, 8125.509526806234, 2992437030.8218946, 1383.0, 8549.96328742841, 2836236121.2594604, 968.0]
[2019-03-26 18:54:27,731] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.62354372e-17 1.00000000e+00 1.13489325e-20 2.63847432e-20
 1.86038829e-29], sum to 1.0000
[2019-03-26 18:54:27,740] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6605
[2019-03-26 18:54:27,754] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 83.0, 1.0, 2.0, 0.4209428935094727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 616340.1499663205, 616340.1499663205, 175742.8214674003], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3304200.0000, 
sim time next is 3304800.0000, 
raw observation next is [25.0, 83.0, 1.0, 2.0, 0.421087259009552, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 616551.6015760098, 616551.6015760098, 175763.073442786], 
processed observation next is [0.0, 0.2608695652173913, 0.38388625592417064, 0.83, 1.0, 1.0, 0.3025147698910265, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17126433377111383, 0.17126433377111383, 0.26233294543699404], 
reward next is 0.7377, 
noisyNet noise sample is [array([-1.815435], dtype=float32), 0.7024221]. 
=============================================
[2019-03-26 18:54:29,665] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0006874e-14 1.0000000e+00 2.4629187e-17 1.7579971e-14 2.0371316e-25], sum to 1.0000
[2019-03-26 18:54:29,673] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5965
[2019-03-26 18:54:29,683] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 91.5, 1.0, 2.0, 0.8671886007029677, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1212054.125597888, 1212054.125597888, 261072.4786098207], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4084200.0000, 
sim time next is 4084800.0000, 
raw observation next is [27.0, 92.33333333333334, 1.0, 2.0, 0.7889234493354715, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1102607.515297357, 1102607.515297357, 241211.4365035613], 
processed observation next is [1.0, 0.2608695652173913, 0.4786729857819906, 0.9233333333333335, 1.0, 1.0, 0.7456909028138211, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.30627986536037693, 0.30627986536037693, 0.36001706940830047], 
reward next is 0.6400, 
noisyNet noise sample is [array([-0.27340895], dtype=float32), 1.4780217]. 
=============================================
[2019-03-26 18:54:36,899] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.2487823e-17 1.0000000e+00 2.7502765e-19 5.0209145e-17 6.0391116e-28], sum to 1.0000
[2019-03-26 18:54:36,909] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4259
[2019-03-26 18:54:36,929] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 74.0, 1.0, 2.0, 0.4916570767816245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 687010.6072135383, 687010.6072135377, 182299.063737542], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3711000.0000, 
sim time next is 3711600.0000, 
raw observation next is [28.0, 74.0, 1.0, 2.0, 0.4912694198786736, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 686468.7448684189, 686468.7448684195, 182239.3287825253], 
processed observation next is [1.0, 1.0, 0.5260663507109005, 0.74, 1.0, 1.0, 0.38707159021526943, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1906857624634497, 0.19068576246344984, 0.2719989981828736], 
reward next is 0.7280, 
noisyNet noise sample is [array([2.1734567], dtype=float32), 0.2713621]. 
=============================================
[2019-03-26 18:54:37,712] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.6927582e-15 1.0000000e+00 4.2143148e-17 2.3549471e-14 1.3017745e-24], sum to 1.0000
[2019-03-26 18:54:37,723] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6365
[2019-03-26 18:54:37,731] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 74.0, 1.0, 2.0, 0.8173905210953945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1142414.789522128, 1142414.789522127, 248221.2262875607], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3484800.0000, 
sim time next is 3485400.0000, 
raw observation next is [28.33333333333334, 72.66666666666667, 1.0, 2.0, 0.766257362419957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1070913.185520441, 1070913.185520442, 235794.0377384329], 
processed observation next is [1.0, 0.34782608695652173, 0.5418641390205374, 0.7266666666666667, 1.0, 1.0, 0.718382364361394, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.29747588486678916, 0.29747588486678944, 0.35193139960960135], 
reward next is 0.6481, 
noisyNet noise sample is [array([1.2599425], dtype=float32), -0.57656276]. 
=============================================
[2019-03-26 18:54:46,117] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.21426111e-12 8.92994925e-04 2.35205796e-11 9.99106944e-01
 1.02653974e-17], sum to 1.0000
[2019-03-26 18:54:46,126] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8713
[2019-03-26 18:54:46,132] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.0, 59.0, 1.0, 2.0, 0.9796748494341041, 1.0, 2.0, 0.9796748494341041, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2740389.13315385, 2740389.133153849, 516820.5969148087], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3685800.0000, 
sim time next is 3686400.0000, 
raw observation next is [33.0, 59.0, 1.0, 2.0, 0.945499664683147, 1.0, 2.0, 0.945499664683147, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2644691.634900093, 2644691.634900093, 496920.3643673559], 
processed observation next is [1.0, 0.6956521739130435, 0.7630331753554502, 0.59, 1.0, 1.0, 0.9343369454013819, 1.0, 1.0, 0.9343369454013819, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7346365652500259, 0.7346365652500259, 0.7416721856229193], 
reward next is 0.2583, 
noisyNet noise sample is [array([-0.67746836], dtype=float32), -0.039350502]. 
=============================================
[2019-03-26 18:54:50,255] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.10896604e-11 7.05392100e-04 3.43891304e-11 9.99294639e-01
 1.90098314e-17], sum to 1.0000
[2019-03-26 18:54:50,265] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9546
[2019-03-26 18:54:50,272] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.0, 59.0, 1.0, 2.0, 0.8675780727728671, 1.0, 2.0, 0.8675780727728671, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2426522.665736567, 2426522.665736567, 454111.5500424092], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3679800.0000, 
sim time next is 3680400.0000, 
raw observation next is [33.0, 59.0, 1.0, 2.0, 0.88268415174745, 1.0, 2.0, 0.88268415174745, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2468814.483233926, 2468814.483233926, 462131.8775371061], 
processed observation next is [1.0, 0.6086956521739131, 0.7630331753554502, 0.59, 1.0, 1.0, 0.858655604515, 1.0, 1.0, 0.858655604515, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6857818008983128, 0.6857818008983128, 0.6897490709509047], 
reward next is 0.3103, 
noisyNet noise sample is [array([-0.09812766], dtype=float32), -0.53679484]. 
=============================================
[2019-03-26 18:54:51,853] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.2197687e-16 1.0000000e+00 5.9880723e-20 2.4568448e-19 2.7480196e-28], sum to 1.0000
[2019-03-26 18:54:51,862] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5111
[2019-03-26 18:54:51,870] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.33333333333334, 73.66666666666666, 1.0, 2.0, 0.6007832373284243, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 839556.8869685862, 839556.8869685855, 200892.2111110543], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3919200.0000, 
sim time next is 3919800.0000, 
raw observation next is [31.66666666666667, 72.33333333333334, 1.0, 2.0, 0.6032727929619313, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 843037.2654826796, 843037.2654826796, 201357.582725948], 
processed observation next is [0.0, 0.34782608695652173, 0.6998420221169038, 0.7233333333333334, 1.0, 1.0, 0.5220154132071461, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2341770181896332, 0.2341770181896332, 0.3005337055611164], 
reward next is 0.6995, 
noisyNet noise sample is [array([0.37867033], dtype=float32), -0.18460612]. 
=============================================
[2019-03-26 18:55:01,233] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.2298927e-18 1.0000000e+00 6.4328466e-20 3.4572374e-17 7.1573017e-28], sum to 1.0000
[2019-03-26 18:55:01,243] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2404
[2019-03-26 18:55:01,250] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 79.0, 1.0, 2.0, 0.6196549133722872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 865939.6209307091, 865939.6209307091, 204465.4127909181], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4312800.0000, 
sim time next is 4313400.0000, 
raw observation next is [31.0, 79.00000000000001, 1.0, 2.0, 0.6225927536582418, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 870046.8009729541, 870046.8009729536, 205030.9167263089], 
processed observation next is [1.0, 0.9565217391304348, 0.6682464454976303, 0.7900000000000001, 1.0, 1.0, 0.5452924742870383, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.24167966693693171, 0.24167966693693155, 0.30601629362135657], 
reward next is 0.6940, 
noisyNet noise sample is [array([0.0347819], dtype=float32), 0.35932827]. 
=============================================
[2019-03-26 18:55:08,327] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.4808077e-12 1.6845119e-03 2.0487896e-11 9.9831545e-01 3.2194164e-17], sum to 1.0000
[2019-03-26 18:55:08,335] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5921
[2019-03-26 18:55:08,342] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [36.0, 54.33333333333334, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 7.114583578126186, 6.9112, 170.5573041426782, 3055191.377873703, 2909499.447746908, 552591.0747311102], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4195200.0000, 
sim time next is 4195800.0000, 
raw observation next is [36.0, 55.0, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 7.843665774258208, 6.9112, 170.5573041426782, 3578071.028772436, 2910107.864388696, 548321.6895945467], 
processed observation next is [1.0, 0.5652173913043478, 0.9052132701421801, 0.55, 1.0, 1.0, 1.0481927710843375, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.2195121951219512, 0.09324657742582083, 0.0, 0.8375144448122397, 0.9939086191034545, 0.8083632956635266, 0.818390581484398], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.60321134], dtype=float32), 0.27462062]. 
=============================================
[2019-03-26 18:55:10,285] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.4503524e-16 1.0000000e+00 2.2976277e-18 6.8272198e-15 3.1020834e-27], sum to 1.0000
[2019-03-26 18:55:10,294] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0753
[2019-03-26 18:55:10,299] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.5, 73.0, 1.0, 2.0, 0.6022286390928935, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 841577.5454832029, 841577.5454832029, 201162.1590519047], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4228200.0000, 
sim time next is 4228800.0000, 
raw observation next is [31.33333333333333, 73.66666666666667, 1.0, 2.0, 0.6003760123385354, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 838987.5908322779, 838987.5908322772, 200816.3024063902], 
processed observation next is [1.0, 0.9565217391304348, 0.6840442338072668, 0.7366666666666667, 1.0, 1.0, 0.5185253160705245, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.23305210856452163, 0.23305210856452144, 0.2997258244871496], 
reward next is 0.7003, 
noisyNet noise sample is [array([0.36328116], dtype=float32), -0.5835756]. 
=============================================
[2019-03-26 18:55:18,620] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.02786164e-16 1.00000000e+00 1.12191579e-19 1.12521185e-19
 5.11349278e-28], sum to 1.0000
[2019-03-26 18:55:18,627] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5863
[2019-03-26 18:55:18,632] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.66666666666667, 67.66666666666667, 1.0, 2.0, 0.5570139373287976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 778369.6244875496, 778369.6244875503, 193009.9096949909], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4459200.0000, 
sim time next is 4459800.0000, 
raw observation next is [30.33333333333333, 66.83333333333333, 1.0, 2.0, 0.5417347371058826, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 757010.9071168598, 757010.9071168598, 190392.2489773461], 
processed observation next is [0.0, 0.6086956521739131, 0.6366508688783569, 0.6683333333333333, 1.0, 1.0, 0.4478731772360031, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21028080753246106, 0.21028080753246106, 0.28416753578708376], 
reward next is 0.7158, 
noisyNet noise sample is [array([-0.34637025], dtype=float32), 2.6917396]. 
=============================================
[2019-03-26 18:55:22,556] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.2913169e-12 1.3726548e-05 2.7801650e-11 9.9998629e-01 6.4851999e-17], sum to 1.0000
[2019-03-26 18:55:22,562] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1521
[2019-03-26 18:55:22,571] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 3 has been changed to 4 for the demand 3460593.470811557 W.
[2019-03-26 18:55:22,577] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.83333333333334, 71.66666666666667, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 7.679859859014265, 6.9112, 170.5573041426782, 3460593.470811557, 2909971.146715668, 549362.7984633737], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4269000.0000, 
sim time next is 4269600.0000, 
raw observation next is [34.0, 71.0, 1.0, 2.0, 0.8807667309107523, 1.0, 2.0, 0.7609734049696387, 1.0, 1.0, 1.03, 7.005111989775698, 6.9112, 170.5573041426782, 3193520.433873883, 3126247.455502049, 584508.1345444643], 
processed observation next is [1.0, 0.43478260869565216, 0.8104265402843602, 0.71, 1.0, 1.0, 0.8563454589286172, 1.0, 1.0, 0.7120161505658298, 1.0, 0.5, 1.0365853658536586, 0.009391198977569815, 0.0, 0.8375144448122397, 0.8870890094094119, 0.8684020709727914, 0.8724002008126333], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2582662], dtype=float32), 0.46870658]. 
=============================================
[2019-03-26 18:55:22,693] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-26 18:55:22,694] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 18:55:22,697] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 18:55:22,698] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 18:55:22,697] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 18:55:22,699] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:55:22,700] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:55:22,699] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 18:55:22,698] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:55:22,703] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:55:22,701] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:55:22,730] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run99
[2019-03-26 18:55:22,755] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run99
[2019-03-26 18:55:22,778] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run99
[2019-03-26 18:55:22,810] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run99
[2019-03-26 18:55:22,811] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run99
[2019-03-26 18:55:23,940] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.11078822], dtype=float32), 0.096087985]
[2019-03-26 18:55:23,942] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.51666666666667, 81.50000000000001, 1.0, 2.0, 0.3855761594722787, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 578756.9998621198, 578756.9998621204, 172703.365321683]
[2019-03-26 18:55:23,946] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 18:55:23,948] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.9757697e-17 1.0000000e+00 1.8402523e-20 2.8801847e-21 3.2782626e-29], sampled 0.07112010395192658
[2019-03-26 18:55:33,235] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.11078822], dtype=float32), 0.096087985]
[2019-03-26 18:55:33,237] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.859232575, 63.993716015, 1.0, 2.0, 0.4560880708334998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 735514.5265270885, 735514.5265270885, 187731.9766060055]
[2019-03-26 18:55:33,239] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:55:33,241] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.1704585e-17 1.0000000e+00 1.8745018e-20 2.9874218e-21 3.7606978e-29], sampled 0.599308935232179
[2019-03-26 18:55:35,887] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.11078822], dtype=float32), 0.096087985]
[2019-03-26 18:55:35,888] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [24.9, 88.66666666666667, 1.0, 2.0, 0.4575362190667369, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 651900.7227056501, 651900.7227056501, 178828.7784240585]
[2019-03-26 18:55:35,889] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:55:35,892] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.6136572e-17 1.0000000e+00 9.4337525e-21 3.1353926e-21 1.1733859e-29], sampled 0.6272246809861766
[2019-03-26 18:55:41,170] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.11078822], dtype=float32), 0.096087985]
[2019-03-26 18:55:41,172] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [22.21666666666667, 68.33333333333333, 1.0, 2.0, 0.2659366302177055, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 437021.9839436618, 437021.9839436618, 162522.8477358853]
[2019-03-26 18:55:41,175] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 18:55:41,179] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [8.5950162e-18 1.0000000e+00 3.7448801e-21 8.6175206e-22 3.6810562e-30], sampled 0.7687896359678067
[2019-03-26 18:55:50,501] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.11078822], dtype=float32), 0.096087985]
[2019-03-26 18:55:50,502] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.0, 85.5, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.547369398585685, 6.9112, 168.9094757314774, 1905375.224111458, 1454064.057827085, 311349.2422568751]
[2019-03-26 18:55:50,505] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 18:55:50,510] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.3344177e-11 9.9999738e-01 4.7506786e-12 2.6515374e-06 4.2097843e-19], sampled 0.12615288431145177
[2019-03-26 18:55:50,511] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1905375.224111458 W.
[2019-03-26 18:56:13,921] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.11078822], dtype=float32), 0.096087985]
[2019-03-26 18:56:13,925] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [27.0, 81.66666666666667, 1.0, 2.0, 0.511421651181599, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 714637.66751218, 714637.6675121794, 185404.0945686696]
[2019-03-26 18:56:13,927] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:56:13,930] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.0891331e-17 1.0000000e+00 3.4039833e-20 1.6803832e-19 5.0293569e-29], sampled 0.8887076163153507
[2019-03-26 18:56:31,485] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.11078822], dtype=float32), 0.096087985]
[2019-03-26 18:56:31,488] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [30.1608947, 79.9106425, 1.0, 2.0, 0.8044046692716293, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1124255.681397919, 1124255.68139792, 244999.6218817541]
[2019-03-26 18:56:31,490] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:56:31,492] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [4.2119222e-16 1.0000000e+00 1.1713174e-18 1.1473401e-17 5.7389808e-27], sampled 0.5122426619031424
[2019-03-26 18:56:55,942] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.11078822], dtype=float32), 0.096087985]
[2019-03-26 18:56:55,944] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.29206466, 68.938862725, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.501384873133931, 6.9112, 168.9096350116509, 1872730.937270821, 1454041.708926932, 311348.3308500092]
[2019-03-26 18:56:55,945] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:56:55,948] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [9.2737219e-14 1.0000000e+00 1.3848133e-15 3.9104141e-12 2.8188985e-23], sampled 0.1553808472135536
[2019-03-26 18:56:55,950] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1872730.937270821 W.
[2019-03-26 18:57:09,395] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.11078822], dtype=float32), 0.096087985]
[2019-03-26 18:57:09,396] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [22.72953568, 94.72180210666666, 1.0, 2.0, 0.4043746406301829, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 610156.3972483334, 610156.3972483327, 175648.5876234971]
[2019-03-26 18:57:09,397] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 18:57:09,402] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.7774014e-17 1.0000000e+00 1.0355577e-20 2.0502096e-21 1.5732517e-29], sampled 0.5665576360884041
[2019-03-26 18:57:16,268] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.11078822], dtype=float32), 0.096087985]
[2019-03-26 18:57:16,269] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [25.18333333333333, 58.0, 1.0, 2.0, 0.2929367366952576, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 473052.244718896, 473052.2447188966, 165167.5521193472]
[2019-03-26 18:57:16,271] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:57:16,274] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.3871063e-17 1.0000000e+00 1.8537449e-20 1.9266928e-20 2.2713580e-29], sampled 0.14834320514740462
[2019-03-26 18:57:16,890] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8539.2867 2836807391.1426 983.0000
[2019-03-26 18:57:16,971] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8679.7422 2777157738.9518 874.0000
[2019-03-26 18:57:17,008] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 8010.4976 3150173484.0532 1403.0000
[2019-03-26 18:57:17,052] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8314.5315 2920775908.8634 1163.0000
[2019-03-26 18:57:17,082] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8120.4384 2993523318.3941 1416.0000
[2019-03-26 18:57:18,101] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 2450000, evaluation results [2450000.0, 8010.497572926138, 3150173484.0532246, 1403.0, 8314.53148014083, 2920775908.863413, 1163.0, 8679.742182388303, 2777157738.9518065, 874.0, 8120.438432839592, 2993523318.3941355, 1416.0, 8539.286712256688, 2836807391.1426306, 983.0]
[2019-03-26 18:57:22,802] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.3606288e-18 1.0000000e+00 1.6848625e-20 5.1764409e-18 2.5140298e-29], sum to 1.0000
[2019-03-26 18:57:22,809] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8754
[2019-03-26 18:57:22,815] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.33333333333334, 65.66666666666667, 1.0, 2.0, 0.6086404693265061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 850541.2721576737, 850541.2721576737, 202367.6636673483], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4308000.0000, 
sim time next is 4308600.0000, 
raw observation next is [33.16666666666666, 66.33333333333333, 1.0, 2.0, 0.6085318629347393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 850389.4399952731, 850389.4399952731, 202347.0812606724], 
processed observation next is [1.0, 0.8695652173913043, 0.7709320695102682, 0.6633333333333333, 1.0, 1.0, 0.5283516420900473, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23621928888757587, 0.23621928888757587, 0.30201056904577966], 
reward next is 0.6980, 
noisyNet noise sample is [array([0.6640184], dtype=float32), -1.1929789]. 
=============================================
[2019-03-26 18:57:25,986] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.3293238e-17 1.0000000e+00 2.6323519e-20 5.0742619e-20 2.5333222e-29], sum to 1.0000
[2019-03-26 18:57:25,991] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7046
[2019-03-26 18:57:25,998] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666667, 85.66666666666667, 1.0, 2.0, 0.5162255930472541, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 721352.7595897908, 721352.7595897908, 186176.7387330674], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4490400.0000, 
sim time next is 4491000.0000, 
raw observation next is [26.5, 86.5, 1.0, 2.0, 0.5142657200147461, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 718613.1859502372, 718613.1859502365, 185860.829198575], 
processed observation next is [0.0, 1.0, 0.4549763033175356, 0.865, 1.0, 1.0, 0.4147779759213808, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1996147738750659, 0.1996147738750657, 0.2774042226844403], 
reward next is 0.7226, 
noisyNet noise sample is [array([-2.3016121], dtype=float32), 0.11234143]. 
=============================================
[2019-03-26 18:57:26,042] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[74.375465]
 [74.333855]
 [74.26808 ]
 [74.188225]
 [74.15157 ]], R is [[74.39027405]
 [74.36849213]
 [74.34642792]
 [74.32387543]
 [74.30023193]].
[2019-03-26 18:57:34,220] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.7874847e-17 1.0000000e+00 4.0699183e-20 3.3323556e-20 5.5540088e-29], sum to 1.0000
[2019-03-26 18:57:34,228] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2268
[2019-03-26 18:57:34,234] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [34.0, 50.5, 1.0, 2.0, 0.5416952461503156, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 756955.7034645606, 756955.7034645611, 190385.9096379447], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4543800.0000, 
sim time next is 4544400.0000, 
raw observation next is [34.0, 51.0, 1.0, 2.0, 0.5252597767891714, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 733981.1239060323, 733981.1239060316, 187649.1260269228], 
processed observation next is [0.0, 0.6086956521739131, 0.8104265402843602, 0.51, 1.0, 1.0, 0.42802382745683293, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20388364552945343, 0.20388364552945323, 0.280073322428243], 
reward next is 0.7199, 
noisyNet noise sample is [array([0.83570176], dtype=float32), 0.96045595]. 
=============================================
[2019-03-26 18:57:39,386] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.0441791e-10 5.5384148e-02 2.4410060e-10 9.4461584e-01 8.7283652e-18], sum to 1.0000
[2019-03-26 18:57:39,394] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9124
[2019-03-26 18:57:39,398] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.83333333333334, 67.5, 1.0, 2.0, 0.7745611870992664, 1.0, 2.0, 0.7745611870992664, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2166132.24728358, 2166132.247283581, 407675.9155693157], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4716600.0000, 
sim time next is 4717200.0000, 
raw observation next is [30.66666666666667, 69.0, 1.0, 2.0, 0.7808725648467861, 1.0, 2.0, 0.7808725648467861, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2183800.593364415, 2183800.593364415, 410666.456002394], 
processed observation next is [1.0, 0.6086956521739131, 0.6524486571879939, 0.69, 1.0, 1.0, 0.7359910419840797, 1.0, 1.0, 0.7359910419840797, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6066112759345598, 0.6066112759345598, 0.612935008958797], 
reward next is 0.3871, 
noisyNet noise sample is [array([-0.26419112], dtype=float32), 0.59992933]. 
=============================================
[2019-03-26 18:57:41,390] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.1369007e-17 1.0000000e+00 4.7760954e-19 7.9247218e-17 3.9494119e-28], sum to 1.0000
[2019-03-26 18:57:41,397] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2942
[2019-03-26 18:57:41,402] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.5093125521134234, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 711689.5198407974, 711689.5198407968, 185068.074878838], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4920000.0000, 
sim time next is 4920600.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.5095323512195129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 711996.7597552518, 711996.7597552518, 185103.113205666], 
processed observation next is [1.0, 0.9565217391304348, 0.4786729857819906, 0.84, 1.0, 1.0, 0.4090751219512203, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19777687770979216, 0.19777687770979216, 0.2762733032920388], 
reward next is 0.7237, 
noisyNet noise sample is [array([0.667595], dtype=float32), 0.5830898]. 
=============================================
[2019-03-26 18:57:45,916] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.11574831e-17 1.00000000e+00 8.38790157e-20 1.03065265e-17
 2.12126334e-27], sum to 1.0000
[2019-03-26 18:57:45,925] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2180
[2019-03-26 18:57:45,929] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 74.0, 1.0, 2.0, 0.4935206361137114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 689615.4727992949, 689615.4727992954, 182586.8451089793], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4828200.0000, 
sim time next is 4828800.0000, 
raw observation next is [28.0, 74.0, 1.0, 2.0, 0.4922288899963707, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 687809.8816305388, 687809.8816305388, 182387.2570110616], 
processed observation next is [1.0, 0.9130434782608695, 0.5260663507109005, 0.74, 1.0, 1.0, 0.38822757830888033, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19105830045292746, 0.19105830045292746, 0.272219786583674], 
reward next is 0.7278, 
noisyNet noise sample is [array([-1.5061125], dtype=float32), 1.5095433]. 
=============================================
[2019-03-26 18:57:47,026] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.3339324e-16 1.0000000e+00 2.6282695e-19 7.0866466e-18 1.1830458e-27], sum to 1.0000
[2019-03-26 18:57:47,034] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9225
[2019-03-26 18:57:47,038] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.08333333333334, 84.0, 1.0, 2.0, 0.4821069802189829, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 673661.6729216995, 673661.6729216989, 180839.6229727611], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5014200.0000, 
sim time next is 5014800.0000, 
raw observation next is [26.0, 84.0, 1.0, 2.0, 0.4792585827153151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 669680.2722406677, 669680.2722406677, 180409.6123663083], 
processed observation next is [0.0, 0.043478260869565216, 0.4312796208530806, 0.84, 1.0, 1.0, 0.37260070206664464, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18602229784462992, 0.18602229784462992, 0.2692680781586691], 
reward next is 0.7307, 
noisyNet noise sample is [array([-1.5857663], dtype=float32), -0.44415936]. 
=============================================
[2019-03-26 18:57:51,904] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.8331208e-11 3.2177456e-03 5.9482408e-10 9.9678218e-01 6.0102853e-16], sum to 1.0000
[2019-03-26 18:57:51,911] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5774
[2019-03-26 18:57:51,921] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 66.0, 1.0, 2.0, 0.7426961125940024, 1.0, 2.0, 0.7426961125940024, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2076932.217977459, 2076932.21797746, 392937.0289240495], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4878600.0000, 
sim time next is 4879200.0000, 
raw observation next is [31.0, 66.0, 1.0, 2.0, 0.7776803028388825, 1.0, 2.0, 0.7776803028388825, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2174863.999472658, 2174863.999472658, 409149.7679903282], 
processed observation next is [1.0, 0.4782608695652174, 0.6682464454976303, 0.66, 1.0, 1.0, 0.7321449431793764, 1.0, 1.0, 0.7321449431793764, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.604128888742405, 0.604128888742405, 0.6106712955079525], 
reward next is 0.3893, 
noisyNet noise sample is [array([0.44141698], dtype=float32), 1.3997425]. 
=============================================
[2019-03-26 18:57:52,925] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.5341127e-16 9.1000962e-10 4.2930333e-14 1.0000000e+00 1.0379509e-19], sum to 1.0000
[2019-03-26 18:57:52,935] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1017
[2019-03-26 18:57:52,940] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [35.96666666666667, 53.33333333333334, 1.0, 2.0, 0.864880441195356, 1.0, 2.0, 0.7530302601119404, 1.0, 1.0, 1.03, 7.005110736428587, 6.9112, 170.5573041426782, 3160143.853454562, 3092871.772906246, 578465.9558366762], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5329200.0000, 
sim time next is 5329800.0000, 
raw observation next is [35.95, 53.5, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 7.412159344379479, 6.9112, 170.5573041426782, 3268605.299060037, 2909747.742957758, 550947.367707111], 
processed observation next is [1.0, 0.6956521739130435, 0.9028436018957348, 0.535, 1.0, 1.0, 1.0481927710843375, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.2195121951219512, 0.05009593443794787, 0.0, 0.8375144448122397, 0.9079459164055658, 0.8082632619327105, 0.8223095040404642], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.86513245], dtype=float32), -0.96409225]. 
=============================================
[2019-03-26 18:57:55,864] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.9166547e-15 1.0000000e+00 1.4674760e-17 6.6999438e-16 6.6050510e-26], sum to 1.0000
[2019-03-26 18:57:55,879] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7774
[2019-03-26 18:57:55,884] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 79.0, 1.0, 2.0, 0.7316039499709531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1022458.62703462, 1022458.62703462, 227813.60955987], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4867200.0000, 
sim time next is 4867800.0000, 
raw observation next is [28.16666666666667, 78.16666666666667, 1.0, 2.0, 0.8029879221334711, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1122274.554489039, 1122274.554489039, 244644.3791342582], 
processed observation next is [1.0, 0.34782608695652173, 0.5339652448657191, 0.7816666666666667, 1.0, 1.0, 0.7626360507632183, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3117429318025108, 0.3117429318025108, 0.36514086437948984], 
reward next is 0.6349, 
noisyNet noise sample is [array([-0.9147198], dtype=float32), 1.2436279]. 
=============================================
[2019-03-26 18:57:57,655] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.6151554e-15 1.0000000e+00 1.1586349e-17 6.5212135e-16 8.5745791e-26], sum to 1.0000
[2019-03-26 18:57:57,664] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8710
[2019-03-26 18:57:57,670] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.7105480137788664, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 993017.9860857257, 993017.9860857251, 223136.1282060435], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4937400.0000, 
sim time next is 4938000.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.7044352568551113, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 984471.2151669071, 984471.2151669076, 221803.1410403291], 
processed observation next is [1.0, 0.13043478260869565, 0.4312796208530806, 0.89, 1.0, 1.0, 0.6438978998254353, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.273464226435252, 0.27346422643525214, 0.33104946423929715], 
reward next is 0.6690, 
noisyNet noise sample is [array([-0.00462669], dtype=float32), -1.5792949]. 
=============================================
[2019-03-26 18:57:57,685] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[66.24081 ]
 [66.301216]
 [66.17818 ]
 [66.31861 ]
 [66.28781 ]], R is [[66.23323059]
 [66.23786163]
 [66.24512482]
 [66.2264328 ]
 [66.22661591]].
[2019-03-26 18:57:57,778] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.7041394e-12 9.9997175e-01 1.3326869e-12 2.8230173e-05 6.2003644e-19], sum to 1.0000
[2019-03-26 18:57:57,786] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5061
[2019-03-26 18:57:57,795] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1961857.864953073 W.
[2019-03-26 18:57:57,800] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.53333333333333, 64.33333333333333, 1.0, 2.0, 0.4677226605736975, 1.0, 2.0, 0.4677226605736975, 1.0, 1.0, 0.8007686384010898, 6.911199999999999, 6.9112, 170.5573041426782, 1961857.864953073, 1961857.864953074, 391601.2211820504], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4974000.0000, 
sim time next is 4974600.0000, 
raw observation next is [30.56666666666667, 64.16666666666667, 1.0, 2.0, 0.4618562315517569, 1.0, 2.0, 0.4618562315517569, 1.0, 2.0, 0.7908013396405019, 6.9112, 6.9112, 170.5573041426782, 1937228.942323506, 1937228.942323506, 387893.7151376305], 
processed observation next is [1.0, 0.5652173913043478, 0.6477093206951029, 0.6416666666666667, 1.0, 1.0, 0.3516340139177794, 1.0, 1.0, 0.3516340139177794, 1.0, 1.0, 0.7448796824884168, 0.0, 0.0, 0.8375144448122397, 0.5381191506454184, 0.5381191506454184, 0.5789458434890008], 
reward next is 0.4211, 
noisyNet noise sample is [array([-0.4751339], dtype=float32), 0.16682093]. 
=============================================
[2019-03-26 18:57:58,711] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.04567245e-12 1.00000000e+00 1.05350346e-13 4.21303792e-09
 2.33983368e-20], sum to 1.0000
[2019-03-26 18:57:58,718] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9331
[2019-03-26 18:57:58,727] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1804215.569904958 W.
[2019-03-26 18:57:58,733] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.15, 87.5, 1.0, 2.0, 0.6452566339811776, 1.0, 2.0, 0.6452566339811776, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1804215.569904958, 1804215.569904958, 351582.0732663954], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5365800.0000, 
sim time next is 5366400.0000, 
raw observation next is [29.1, 88.0, 1.0, 2.0, 0.392875012384643, 1.0, 2.0, 0.392875012384643, 1.0, 1.0, 0.6822939707601474, 6.911199999999999, 6.9112, 170.5573041426782, 1647668.798498359, 1647668.79849836, 348980.6828116485], 
processed observation next is [1.0, 0.08695652173913043, 0.5781990521327015, 0.88, 1.0, 1.0, 0.2685241113067988, 1.0, 1.0, 0.2685241113067988, 1.0, 0.5, 0.6125536228782286, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.4576857773606553, 0.4576857773606555, 0.5208666907636545], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.78554446], dtype=float32), 0.021211978]. 
=============================================
[2019-03-26 18:57:59,056] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0826989e-10 4.6020597e-01 3.2260902e-10 5.3979403e-01 2.2655966e-16], sum to 1.0000
[2019-03-26 18:57:59,065] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8937
[2019-03-26 18:57:59,072] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 63.0, 1.0, 2.0, 0.7931062916944132, 1.0, 2.0, 0.7931062916944132, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2218048.250768327, 2218048.250768327, 416523.2199684642], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4986000.0000, 
sim time next is 4986600.0000, 
raw observation next is [30.83333333333334, 64.16666666666667, 1.0, 2.0, 0.3617278375665197, 1.0, 2.0, 0.3617278375665197, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1011060.882715563, 1011060.882715563, 262915.4602153528], 
processed observation next is [1.0, 0.7391304347826086, 0.6603475513428123, 0.6416666666666667, 1.0, 1.0, 0.23099739465845748, 1.0, 1.0, 0.23099739465845748, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.2808502451987675, 0.2808502451987675, 0.39241113464978034], 
reward next is 0.6076, 
noisyNet noise sample is [array([0.09267037], dtype=float32), 0.92569584]. 
=============================================
[2019-03-26 18:58:02,940] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.3806598e-15 1.0000000e+00 7.8578340e-17 5.8110892e-14 2.5453001e-25], sum to 1.0000
[2019-03-26 18:58:02,951] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1698
[2019-03-26 18:58:02,958] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.6, 88.0, 1.0, 2.0, 0.8713759509271689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510427, 1217910.067413471, 1217910.067413472, 262189.1899330982], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5286000.0000, 
sim time next is 5286600.0000, 
raw observation next is [28.6, 88.0, 1.0, 2.0, 0.8658029850654017, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1210116.371567856, 1210116.371567856, 260708.0426498714], 
processed observation next is [1.0, 0.17391304347826086, 0.5545023696682465, 0.88, 1.0, 1.0, 0.8383168494763875, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3361434365466267, 0.3361434365466267, 0.38911648156697226], 
reward next is 0.6109, 
noisyNet noise sample is [array([-1.0357577], dtype=float32), -0.22580554]. 
=============================================
[2019-03-26 18:58:03,095] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.6363959e-09 6.1479586e-01 8.9101587e-10 3.8520414e-01 3.9622949e-16], sum to 1.0000
[2019-03-26 18:58:03,107] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8757
[2019-03-26 18:58:03,111] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 63.0, 1.0, 2.0, 0.8150082464013609, 1.0, 2.0, 0.8150082464013609, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2279356.417349071, 2279356.417349071, 427237.6184104813], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4984200.0000, 
sim time next is 4984800.0000, 
raw observation next is [31.0, 63.0, 1.0, 2.0, 0.7297577390383853, 1.0, 2.0, 0.7297577390383853, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2040715.897744755, 2040715.897744755, 387119.3960294827], 
processed observation next is [1.0, 0.6956521739130435, 0.6682464454976303, 0.63, 1.0, 1.0, 0.6744069145040786, 1.0, 1.0, 0.6744069145040786, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5668655271513209, 0.5668655271513209, 0.5777901433275862], 
reward next is 0.4222, 
noisyNet noise sample is [array([-0.6285196], dtype=float32), 0.53494227]. 
=============================================
[2019-03-26 18:58:13,727] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-26 18:58:13,728] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 18:58:13,730] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 18:58:13,732] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:58:13,733] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 18:58:13,734] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:58:13,735] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:58:13,736] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 18:58:13,737] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 18:58:13,737] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:58:13,739] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:58:13,768] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run100
[2019-03-26 18:58:13,792] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run100
[2019-03-26 18:58:13,817] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run100
[2019-03-26 18:58:13,844] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run100
[2019-03-26 18:58:13,845] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run100
[2019-03-26 18:58:37,876] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.11037645], dtype=float32), 0.09690082]
[2019-03-26 18:58:37,878] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [20.28698775, 100.0, 1.0, 2.0, 0.3606719205995488, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 572046.7352792356, 572046.7352792356, 172784.2105460788]
[2019-03-26 18:58:37,879] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 18:58:37,883] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.1597836e-18 1.0000000e+00 1.3593824e-21 1.7186621e-22 9.9599495e-31], sampled 0.5198386136267047
[2019-03-26 18:58:40,847] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.11037645], dtype=float32), 0.09690082]
[2019-03-26 18:58:40,852] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [21.68688836, 72.35242481, 1.0, 2.0, 0.335375414724278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 549187.0549123563, 549187.0549123569, 170578.440931748]
[2019-03-26 18:58:40,856] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:58:40,859] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.05488466e-17 1.00000000e+00 8.26538740e-21 2.64989127e-21
 7.78976446e-30], sampled 0.6831889272676674
[2019-03-26 18:59:27,902] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.11037645], dtype=float32), 0.09690082]
[2019-03-26 18:59:27,903] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.0, 89.0, 1.0, 2.0, 0.4680428867001918, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 661094.291969632, 661094.2919696313, 179654.2606958098]
[2019-03-26 18:59:27,904] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 18:59:27,909] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.3438355e-18 1.0000000e+00 4.8202932e-21 4.2663239e-22 6.5524372e-30], sampled 0.9748219739211897
[2019-03-26 18:59:39,784] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.11037645], dtype=float32), 0.09690082]
[2019-03-26 18:59:39,787] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.55, 80.5, 1.0, 2.0, 0.7393261843622403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1033256.144428274, 1033256.144428274, 229566.2089398333]
[2019-03-26 18:59:39,789] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 18:59:39,793] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [4.4799238e-17 1.0000000e+00 8.5065141e-20 2.9012166e-19 2.6836452e-28], sampled 0.7670263655278436
[2019-03-26 18:59:54,271] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.11037645], dtype=float32), 0.09690082]
[2019-03-26 18:59:54,271] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [23.16666666666667, 95.0, 1.0, 2.0, 0.4282902128771636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 632647.3081031461, 632647.3081031456, 177461.1469126499]
[2019-03-26 18:59:54,272] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:59:54,274] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.2279991e-17 1.0000000e+00 6.0865452e-21 1.4948929e-21 1.1406475e-29], sampled 0.28956319538569975
[2019-03-26 18:59:54,526] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.11037645], dtype=float32), 0.09690082]
[2019-03-26 18:59:54,527] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [25.05, 92.5, 1.0, 2.0, 0.4997191279350723, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 698279.7119220312, 698279.7119220318, 183550.9897263653]
[2019-03-26 18:59:54,530] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:59:54,533] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [6.9547766e-18 1.0000000e+00 3.3120134e-21 2.3343129e-22 3.8007464e-30], sampled 0.06310616831726146
[2019-03-26 18:59:55,139] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.11037645], dtype=float32), 0.09690082]
[2019-03-26 18:59:55,142] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.7, 88.00000000000001, 1.0, 2.0, 0.5304324156581043, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 741211.7249868255, 741211.7249868248, 188500.8537819945]
[2019-03-26 18:59:55,142] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:59:55,144] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [4.8100143e-18 1.0000000e+00 2.7905913e-21 1.3992793e-21 2.4448454e-30], sampled 0.06129174369480517
[2019-03-26 18:59:56,985] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.11037645], dtype=float32), 0.09690082]
[2019-03-26 18:59:56,986] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.95319676333333, 84.73944885333334, 1.0, 2.0, 0.4827273967638067, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 677842.2192871599, 677842.2192871604, 181361.0669058048]
[2019-03-26 18:59:56,987] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:59:56,990] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [5.5898980e-18 1.0000000e+00 3.9067506e-21 3.7970829e-21 3.5999573e-30], sampled 0.09787558277843222
[2019-03-26 19:00:07,287] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8664.4781 2778565001.2755 914.0000
[2019-03-26 19:00:08,054] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8278.3908 2924834652.2596 1268.0000
[2019-03-26 19:00:08,281] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8052.4973 3001021151.6800 1595.0000
[2019-03-26 19:00:08,423] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7951.6874 3156968760.2880 1586.0000
[2019-03-26 19:00:08,455] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8515.2696 2839992574.0893 1074.0000
[2019-03-26 19:00:09,471] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 2475000, evaluation results [2475000.0, 7951.687367481515, 3156968760.288013, 1586.0, 8278.390838128455, 2924834652.2595854, 1268.0, 8664.478132474707, 2778565001.2754564, 914.0, 8052.497261812703, 3001021151.6800337, 1595.0, 8515.26959458854, 2839992574.089302, 1074.0]
[2019-03-26 19:00:12,799] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.2981825e-12 3.7398268e-06 3.0087152e-11 9.9999630e-01 3.4537183e-17], sum to 1.0000
[2019-03-26 19:00:12,811] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2703
[2019-03-26 19:00:12,816] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [36.28333333333333, 52.0, 1.0, 2.0, 0.7388596855423187, 1.0, 2.0, 0.6900198822854219, 1.0, 2.0, 1.03, 7.005100796406106, 6.9112, 170.5573041426782, 2895409.922710001, 2828144.962604122, 533884.3566024029], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5314200.0000, 
sim time next is 5314800.0000, 
raw observation next is [36.26666666666667, 52.0, 1.0, 2.0, 0.8055112294057574, 1.0, 2.0, 0.8055112294057574, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2252771.904849644, 2252771.904849644, 422574.6078209365], 
processed observation next is [1.0, 0.5217391304347826, 0.9178515007898898, 0.52, 1.0, 1.0, 0.7656761800069366, 1.0, 1.0, 0.7656761800069366, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6257699735693455, 0.6257699735693455, 0.6307083698819947], 
reward next is 0.3693, 
noisyNet noise sample is [array([-0.28705686], dtype=float32), 1.7997109]. 
=============================================
[2019-03-26 19:00:13,349] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.6743044e-11 8.8030429e-05 7.3193271e-11 9.9991190e-01 9.8687193e-17], sum to 1.0000
[2019-03-26 19:00:13,357] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8773
[2019-03-26 19:00:13,364] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [36.28333333333333, 52.0, 1.0, 2.0, 1.016314524701731, 1.0, 2.0, 1.016314524701731, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2842995.85161871, 2842995.85161871, 538927.905010001], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5314200.0000, 
sim time next is 5314800.0000, 
raw observation next is [36.26666666666667, 52.0, 1.0, 2.0, 0.8016979240047242, 1.0, 2.0, 0.8016979240047242, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2242097.673770003, 2242097.673770003, 420710.2166032632], 
processed observation next is [1.0, 0.5217391304347826, 0.9178515007898898, 0.52, 1.0, 1.0, 0.76108183615027, 1.0, 1.0, 0.76108183615027, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6228049093805564, 0.6228049093805564, 0.627925696422781], 
reward next is 0.3721, 
noisyNet noise sample is [array([0.00014376], dtype=float32), -1.3288299]. 
=============================================
[2019-03-26 19:00:14,580] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.4156299e-18 1.0000000e+00 2.6748139e-21 5.2208404e-19 1.0026017e-29], sum to 1.0000
[2019-03-26 19:00:14,587] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8085
[2019-03-26 19:00:14,591] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.41666666666666, 78.16666666666667, 1.0, 2.0, 0.630550140738688, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 881171.5227346177, 881171.5227346184, 206576.2042180133], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5343000.0000, 
sim time next is 5343600.0000, 
raw observation next is [31.33333333333334, 78.33333333333334, 1.0, 2.0, 0.6295074414243633, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 879713.7838530749, 879713.7838530749, 206372.6021989454], 
processed observation next is [1.0, 0.8695652173913043, 0.6840442338072673, 0.7833333333333334, 1.0, 1.0, 0.5536234234028473, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.24436493995918745, 0.24436493995918745, 0.3080188092521573], 
reward next is 0.6920, 
noisyNet noise sample is [array([0.22692794], dtype=float32), 0.677102]. 
=============================================
[2019-03-26 19:00:15,886] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.6255777e-14 1.0000000e+00 3.7148819e-16 1.3714623e-12 2.0190447e-24], sum to 1.0000
[2019-03-26 19:00:15,896] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8430
[2019-03-26 19:00:15,900] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.6, 88.0, 1.0, 2.0, 0.9837427349584036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.9128929847002, 1375065.268637219, 1375065.268637219, 294015.586360425], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5284800.0000, 
sim time next is 5285400.0000, 
raw observation next is [28.6, 88.00000000000001, 1.0, 2.0, 0.9223265759117579, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.9129564945685, 1289166.283033006, 1289166.283033005, 276156.9458759728], 
processed observation next is [1.0, 0.17391304347826086, 0.5545023696682465, 0.8800000000000001, 1.0, 1.0, 0.9064175613394674, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399450744105, 0.3581017452869461, 0.3581017452869458, 0.4121745460835415], 
reward next is 0.5878, 
noisyNet noise sample is [array([0.4014281], dtype=float32), -0.19678329]. 
=============================================
[2019-03-26 19:00:16,459] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.8513011e-16 1.0000000e+00 3.9397545e-19 1.3270622e-13 5.8968566e-27], sum to 1.0000
[2019-03-26 19:00:16,466] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1931
[2019-03-26 19:00:16,470] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.85, 77.0, 1.0, 2.0, 0.5898663324565494, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 824295.2774574131, 824295.2774574131, 198874.5015047156], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5423400.0000, 
sim time next is 5424000.0000, 
raw observation next is [30.83333333333333, 77.66666666666667, 1.0, 2.0, 0.5923042521981867, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 827703.420327656, 827703.420327656, 199322.3425359676], 
processed observation next is [1.0, 0.782608695652174, 0.6603475513428118, 0.7766666666666667, 1.0, 1.0, 0.5088003038532369, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2299176167576822, 0.2299176167576822, 0.29749603363577254], 
reward next is 0.7025, 
noisyNet noise sample is [array([-1.2084956], dtype=float32), -0.77415717]. 
=============================================
[2019-03-26 19:00:16,486] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[71.01077 ]
 [70.983215]
 [71.11519 ]
 [70.655975]
 [69.60387 ]], R is [[70.47693634]
 [70.4753418 ]
 [70.47447968]
 [70.47501373]
 [70.47809601]].
[2019-03-26 19:00:16,608] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.01241417e-13 1.00000000e+00 5.52250616e-15 1.41130857e-10
 3.14453008e-22], sum to 1.0000
[2019-03-26 19:00:16,618] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7581
[2019-03-26 19:00:16,625] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.1, 88.66666666666666, 1.0, 2.0, 0.8738278258066368, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1221338.989916776, 1221338.989916775, 262845.3602448286], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5377200.0000, 
sim time next is 5377800.0000, 
raw observation next is [29.3, 87.33333333333333, 1.0, 2.0, 0.8827643314146263, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1233836.697391138, 1233836.697391138, 265246.136168732], 
processed observation next is [1.0, 0.21739130434782608, 0.5876777251184835, 0.8733333333333333, 1.0, 1.0, 0.8587522065236461, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3427324159419828, 0.3427324159419828, 0.3958897554757194], 
reward next is 0.6041, 
noisyNet noise sample is [array([0.9909133], dtype=float32), -0.23784654]. 
=============================================
[2019-03-26 19:00:23,626] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0466246e-15 1.0000000e+00 7.8954183e-18 7.8748521e-16 5.1868566e-26], sum to 1.0000
[2019-03-26 19:00:23,636] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2154
[2019-03-26 19:00:23,641] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666667, 95.0, 1.0, 2.0, 0.6727435266841869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 940161.3856267879, 940161.3856267885, 215070.7680563582], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5546400.0000, 
sim time next is 5547000.0000, 
raw observation next is [25.63333333333333, 95.0, 1.0, 2.0, 0.6666946170284421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 931704.3056290358, 931704.3056290364, 213819.2751754902], 
processed observation next is [1.0, 0.17391304347826086, 0.4139020537124801, 0.95, 1.0, 1.0, 0.598427249431858, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.25880675156362104, 0.2588067515636212, 0.3191332465305824], 
reward next is 0.6809, 
noisyNet noise sample is [array([0.511113], dtype=float32), -0.78243846]. 
=============================================
[2019-03-26 19:00:23,653] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[64.318954]
 [64.4393  ]
 [64.45731 ]
 [64.37208 ]
 [64.26343 ]], R is [[64.13954926]
 [64.17715454]
 [64.21195984]
 [64.24025726]
 [64.25001526]].
[2019-03-26 19:00:24,918] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.5768418e-18 1.0000000e+00 1.4029573e-20 9.4805889e-19 2.8941067e-28], sum to 1.0000
[2019-03-26 19:00:24,927] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8512
[2019-03-26 19:00:24,933] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.26666666666667, 82.0, 1.0, 2.0, 0.6158046336834332, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 860556.8500148747, 860556.8500148754, 203727.530860143], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5433600.0000, 
sim time next is 5434200.0000, 
raw observation next is [30.2, 82.0, 1.0, 2.0, 0.6140203050687977, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 858062.3308292129, 858062.3308292129, 203387.1720910434], 
processed observation next is [1.0, 0.9130434782608695, 0.6303317535545023, 0.82, 1.0, 1.0, 0.534964222974455, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23835064745255913, 0.23835064745255913, 0.30356294341946777], 
reward next is 0.6964, 
noisyNet noise sample is [array([0.9300718], dtype=float32), -1.2201972]. 
=============================================
[2019-03-26 19:00:26,060] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.0642531e-16 1.0000000e+00 1.5486684e-18 5.9779509e-16 4.2198613e-26], sum to 1.0000
[2019-03-26 19:00:26,068] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4926
[2019-03-26 19:00:26,076] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.16666666666666, 91.66666666666667, 1.0, 2.0, 0.5909877903295313, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 825863.0424980453, 825863.0424980447, 199079.1238759471], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5449200.0000, 
sim time next is 5449800.0000, 
raw observation next is [28.08333333333334, 92.33333333333333, 1.0, 2.0, 0.5916375406498293, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 826771.375346926, 826771.375346926, 199198.4885205289], 
processed observation next is [1.0, 0.043478260869565216, 0.53001579778831, 0.9233333333333333, 1.0, 1.0, 0.5079970369275052, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22965871537414612, 0.22965871537414612, 0.29731117689631176], 
reward next is 0.7027, 
noisyNet noise sample is [array([-0.5981801], dtype=float32), -0.5721757]. 
=============================================
[2019-03-26 19:00:29,865] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.2597399e-18 1.0000000e+00 1.4747524e-20 9.0153373e-18 3.9026385e-29], sum to 1.0000
[2019-03-26 19:00:29,878] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9408
[2019-03-26 19:00:29,885] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.56666666666667, 80.0, 1.0, 2.0, 0.5794609501533077, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 809748.9701397619, 809748.9701397613, 196981.8790276434], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5517600.0000, 
sim time next is 5518200.0000, 
raw observation next is [29.43333333333333, 80.5, 1.0, 2.0, 0.5779775225271246, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 807675.214012238, 807675.214012238, 196714.8250113312], 
processed observation next is [1.0, 0.8695652173913043, 0.5939968404423379, 0.805, 1.0, 1.0, 0.49153918376762, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22435422611451056, 0.22435422611451056, 0.2936042164348227], 
reward next is 0.7064, 
noisyNet noise sample is [array([-1.9358218], dtype=float32), 1.0981796]. 
=============================================
[2019-03-26 19:00:36,296] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.0009170e-17 1.0000000e+00 1.9782067e-21 1.3411487e-21 3.2182034e-30], sum to 1.0000
[2019-03-26 19:00:36,302] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3178
[2019-03-26 19:00:36,307] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.33333333333333, 60.0, 1.0, 2.0, 0.5424108588292609, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 757956.0452014727, 757956.0452014727, 190508.1461050543], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5669400.0000, 
sim time next is 5670000.0000, 
raw observation next is [32.3, 60.0, 1.0, 2.0, 0.5416232201597805, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 756855.0197158619, 756855.0197158626, 190374.9048115258], 
processed observation next is [0.0, 0.6521739130434783, 0.7298578199052131, 0.6, 1.0, 1.0, 0.447738819469615, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2102375054766283, 0.2102375054766285, 0.28414164897242655], 
reward next is 0.7159, 
noisyNet noise sample is [array([1.1139817], dtype=float32), 0.47919664]. 
=============================================
[2019-03-26 19:00:36,320] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[73.59107 ]
 [73.554016]
 [73.51165 ]
 [73.47065 ]
 [73.427734]], R is [[73.6470108 ]
 [73.62619781]
 [73.60534668]
 [73.5843811 ]
 [73.56305695]].
[2019-03-26 19:00:36,912] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.14950798e-12 8.51908117e-04 1.39709746e-11 9.99148130e-01
 2.51365762e-17], sum to 1.0000
[2019-03-26 19:00:36,922] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5750
[2019-03-26 19:00:36,928] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.5, 62.33333333333334, 1.0, 2.0, 0.8453105903781825, 1.0, 2.0, 0.8453105903781825, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2364183.99548175, 2364183.99548175, 442534.6685552156], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5844000.0000, 
sim time next is 5844600.0000, 
raw observation next is [32.45, 62.5, 1.0, 2.0, 0.837211140813475, 1.0, 2.0, 0.837211140813475, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2341510.047316698, 2341510.047316698, 438395.3631201087], 
processed observation next is [1.0, 0.6521739130434783, 0.7369668246445499, 0.625, 1.0, 1.0, 0.8038688443535844, 1.0, 1.0, 0.8038688443535844, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6504194575879716, 0.6504194575879716, 0.6543214374926996], 
reward next is 0.3457, 
noisyNet noise sample is [array([0.25790274], dtype=float32), 0.16871321]. 
=============================================
[2019-03-26 19:00:39,970] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.1163760e-09 9.9015361e-01 1.0522451e-08 9.8463641e-03 1.0757491e-15], sum to 1.0000
[2019-03-26 19:00:39,979] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0336
[2019-03-26 19:00:39,990] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1844699.95315459 W.
[2019-03-26 19:00:39,994] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.85, 75.0, 1.0, 2.0, 0.4398152988225394, 1.0, 1.0, 0.4398152988225394, 1.0, 2.0, 0.7543482520834478, 6.911199999999999, 6.9112, 170.5573041426782, 1844699.95315459, 1844699.953154591, 374537.6448467174], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6427800.0000, 
sim time next is 6428400.0000, 
raw observation next is [28.96666666666667, 74.33333333333333, 1.0, 2.0, 0.479442243162075, 1.0, 2.0, 0.479442243162075, 1.0, 2.0, 0.8236275476034316, 6.9112, 6.9112, 170.5573041426782, 2011061.671538788, 2011061.671538788, 399663.0803932959], 
processed observation next is [1.0, 0.391304347826087, 0.5718799368088469, 0.7433333333333333, 1.0, 1.0, 0.3728219797133434, 1.0, 1.0, 0.3728219797133434, 1.0, 1.0, 0.784911643418819, 0.0, 0.0, 0.8375144448122397, 0.5586282420941078, 0.5586282420941078, 0.5965120602885013], 
reward next is 0.4035, 
noisyNet noise sample is [array([-1.1320235], dtype=float32), -0.03736124]. 
=============================================
[2019-03-26 19:00:41,796] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.5231771e-18 1.0000000e+00 1.1614918e-20 3.5063596e-21 1.3760201e-29], sum to 1.0000
[2019-03-26 19:00:41,805] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0968
[2019-03-26 19:00:41,815] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.23333333333333, 88.66666666666667, 1.0, 2.0, 0.5107669127942012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 713722.4581090902, 713722.4581090902, 185299.9764501694], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5712600.0000, 
sim time next is 5713200.0000, 
raw observation next is [26.2, 89.0, 1.0, 2.0, 0.5111576241807001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 714268.6039890058, 714268.6039890052, 185362.4687883704], 
processed observation next is [0.0, 0.13043478260869565, 0.44075829383886256, 0.89, 1.0, 1.0, 0.4110332821454218, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1984079455525016, 0.19840794555250144, 0.27666040117667223], 
reward next is 0.7233, 
noisyNet noise sample is [array([-0.2988525], dtype=float32), 1.9526756]. 
=============================================
[2019-03-26 19:00:41,831] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.9066918e-17 1.0000000e+00 9.8174868e-21 6.7319729e-22 1.0122211e-28], sum to 1.0000
[2019-03-26 19:00:41,842] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7134
[2019-03-26 19:00:41,847] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.46666666666667, 76.66666666666667, 1.0, 2.0, 0.5231095193629334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 730975.3894732237, 730975.3894732231, 187295.9904514712], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5730000.0000, 
sim time next is 5730600.0000, 
raw observation next is [28.63333333333333, 75.83333333333333, 1.0, 2.0, 0.5236745060107719, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 731765.1544703929, 731765.1544703934, 187388.4692998539], 
processed observation next is [0.0, 0.30434782608695654, 0.55608214849921, 0.7583333333333333, 1.0, 1.0, 0.4261138626635806, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20326809846399801, 0.20326809846399818, 0.2796842825370954], 
reward next is 0.7203, 
noisyNet noise sample is [array([-0.21812531], dtype=float32), -0.44074768]. 
=============================================
[2019-03-26 19:00:43,754] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.6846016e-17 1.0000000e+00 1.8866327e-20 9.9716110e-18 1.3576104e-28], sum to 1.0000
[2019-03-26 19:00:43,760] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1821
[2019-03-26 19:00:43,767] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.75, 83.5, 1.0, 2.0, 0.5296092229843834, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 740061.0173844877, 740061.0173844884, 188365.6451705839], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6204600.0000, 
sim time next is 6205200.0000, 
raw observation next is [27.66666666666666, 84.0, 1.0, 2.0, 0.5296840628485503, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 740165.6329392651, 740165.6329392645, 188378.0031029248], 
processed observation next is [1.0, 0.8260869565217391, 0.5102685624012636, 0.84, 1.0, 1.0, 0.4333542925886148, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20560156470535143, 0.20560156470535126, 0.2811611986610818], 
reward next is 0.7188, 
noisyNet noise sample is [array([-0.93027586], dtype=float32), -0.99748755]. 
=============================================
[2019-03-26 19:00:44,352] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.7748874e-16 1.0000000e+00 4.2973671e-18 1.9274318e-16 2.4153442e-26], sum to 1.0000
[2019-03-26 19:00:44,363] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4377
[2019-03-26 19:00:44,371] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.55, 90.66666666666667, 1.0, 2.0, 0.8007147819360332, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1119095.886856724, 1119095.886856725, 244085.821978383], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6502200.0000, 
sim time next is 6502800.0000, 
raw observation next is [26.6, 90.33333333333334, 1.0, 2.0, 0.7539859906009506, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1053754.336698398, 1053754.336698399, 232929.1351488232], 
processed observation next is [1.0, 0.2608695652173913, 0.4597156398104266, 0.9033333333333334, 1.0, 1.0, 0.7035975790372899, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.29270953797177723, 0.29270953797177746, 0.3476554255952585], 
reward next is 0.6523, 
noisyNet noise sample is [array([-0.9022041], dtype=float32), 0.7933084]. 
=============================================
[2019-03-26 19:00:44,551] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.1619859e-11 3.2383329e-04 6.1175849e-11 9.9967623e-01 5.9315878e-17], sum to 1.0000
[2019-03-26 19:00:44,559] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5716
[2019-03-26 19:00:44,565] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.9, 61.0, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 6.94900410039548, 6.9112, 170.5573041426782, 2936441.922603839, 2909361.307718071, 553435.3246600832], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5839200.0000, 
sim time next is 5839800.0000, 
raw observation next is [32.85, 61.16666666666667, 1.0, 2.0, 0.9759481710962506, 1.0, 2.0, 0.9759481710962506, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2729953.31645801, 2729953.31645801, 514619.328188898], 
processed observation next is [1.0, 0.6086956521739131, 0.7559241706161138, 0.6116666666666667, 1.0, 1.0, 0.971021892887049, 1.0, 1.0, 0.971021892887049, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7583203656827806, 0.7583203656827806, 0.7680885495356686], 
reward next is 0.2319, 
noisyNet noise sample is [array([-0.5386989], dtype=float32), -0.22628489]. 
=============================================
[2019-03-26 19:01:01,006] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.7035866e-18 1.0000000e+00 1.8601050e-21 6.0994422e-22 3.4837832e-31], sum to 1.0000
[2019-03-26 19:01:01,015] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6023
[2019-03-26 19:01:01,023] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.5, 64.5, 1.0, 2.0, 0.5448891107539391, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 761420.3550409013, 761420.3550409013, 190928.5325565219], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6348600.0000, 
sim time next is 6349200.0000, 
raw observation next is [31.66666666666666, 64.0, 1.0, 2.0, 0.5462490005464246, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 763321.3286423986, 763321.3286423986, 191160.036054712], 
processed observation next is [0.0, 0.4782608695652174, 0.6998420221169034, 0.64, 1.0, 1.0, 0.4533120488511139, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21203370240066627, 0.21203370240066627, 0.2853134866488239], 
reward next is 0.7147, 
noisyNet noise sample is [array([1.1562791], dtype=float32), -0.6044839]. 
=============================================
[2019-03-26 19:01:01,639] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.1024409e-18 1.0000000e+00 9.3803913e-21 4.0198312e-21 4.0726175e-29], sum to 1.0000
[2019-03-26 19:01:01,647] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0646
[2019-03-26 19:01:01,653] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.26666666666667, 86.16666666666667, 1.0, 2.0, 0.5340542116640158, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 746274.5013215193, 746274.5013215187, 189103.4894171029], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6315000.0000, 
sim time next is 6315600.0000, 
raw observation next is [27.23333333333333, 86.33333333333334, 1.0, 2.0, 0.5327938524652397, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 744512.6885001892, 744512.6885001892, 188893.5925057874], 
processed observation next is [0.0, 0.08695652173913043, 0.4897314375987361, 0.8633333333333334, 1.0, 1.0, 0.4371010270665538, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20680908013894145, 0.20680908013894145, 0.28193073508326477], 
reward next is 0.7181, 
noisyNet noise sample is [array([-0.21278153], dtype=float32), -0.8041631]. 
=============================================
[2019-03-26 19:01:03,920] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.1189945e-18 1.0000000e+00 2.1847191e-21 2.7286613e-22 2.5994598e-29], sum to 1.0000
[2019-03-26 19:01:03,929] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2397
[2019-03-26 19:01:03,936] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 63.0, 1.0, 2.0, 0.5250703621992528, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 733716.3506362874, 733716.3506362874, 187617.2523374262], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6354000.0000, 
sim time next is 6354600.0000, 
raw observation next is [30.95, 62.83333333333333, 1.0, 2.0, 0.5292061733555125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 739497.6111338534, 739497.611133854, 188298.0382992323], 
processed observation next is [0.0, 0.5652173913043478, 0.6658767772511848, 0.6283333333333333, 1.0, 1.0, 0.4327785221150752, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20541600309273705, 0.20541600309273722, 0.2810418482078094], 
reward next is 0.7190, 
noisyNet noise sample is [array([-1.3336302], dtype=float32), -0.5601636]. 
=============================================
[2019-03-26 19:01:04,604] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-26 19:01:04,608] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:01:04,609] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:01:04,609] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:01:04,609] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:01:04,611] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:01:04,612] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:01:04,613] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:01:04,614] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:01:04,615] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:01:04,616] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:01:05,445] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run101
[2019-03-26 19:01:05,506] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run101
[2019-03-26 19:01:05,518] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run101
[2019-03-26 19:01:05,533] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run101
[2019-03-26 19:01:05,578] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/5/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run101
[2019-03-26 19:01:16,596] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.11117979], dtype=float32), 0.097286895]
[2019-03-26 19:01:16,598] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [17.468050315, 84.61873607999999, 1.0, 2.0, 0.1972484243368606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 329901.1031414548, 329901.1031414548, 150235.4637156144]
[2019-03-26 19:01:16,600] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:01:16,603] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.3049051e-18 1.0000000e+00 4.1794348e-22 1.2342456e-24 4.3870131e-31], sampled 0.26132363230635114
[2019-03-26 19:01:35,206] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.11117979], dtype=float32), 0.097286895]
[2019-03-26 19:01:35,208] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [23.0, 92.0, 1.0, 2.0, 0.3933154718084814, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 591915.278044383, 591915.278044383, 173939.5683752929]
[2019-03-26 19:01:35,209] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:01:35,211] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.9484024e-18 1.0000000e+00 7.1784873e-22 1.8068817e-22 6.2396284e-31], sampled 0.5354819370022866
[2019-03-26 19:01:43,660] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.11117979], dtype=float32), 0.097286895]
[2019-03-26 19:01:43,660] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [26.85, 73.66666666666667, 1.0, 2.0, 0.488575968272192, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 703737.8056756158, 703737.8056756158, 184500.8632480208]
[2019-03-26 19:01:43,663] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:01:43,667] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [7.512309e-18 1.000000e+00 3.912045e-21 9.293197e-22 6.381974e-30], sampled 0.02893432554145181
[2019-03-26 19:02:23,498] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.11117979], dtype=float32), 0.097286895]
[2019-03-26 19:02:23,500] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [32.0, 67.0, 1.0, 2.0, 0.9404043635860685, 1.0, 2.0, 0.9404043635860685, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2630424.378911037, 2630424.378911038, 494016.1554176487]
[2019-03-26 19:02:23,501] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:02:23,504] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [6.4540506e-10 4.0727586e-01 4.3802428e-10 5.9272414e-01 2.4179453e-16], sampled 0.32729771877069136
[2019-03-26 19:02:23,505] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2630424.378911037 W.
[2019-03-26 19:02:38,514] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.11117979], dtype=float32), 0.097286895]
[2019-03-26 19:02:38,516] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [31.40161472, 62.18993823, 1.0, 2.0, 0.5479048793386133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 765636.0663036009, 765636.0663036009, 191440.9258306166]
[2019-03-26 19:02:38,517] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:02:38,520] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [5.0737253e-18 1.0000000e+00 2.8174822e-21 2.0609209e-21 3.1126759e-30], sampled 0.8117764825841584
[2019-03-26 19:02:41,729] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.11117979], dtype=float32), 0.097286895]
[2019-03-26 19:02:41,733] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.0, 78.33333333333334, 1.0, 2.0, 0.5548883375041221, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 775398.2334336169, 775398.2334336162, 192642.2914868131]
[2019-03-26 19:02:41,735] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:02:41,737] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [4.7308378e-18 1.0000000e+00 2.9679751e-21 4.2877646e-21 3.5121134e-30], sampled 0.48134004398276653
[2019-03-26 19:03:01,153] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8038.0582 3001776985.8766 1623.0000
[2019-03-26 19:03:01,236] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8664.2639 2778687143.1302 916.0000
[2019-03-26 19:03:01,617] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7940.8385 3157499721.4245 1607.0000
[2019-03-26 19:03:01,636] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8513.5339 2840939660.1916 1088.0000
[2019-03-26 19:03:01,639] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8286.7734 2924665606.7572 1260.0000
[2019-03-26 19:03:02,658] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 2500000, evaluation results [2500000.0, 7940.838548915471, 3157499721.4244785, 1607.0, 8286.773424964611, 2924665606.757229, 1260.0, 8664.263889572067, 2778687143.130163, 916.0, 8038.058162770117, 3001776985.8766317, 1623.0, 8513.533880637026, 2840939660.191594, 1088.0]
